<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" id="dark-theme">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" id="light-theme">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --bg-primary: #ffffff; --bg-secondary: #f8f9fa; --text-primary: #333333;
            --text-secondary: #666666; --border-color: #e1e5e9; --accent-color: #6366f1;
            --code-bg: #f8f9fa; --sidebar-bg: #ffffff; --shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        [data-theme="dark"] {
            --bg-primary: #0d1117; --bg-secondary: #161b22; --text-primary: #e6edf3;
            --text-secondary: #7d8590; --border-color: #30363d; --accent-color: #58a6ff;
            --code-bg: #161b22; --sidebar-bg: #0d1117; --shadow: 0 2px 10px rgba(0,0,0,0.3);
        }
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
            line-height: 1.6; 
            background-color: var(--bg-primary); 
            color: var(--text-primary); 
            transition: all 0.3s ease;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .container { 
            display: flex; 
            min-height: 100vh;
            width: 100%;
            max-width: 100vw;
            overflow-x: hidden;
        }
        
        .sidebar { 
            width: 280px; 
            background-color: var(--sidebar-bg); 
            border-right: 1px solid var(--border-color); 
            position: fixed; 
            height: 100vh; 
            overflow-y: auto; 
            box-shadow: var(--shadow); 
            transition: transform 0.3s ease; 
            z-index: 200;
        }
        
        .main-content { 
            flex: 1; 
            margin-left: 280px; 
            transition: margin-left 0.3s ease;
            width: calc(100% - 280px);
            max-width: calc(100vw - 280px);
            overflow-x: hidden;
        }
        
        .header { 
            background-color: var(--sidebar-bg); 
            border-bottom: 1px solid var(--border-color); 
            padding: 1rem 2rem; 
            display: flex; 
            justify-content: space-between; 
            align-items: center; 
            position: sticky; 
            top: 0; 
            z-index: 100; 
            box-shadow: var(--shadow);
        }
        
        .theme-toggle { 
            background: none; 
            border: 2px solid var(--border-color); 
            padding: 0.5rem 1rem; 
            border-radius: 6px; 
            cursor: pointer; 
            color: var(--text-primary); 
            font-size: 0.9rem; 
            transition: all 0.2s ease;
            white-space: nowrap;
        }
        .theme-toggle:hover { background-color: var(--bg-secondary); }
        
        .mobile-menu-btn { 
            display: none; 
            background: none; 
            border: 2px solid var(--border-color); 
            padding: 0.5rem; 
            border-radius: 6px; 
            cursor: pointer; 
            color: var(--text-primary); 
            font-size: 1.2rem; 
            transition: all 0.2s ease;
        }
        .mobile-menu-btn:hover { background-color: var(--bg-secondary); }
        
        .mobile-overlay { 
            display: none; 
            position: fixed; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            background-color: rgba(0, 0, 0, 0.5); 
            z-index: 150; 
            opacity: 0; 
            transition: opacity 0.3s ease;
            pointer-events: none;
        }
        .mobile-overlay.active { 
            opacity: 1; 
            pointer-events: auto;
        }
        
        .content { 
            padding: 2rem; 
            max-width: 1200px; 
            margin: 0 auto;
            width: 100%;
            overflow-x: auto;
            -webkit-overflow-scrolling: touch;
        }
        
        h1 { 
            font-size: clamp(1.8rem, 4vw, 2.5rem); 
            margin-bottom: 1rem; 
            color: var(--text-primary); 
            border-bottom: 3px solid var(--accent-color); 
            padding-bottom: 0.5rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        h2 { 
            font-size: clamp(1.4rem, 3vw, 2rem); 
            margin: 2rem 0 1rem 0; 
            color: var(--text-primary); 
            border-bottom: 2px solid var(--border-color); 
            padding-bottom: 0.5rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .h2-link{
            font-weight:700;
        }
        
        h3 { 
            font-size: clamp(1.2rem, 2.5vw, 1.5rem); 
            margin: 1.5rem 0 1rem 0; 
            color: var(--accent-color);
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        p { 
            margin-bottom: 1rem; 
            color: var(--text-secondary);
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
            max-width: 100%;
        }
        
        .code-container { 
            position: relative; 
            margin: 1.5rem 0; 
            border-radius: 8px; 
            overflow: hidden; 
            box-shadow: var(--shadow);
            max-width: 100%;
        }
        
        .code-header { 
            background-color: var(--bg-secondary); 
            padding: 0.75rem 1rem; 
            border-bottom: 1px solid var(--border-color); 
            display: flex; 
            justify-content: space-between; 
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }
        
        .copy-btn { 
            background: var(--accent-color); 
            color: white; 
            border: none; 
            padding: 0.4rem 0.8rem; 
            border-radius: 4px; 
            cursor: pointer; 
            font-size: 0.8rem;
            white-space: nowrap;
            transition: all 0.2s ease;
        }
        .copy-btn:hover { opacity: 0.9; }
        
        pre[class*="language-"] { 
            margin: 0 !important; 
            padding: 1rem !important;
            background: var(--code-bg) !important;
            border: none !important;
            border-radius: 0 !important;
            font-size: clamp(0.75rem, 2vw, 0.9rem) !important;
            line-height: 1.5 !important;
            overflow-x: auto !important;
            overflow-y: hidden !important;
            white-space: pre !important;
            word-wrap: normal !important;
            max-width: 100% !important;
            -webkit-overflow-scrolling: touch !important;
            scrollbar-width: thin !important;
            scrollbar-color: var(--accent-color) transparent !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar {
            height: 12px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-track {
            background: var(--bg-secondary) !important;
            border-radius: 6px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-thumb {
            background: var(--accent-color) !important;
            border-radius: 6px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-thumb:hover {
            background: var(--text-secondary) !important;
        }
        
        code[class*="language-"] { 
            background: transparent !important;
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace !important;
            font-size: inherit !important;
            color: inherit !important;
            white-space: pre !important;
            word-wrap: normal !important;
            display: inline-block !important;
            min-width: max-content !important;
            width: auto !important;
        }
        
        [data-theme="dark"] .token.comment, [data-theme="dark"] .token.prolog, [data-theme="dark"] .token.doctype, [data-theme="dark"] .token.cdata { color: #7d8590 !important; font-style: italic !important; }
        [data-theme="dark"] .token.punctuation { color: #e6edf3 !important; }
        [data-theme="dark"] .token.property, [data-theme="dark"] .token.tag, [data-theme="dark"] .token.boolean, [data-theme="dark"] .token.number, [data-theme="dark"] .token.constant, .token.symbol, .token.deleted { color: #ff7b72 !important; }
        [data-theme="dark"] .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted { color: #a5d6ff !important; }
        [data-theme="dark"] .token.operator, [data-theme="dark"] .token.entity, [data-theme="dark"] .token.url, .language-css .token.string, .style .token.string { color: #79c0ff !important; }
        [data-theme="dark"] .token.atrule, [data-theme="dark"] .token.attr-value, [data-theme="dark"] .token.keyword { color: #ff7b72 !important; }
        [data-theme="dark"] .token.function, [data-theme="dark"] .token.class-name { color: #d2a8ff !important; }
        [data-theme="dark"] .token.regex, [data-theme="dark"] .token.important, [data-theme="dark"] .token.variable { color: #ffa657 !important; }
        
        [data-theme="light"] .token.comment, [data-theme="light"] .token.prolog, [data-theme="light"] .token.doctype, [data-theme="light"] .token.cdata { color: #6a737d !important; }
        [data-theme="light"] .token.punctuation { color: #24292e !important; }
        [data-theme="light"] .token.property, .token.tag, .token.boolean, .token.number, .token.constant, .token.symbol, .token.deleted { color: #d73a49 !important; }
        [data-theme="light"] .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted { color: #032f62 !important; }
        [data-theme="light"] .token.operator, .token.entity, .token.url, .language-css .token.string, .style .token.string { color: #24292e !important; }
        [data-theme="light"] .token.atrule, .token.attr-value, .token.keyword { color: #d73a49 !important; }
        [data-theme="light"] .token.function, .token.class-name { color: #6f42c1 !important; }
        [data-theme="light"] .token.regex, [data-theme="light"] .token.important, [data-theme="light"] .token.variable { color: #e36209 !important; }
        
        .toc { padding: 1rem; }
        .toc ul { list-style: none; }
        .toc li { margin: 0.5rem 0; }
        .toc a { 
            color: var(--text-secondary); 
            text-decoration: none; 
            display: block; 
            padding: 0.5rem; 
            border-radius: 6px; 
            transition: all 0.2s ease; 
            font-size: 0.9rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }

        .toc a.active {
            color: blue !important;
             background-color: #5ec7ff2a;
}


        .toc a:hover { background-color: #0077ff16}
        
        @media (max-width: 767px) { 
            .sidebar { 
                transform: translateX(-100%);
                width: 85vw;
                max-width: 320px;
            }
            .sidebar.mobile-open { transform: translateX(0); }
            .main-content { 
                margin-left: 0;
                width: 100%;
                max-width: 100vw;
                overflow-x: auto;
            }
            .mobile-menu-btn { display: block; }
            .mobile-overlay { display: block; }
            .header { 
                padding: 0.75rem 1rem;
                flex-wrap: wrap;
                gap: 0.5rem;
            }
            .content { 
                padding: 1rem;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
            }
            .theme-toggle {
                font-size: 0.8rem;
                padding: 0.4rem 0.8rem;
            }
            .code-header {
                padding: 0.5rem;
                font-size: 0.8rem;
            }
            .copy-btn {
                padding: 0.3rem 0.6rem;
                font-size: 0.7rem;
            }
            pre[class*="language-"] {
                padding: 0.75rem !important;
                font-size: 0.75rem !important;
            }
            pre[class*="language-"]::-webkit-scrollbar {
                height: 10px !important;
            }
            .toc {
                padding: 0.75rem;
            }
            .toc a {
                font-size: 0.8rem;
                padding: 0.4rem;
            }
        }
        
        @media (max-width: 480px) {
            h1 { font-size: 1.5rem; }
            h2 { font-size: 1.3rem; }
            h3 { font-size: 1.1rem; }
            .content { padding: 0.75rem; }
            .header { padding: 0.5rem; }
            .sidebar { width: 90vw; }
            pre[class*="language-"] {
                font-size: 0.7rem !important;
                padding: 0.5rem !important;
            }
        }
    </style>
</head>
<body data-theme="light">
    <div class="mobile-overlay" id="mobile-overlay"></div>
    
    <div class="container">
        <nav class="sidebar" id="sidebar">
            <div class="toc">
                <h3 style="padding: 0.5rem; color: var(--text-primary);">Table of Contents</h3>
                <ul id="toc-list"></ul>
            </div>
        </nav>
        <main class="main-content">
            <header class="header">
                <div style="display: flex; align-items: center; gap: 1rem;">
                    <button class="mobile-menu-btn" id="mobile-menu-btn">â˜°</button>
                    <h2 style="margin: 0; color: var(--text-primary);">Documentation</h2>
                </div>
                <button class="theme-toggle" id="theme-toggle">ðŸŒ™ Dark Mode</button>
            </header>
            <div class="content" id="content">
<p>section (Questions 346-370) next?</p>

<h2 id="-321-what-are-indexes-and-how-do-they-work-">**321. What are indexes and how do they work?**</h2>

<p><strong>Answer:</strong> Indexes are database objects that improve the speed of data retrieval operations on a table. They work like an index in a book - instead of scanning every page to find information, you can jump directly to the relevant section.</p>

<p><strong>How they work:</strong></p>

<p>- Indexes create a separate data structure that contains sorted references to the actual table rows</p>
<p>- When a query is executed, MySQL uses the index to quickly locate the relevant rows</p>
<p>- Indexes store key values and pointers to the corresponding rows in the table</p>


<p><strong>Example:</strong> If you have a `users` table with 1 million records and frequently search by `email`, creating an index on the `email` column allows MySQL to find a specific email in milliseconds instead of scanning all 1 million rows.</p>

<p>---</p>

<h2 id="-322-what-are-the-different-types-of-indexes-in-mysql-">**322. What are the different types of indexes in MySQL?**</h2>

<p><strong>Answer:</strong> MySQL supports several types of indexes:</p>

<p><strong>1. Primary Index (Clustered):</strong></p>

<p>- Automatically created for PRIMARY KEY</p>
<p>- Data is physically stored in the order of the primary key</p>


<p><strong>2. Secondary Index (Non-clustered):</strong></p>

<p>- Created on non-primary key columns</p>
<p>- Contains pointers to the actual data rows</p>


<p><strong>3. Unique Index:</strong></p>

<p>- Ensures uniqueness of values</p>
<p>- Automatically created for UNIQUE constraints</p>


<p><strong>4. Composite Index:</strong></p>

<p>- Covers multiple columns</p>
<p>- Example: INDEX(last_name, first_name)</p>


<p><strong>5. Partial Index:</strong></p>

<p>- Index on a subset of data based on conditions</p>


<p><strong>6. Full-text Index:</strong></p>

<p>- Used for text searching in VARCHAR, TEXT columns</p>


<p><strong>7. Spatial Index:</strong></p>

<p>- Used for geometric data types</p>


<p>---</p>

<h2 id="-323-how-do-you-create-and-optimize-composite-indexes-">**323. How do you create and optimize composite indexes?**</h2>

<p><strong>Answer:</strong> Composite indexes cover multiple columns and are crucial for multi-column queries.</p>

<p><strong>Creation Strategy:</strong></p>

<p>- Order columns by selectivity (most selective first)</p>
<p>- Consider query patterns and WHERE clause usage</p>
<p>- Follow the "leftmost prefix" rule</p>


<p><strong>Example Scenario:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20orders%0ACommon%20queries%3A%0A-%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%0A-%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%20AND%20created_date%20%3E%20'2024-01-01'%0A%0AOptimal%20composite%20index%3A%20(customer_id%2C%20status%2C%20created_date)%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: orders
Common queries:
- WHERE customer_id = 123 AND status = 'pending'
- WHERE customer_id = 123 AND status = 'pending' AND created_date &gt; '2024-01-01'

Optimal composite index: (customer_id, status, created_date)
</code></pre>
</div>

<p><strong>Optimization Tips:</strong></p>

<p>- Most selective column first</p>
<p>- Consider column cardinality</p>
<p>- Avoid too many columns (usually max 3-4)</p>
<p>- Monitor index usage with EXPLAIN</p>


<p>---</p>

<h2 id="-324-what-is-the-difference-between-clustered-and-non-clustered-indexes-">**324. What is the difference between clustered and non-clustered indexes?**</h2>

<p><strong>Answer:</strong></p>

<p><strong>Clustered Index:</strong></p>

<p>- Physical storage order matches index order</p>
<p>- Only one per table (usually PRIMARY KEY)</p>
<p>- Data pages are stored in order of the clustered index key</p>
<p>- Faster for range queries and sorting</p>


<p><strong>Non-clustered Index:</strong></p>

<p>- Separate structure from table data</p>
<p>- Multiple non-clustered indexes per table</p>
<p>- Contains pointers to actual data rows</p>
<p>- Additional lookup required to fetch data</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20employees%20(clustered%20on%20employee_id)%0APhysical%20storage%3A%20%5B1%2C%202%2C%203%2C%204%2C%205...%5D%20(sorted%20by%20employee_id)%0A%0ANon-clustered%20index%20on%20last_name%3A%0AIndex%3A%20%5BAdams-%3Erow_ptr%2C%20Brown-%3Erow_ptr%2C%20Clark-%3Erow_ptr%5D%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: employees (clustered on employee_id)
Physical storage: [1, 2, 3, 4, 5...] (sorted by employee_id)

Non-clustered index on last_name:
Index: [Adams-&gt;row_ptr, Brown-&gt;row_ptr, Clark-&gt;row_ptr]
</code></pre>
</div>

<p>---</p>

<h2 id="-325-how-do-you-analyze-index-usage-and-effectiveness-">**325. How do you analyze index usage and effectiveness?**</h2>

<p><strong>Answer:</strong> Several methods to analyze index performance:</p>

<p><strong>1. EXPLAIN Statement:</strong></p>

<p>- Shows query execution plan</p>
<p>- Indicates which indexes are used</p>
<p>- Shows estimated rows examined</p>


<p><strong>2. Performance Schema:</strong></p>

<p>- `performance_schema.table_io_waits_summary_by_index_usage`</p>
<p>- Shows index usage statistics</p>


<p><strong>3. SHOW INDEX:</strong></p>

<p>- Displays index information and cardinality</p>


<p><strong>4. Slow Query Log:</strong></p>

<p>- Identifies queries not using indexes effectively</p>


<p><strong>Example Analysis:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'john%40example.com'%3B%0A%0AKey%20indicators%3A%0A-%20type%3A%20'ref'%20(good)%20vs%20'ALL'%20(bad%20-%20full%20table%20scan)%0A-%20key%3A%20shows%20which%20index%20is%20used%0A-%20rows%3A%20estimated%20rows%20examined%0A-%20Extra%3A%20'Using%20index'%20means%20covering%20index%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">EXPLAIN SELECT * FROM users WHERE email = 'john@example.com';

Key indicators:
- type: 'ref' (good) vs 'ALL' (bad - full table scan)
- key: shows which index is used
- rows: estimated rows examined
- Extra: 'Using index' means covering index
</code></pre>
</div>

<p>---</p>

<h2 id="-326-what-is-index-cardinality-and-why-is-it-important-">**326. What is index cardinality and why is it important?**</h2>

<p><strong>Answer:</strong> Index cardinality refers to the number of unique values in an indexed column relative to the total number of rows.</p>

<p><strong>Types:</strong></p>

<p>- <strong>High Cardinality:</strong> Many unique values (e.g., email addresses, IDs)</p>
<p>- <strong>Low Cardinality:</strong> Few unique values (e.g., gender, status)</p>


<p><strong>Importance:</strong></p>

<p>- High cardinality indexes are more selective and efficient</p>
<p>- Low cardinality indexes may not provide significant performance benefits</p>
<p>- MySQL optimizer uses cardinality to choose optimal execution plans</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20users%20(1%2C000%2C000%20rows)%0A-%20email%20column%3A%20999%2C000%20unique%20values%20(high%20cardinality%20-%20good%20for%20indexing)%0A-%20gender%20column%3A%203%20unique%20values%20(low%20cardinality%20-%20poor%20for%20indexing)%0A-%20status%20column%3A%205%20unique%20values%20(low%20cardinality)%0A%0AIndex%20on%20email%3A%20Very%20effective%0AIndex%20on%20gender%3A%20Ineffective%20for%20single-value%20queries%0AComposite%20index%20(status%2C%20email)%3A%20Can%20be%20effective%20for%20combined%20queries%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: users (1,000,000 rows)
- email column: 999,000 unique values (high cardinality - good for indexing)
- gender column: 3 unique values (low cardinality - poor for indexing)
- status column: 5 unique values (low cardinality)

Index on email: Very effective
Index on gender: Ineffective for single-value queries
Composite index (status, email): Can be effective for combined queries
</code></pre>
</div>

<p>---</p>

<h2 id="-327-how-do-you-handle-index-maintenance-and-rebuilding-">**327. How do you handle index maintenance and rebuilding?**</h2>

<p><strong>Answer:</strong> Index maintenance ensures optimal performance over time.</p>

<p><strong>Maintenance Tasks:</strong></p>

<p><strong>1. Monitor Index Fragmentation:</strong></p>

<p>- Fragmentation occurs with frequent INSERT/UPDATE/DELETE operations</p>
<p>- Check using `INFORMATION_SCHEMA.INNODB_SYS_INDEXES`</p>


<p><strong>2. Rebuild Indexes:</strong></p>

<p>- `ALTER TABLE table_name ENGINE=InnoDB` (rebuilds all indexes)</p>
<p>- `OPTIMIZE TABLE table_name` (defragments and rebuilds)</p>


<p><strong>3. Update Statistics:</strong></p>

<p>- `ANALYZE TABLE table_name` (updates index statistics)</p>
<p>- Helps optimizer make better decisions</p>


<p><strong>4. Regular Monitoring:</strong></p>

<p>- Check index usage patterns</p>
<p>- Remove unused indexes</p>
<p>- Add missing indexes based on query patterns</p>


<p><strong>Best Practices:</strong></p>

<p>- Schedule maintenance during low-traffic periods</p>
<p>- Monitor performance before and after maintenance</p>
<p>- Keep statistics updated regularly</p>


<p>---</p>

<h2 id="-328-what-are-covering-indexes-and-when-do-you-use-them-">**328. What are covering indexes and when do you use them?**</h2>

<p><strong>Answer:</strong> A covering index contains all columns needed to satisfy a query, eliminating the need to access the actual table data.</p>

<p><strong>Benefits:</strong></p>

<p>- Faster query execution (no additional data page reads)</p>
<p>- Reduced I/O operations</p>
<p>- Better performance for SELECT queries</p>


<p><strong>When to Use:</strong></p>

<p>- Frequently executed queries with specific column sets</p>
<p>- Queries that only need indexed columns</p>
<p>- Read-heavy applications</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Query%3A%20SELECT%20customer_id%2C%20order_date%2C%20total%20FROM%20orders%20WHERE%20status%20%3D%20'completed'%0A%0ACovering%20Index%3A%20(status%2C%20customer_id%2C%20order_date%2C%20total)%0A%0AThis%20index%20contains%20all%20needed%20columns%2C%20so%20MySQL%20doesn't%20need%20to%20access%20the%20orders%20table%20data%20pages.%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Query: SELECT customer_id, order_date, total FROM orders WHERE status = 'completed'

Covering Index: (status, customer_id, order_date, total)

This index contains all needed columns, so MySQL doesn't need to access the orders table data pages.
</code></pre>
</div>

<p><strong>Considerations:</strong></p>

<p>- Larger index size (more storage)</p>
<p>- Slower INSERT/UPDATE operations</p>
<p>- Maintenance overhead</p>


<p>---</p>

<h2 id="-329-how-do-you-implement-full-text-search-indexes-">**329. How do you implement full-text search indexes?**</h2>

<p><strong>Answer:</strong> Full-text indexes enable efficient text searching in VARCHAR, TEXT, and JSON columns.</p>

<p><strong>Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20full-text%20index%0AALTER%20TABLE%20articles%20ADD%20FULLTEXT(title%2C%20content)%3B%0A%0A--%20Or%20during%20table%20creation%0ACREATE%20TABLE%20articles%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20title%20VARCHAR(255)%2C%0A%20%20%20%20content%20TEXT%2C%0A%20%20%20%20FULLTEXT(title%2C%20content)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create full-text index
ALTER TABLE articles ADD FULLTEXT(title, content);

-- Or during table creation
CREATE TABLE articles (
    id INT PRIMARY KEY,
    title VARCHAR(255),
    content TEXT,
    FULLTEXT(title, content)
);
</code></pre>
</div>

<p><strong>Search Modes:</strong></p>

<p><strong>1. Natural Language Mode (default):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('database%20optimization')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('database optimization');
</code></pre>
</div>

<p><strong>2. Boolean Mode:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('%2Bdatabase%20-mysql'%20IN%20BOOLEAN%20MODE)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('+database -mysql' IN BOOLEAN MODE);
</code></pre>
</div>

<p><strong>3. Query Expansion:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('database'%20WITH%20QUERY%20EXPANSION)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('database' WITH QUERY EXPANSION);
</code></pre>
</div>

<p><strong>Configuration:</strong></p>

<p>- Minimum word length: `ft_min_word_len` (default 4)</p>
<p>- Stop words: Common words ignored in searches</p>
<p>- Relevance scoring: Automatic ranking of results</p>


<p>---</p>

<h2 id="-330-what-is-the-impact-of-indexes-on-insert-update-delete-operations-">**330. What is the impact of indexes on INSERT/UPDATE/DELETE operations?**</h2>

<p><strong>Answer:</strong> Indexes improve SELECT performance but can slow down data modification operations.</p>

<p><strong>Impact on INSERT:</strong></p>

<p>- Each index must be updated with new entry</p>
<p>- More indexes = slower INSERTs</p>
<p>- Index maintenance overhead</p>


<p><strong>Impact on UPDATE:</strong></p>

<p>- If indexed columns are updated, index entries must be modified</p>
<p>- May require index reorganization</p>
<p>- Non-indexed column updates have minimal impact</p>


<p><strong>Impact on DELETE:</strong></p>

<p>- Index entries must be removed</p>
<p>- May cause index fragmentation</p>
<p>- Cleanup overhead</p>


<p><strong>Example Performance Impact:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%20with%205%20indexes%3A%0A-%20INSERT%3A%205x%20index%20updates%20per%20row%0A-%20UPDATE%20(indexed%20column)%3A%20Potential%20index%20reorganization%0A-%20DELETE%3A%205x%20index%20cleanup%20operations%0A%0AMitigation%20strategies%3A%0A-%20Bulk%20operations%20during%20low-traffic%20periods%0A-%20Disable%20indexes%20during%20large%20data%20loads%0A-%20Use%20appropriate%20batch%20sizes%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table with 5 indexes:
- INSERT: 5x index updates per row
- UPDATE (indexed column): Potential index reorganization
- DELETE: 5x index cleanup operations

Mitigation strategies:
- Bulk operations during low-traffic periods
- Disable indexes during large data loads
- Use appropriate batch sizes
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Balance read vs. write performance needs</p>
<p>- Consider dropping indexes during bulk operations</p>
<p>- Monitor write operation performance</p>
<p>- Use covering indexes to reduce index count</p>


<p>---</p>

<h2 id="-331-how-do-you-optimize-queries-using-explain-">**331. How do you optimize queries using EXPLAIN?**</h2>

<p><strong>Answer:</strong> EXPLAIN shows MySQL's execution plan, helping identify performance bottlenecks.</p>

<p><strong>Key EXPLAIN Columns:</strong></p>
<p>- <strong>select_type:</strong> Query type (SIMPLE, SUBQUERY, UNION)</p>
<p>- <strong>table:</strong> Table being accessed</p>
<p>- <strong>type:</strong> Join type (const, eq_ref, ref, range, index, ALL)</p>
<p>- <strong>key:</strong> Index used (NULL means no index)</p>
<p>- <strong>rows:</strong> Estimated rows examined</p>
<p>- <strong>Extra:</strong> Additional information</p>

<p><strong>Optimization Process:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20orders%20o%20%0AJOIN%20customers%20c%20ON%20o.customer_id%20%3D%20c.id%20%0AWHERE%20o.status%20%3D%20'pending'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">EXPLAIN SELECT * FROM orders o 
JOIN customers c ON o.customer_id = c.id 
WHERE o.status = 'pending';
</code></pre>
</div>

<p><strong>Red Flags to Look For:</strong></p>
<p>- <strong>type: ALL</strong> (full table scan)</p>
<p>- <strong>Extra: Using filesort</strong> (expensive sorting)</p>
<p>- <strong>Extra: Using temporary</strong> (temporary table creation)</p>
<p>- <strong>High rows count</strong> with small result set</p>

<p><strong>Optimization Actions:</strong></p>
<p>1. Add missing indexes for WHERE/JOIN conditions</p>
<p>2. Rewrite queries to avoid filesort</p>
<p>3. Use covering indexes</p>
<p>4. Consider query restructuring</p>

<p>---</p>

<h2 id="-332-what-are-query-execution-plans-and-how-do-you-read-them-">**332. What are query execution plans and how do you read them?**</h2>

<p><strong>Answer:</strong> Query execution plans show the step-by-step process MySQL uses to execute a query.</p>

<p><strong>Reading Execution Plans:</strong></p>

<p><strong>1. Join Types (Best to Worst):</strong></p>
<p>- <strong>const:</strong> Single row match (PRIMARY KEY lookup)</p>
<p>- <strong>eq_ref:</strong> One row per join (UNIQUE index)</p>
<p>- <strong>ref:</strong> Multiple rows with same key value</p>
<p>- <strong>range:</strong> Index range scan (BETWEEN, >, <)</p>
<p>- <strong>index:</strong> Full index scan</p>
<p>- <strong>ALL:</strong> Full table scan (worst)</p>

<p><strong>2. Extra Information:</strong></p>
<p>- <strong>Using index:</strong> Covering index used</p>
<p>- <strong>Using where:</strong> WHERE clause filtering</p>
<p>- <strong>Using filesort:</strong> External sorting required</p>
<p>- <strong>Using temporary:</strong> Temporary table created</p>

<p><strong>Example Analysis:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Good%20plan%3A%0Atype%3A%20const%2C%20key%3A%20PRIMARY%2C%20rows%3A%201%2C%20Extra%3A%20Using%20index%0A%0A--%20Bad%20plan%3A%0Atype%3A%20ALL%2C%20key%3A%20NULL%2C%20rows%3A%20100000%2C%20Extra%3A%20Using%20filesort%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Good plan:
type: const, key: PRIMARY, rows: 1, Extra: Using index

-- Bad plan:
type: ALL, key: NULL, rows: 100000, Extra: Using filesort
</code></pre>
</div>

<p><strong>Optimization Priority:</strong></p>
<p>1. Eliminate full table scans (type: ALL)</p>
<p>2. Add indexes for JOIN conditions</p>
<p>3. Optimize ORDER BY clauses</p>
<p>4. Reduce rows examined</p>

<p>---</p>

<h2 id="-333-how-do-you-handle-index-hints-and-force-index-usage-">**333. How do you handle index hints and force index usage?**</h2>

<p><strong>Answer:</strong> Index hints guide MySQL's optimizer to use specific indexes when automatic selection is suboptimal.</p>

<p><strong>Types of Index Hints:</strong></p>

<p><strong>1. USE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20USE%20INDEX%20(idx_email)%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A--%20Suggests%20using%20idx_email%2C%20but%20optimizer%20can%20ignore%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users USE INDEX (idx_email) 
WHERE email = 'john@example.com';
-- Suggests using idx_email, but optimizer can ignore
</code></pre>
</div>

<p><strong>2. FORCE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20FORCE%20INDEX%20(idx_email)%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A--%20Forces%20use%20of%20idx_email%2C%20optimizer%20must%20comply%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users FORCE INDEX (idx_email) 
WHERE email = 'john@example.com';
-- Forces use of idx_email, optimizer must comply
</code></pre>
</div>

<p><strong>3. IGNORE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20IGNORE%20INDEX%20(idx_name)%20%0AWHERE%20name%20%3D%20'John'%3B%0A--%20Prevents%20use%20of%20idx_name%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users IGNORE INDEX (idx_name) 
WHERE name = 'John';
-- Prevents use of idx_name
</code></pre>
</div>

<p><strong>When to Use:</strong></p>
<p>- Optimizer chooses wrong index</p>
<p>- Testing different index strategies</p>
<p>- Temporary performance fixes</p>
<p>- Complex queries with multiple possible indexes</p>

<p><strong>Best Practices:</strong></p>
<p>- Use sparingly - optimizer is usually correct</p>
<p>- Document why hints are needed</p>
<p>- Review hints after MySQL upgrades</p>
<p>- Prefer query rewriting over hints</p>

<p>---</p>

<h2 id="-334-what-is-index-selectivity-and-how-do-you-calculate-it-">**334. What is index selectivity and how do you calculate it?**</h2>

<p><strong>Answer:</strong> Index selectivity measures how unique the values in an indexed column are.</p>

<p><strong>Formula:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">text</span>
        <button class="copy-btn" data-code="Selectivity%20%3D%20Number%20of%20Distinct%20Values%20%2F%20Total%20Number%20of%20Rows%0A">Copy</button>
    </div>
    <pre><code class="language-text">Selectivity = Number of Distinct Values / Total Number of Rows
</code></pre>
</div>

<p><strong>Selectivity Ranges:</strong></p>
<p>- <strong>1.0:</strong> Perfect selectivity (all unique values)</p>
<p>- <strong>0.5:</strong> Moderate selectivity</p>
<p>- <strong>0.01:</strong> Poor selectivity (many duplicates)</p>

<p><strong>Calculation Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Calculate%20selectivity%20for%20email%20column%0ASELECT%20%0A%20%20%20%20COUNT(DISTINCT%20email)%20%2F%20COUNT(*)%20as%20email_selectivity%2C%0A%20%20%20%20COUNT(DISTINCT%20status)%20%2F%20COUNT(*)%20as%20status_selectivity%0AFROM%20users%3B%0A%0A--%20Results%3A%0A--%20email_selectivity%3A%200.98%20(excellent)%0A--%20status_selectivity%3A%200.003%20(poor)%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Calculate selectivity for email column
SELECT 
    COUNT(DISTINCT email) / COUNT(*) as email_selectivity,
    COUNT(DISTINCT status) / COUNT(*) as status_selectivity
FROM users;

-- Results:
-- email_selectivity: 0.98 (excellent)
-- status_selectivity: 0.003 (poor)
</code></pre>
</div>

<p><strong>Impact on Performance:</strong></p>
<p>- <strong>High Selectivity (>0.1):</strong> Good index candidates</p>
<p>- <strong>Low Selectivity (<0.01):</strong> Poor index candidates</p>
<p>- <strong>Composite Indexes:</strong> Combine low-selectivity columns</p>

<p><strong>Optimization Strategy:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20indexing%20low-selectivity%20'status'%20alone%3A%0ACREATE%20INDEX%20idx_status%20ON%20orders%20(status)%3B%20%20--%20Poor%0A%0A--%20Combine%20with%20high-selectivity%20column%3A%0ACREATE%20INDEX%20idx_status_date%20ON%20orders%20(status%2C%20created_date)%3B%20%20--%20Better%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of indexing low-selectivity 'status' alone:
CREATE INDEX idx_status ON orders (status);  -- Poor

-- Combine with high-selectivity column:
CREATE INDEX idx_status_date ON orders (status, created_date);  -- Better
</code></pre>
</div>

<p>---</p>

<h2 id="-335-how-do-you-optimize-order-by-and-group-by-clauses-">**335. How do you optimize ORDER BY and GROUP BY clauses?**</h2>

<p><strong>Answer:</strong> ORDER BY and GROUP BY optimization focuses on index usage and avoiding filesort operations.</p>

<p><strong>ORDER BY Optimization:</strong></p>

<p><strong>1. Index Column Order:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20last_name%2C%20first_name%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_name%20ON%20users%20(last_name%2C%20first_name)%3B%0A--%20Index%20order%20must%20match%20ORDER%20BY%20order%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users ORDER BY last_name, first_name;

-- Optimal index:
CREATE INDEX idx_name ON users (last_name, first_name);
-- Index order must match ORDER BY order
</code></pre>
</div>

<p><strong>2. Covering Indexes:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20id%2C%20email%20FROM%20users%20ORDER%20BY%20created_date%3B%0A%0A--%20Covering%20index%3A%0ACREATE%20INDEX%20idx_covering%20ON%20users%20(created_date%2C%20id%2C%20email)%3B%0A--%20Avoids%20table%20access%20entirely%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT id, email FROM users ORDER BY created_date;

-- Covering index:
CREATE INDEX idx_covering ON users (created_date, id, email);
-- Avoids table access entirely
</code></pre>
</div>

<p><strong>GROUP BY Optimization:</strong></p>

<p><strong>1. Index on GROUP BY Columns:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20status%2C%20COUNT(*)%20FROM%20orders%20GROUP%20BY%20status%3B%0A%0A--%20Index%3A%0ACREATE%20INDEX%20idx_status%20ON%20orders%20(status)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT status, COUNT(*) FROM orders GROUP BY status;

-- Index:
CREATE INDEX idx_status ON orders (status);
</code></pre>
</div>

<p><strong>2. Composite Index for GROUP BY + WHERE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20category%2C%20COUNT(*)%20FROM%20products%20%0AWHERE%20active%20%3D%201%20GROUP%20BY%20category%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_active_category%20ON%20products%20(active%2C%20category)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT category, COUNT(*) FROM products 
WHERE active = 1 GROUP BY category;

-- Optimal index:
CREATE INDEX idx_active_category ON products (active, category);
</code></pre>
</div>

<p><strong>Avoiding Filesort:</strong></p>
<p>- Match index column order exactly</p>
<p>- Use LIMIT with ORDER BY when possible</p>
<p>- Consider partial indexes for large datasets</p>

<p>---</p>

<h2 id="-336-what-are-partial-indexes-and-when-do-you-use-them-">**336. What are partial indexes and when do you use them?**</h2>

<p><strong>Answer:</strong> Partial indexes index only a subset of rows or column data, reducing index size and maintenance overhead.</p>

<p><strong>Types of Partial Indexes:</strong></p>

<p><strong>1. Conditional Partial Index (PostgreSQL concept, MySQL workaround):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20doesn't%20support%20WHERE%20clauses%20in%20indexes%20directly%0A--%20Workaround%3A%20Use%20functional%20indexes%20or%20filtered%20views%0A%0A--%20Simulate%20with%20functional%20index%3A%0ACREATE%20INDEX%20idx_active_users%20ON%20users%20(email%2C%20(CASE%20WHEN%20status%20%3D%20'active'%20THEN%201%20END))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL doesn't support WHERE clauses in indexes directly
-- Workaround: Use functional indexes or filtered views

-- Simulate with functional index:
CREATE INDEX idx_active_users ON users (email, (CASE WHEN status = 'active' THEN 1 END));
</code></pre>
</div>

<p><strong>2. Prefix Indexes (MySQL Native):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20only%20first%2010%20characters%20of%20email%0ACREATE%20INDEX%20idx_email_prefix%20ON%20users%20(email(10))%3B%0A%0A--%20Useful%20for%3A%0A--%20-%20Large%20VARCHAR%2FTEXT%20columns%0A--%20-%20Reducing%20index%20size%0A--%20-%20When%20full%20column%20indexing%20is%20unnecessary%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index only first 10 characters of email
CREATE INDEX idx_email_prefix ON users (email(10));

-- Useful for:
-- - Large VARCHAR/TEXT columns
-- - Reducing index size
-- - When full column indexing is unnecessary
</code></pre>
</div>

<p><strong>When to Use:</strong></p>
<p>1. <strong>Large Text Columns:</strong> Index prefixes instead of full content</p>
<p>2. <strong>Sparse Data:</strong> When most rows don't need indexing</p>
<p>3. <strong>Storage Optimization:</strong> Reduce index storage requirements</p>
<p>4. <strong>Selective Queries:</strong> When queries filter on specific conditions</p>

<p><strong>Example Use Case:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20with%20mostly%20inactive%20users%0A--%20Only%20index%20active%20users'%20emails%0ACREATE%20INDEX%20idx_active_email%20ON%20users%20(email)%20%0AWHERE%20status%20%3D%20'active'%3B%20%20--%20PostgreSQL%20syntax%0A%0A--%20MySQL%20alternative%3A%0ACREATE%20INDEX%20idx_status_email%20ON%20users%20(status%2C%20email)%3B%0A--%20Query%3A%20WHERE%20status%20%3D%20'active'%20AND%20email%20%3D%20'x'%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table with mostly inactive users
-- Only index active users' emails
CREATE INDEX idx_active_email ON users (email) 
WHERE status = 'active';  -- PostgreSQL syntax

-- MySQL alternative:
CREATE INDEX idx_status_email ON users (status, email);
-- Query: WHERE status = 'active' AND email = 'x'
</code></pre>
</div>

<p>---</p>

<h2 id="-337-how-do-you-handle-index-fragmentation-">**337. How do you handle index fragmentation?**</h2>

<p><strong>Answer:</strong> Index fragmentation occurs when index pages are not stored contiguously, leading to performance degradation.</p>

<p><strong>Types of Fragmentation:</strong></p>

<p><strong>1. Internal Fragmentation:</strong></p>
<p>- Partially filled index pages</p>
<p>- Caused by random INSERTs/DELETEs</p>
<p>- Wastes storage space</p>

<p><strong>2. External Fragmentation:</strong></p>
<p>- Index pages scattered across disk</p>
<p>- Causes additional I/O operations</p>
<p>- Slows range scans</p>

<p><strong>Detection Methods:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20table%20fragmentation%0ASHOW%20TABLE%20STATUS%20LIKE%20'users'%3B%0A--%20Look%20at%20'Data_free'%20column%20for%20fragmented%20space%0A%0A--%20InnoDB%20specific%3A%0ASELECT%20table_name%2C%20%0A%20%20%20%20%20%20%20ROUND(data_length%2F1024%2F1024%2C%202)%20AS%20data_mb%2C%0A%20%20%20%20%20%20%20ROUND(index_length%2F1024%2F1024%2C%202)%20AS%20index_mb%2C%0A%20%20%20%20%20%20%20ROUND(data_free%2F1024%2F1024%2C%202)%20AS%20fragmented_mb%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check table fragmentation
SHOW TABLE STATUS LIKE 'users';
-- Look at 'Data_free' column for fragmented space

-- InnoDB specific:
SELECT table_name, 
       ROUND(data_length/1024/1024, 2) AS data_mb,
       ROUND(index_length/1024/1024, 2) AS index_mb,
       ROUND(data_free/1024/1024, 2) AS fragmented_mb
FROM information_schema.tables 
WHERE table_schema = 'your_database';
</code></pre>
</div>

<p><strong>Defragmentation Solutions:</strong></p>

<p><strong>1. OPTIMIZE TABLE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="OPTIMIZE%20TABLE%20users%3B%0A--%20Rebuilds%20table%20and%20all%20indexes%0A--%20Reclaims%20fragmented%20space%0A">Copy</button>
    </div>
    <pre><code class="language-sql">OPTIMIZE TABLE users;
-- Rebuilds table and all indexes
-- Reclaims fragmented space
</code></pre>
</div>

<p><strong>2. ALTER TABLE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="ALTER%20TABLE%20users%20ENGINE%3DInnoDB%3B%0A--%20Forces%20table%20rebuild%0A--%20More%20control%20over%20process%0A">Copy</button>
    </div>
    <pre><code class="language-sql">ALTER TABLE users ENGINE=InnoDB;
-- Forces table rebuild
-- More control over process
</code></pre>
</div>

<p><strong>3. Scheduled Maintenance:</strong></p>
<p>- Run during low-traffic periods</p>
<p>- Monitor fragmentation levels</p>
<p>- Automate based on fragmentation percentage</p>

<p><strong>Prevention:</strong></p>
<p>- Use appropriate PRIMARY KEY design</p>
<p>- Avoid random UUID keys</p>
<p>- Regular maintenance schedules</p>

<p>---</p>

<h2 id="-338-what-is-the-difference-between-b-tree-and-hash-indexes-">**338. What is the difference between B-tree and Hash indexes?**</h2>

<p><strong>Answer:</strong> B-tree and Hash indexes use different data structures and are optimized for different query patterns.</p>

<p><strong>B-tree Indexes:</strong></p>

<p><strong>Structure:</strong></p>
<p>- Balanced tree structure</p>
<p>- Sorted data organization</p>
<p>- Multiple levels (root, internal, leaf)</p>

<p><strong>Best For:</strong></p>
<p>- Range queries (BETWEEN, >, <)</p>
<p>- ORDER BY operations</p>
<p>- Pattern matching (LIKE 'prefix%')</p>
<p>- Equality searches</p>

<p><strong>Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20B-tree%20excels%20at%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20BETWEEN%2025%20AND%2035%3B%0ASELECT%20*%20FROM%20users%20WHERE%20name%20LIKE%20'John%25'%3B%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20created_date%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- B-tree excels at:
SELECT * FROM users WHERE age BETWEEN 25 AND 35;
SELECT * FROM users WHERE name LIKE 'John%';
SELECT * FROM users ORDER BY created_date;
</code></pre>
</div>

<p><strong>Hash Indexes:</strong></p>

<p><strong>Structure:</strong></p>
<p>- Hash table implementation</p>
<p>- Direct key-to-location mapping</p>
<p>- Single-level lookup</p>

<p><strong>Best For:</strong></p>
<p>- Exact equality matches only</p>
<p>- Very fast single-row lookups</p>
<p>- Memory-based storage engines</p>

<p><strong>Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Hash%20excels%20at%3A%0ASELECT%20*%20FROM%20users%20WHERE%20id%20%3D%2012345%3B%0ASELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'exact%40match.com'%3B%0A%0A--%20Hash%20cannot%20handle%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3E%2025%3B%20%20--%20No%20range%20support%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20name%3B%20%20%20--%20No%20sorting%20support%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Hash excels at:
SELECT * FROM users WHERE id = 12345;
SELECT * FROM users WHERE email = 'exact@match.com';

-- Hash cannot handle:
SELECT * FROM users WHERE age &gt; 25;  -- No range support
SELECT * FROM users ORDER BY name;   -- No sorting support
</code></pre>
</div>

<p><strong>Comparison:</strong></p>
<p>| Feature | B-tree | Hash |</p>
<p>|---------|--------|------|</p>
<p>| Equality | Good | Excellent |</p>
<p>| Range | Excellent | Not supported |</p>
<p>| Sorting | Excellent | Not supported |</p>
<p>| Memory usage | Higher | Lower |</p>
<p>| Maintenance | Moderate | Low |</p>

<p>---</p>

<h2 id="-339-how-do-you-optimize-joins-using-indexes-">**339. How do you optimize joins using indexes?**</h2>

<p><strong>Answer:</strong> Join optimization relies heavily on proper indexing of join columns and understanding join algorithms.</p>

<p><strong>Join Index Strategy:</strong></p>

<p><strong>1. Index Join Columns:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20u.name%2C%20o.total%20%0AFROM%20users%20u%20%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%3B%0A%0A--%20Required%20indexes%3A%0ACREATE%20INDEX%20idx_user_id%20ON%20orders%20(user_id)%3B%20%20--%20Foreign%20key%0A--%20users.id%20already%20has%20PRIMARY%20KEY%20index%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT u.name, o.total 
FROM users u 
JOIN orders o ON u.id = o.user_id;

-- Required indexes:
CREATE INDEX idx_user_id ON orders (user_id);  -- Foreign key
-- users.id already has PRIMARY KEY index
</code></pre>
</div>

<p><strong>2. Composite Indexes for Filtered Joins:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20with%20WHERE%20clause%3A%0ASELECT%20u.name%2C%20o.total%20%0AFROM%20users%20u%20%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%20%0AWHERE%20o.status%20%3D%20'completed'%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_status_user_id%20ON%20orders%20(status%2C%20user_id)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query with WHERE clause:
SELECT u.name, o.total 
FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE o.status = 'completed';

-- Optimal index:
CREATE INDEX idx_status_user_id ON orders (status, user_id);
</code></pre>
</div>

<p><strong>Join Algorithm Optimization:</strong></p>

<p><strong>1. Nested Loop Join:</strong></p>
<p>- Best for small result sets</p>
<p>- Requires index on inner table join column</p>
<p>- O(n*m) complexity without index</p>

<p><strong>2. Hash Join:</strong></p>
<p>- Good for larger datasets</p>
<p>- Builds hash table from smaller table</p>
<p>- Requires sufficient memory</p>

<p><strong>3. Sort-Merge Join:</strong></p>
<p>- When both tables are large</p>
<p>- Benefits from sorted data/indexes</p>
<p>- Used when hash join memory insufficient</p>

<p><strong>Best Practices:</strong></p>
<p>- Always index foreign key columns</p>
<p>- Consider covering indexes for join queries</p>
<p>- Use STRAIGHT_JOIN to force join order when needed</p>
<p>- Monitor join buffer size settings</p>

<p>---</p>

<h2 id="-340-what-are-invisible-indexes-and-their-use-cases-">**340. What are invisible indexes and their use cases?**</h2>

<p><strong>Answer:</strong> Invisible indexes exist in the database but are ignored by the query optimizer, allowing safe testing of index removal.</p>

<p><strong>Purpose:</strong></p>
<p>- Test index removal impact without dropping</p>
<p>- Gradual index deprecation</p>
<p>- Performance testing scenarios</p>
<p>- Maintenance planning</p>

<p><strong>MySQL Implementation:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20invisible%20index%3A%0ACREATE%20INDEX%20idx_email%20ON%20users%20(email)%20INVISIBLE%3B%0A%0A--%20Make%20existing%20index%20invisible%3A%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_email%20INVISIBLE%3B%0A%0A--%20Make%20invisible%20index%20visible%3A%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_email%20VISIBLE%3B%0A%0A--%20Force%20use%20of%20invisible%20index%20(for%20testing)%3A%0ASELECT%20%2F*%2B%20USE_INDEX(users%2C%20idx_email)%20*%2F%20*%20FROM%20users%20WHERE%20email%20%3D%20'test%40example.com'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create invisible index:
CREATE INDEX idx_email ON users (email) INVISIBLE;

-- Make existing index invisible:
ALTER TABLE users ALTER INDEX idx_email INVISIBLE;

-- Make invisible index visible:
ALTER TABLE users ALTER INDEX idx_email VISIBLE;

-- Force use of invisible index (for testing):
SELECT /*+ USE_INDEX(users, idx_email) */ * FROM users WHERE email = 'test@example.com';
</code></pre>
</div>

<p><strong>Use Cases:</strong></p>

<p><strong>1. Safe Index Removal:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Step%201%3A%20Make%20index%20invisible%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_old_column%20INVISIBLE%3B%0A%0A--%20Step%202%3A%20Monitor%20performance%20for%20days%2Fweeks%0A--%20Step%203%3A%20If%20no%20issues%2C%20drop%20the%20index%0ADROP%20INDEX%20idx_old_column%20ON%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Step 1: Make index invisible
ALTER TABLE users ALTER INDEX idx_old_column INVISIBLE;

-- Step 2: Monitor performance for days/weeks
-- Step 3: If no issues, drop the index
DROP INDEX idx_old_column ON users;
</code></pre>
</div>

<p><strong>2. A/B Testing:</strong></p>
<p>- Compare query performance with/without specific indexes</p>
<p>- Test different index strategies</p>
<p>- Validate optimizer decisions</p>

<p><strong>3. Maintenance Windows:</strong></p>
<p>- Prepare indexes before maintenance</p>
<p>- Quick activation/deactivation</p>
<p>- Rollback capability</p>

<p><strong>Limitations:</strong></p>
<p>- PRIMARY KEY cannot be invisible</p>
<p>- UNIQUE indexes enforce constraints even when invisible</p>
<p>- Available in MySQL 8.0+</p>

<p>---</p>

<h2 id="-341-how-do-you-monitor-index-performance-and-usage-">**341. How do you monitor index performance and usage?**</h2>

<p><strong>Answer:</strong> Index monitoring involves tracking usage patterns, performance metrics, and identifying optimization opportunities.</p>

<p><strong>Monitoring Tools:</strong></p>

<p><strong>1. Performance Schema:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20usage%20statistics%3A%0ASELECT%20object_schema%2C%20object_name%2C%20index_name%2C%0A%20%20%20%20%20%20%20count_read%2C%20count_write%2C%20count_fetch%2C%0A%20%20%20%20%20%20%20sum_timer_read%2C%20sum_timer_write%0AFROM%20performance_schema.table_io_waits_summary_by_index_usage%0AWHERE%20object_schema%20%3D%20'your_database'%0AORDER%20BY%20count_read%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index usage statistics:
SELECT object_schema, object_name, index_name,
       count_read, count_write, count_fetch,
       sum_timer_read, sum_timer_write
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
ORDER BY count_read DESC;
</code></pre>
</div>

<p><strong>2. Information Schema:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20information%3A%0ASELECT%20table_name%2C%20index_name%2C%20column_name%2C%20cardinality%0AFROM%20information_schema.statistics%0AWHERE%20table_schema%20%3D%20'your_database'%0AORDER%20BY%20table_name%2C%20seq_in_index%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index information:
SELECT table_name, index_name, column_name, cardinality
FROM information_schema.statistics
WHERE table_schema = 'your_database'
ORDER BY table_name, seq_in_index;
</code></pre>
</div>

<p><strong>3. Slow Query Log:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20slow%20query%20log%3A%0ASET%20GLOBAL%20slow_query_log%20%3D%20'ON'%3B%0ASET%20GLOBAL%20long_query_time%20%3D%201%3B%0ASET%20GLOBAL%20log_queries_not_using_indexes%20%3D%20'ON'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable slow query log:
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 1;
SET GLOBAL log_queries_not_using_indexes = 'ON';
</code></pre>
</div>

<p><strong>Key Metrics to Monitor:</strong></p>

<p><strong>1. Index Usage Frequency:</strong></p>
<p>- Reads vs. writes ratio</p>
<p>- Unused indexes identification</p>
<p>- Most accessed indexes</p>

<p><strong>2. Performance Metrics:</strong></p>
<p>- Query execution time</p>
<p>- Rows examined vs. rows returned</p>
<p>- Index seek vs. scan operations</p>

<p><strong>3. Storage Metrics:</strong></p>
<p>- Index size growth</p>
<p>- Fragmentation levels</p>
<p>- Memory usage</p>

<p><strong>Automated Monitoring:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20monitoring%20view%3A%0ACREATE%20VIEW%20index_usage_summary%20AS%0ASELECT%20%0A%20%20%20%20t.table_name%2C%0A%20%20%20%20t.index_name%2C%0A%20%20%20%20t.count_read%2C%0A%20%20%20%20t.count_write%2C%0A%20%20%20%20ROUND(t.sum_timer_read%2F1000000000%2C%202)%20as%20read_time_sec%2C%0A%20%20%20%20s.cardinality%0AFROM%20performance_schema.table_io_waits_summary_by_index_usage%20t%0AJOIN%20information_schema.statistics%20s%20ON%20%0A%20%20%20%20t.object_name%20%3D%20s.table_name%20AND%20t.index_name%20%3D%20s.index_name%0AWHERE%20t.object_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create monitoring view:
CREATE VIEW index_usage_summary AS
SELECT 
    t.table_name,
    t.index_name,
    t.count_read,
    t.count_write,
    ROUND(t.sum_timer_read/1000000000, 2) as read_time_sec,
    s.cardinality
FROM performance_schema.table_io_waits_summary_by_index_usage t
JOIN information_schema.statistics s ON 
    t.object_name = s.table_name AND t.index_name = s.index_name
WHERE t.object_schema = 'your_database';
</code></pre>
</div>

<p>---</p>

<h2 id="-342-what-are-functional-indexes-and-how-do-you-implement-them-">**342. What are functional indexes and how do you implement them?**</h2>

<p><strong>Answer:</strong> Functional indexes are built on expressions or functions rather than direct column values, enabling optimization of computed queries.</p>

<p><strong>MySQL Implementation (8.0+):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20on%20expression%3A%0ACREATE%20INDEX%20idx_upper_email%20ON%20users%20((UPPER(email)))%3B%0A%0A--%20Index%20on%20JSON%20extraction%3A%0ACREATE%20INDEX%20idx_json_field%20ON%20products%20((JSON_EXTRACT(attributes%2C%20'%24.category')))%3B%0A%0A--%20Index%20on%20calculated%20field%3A%0ACREATE%20INDEX%20idx_full_name%20ON%20users%20((CONCAT(first_name%2C%20'%20'%2C%20last_name)))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index on expression:
CREATE INDEX idx_upper_email ON users ((UPPER(email)));

-- Index on JSON extraction:
CREATE INDEX idx_json_field ON products ((JSON_EXTRACT(attributes, '$.category')));

-- Index on calculated field:
CREATE INDEX idx_full_name ON users ((CONCAT(first_name, ' ', last_name)));
</code></pre>
</div>

<p><strong>Use Cases:</strong></p>

<p><strong>1. Case-Insensitive Searches:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Without%20functional%20index%3A%0ASELECT%20*%20FROM%20users%20WHERE%20UPPER(email)%20%3D%20'JOHN%40EXAMPLE.COM'%3B%0A--%20Requires%20full%20table%20scan%0A%0A--%20With%20functional%20index%3A%0ACREATE%20INDEX%20idx_upper_email%20ON%20users%20((UPPER(email)))%3B%0A--%20Now%20the%20query%20uses%20the%20index%20efficiently%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Without functional index:
SELECT * FROM users WHERE UPPER(email) = 'JOHN@EXAMPLE.COM';
-- Requires full table scan

-- With functional index:
CREATE INDEX idx_upper_email ON users ((UPPER(email)));
-- Now the query uses the index efficiently
</code></pre>
</div>

<p><strong>2. JSON Data Indexing:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20JSON%20field%3A%0ACREATE%20INDEX%20idx_product_category%20ON%20products%20((JSON_EXTRACT(data%2C%20'%24.category')))%3B%0A%0A--%20Optimized%20query%3A%0ASELECT%20*%20FROM%20products%20WHERE%20JSON_EXTRACT(data%2C%20'%24.category')%20%3D%20'electronics'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index JSON field:
CREATE INDEX idx_product_category ON products ((JSON_EXTRACT(data, '$.category')));

-- Optimized query:
SELECT * FROM products WHERE JSON_EXTRACT(data, '$.category') = 'electronics';
</code></pre>
</div>

<p><strong>3. Date Calculations:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20on%20year%20extraction%3A%0ACREATE%20INDEX%20idx_birth_year%20ON%20users%20((YEAR(birth_date)))%3B%0A%0A--%20Optimized%20query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20YEAR(birth_date)%20%3D%201990%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index on year extraction:
CREATE INDEX idx_birth_year ON users ((YEAR(birth_date)));

-- Optimized query:
SELECT * FROM users WHERE YEAR(birth_date) = 1990;
</code></pre>
</div>

<p><strong>Benefits:</strong></p>
<p>- Optimize function-based WHERE clauses</p>
<p>- Avoid full table scans on computed values</p>
<p>- Support complex data types (JSON, spatial)</p>

<p><strong>Limitations:</strong></p>
<p>- Increased storage requirements</p>
<p>- Slower INSERT/UPDATE operations</p>
<p>- Expression must be deterministic</p>

<p>---</p>

<h2 id="-343-how-do-you-handle-index-bloat-and-maintenance-">**343. How do you handle index bloat and maintenance?**</h2>

<p><strong>Answer:</strong> Index bloat occurs when indexes grow larger than necessary due to fragmentation, deleted records, or inefficient design.</p>

<p><strong>Causes of Index Bloat:</strong></p>
<p>1. <strong>Frequent DELETE operations</strong> leaving empty pages</p>
<p>2. <strong>Random INSERT patterns</strong> causing page splits</p>
<p>3. <strong>UPDATE operations</strong> on indexed columns</p>
<p>4. <strong>Poor fill factor</strong> settings</p>

<p><strong>Detection Methods:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20index%20sizes%3A%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20index_name%2C%0A%20%20%20%20ROUND(stat_value%20*%20%40%40innodb_page_size%20%2F%201024%20%2F%201024%2C%202)%20AS%20size_mb%0AFROM%20mysql.innodb_index_stats%20%0AWHERE%20stat_name%20%3D%20'size'%20AND%20database_name%20%3D%20'your_db'%0AORDER%20BY%20stat_value%20DESC%3B%0A%0A--%20Compare%20logical%20vs%20physical%20size%3A%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20ROUND(data_length%2F1024%2F1024%2C%202)%20AS%20data_mb%2C%0A%20%20%20%20ROUND(index_length%2F1024%2F1024%2C%202)%20AS%20index_mb%2C%0A%20%20%20%20ROUND(data_free%2F1024%2F1024%2C%202)%20AS%20free_mb%0AFROM%20information_schema.tables%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check index sizes:
SELECT 
    table_name,
    index_name,
    ROUND(stat_value * @@innodb_page_size / 1024 / 1024, 2) AS size_mb
FROM mysql.innodb_index_stats 
WHERE stat_name = 'size' AND database_name = 'your_db'
ORDER BY stat_value DESC;

-- Compare logical vs physical size:
SELECT 
    table_name,
    ROUND(data_length/1024/1024, 2) AS data_mb,
    ROUND(index_length/1024/1024, 2) AS index_mb,
    ROUND(data_free/1024/1024, 2) AS free_mb
FROM information_schema.tables
WHERE table_schema = 'your_database';
</code></pre>
</div>

<p><strong>Maintenance Strategies:</strong></p>

<p><strong>1. Regular Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Rebuild%20indexes%20and%20reclaim%20space%3A%0AOPTIMIZE%20TABLE%20users%3B%0A%0A--%20Alternative%20approach%3A%0AALTER%20TABLE%20users%20ENGINE%3DInnoDB%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Rebuild indexes and reclaim space:
OPTIMIZE TABLE users;

-- Alternative approach:
ALTER TABLE users ENGINE=InnoDB;
</code></pre>
</div>

<p><strong>2. Proactive Maintenance:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Schedule%20regular%20maintenance%3A%0A--%20Daily%20for%20high-write%20tables%0A--%20Weekly%20for%20moderate-write%20tables%0A--%20Monthly%20for%20read-heavy%20tables%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Schedule regular maintenance:
-- Daily for high-write tables
-- Weekly for moderate-write tables
-- Monthly for read-heavy tables
</code></pre>
</div>

<p><strong>3. Fill Factor Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Leave%20space%20for%20future%20inserts%20(InnoDB%20automatic)%0A--%20Reduces%20page%20splits%20and%20fragmentation%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Leave space for future inserts (InnoDB automatic)
-- Reduces page splits and fragmentation
</code></pre>
</div>

<p><strong>Prevention Strategies:</strong></p>
<p>- Use sequential PRIMARY KEYs when possible</p>
<p>- Batch DELETE operations</p>
<p>- Monitor fragmentation levels</p>
<p>- Regular statistics updates</p>

<p>---</p>

<h2 id="-344-what-is-index-intersection-and-how-does-it-work-">**344. What is index intersection and how does it work?**</h2>

<p><strong>Answer:</strong> Index intersection (Index Merge) allows MySQL to use multiple indexes simultaneously for a single query, combining their results.</p>

<p><strong>How It Works:</strong></p>
<p>1. <strong>Multiple Index Scans:</strong> Query uses several single-column indexes</p>
<p>2. <strong>Result Intersection:</strong> Combines results using AND/OR logic</p>
<p>3. <strong>Row ID Merging:</strong> Merges row identifiers from different indexes</p>
<p>4. <strong>Final Row Retrieval:</strong> Fetches actual rows using merged IDs</p>

<p><strong>Types of Index Merge:</strong></p>

<p><strong>1. Intersection (AND conditions):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20AND%20city%20%3D%20'New%20York'%3B%0A%0A--%20Indexes%3A%0ACREATE%20INDEX%20idx_age%20ON%20users%20(age)%3B%0ACREATE%20INDEX%20idx_city%20ON%20users%20(city)%3B%0A%0A--%20Execution%3A%0A--%201.%20Scan%20idx_age%20for%20age%20%3D%2025%0A--%202.%20Scan%20idx_city%20for%20city%20%3D%20'New%20York'%20%20%0A--%203.%20Intersect%20results%20(AND%20operation)%0A--%204.%20Fetch%20matching%20rows%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users WHERE age = 25 AND city = 'New York';

-- Indexes:
CREATE INDEX idx_age ON users (age);
CREATE INDEX idx_city ON users (city);

-- Execution:
-- 1. Scan idx_age for age = 25
-- 2. Scan idx_city for city = 'New York'  
-- 3. Intersect results (AND operation)
-- 4. Fetch matching rows
</code></pre>
</div>

<p><strong>2. Union (OR conditions):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20OR%20city%20%3D%20'New%20York'%3B%0A%0A--%20Uses%20same%20indexes%20but%20unions%20results%20instead%20of%20intersecting%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users WHERE age = 25 OR city = 'New York';

-- Uses same indexes but unions results instead of intersecting
</code></pre>
</div>

<p><strong>When MySQL Uses Index Merge:</strong></p>
<p>- Multiple single-column indexes available</p>
<p>- No suitable composite index exists</p>
<p>- Cost-based optimizer determines it's efficient</p>
<p>- Conditions use AND/OR operators</p>

<p><strong>EXPLAIN Output:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20AND%20city%20%3D%20'New%20York'%3B%0A--%20type%3A%20index_merge%0A--%20key%3A%20idx_age%2Cidx_city%0A--%20Extra%3A%20Using%20intersect(idx_age%2Cidx_city)%3B%20Using%20where%0A">Copy</button>
    </div>
    <pre><code class="language-sql">EXPLAIN SELECT * FROM users WHERE age = 25 AND city = 'New York';
-- type: index_merge
-- key: idx_age,idx_city
-- Extra: Using intersect(idx_age,idx_city); Using where
</code></pre>
</div>

<p><strong>Optimization Considerations:</strong></p>
<p>- <strong>Composite Index Usually Better:</strong> Single index often outperforms merge</p>
<p>- <strong>Cost Overhead:</strong> Merging operation has CPU cost</p>
<p>- <strong>Memory Usage:</strong> Requires sort buffers for merging</p>

<p><strong>Best Practice:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20relying%20on%20index%20merge%3A%0ACREATE%20INDEX%20idx_age_city%20ON%20users%20(age%2C%20city)%3B%0A--%20Single%20composite%20index%20is%20typically%20more%20efficient%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of relying on index merge:
CREATE INDEX idx_age_city ON users (age, city);
-- Single composite index is typically more efficient
</code></pre>
</div>

<p>---</p>

<h2 id="-345-how-do-you-optimize-database-schema-for-better-index-performance-">**345. How do you optimize database schema for better index performance?**</h2>

<p><strong>Answer:</strong> Schema optimization for indexing involves strategic design decisions that maximize index effectiveness.</p>

<p><strong>Schema Design Principles:</strong></p>

<p><strong>1. Primary Key Design:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Good%3A%20Sequential%2C%20compact%20primary%20key%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%20%20--%20Sequential%2C%208%20bytes%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20created_at%20TIMESTAMP%0A)%3B%0A%0A--%20Avoid%3A%20Random%20UUIDs%20as%20primary%20key%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20CHAR(36)%20PRIMARY%20KEY%2C%20%20--%20Random%2C%2036%20bytes%2C%20causes%20fragmentation%0A%20%20%20%20email%20VARCHAR(255)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Good: Sequential, compact primary key
CREATE TABLE users (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,  -- Sequential, 8 bytes
    email VARCHAR(255),
    created_at TIMESTAMP
);

-- Avoid: Random UUIDs as primary key
CREATE TABLE users (
    id CHAR(36) PRIMARY KEY,  -- Random, 36 bytes, causes fragmentation
    email VARCHAR(255)
);
</code></pre>
</div>

<p><strong>2. Data Type Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Efficient%20data%20types%20for%20indexing%3A%0Auser_id%20INT%20NOT%20NULL%2C%20%20%20%20%20%20%20%20%20%20%20--%204%20bytes%20vs%20BIGINT%208%20bytes%0Astatus%20ENUM('active'%2C'inactive')%2C%20--%201%20byte%20vs%20VARCHAR%0Acreated_date%20DATE%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%203%20bytes%20vs%20DATETIME%208%20bytes%0Ais_verified%20BOOLEAN%20%20%20%20%20%20%20%20%20%20%20%20%20--%201%20bit%20vs%20TINYINT%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Efficient data types for indexing:
user_id INT NOT NULL,           -- 4 bytes vs BIGINT 8 bytes
status ENUM('active','inactive'), -- 1 byte vs VARCHAR
created_date DATE,              -- 3 bytes vs DATETIME 8 bytes
is_verified BOOLEAN             -- 1 bit vs TINYINT
</code></pre>
</div>

<p><strong>3. Column Order in Composite Indexes:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Optimal%20order%3A%20Most%20selective%20first%0ACREATE%20INDEX%20idx_user_search%20ON%20users%20(%0A%20%20%20%20status%2C%20%20%20%20%20%20%20%20--%20High%20selectivity%20(many%20statuses)%0A%20%20%20%20created_date%2C%20%20--%20Medium%20selectivity%20%20%0A%20%20%20%20user_type%20%20%20%20%20%20--%20Low%20selectivity%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Optimal order: Most selective first
CREATE INDEX idx_user_search ON users (
    status,        -- High selectivity (many statuses)
    created_date,  -- Medium selectivity  
    user_type      -- Low selectivity
);
</code></pre>
</div>

<p><strong>4. Normalization vs. Denormalization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Normalized%20(better%20for%20writes)%3A%0ACREATE%20TABLE%20orders%20(id%2C%20customer_id%2C%20total)%3B%0ACREATE%20TABLE%20customers%20(id%2C%20name%2C%20email)%3B%0A%0A--%20Denormalized%20(better%20for%20reads)%3A%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%2C%20%0A%20%20%20%20customer_id%2C%20%0A%20%20%20%20customer_name%2C%20%20--%20Denormalized%20for%20faster%20joins%0A%20%20%20%20customer_email%2C%20--%20Denormalized%20for%20faster%20joins%0A%20%20%20%20total%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Normalized (better for writes):
CREATE TABLE orders (id, customer_id, total);
CREATE TABLE customers (id, name, email);

-- Denormalized (better for reads):
CREATE TABLE orders (
    id, 
    customer_id, 
    customer_name,  -- Denormalized for faster joins
    customer_email, -- Denormalized for faster joins
    total
);
</code></pre>
</div>

<p><strong>Schema Optimization Strategies:</strong></p>

<p><strong>1. Vertical Partitioning:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Split%20wide%20tables%3A%0A--%20Hot%20columns%20(frequently%20accessed)%3A%0ACREATE%20TABLE%20users_core%20(id%2C%20email%2C%20status%2C%20last_login)%3B%0A%0A--%20Cold%20columns%20(rarely%20accessed)%3A%0ACREATE%20TABLE%20users_profile%20(id%2C%20bio%2C%20preferences%2C%20settings)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Split wide tables:
-- Hot columns (frequently accessed):
CREATE TABLE users_core (id, email, status, last_login);

-- Cold columns (rarely accessed):
CREATE TABLE users_profile (id, bio, preferences, settings);
</code></pre>
</div>

<p><strong>2. Horizontal Partitioning:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20date%20for%20time-series%20data%3A%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(order_date))%20(%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by date for time-series data:
CREATE TABLE orders (
    id INT,
    customer_id INT,
    order_date DATE,
    total DECIMAL(10,2)
) PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025)
);
</code></pre>
</div>

<p><strong>3. Index-Only Table Design:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Design%20tables%20to%20support%20covering%20indexes%3A%0ACREATE%20TABLE%20user_activity%20(%0A%20%20%20%20user_id%20INT%2C%0A%20%20%20%20activity_date%20DATE%2C%0A%20%20%20%20activity_type%20VARCHAR(50)%2C%0A%20%20%20%20activity_count%20INT%2C%0A%20%20%20%20INDEX%20idx_covering%20(user_id%2C%20activity_date%2C%20activity_type%2C%20activity_count)%0A)%3B%0A--%20Queries%20can%20be%20satisfied%20entirely%20from%20index%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Design tables to support covering indexes:
CREATE TABLE user_activity (
    user_id INT,
    activity_date DATE,
    activity_type VARCHAR(50),
    activity_count INT,
    INDEX idx_covering (user_id, activity_date, activity_type, activity_count)
);
-- Queries can be satisfied entirely from index
</code></pre>
</div>

<h2 id="-346-what-are-stored-procedures-and-their-advantages-disadvantages-">**346. What are stored procedures and their advantages/disadvantages?**</h2>

<p><strong>Answer:</strong> Stored procedures are precompiled SQL code blocks stored in the database that can be executed with parameters.</p>

<p><strong>Advantages:</strong></p>

<p>1. <strong>Performance:</strong> Precompiled and cached execution plans</p>
<p>2. <strong>Security:</strong> Prevent SQL injection, controlled data access</p>
<p>3. <strong>Reusability:</strong> Centralized business logic</p>
<p>4. <strong>Network Traffic:</strong> Reduced data transfer</p>
<p>5. <strong>Consistency:</strong> Standardized operations across applications</p>


<p><strong>Disadvantages:</strong></p>

<p>1. <strong>Database Lock-in:</strong> Vendor-specific syntax</p>
<p>2. <strong>Version Control:</strong> Difficult to track changes</p>
<p>3. <strong>Debugging:</strong> Limited debugging tools</p>
<p>4. <strong>Scalability:</strong> Database server resource consumption</p>
<p>5. <strong>Maintenance:</strong> Complex deployment processes</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20GetUserOrders(IN%20user_id%20INT%2C%20IN%20status%20VARCHAR(20))%0ABEGIN%0A%20%20%20%20SELECT%20o.id%2C%20o.total%2C%20o.created_date%0A%20%20%20%20FROM%20orders%20o%0A%20%20%20%20WHERE%20o.user_id%20%3D%20user_id%20%0A%20%20%20%20AND%20(status%20IS%20NULL%20OR%20o.status%20%3D%20status)%0A%20%20%20%20ORDER%20BY%20o.created_date%20DESC%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%3A%0ACALL%20GetUserOrders(123%2C%20'completed')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE GetUserOrders(IN user_id INT, IN status VARCHAR(20))
BEGIN
    SELECT o.id, o.total, o.created_date
    FROM orders o
    WHERE o.user_id = user_id 
    AND (status IS NULL OR o.status = status)
    ORDER BY o.created_date DESC;
END //
DELIMITER ;

-- Usage:
CALL GetUserOrders(123, 'completed');
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use for complex business logic</p>
<p>- Implement proper error handling</p>
<p>- Document parameters and return values</p>
<p>- Keep procedures focused and small</p>


<p>---</p>

<h2 id="-347-how-do-you-implement-and-use-triggers-">**347. How do you implement and use triggers?**</h2>

<p><strong>Answer:</strong> Triggers are special stored procedures that automatically execute in response to database events (INSERT, UPDATE, DELETE).</p>

<p><strong>Types of Triggers:</strong></p>

<p><strong>1. BEFORE Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Validate%20data%20before%20insertion%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20before_user_insert%0ABEFORE%20INSERT%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Validate%20email%20format%0A%20%20%20%20IF%20NEW.email%20NOT%20REGEXP%20'%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C.%5BA-Za-z%5D%7B2%2C%7D%24'%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Invalid%20email%20format'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Set%20default%20values%0A%20%20%20%20IF%20NEW.created_at%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20NEW.created_at%20%3D%20NOW()%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Validate data before insertion
DELIMITER //
CREATE TRIGGER before_user_insert
BEFORE INSERT ON users
FOR EACH ROW
BEGIN
    -- Validate email format
    IF NEW.email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Invalid email format';
    END IF;
    
    -- Set default values
    IF NEW.created_at IS NULL THEN
        SET NEW.created_at = NOW();
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. AFTER Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Audit%20trail%20after%20updates%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20after_user_update%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20user_audit%20(%0A%20%20%20%20%20%20%20%20user_id%2C%20%0A%20%20%20%20%20%20%20%20old_email%2C%20%0A%20%20%20%20%20%20%20%20new_email%2C%20%0A%20%20%20%20%20%20%20%20changed_by%2C%20%0A%20%20%20%20%20%20%20%20changed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20OLD.email%2C%0A%20%20%20%20%20%20%20%20NEW.email%2C%0A%20%20%20%20%20%20%20%20USER()%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Audit trail after updates
DELIMITER //
CREATE TRIGGER after_user_update
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    INSERT INTO user_audit (
        user_id, 
        old_email, 
        new_email, 
        changed_by, 
        changed_at
    ) VALUES (
        NEW.id,
        OLD.email,
        NEW.email,
        USER(),
        NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. INSTEAD OF Triggers (Views):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Make%20views%20updatable%0ACREATE%20VIEW%20active_users%20AS%0ASELECT%20id%2C%20name%2C%20email%20FROM%20users%20WHERE%20status%20%3D%20'active'%3B%0A%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20instead_of_active_users_update%0AINSTEAD%20OF%20UPDATE%20ON%20active_users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20NEW.name%2C%20email%20%3D%20NEW.email%0A%20%20%20%20WHERE%20id%20%3D%20NEW.id%20AND%20status%20%3D%20'active'%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Make views updatable
CREATE VIEW active_users AS
SELECT id, name, email FROM users WHERE status = 'active';

DELIMITER //
CREATE TRIGGER instead_of_active_users_update
INSTEAD OF UPDATE ON active_users
FOR EACH ROW
BEGIN
    UPDATE users 
    SET name = NEW.name, email = NEW.email
    WHERE id = NEW.id AND status = 'active';
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Common Use Cases:</strong></p>

<p>- <strong>Auditing:</strong> Track data changes</p>
<p>- <strong>Validation:</strong> Complex business rules</p>
<p>- <strong>Logging:</strong> Activity tracking</p>
<p>- <strong>Denormalization:</strong> Maintain calculated fields</p>
<p>- <strong>Security:</strong> Access control</p>


<p><strong>Best Practices:</strong></p>

<p>- Keep triggers simple and fast</p>
<p>- Avoid recursive triggers</p>
<p>- Handle errors gracefully</p>
<p>- Document trigger logic thoroughly</p>


<p>---</p>

<h2 id="-348-what-are-views-and-materialized-views-">**348. What are views and materialized views?**</h2>

<p><strong>Answer:</strong> Views are virtual tables based on queries, while materialized views store query results physically.</p>

<p><strong>Regular Views:</strong></p>

<p><strong>Definition:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20VIEW%20user_summary%20AS%0ASELECT%20%0A%20%20%20%20u.id%2C%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20SUM(o.total)%20as%20total_spent%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE VIEW user_summary AS
SELECT 
    u.id,
    u.name,
    u.email,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name, u.email;
</code></pre>
</div>

<p><strong>Characteristics:</strong></p>

<p>- Virtual table (no data storage)</p>
<p>- Query executed each time view is accessed</p>
<p>- Always shows current data</p>
<p>- Can be updatable under certain conditions</p>


<p><strong>Materialized Views (MySQL doesn't support natively):</strong></p>

<p><strong>Workaround Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20table%20to%20store%20materialized%20data%0ACREATE%20TABLE%20mv_user_summary%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20order_count%20INT%2C%0A%20%20%20%20total_spent%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_updated%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Populate%20materialized%20view%0AINSERT%20INTO%20mv_user_summary%20%0ASELECT%20%0A%20%20%20%20u.id%2C%20u.name%2C%20u.email%2C%0A%20%20%20%20COUNT(o.id)%2C%20SUM(o.total)%2C%0A%20%20%20%20NOW()%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A%0A--%20Refresh%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20RefreshUserSummary()%0ABEGIN%0A%20%20%20%20TRUNCATE%20TABLE%20mv_user_summary%3B%0A%20%20%20%20INSERT%20INTO%20mv_user_summary%20%0A%20%20%20%20SELECT%20u.id%2C%20u.name%2C%20u.email%2C%20COUNT(o.id)%2C%20SUM(o.total)%2C%20NOW()%0A%20%20%20%20FROM%20users%20u%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0A%20%20%20%20GROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create table to store materialized data
CREATE TABLE mv_user_summary (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    order_count INT,
    total_spent DECIMAL(10,2),
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Populate materialized view
INSERT INTO mv_user_summary 
SELECT 
    u.id, u.name, u.email,
    COUNT(o.id), SUM(o.total),
    NOW()
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name, u.email;

-- Refresh procedure
DELIMITER //
CREATE PROCEDURE RefreshUserSummary()
BEGIN
    TRUNCATE TABLE mv_user_summary;
    INSERT INTO mv_user_summary 
    SELECT u.id, u.name, u.email, COUNT(o.id), SUM(o.total), NOW()
    FROM users u
    LEFT JOIN orders o ON u.id = o.user_id
    GROUP BY u.id, u.name, u.email;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>When to Use:</strong></p>

<p>- <strong>Views:</strong> Simple queries, always current data needed</p>
<p>- <strong>Materialized Views:</strong> Complex aggregations, acceptable data lag</p>


<p>---</p>

<h2 id="-349-how-do-you-work-with-json-data-in-mysql-">**349. How do you work with JSON data in MySQL?**</h2>

<p><strong>Answer:</strong> MySQL provides extensive JSON support with native data type and specialized functions.</p>

<p><strong>JSON Data Type:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20attributes%20JSON%2C%0A%20%20%20%20metadata%20JSON%0A)%3B%0A%0A--%20Insert%20JSON%20data%0AINSERT%20INTO%20products%20(id%2C%20name%2C%20attributes)%20VALUES%0A(1%2C%20'Laptop'%2C%20'%7B%22brand%22%3A%20%22Dell%22%2C%20%22ram%22%3A%20%2216GB%22%2C%20%22storage%22%3A%20%22512GB%20SSD%22%7D')%2C%0A(2%2C%20'Phone'%2C%20'%7B%22brand%22%3A%20%22Apple%22%2C%20%22model%22%3A%20%22iPhone%2014%22%2C%20%22color%22%3A%20%22blue%22%7D')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255),
    attributes JSON,
    metadata JSON
);

-- Insert JSON data
INSERT INTO products (id, name, attributes) VALUES
(1, 'Laptop', '{"brand": "Dell", "ram": "16GB", "storage": "512GB SSD"}'),
(2, 'Phone', '{"brand": "Apple", "model": "iPhone 14", "color": "blue"}');
</code></pre>
</div>

<p><strong>JSON Functions:</strong></p>

<p><strong>1. Extraction Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Extract%20specific%20values%0ASELECT%20%0A%20%20%20%20name%2C%0A%20%20%20%20JSON_EXTRACT(attributes%2C%20'%24.brand')%20as%20brand%2C%0A%20%20%20%20attributes-%3E%3E'%24.ram'%20as%20ram%2C%20%20--%20Shorthand%20syntax%0A%20%20%20%20attributes-%3E'%24.storage'%20as%20storage%0AFROM%20products%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Extract specific values
SELECT 
    name,
    JSON_EXTRACT(attributes, '$.brand') as brand,
    attributes-&gt;&gt;'$.ram' as ram,  -- Shorthand syntax
    attributes-&gt;'$.storage' as storage
FROM products;
</code></pre>
</div>

<p><strong>2. Modification Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Update%20JSON%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_SET(attributes%2C%20'%24.warranty'%2C%20'2%20years')%0AWHERE%20id%20%3D%201%3B%0A%0A--%20Add%20new%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_INSERT(attributes%2C%20'%24.price'%2C%20999.99)%0AWHERE%20id%20%3D%201%3B%0A%0A--%20Remove%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_REMOVE(attributes%2C%20'%24.color')%0AWHERE%20id%20%3D%202%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Update JSON fields
UPDATE products 
SET attributes = JSON_SET(attributes, '$.warranty', '2 years')
WHERE id = 1;

-- Add new fields
UPDATE products 
SET attributes = JSON_INSERT(attributes, '$.price', 999.99)
WHERE id = 1;

-- Remove fields
UPDATE products 
SET attributes = JSON_REMOVE(attributes, '$.color')
WHERE id = 2;
</code></pre>
</div>

<p><strong>3. Search Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Search%20within%20JSON%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_EXTRACT(attributes%2C%20'%24.brand')%20%3D%20'Dell'%3B%0A%0A--%20Search%20for%20key%20existence%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_CONTAINS_PATH(attributes%2C%20'one'%2C%20'%24.warranty')%3B%0A%0A--%20Search%20array%20values%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_CONTAINS(attributes%2C%20'%22blue%22'%2C%20'%24.colors')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Search within JSON
SELECT * FROM products 
WHERE JSON_EXTRACT(attributes, '$.brand') = 'Dell';

-- Search for key existence
SELECT * FROM products 
WHERE JSON_CONTAINS_PATH(attributes, 'one', '$.warranty');

-- Search array values
SELECT * FROM products 
WHERE JSON_CONTAINS(attributes, '"blue"', '$.colors');
</code></pre>
</div>

<p><strong>JSON Indexing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20functional%20index%20on%20JSON%20field%0ACREATE%20INDEX%20idx_brand%20ON%20products%20((JSON_EXTRACT(attributes%2C%20'%24.brand')))%3B%0A%0A--%20Create%20generated%20column%20for%20better%20performance%0AALTER%20TABLE%20products%20%0AADD%20COLUMN%20brand%20VARCHAR(50)%20AS%20(JSON_EXTRACT(attributes%2C%20'%24.brand'))%3B%0ACREATE%20INDEX%20idx_generated_brand%20ON%20products%20(brand)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create functional index on JSON field
CREATE INDEX idx_brand ON products ((JSON_EXTRACT(attributes, '$.brand')));

-- Create generated column for better performance
ALTER TABLE products 
ADD COLUMN brand VARCHAR(50) AS (JSON_EXTRACT(attributes, '$.brand'));
CREATE INDEX idx_generated_brand ON products (brand);
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use generated columns for frequently queried JSON fields</p>
<p>- Index JSON paths that are commonly searched</p>
<p>- Validate JSON structure in application layer</p>
<p>- Consider normalization for highly structured data</p>


<p>---</p>

<h2 id="-350-what-are-window-functions-and-how-do-you-use-them-">**350. What are window functions and how do you use them?**</h2>

<p><strong>Answer:</strong> Window functions perform calculations across related rows without grouping them, providing analytical capabilities.</p>

<p><strong>Basic Syntax:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20column1%2C%0A%20%20%20%20window_function()%20OVER%20(%0A%20%20%20%20%20%20%20%20%5BPARTITION%20BY%20column2%5D%0A%20%20%20%20%20%20%20%20%5BORDER%20BY%20column3%5D%0A%20%20%20%20%20%20%20%20%5BROWS%2FRANGE%20frame_specification%5D%0A%20%20%20%20)%0AFROM%20table%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    column1,
    window_function() OVER (
        [PARTITION BY column2]
        [ORDER BY column3]
        [ROWS/RANGE frame_specification]
    )
FROM table;
</code></pre>
</div>

<p><strong>Common Window Functions:</strong></p>

<p><strong>1. Ranking Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20employee_id%2C%0A%20%20%20%20department%2C%0A%20%20%20%20salary%2C%0A%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20row_num%2C%0A%20%20%20%20RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20rank_pos%2C%0A%20%20%20%20DENSE_RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20dense_rank%2C%0A%20%20%20%20PERCENT_RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20percent_rank%0AFROM%20employees%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    employee_id,
    department,
    salary,
    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as row_num,
    RANK() OVER (PARTITION BY department ORDER BY salary DESC) as rank_pos,
    DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dense_rank,
    PERCENT_RANK() OVER (PARTITION BY department ORDER BY salary DESC) as percent_rank
FROM employees;
</code></pre>
</div>

<p><strong>2. Aggregate Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20order_date%2C%0A%20%20%20%20daily_sales%2C%0A%20%20%20%20SUM(daily_sales)%20OVER%20(ORDER%20BY%20order_date)%20as%20running_total%2C%0A%20%20%20%20AVG(daily_sales)%20OVER%20(ORDER%20BY%20order_date%20ROWS%206%20PRECEDING)%20as%20moving_avg_7days%2C%0A%20%20%20%20COUNT(*)%20OVER%20(PARTITION%20BY%20MONTH(order_date))%20as%20monthly_count%0AFROM%20daily_sales%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    order_date,
    daily_sales,
    SUM(daily_sales) OVER (ORDER BY order_date) as running_total,
    AVG(daily_sales) OVER (ORDER BY order_date ROWS 6 PRECEDING) as moving_avg_7days,
    COUNT(*) OVER (PARTITION BY MONTH(order_date)) as monthly_count
FROM daily_sales;
</code></pre>
</div>

<p><strong>3. Value Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20employee_id%2C%0A%20%20%20%20salary%2C%0A%20%20%20%20LAG(salary%2C%201)%20OVER%20(ORDER%20BY%20hire_date)%20as%20prev_salary%2C%0A%20%20%20%20LEAD(salary%2C%201)%20OVER%20(ORDER%20BY%20hire_date)%20as%20next_salary%2C%0A%20%20%20%20FIRST_VALUE(salary)%20OVER%20(ORDER%20BY%20hire_date)%20as%20first_salary%2C%0A%20%20%20%20LAST_VALUE(salary)%20OVER%20(ORDER%20BY%20hire_date%20ROWS%20UNBOUNDED%20FOLLOWING)%20as%20last_salary%0AFROM%20employees%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    employee_id,
    salary,
    LAG(salary, 1) OVER (ORDER BY hire_date) as prev_salary,
    LEAD(salary, 1) OVER (ORDER BY hire_date) as next_salary,
    FIRST_VALUE(salary) OVER (ORDER BY hire_date) as first_salary,
    LAST_VALUE(salary) OVER (ORDER BY hire_date ROWS UNBOUNDED FOLLOWING) as last_salary
FROM employees;
</code></pre>
</div>

<p><strong>Frame Specifications:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Different%20frame%20types%3A%0AROWS%20BETWEEN%20UNBOUNDED%20PRECEDING%20AND%20CURRENT%20ROW%20%20--%20From%20start%20to%20current%0AROWS%20BETWEEN%202%20PRECEDING%20AND%202%20FOLLOWING%20%20%20%20%20%20%20%20%20%20--%205-row%20window%0ARANGE%20BETWEEN%20INTERVAL%201%20MONTH%20PRECEDING%20AND%20CURRENT%20ROW%20%20--%20Date%20range%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Different frame types:
ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW  -- From start to current
ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING          -- 5-row window
RANGE BETWEEN INTERVAL 1 MONTH PRECEDING AND CURRENT ROW  -- Date range
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Top N per Group:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Top%203%20products%20per%20category%20by%20sales%0ASELECT%20category%2C%20product_name%2C%20sales%0AFROM%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20category%2C%20%0A%20%20%20%20%20%20%20%20product_name%2C%20%0A%20%20%20%20%20%20%20%20sales%2C%0A%20%20%20%20%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20category%20ORDER%20BY%20sales%20DESC)%20as%20rn%0A%20%20%20%20FROM%20products%0A)%20ranked%0AWHERE%20rn%20%3C%3D%203%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Top 3 products per category by sales
SELECT category, product_name, sales
FROM (
    SELECT 
        category, 
        product_name, 
        sales,
        ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as rn
    FROM products
) ranked
WHERE rn &lt;= 3;
</code></pre>
</div>

<p><strong>2. Running Calculations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Running%20total%20and%20percentage%20of%20total%0ASELECT%20%0A%20%20%20%20month%2C%0A%20%20%20%20revenue%2C%0A%20%20%20%20SUM(revenue)%20OVER%20(ORDER%20BY%20month)%20as%20running_total%2C%0A%20%20%20%20revenue%20%2F%20SUM(revenue)%20OVER%20()%20*%20100%20as%20pct_of_total%0AFROM%20monthly_revenue%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Running total and percentage of total
SELECT 
    month,
    revenue,
    SUM(revenue) OVER (ORDER BY month) as running_total,
    revenue / SUM(revenue) OVER () * 100 as pct_of_total
FROM monthly_revenue;
</code></pre>
</div>

<p>---</p>

<h2 id="-351-how-do-you-implement-recursive-queries-with-ctes-">**351. How do you implement recursive queries with CTEs?**</h2>

<p><strong>Answer:</strong> Common Table Expressions (CTEs) with recursion solve hierarchical and tree-structured data problems.</p>

<p><strong>Basic Recursive CTE Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="WITH%20RECURSIVE%20cte_name%20AS%20(%0A%20%20%20%20--%20Anchor%20member%20(base%20case)%0A%20%20%20%20SELECT%20initial_query%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%20member%0A%20%20%20%20SELECT%20recursive_query%0A%20%20%20%20FROM%20cte_name%0A%20%20%20%20WHERE%20termination_condition%0A)%0ASELECT%20*%20FROM%20cte_name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">WITH RECURSIVE cte_name AS (
    -- Anchor member (base case)
    SELECT initial_query
    
    UNION ALL
    
    -- Recursive member
    SELECT recursive_query
    FROM cte_name
    WHERE termination_condition
)
SELECT * FROM cte_name;
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Organizational Hierarchy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20structure%3A%0ACREATE%20TABLE%20employees%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20manager_id%20INT%2C%0A%20%20%20%20FOREIGN%20KEY%20(manager_id)%20REFERENCES%20employees(id)%0A)%3B%0A%0A--%20Find%20all%20subordinates%20of%20a%20manager%0AWITH%20RECURSIVE%20employee_hierarchy%20AS%20(%0A%20%20%20%20--%20Anchor%3A%20Start%20with%20the%20manager%0A%20%20%20%20SELECT%20id%2C%20name%2C%20manager_id%2C%200%20as%20level%0A%20%20%20%20FROM%20employees%20%0A%20%20%20%20WHERE%20id%20%3D%201%20%20--%20CEO%20or%20specific%20manager%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%3A%20Find%20direct%20reports%0A%20%20%20%20SELECT%20e.id%2C%20e.name%2C%20e.manager_id%2C%20eh.level%20%2B%201%0A%20%20%20%20FROM%20employees%20e%0A%20%20%20%20INNER%20JOIN%20employee_hierarchy%20eh%20ON%20e.manager_id%20%3D%20eh.id%0A%20%20%20%20WHERE%20eh.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A)%0ASELECT%20%0A%20%20%20%20CONCAT(REPEAT('%20%20'%2C%20level)%2C%20name)%20as%20hierarchy%2C%0A%20%20%20%20level%0AFROM%20employee_hierarchy%0AORDER%20BY%20level%2C%20name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table structure:
CREATE TABLE employees (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    manager_id INT,
    FOREIGN KEY (manager_id) REFERENCES employees(id)
);

-- Find all subordinates of a manager
WITH RECURSIVE employee_hierarchy AS (
    -- Anchor: Start with the manager
    SELECT id, name, manager_id, 0 as level
    FROM employees 
    WHERE id = 1  -- CEO or specific manager
    
    UNION ALL
    
    -- Recursive: Find direct reports
    SELECT e.id, e.name, e.manager_id, eh.level + 1
    FROM employees e
    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id
    WHERE eh.level &lt; 10  -- Prevent infinite recursion
)
SELECT 
    CONCAT(REPEAT('  ', level), name) as hierarchy,
    level
FROM employee_hierarchy
ORDER BY level, name;
</code></pre>
</div>

<p><strong>2. Category Tree Navigation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Product%20categories%20with%20parent-child%20relationships%0AWITH%20RECURSIVE%20category_path%20AS%20(%0A%20%20%20%20--%20Anchor%3A%20Root%20categories%0A%20%20%20%20SELECT%20id%2C%20name%2C%20parent_id%2C%20name%20as%20path%2C%200%20as%20depth%0A%20%20%20%20FROM%20categories%20%0A%20%20%20%20WHERE%20parent_id%20IS%20NULL%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%3A%20Child%20categories%0A%20%20%20%20SELECT%20c.id%2C%20c.name%2C%20c.parent_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20CONCAT(cp.path%2C%20'%20%3E%20'%2C%20c.name)%20as%20path%2C%0A%20%20%20%20%20%20%20%20%20%20%20cp.depth%20%2B%201%0A%20%20%20%20FROM%20categories%20c%0A%20%20%20%20INNER%20JOIN%20category_path%20cp%20ON%20c.parent_id%20%3D%20cp.id%0A%20%20%20%20WHERE%20cp.depth%20%3C%205%20%20--%20Limit%20depth%0A)%0ASELECT%20id%2C%20name%2C%20path%2C%20depth%0AFROM%20category_path%0AORDER%20BY%20path%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Product categories with parent-child relationships
WITH RECURSIVE category_path AS (
    -- Anchor: Root categories
    SELECT id, name, parent_id, name as path, 0 as depth
    FROM categories 
    WHERE parent_id IS NULL
    
    UNION ALL
    
    -- Recursive: Child categories
    SELECT c.id, c.name, c.parent_id, 
           CONCAT(cp.path, ' &gt; ', c.name) as path,
           cp.depth + 1
    FROM categories c
    INNER JOIN category_path cp ON c.parent_id = cp.id
    WHERE cp.depth &lt; 5  -- Limit depth
)
SELECT id, name, path, depth
FROM category_path
ORDER BY path;
</code></pre>
</div>

<p><strong>3. Graph Traversal:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20all%20connected%20nodes%20in%20a%20network%0AWITH%20RECURSIVE%20connected_nodes%20AS%20(%0A%20%20%20%20--%20Start%20from%20specific%20node%0A%20%20%20%20SELECT%20node_id%2C%20connected_to%2C%201%20as%20distance%0A%20%20%20%20FROM%20connections%20%0A%20%20%20%20WHERE%20node_id%20%3D%20'A'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Follow%20connections%0A%20%20%20%20SELECT%20c.node_id%2C%20c.connected_to%2C%20cn.distance%20%2B%201%0A%20%20%20%20FROM%20connections%20c%0A%20%20%20%20INNER%20JOIN%20connected_nodes%20cn%20ON%20c.node_id%20%3D%20cn.connected_to%0A%20%20%20%20WHERE%20cn.distance%20%3C%206%20%20--%20Limit%20traversal%20depth%0A)%0ASELECT%20DISTINCT%20connected_to%20as%20reachable_nodes%2C%20MIN(distance)%20as%20min_distance%0AFROM%20connected_nodes%0AGROUP%20BY%20connected_to%0AORDER%20BY%20min_distance%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find all connected nodes in a network
WITH RECURSIVE connected_nodes AS (
    -- Start from specific node
    SELECT node_id, connected_to, 1 as distance
    FROM connections 
    WHERE node_id = 'A'
    
    UNION ALL
    
    -- Follow connections
    SELECT c.node_id, c.connected_to, cn.distance + 1
    FROM connections c
    INNER JOIN connected_nodes cn ON c.node_id = cn.connected_to
    WHERE cn.distance &lt; 6  -- Limit traversal depth
)
SELECT DISTINCT connected_to as reachable_nodes, MIN(distance) as min_distance
FROM connected_nodes
GROUP BY connected_to
ORDER BY min_distance;
</code></pre>
</div>

<p><strong>4. Time Series Generation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generate%20date%20series%0AWITH%20RECURSIVE%20date_series%20AS%20(%0A%20%20%20%20SELECT%20DATE('2024-01-01')%20as%20date_value%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20DATE_ADD(date_value%2C%20INTERVAL%201%20DAY)%0A%20%20%20%20FROM%20date_series%0A%20%20%20%20WHERE%20date_value%20%3C%20DATE('2024-12-31')%0A)%0ASELECT%20date_value%2C%20DAYNAME(date_value)%20as%20day_name%0AFROM%20date_series%0AWHERE%20DAYOFWEEK(date_value)%20IN%20(1%2C%207)%3B%20%20--%20Weekends%20only%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generate date series
WITH RECURSIVE date_series AS (
    SELECT DATE('2024-01-01') as date_value
    
    UNION ALL
    
    SELECT DATE_ADD(date_value, INTERVAL 1 DAY)
    FROM date_series
    WHERE date_value &lt; DATE('2024-12-31')
)
SELECT date_value, DAYNAME(date_value) as day_name
FROM date_series
WHERE DAYOFWEEK(date_value) IN (1, 7);  -- Weekends only
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Always include termination conditions</p>
<p>- Limit recursion depth to prevent infinite loops</p>
<p>- Index foreign key columns used in joins</p>
<p>- Consider iterative approaches for very deep hierarchies</p>


<p>---</p>

<h2 id="-352-what-are-user-defined-functions-udfs-">**352. What are user-defined functions (UDFs)?**</h2>

<p><strong>Answer:</strong> User-Defined Functions are custom functions that extend MySQL's built-in function library, allowing reusable logic encapsulation.</p>

<p><strong>Types of UDFs:</strong></p>

<p><strong>1. Scalar Functions (Return single value):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CalculateAge(birth_date%20DATE)%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20TIMESTAMPDIFF(YEAR%2C%20birth_date%2C%20CURDATE())%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%3A%0ASELECT%20name%2C%20birth_date%2C%20CalculateAge(birth_date)%20as%20age%0AFROM%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CalculateAge(birth_date DATE)
RETURNS INT
READS SQL DATA
DETERMINISTIC
BEGIN
    RETURN TIMESTAMPDIFF(YEAR, birth_date, CURDATE());
END //
DELIMITER ;

-- Usage:
SELECT name, birth_date, CalculateAge(birth_date) as age
FROM users;
</code></pre>
</div>

<p><strong>2. Table Functions (MySQL doesn't support, but can simulate):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Workaround%20using%20stored%20procedure%20with%20temporary%20table%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20GetUsersByAge(IN%20min_age%20INT%2C%20IN%20max_age%20INT)%0ABEGIN%0A%20%20%20%20SELECT%20*%20FROM%20users%20%0A%20%20%20%20WHERE%20CalculateAge(birth_date)%20BETWEEN%20min_age%20AND%20max_age%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Workaround using stored procedure with temporary table
DELIMITER //
CREATE PROCEDURE GetUsersByAge(IN min_age INT, IN max_age INT)
BEGIN
    SELECT * FROM users 
    WHERE CalculateAge(birth_date) BETWEEN min_age AND max_age;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Function Characteristics:</strong></p>

<p><strong>1. Deterministic vs Non-deterministic:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Deterministic%20(same%20input%20%3D%20same%20output)%0ACREATE%20FUNCTION%20FormatCurrency(amount%20DECIMAL(10%2C2))%0ARETURNS%20VARCHAR(20)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20CONCAT('%24'%2C%20FORMAT(amount%2C%202))%3B%0AEND%20%2F%2F%0A%0A--%20Non-deterministic%20(output%20can%20vary)%0ACREATE%20FUNCTION%20GetCurrentTimestamp()%0ARETURNS%20TIMESTAMP%0ANOT%20DETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20NOW()%3B%0AEND%20%2F%2F%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Deterministic (same input = same output)
CREATE FUNCTION FormatCurrency(amount DECIMAL(10,2))
RETURNS VARCHAR(20)
DETERMINISTIC
BEGIN
    RETURN CONCAT('$', FORMAT(amount, 2));
END //

-- Non-deterministic (output can vary)
CREATE FUNCTION GetCurrentTimestamp()
RETURNS TIMESTAMP
NOT DETERMINISTIC
BEGIN
    RETURN NOW();
END //
</code></pre>
</div>

<p><strong>2. Data Access Levels:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20NO%20SQL%3A%20No%20database%20access%0ACREATE%20FUNCTION%20SimpleCalculation(x%20INT%2C%20y%20INT)%0ARETURNS%20INT%0ANO%20SQL%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20x%20*%20y%20%2B%2010%3B%0AEND%20%2F%2F%0A%0A--%20READS%20SQL%20DATA%3A%20Read-only%20access%0ACREATE%20FUNCTION%20GetUserCount()%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20user_count%20INT%3B%0A%20%20%20%20SELECT%20COUNT(*)%20INTO%20user_count%20FROM%20users%3B%0A%20%20%20%20RETURN%20user_count%3B%0AEND%20%2F%2F%0A%0A--%20MODIFIES%20SQL%20DATA%3A%20Can%20modify%20data%0ACREATE%20FUNCTION%20LogAndReturn(message%20VARCHAR(255))%0ARETURNS%20VARCHAR(255)%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20function_log%20(message%2C%20called_at)%20VALUES%20(message%2C%20NOW())%3B%0A%20%20%20%20RETURN%20CONCAT('Logged%3A%20'%2C%20message)%3B%0AEND%20%2F%2F%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- NO SQL: No database access
CREATE FUNCTION SimpleCalculation(x INT, y INT)
RETURNS INT
NO SQL
DETERMINISTIC
BEGIN
    RETURN x * y + 10;
END //

-- READS SQL DATA: Read-only access
CREATE FUNCTION GetUserCount()
RETURNS INT
READS SQL DATA
BEGIN
    DECLARE user_count INT;
    SELECT COUNT(*) INTO user_count FROM users;
    RETURN user_count;
END //

-- MODIFIES SQL DATA: Can modify data
CREATE FUNCTION LogAndReturn(message VARCHAR(255))
RETURNS VARCHAR(255)
MODIFIES SQL DATA
BEGIN
    INSERT INTO function_log (message, called_at) VALUES (message, NOW());
    RETURN CONCAT('Logged: ', message);
END //
</code></pre>
</div>

<p><strong>Advanced Examples:</strong></p>

<p><strong>1. Business Logic Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CalculateDiscount(%0A%20%20%20%20customer_type%20VARCHAR(20)%2C%0A%20%20%20%20order_amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20is_member%20BOOLEAN%0A)%0ARETURNS%20DECIMAL(5%2C2)%0AREADS%20SQL%20DATA%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20discount%20DECIMAL(5%2C2)%20DEFAULT%200.00%3B%0A%20%20%20%20%0A%20%20%20%20--%20Base%20discount%20by%20customer%20type%0A%20%20%20%20CASE%20customer_type%0A%20%20%20%20%20%20%20%20WHEN%20'premium'%20THEN%20SET%20discount%20%3D%200.15%3B%0A%20%20%20%20%20%20%20%20WHEN%20'gold'%20THEN%20SET%20discount%20%3D%200.10%3B%0A%20%20%20%20%20%20%20%20WHEN%20'silver'%20THEN%20SET%20discount%20%3D%200.05%3B%0A%20%20%20%20%20%20%20%20ELSE%20SET%20discount%20%3D%200.00%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Additional%20discount%20for%20large%20orders%0A%20%20%20%20IF%20order_amount%20%3E%201000%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%20discount%20%2B%200.05%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Member%20bonus%0A%20%20%20%20IF%20is_member%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%20discount%20%2B%200.02%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Cap%20maximum%20discount%0A%20%20%20%20IF%20discount%20%3E%200.25%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%200.25%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20discount%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CalculateDiscount(
    customer_type VARCHAR(20),
    order_amount DECIMAL(10,2),
    is_member BOOLEAN
)
RETURNS DECIMAL(5,2)
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE discount DECIMAL(5,2) DEFAULT 0.00;
    
    -- Base discount by customer type
    CASE customer_type
        WHEN 'premium' THEN SET discount = 0.15;
        WHEN 'gold' THEN SET discount = 0.10;
        WHEN 'silver' THEN SET discount = 0.05;
        ELSE SET discount = 0.00;
    END CASE;
    
    -- Additional discount for large orders
    IF order_amount &gt; 1000 THEN
        SET discount = discount + 0.05;
    END IF;
    
    -- Member bonus
    IF is_member THEN
        SET discount = discount + 0.02;
    END IF;
    
    -- Cap maximum discount
    IF discount &gt; 0.25 THEN
        SET discount = 0.25;
    END IF;
    
    RETURN discount;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. String Processing Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CleanPhoneNumber(phone%20VARCHAR(20))%0ARETURNS%20VARCHAR(15)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20cleaned%20VARCHAR(15)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20all%20non-numeric%20characters%0A%20%20%20%20SET%20cleaned%20%3D%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%5D'%2C%20'')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Format%20as%20(XXX)%20XXX-XXXX%20if%2010%20digits%0A%20%20%20%20IF%20LENGTH(cleaned)%20%3D%2010%20THEN%0A%20%20%20%20%20%20%20%20SET%20cleaned%20%3D%20CONCAT('('%2C%20SUBSTRING(cleaned%2C%201%2C%203)%2C%20')%20'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(cleaned%2C%204%2C%203)%2C%20'-'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(cleaned%2C%207%2C%204))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20cleaned%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CleanPhoneNumber(phone VARCHAR(20))
RETURNS VARCHAR(15)
DETERMINISTIC
BEGIN
    DECLARE cleaned VARCHAR(15);
    
    -- Remove all non-numeric characters
    SET cleaned = REGEXP_REPLACE(phone, '[^0-9]', '');
    
    -- Format as (XXX) XXX-XXXX if 10 digits
    IF LENGTH(cleaned) = 10 THEN
        SET cleaned = CONCAT('(', SUBSTRING(cleaned, 1, 3), ') ', 
                           SUBSTRING(cleaned, 4, 3), '-', 
                           SUBSTRING(cleaned, 7, 4));
    END IF;
    
    RETURN cleaned;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Keep functions simple and focused</p>
<p>- Use appropriate data access levels</p>
<p>- Handle NULL inputs gracefully</p>
<p>- Document function purpose and parameters</p>
<p>- Consider performance impact on queries</p>


<p>---</p>

<h2 id="-353-how-do-you-work-with-temporary-tables-">**353. How do you work with temporary tables?**</h2>

<p><strong>Answer:</strong> Temporary tables are session-specific tables that exist only during the database connection, useful for complex data processing.</p>

<p><strong>Types of Temporary Tables:</strong></p>

<p><strong>1. Local Temporary Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20temporary%20table%0ACREATE%20TEMPORARY%20TABLE%20temp_user_stats%20(%0A%20%20%20%20user_id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20order_count%20INT%2C%0A%20%20%20%20total_spent%20DECIMAL(10%2C2)%2C%0A%20%20%20%20avg_order_value%20DECIMAL(10%2C2)%0A)%3B%0A%0A--%20Populate%20with%20complex%20logic%0AINSERT%20INTO%20temp_user_stats%0ASELECT%20%0A%20%20%20%20u.id%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20COALESCE(SUM(o.total)%2C%200)%20as%20total_spent%2C%0A%20%20%20%20COALESCE(AVG(o.total)%2C%200)%20as%20avg_order_value%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AWHERE%20u.created_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%0AGROUP%20BY%20u.id%3B%0A%0A--%20Use%20in%20subsequent%20queries%0ASELECT%20%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20ts.order_count%2C%0A%20%20%20%20ts.total_spent%0AFROM%20users%20u%0AJOIN%20temp_user_stats%20ts%20ON%20u.id%20%3D%20ts.user_id%0AWHERE%20ts.total_spent%20%3E%201000%0AORDER%20BY%20ts.total_spent%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create temporary table
CREATE TEMPORARY TABLE temp_user_stats (
    user_id INT PRIMARY KEY,
    order_count INT,
    total_spent DECIMAL(10,2),
    avg_order_value DECIMAL(10,2)
);

-- Populate with complex logic
INSERT INTO temp_user_stats
SELECT 
    u.id,
    COUNT(o.id) as order_count,
    COALESCE(SUM(o.total), 0) as total_spent,
    COALESCE(AVG(o.total), 0) as avg_order_value
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.created_at &gt;= DATE_SUB(NOW(), INTERVAL 1 YEAR)
GROUP BY u.id;

-- Use in subsequent queries
SELECT 
    u.name,
    u.email,
    ts.order_count,
    ts.total_spent
FROM users u
JOIN temp_user_stats ts ON u.id = ts.user_id
WHERE ts.total_spent &gt; 1000
ORDER BY ts.total_spent DESC;
</code></pre>
</div>

<p><strong>2. Memory-Based Temporary Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TEMPORARY%20TABLE%20temp_calculations%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20result%20DECIMAL(15%2C4)%0A)%20ENGINE%3DMEMORY%3B%0A%0A--%20Faster%20for%20small%20datasets%20that%20fit%20in%20memory%0A--%20Automatically%20uses%20MEMORY%20storage%20engine%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TEMPORARY TABLE temp_calculations (
    id INT PRIMARY KEY,
    result DECIMAL(15,4)
) ENGINE=MEMORY;

-- Faster for small datasets that fit in memory
-- Automatically uses MEMORY storage engine
</code></pre>
</div>

<p><strong>Common Use Cases:</strong></p>

<p><strong>1. Complex Data Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multi-step%20data%20transformation%0ACREATE%20TEMPORARY%20TABLE%20temp_sales_analysis%20(%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20category%20VARCHAR(50)%2C%0A%20%20%20%20monthly_sales%20DECIMAL(12%2C2)%2C%0A%20%20%20%20growth_rate%20DECIMAL(5%2C2)%2C%0A%20%20%20%20rank_in_category%20INT%0A)%3B%0A%0A--%20Step%201%3A%20Calculate%20monthly%20sales%0AINSERT%20INTO%20temp_sales_analysis%20(product_id%2C%20category%2C%20monthly_sales)%0ASELECT%20p.id%2C%20p.category%2C%20SUM(oi.quantity%20*%20oi.price)%0AFROM%20products%20p%0AJOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0AJOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0AWHERE%20o.order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20MONTH)%0AGROUP%20BY%20p.id%2C%20p.category%3B%0A%0A--%20Step%202%3A%20Calculate%20growth%20rates%0AUPDATE%20temp_sales_analysis%20tsa%0AJOIN%20(%0A%20%20%20%20SELECT%20product_id%2C%20SUM(oi.quantity%20*%20oi.price)%20as%20prev_sales%0A%20%20%20%20FROM%20products%20p%0A%20%20%20%20JOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0A%20%20%20%20JOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0A%20%20%20%20WHERE%20o.order_date%20BETWEEN%20DATE_SUB(NOW()%2C%20INTERVAL%202%20MONTH)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20DATE_SUB(NOW()%2C%20INTERVAL%201%20MONTH)%0A%20%20%20%20GROUP%20BY%20product_id%0A)%20prev%20ON%20tsa.product_id%20%3D%20prev.product_id%0ASET%20tsa.growth_rate%20%3D%20((tsa.monthly_sales%20-%20prev.prev_sales)%20%2F%20prev.prev_sales)%20*%20100%3B%0A%0A--%20Step%203%3A%20Add%20rankings%0AUPDATE%20temp_sales_analysis%20tsa%0AJOIN%20(%0A%20%20%20%20SELECT%20product_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20category%20ORDER%20BY%20monthly_sales%20DESC)%20as%20rank_num%0A%20%20%20%20FROM%20temp_sales_analysis%0A)%20ranked%20ON%20tsa.product_id%20%3D%20ranked.product_id%0ASET%20tsa.rank_in_category%20%3D%20ranked.rank_num%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multi-step data transformation
CREATE TEMPORARY TABLE temp_sales_analysis (
    product_id INT,
    category VARCHAR(50),
    monthly_sales DECIMAL(12,2),
    growth_rate DECIMAL(5,2),
    rank_in_category INT
);

-- Step 1: Calculate monthly sales
INSERT INTO temp_sales_analysis (product_id, category, monthly_sales)
SELECT p.id, p.category, SUM(oi.quantity * oi.price)
FROM products p
JOIN order_items oi ON p.id = oi.product_id
JOIN orders o ON oi.order_id = o.id
WHERE o.order_date &gt;= DATE_SUB(NOW(), INTERVAL 1 MONTH)
GROUP BY p.id, p.category;

-- Step 2: Calculate growth rates
UPDATE temp_sales_analysis tsa
JOIN (
    SELECT product_id, SUM(oi.quantity * oi.price) as prev_sales
    FROM products p
    JOIN order_items oi ON p.id = oi.product_id
    JOIN orders o ON oi.order_id = o.id
    WHERE o.order_date BETWEEN DATE_SUB(NOW(), INTERVAL 2 MONTH) 
                           AND DATE_SUB(NOW(), INTERVAL 1 MONTH)
    GROUP BY product_id
) prev ON tsa.product_id = prev.product_id
SET tsa.growth_rate = ((tsa.monthly_sales - prev.prev_sales) / prev.prev_sales) * 100;

-- Step 3: Add rankings
UPDATE temp_sales_analysis tsa
JOIN (
    SELECT product_id, 
           ROW_NUMBER() OVER (PARTITION BY category ORDER BY monthly_sales DESC) as rank_num
    FROM temp_sales_analysis
) ranked ON tsa.product_id = ranked.product_id
SET tsa.rank_in_category = ranked.rank_num;
</code></pre>
</div>

<p><strong>2. Data Import/ETL Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Staging%20table%20for%20data%20validation%0ACREATE%20TEMPORARY%20TABLE%20temp_import_users%20(%0A%20%20%20%20external_id%20VARCHAR(50)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20validation_errors%20TEXT%0A)%3B%0A%0A--%20Load%20raw%20data%0ALOAD%20DATA%20INFILE%20'users.csv'%20INTO%20TABLE%20temp_import_users%0AFIELDS%20TERMINATED%20BY%20'%2C'%20ENCLOSED%20BY%20'%22'%0ALINES%20TERMINATED%20BY%20'%5Cn'%0AIGNORE%201%20ROWS%3B%0A%0A--%20Validate%20and%20clean%20data%0AUPDATE%20temp_import_users%20%0ASET%20validation_errors%20%3D%20CASE%0A%20%20%20%20WHEN%20email%20NOT%20REGEXP%20'%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C.%5BA-Za-z%5D%7B2%2C%7D%24'%20%0A%20%20%20%20%20%20%20%20THEN%20CONCAT(COALESCE(validation_errors%2C%20'')%2C%20'Invalid%20email%3B%20')%0A%20%20%20%20WHEN%20LENGTH(name)%20%3C%202%20%0A%20%20%20%20%20%20%20%20THEN%20CONCAT(COALESCE(validation_errors%2C%20'')%2C%20'Name%20too%20short%3B%20')%0A%20%20%20%20ELSE%20validation_errors%0AEND%3B%0A%0A--%20Insert%20only%20valid%20records%0AINSERT%20INTO%20users%20(external_id%2C%20email%2C%20name%2C%20phone%2C%20status)%0ASELECT%20external_id%2C%20email%2C%20name%2C%20phone%2C%20status%0AFROM%20temp_import_users%0AWHERE%20validation_errors%20IS%20NULL%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Staging table for data validation
CREATE TEMPORARY TABLE temp_import_users (
    external_id VARCHAR(50),
    email VARCHAR(255),
    name VARCHAR(100),
    phone VARCHAR(20),
    status VARCHAR(20),
    validation_errors TEXT
);

-- Load raw data
LOAD DATA INFILE 'users.csv' INTO TABLE temp_import_users
FIELDS TERMINATED BY ',' ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

-- Validate and clean data
UPDATE temp_import_users 
SET validation_errors = CASE
    WHEN email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' 
        THEN CONCAT(COALESCE(validation_errors, ''), 'Invalid email; ')
    WHEN LENGTH(name) &lt; 2 
        THEN CONCAT(COALESCE(validation_errors, ''), 'Name too short; ')
    ELSE validation_errors
END;

-- Insert only valid records
INSERT INTO users (external_id, email, name, phone, status)
SELECT external_id, email, name, phone, status
FROM temp_import_users
WHERE validation_errors IS NULL;
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Temporary tables are stored in tmpdir (usually RAM or fast storage)</p>
<p>- Automatically dropped when session ends</p>
<p>- Can be indexed like regular tables</p>
<p>- Use MEMORY engine for small, frequently accessed temp tables</p>
<p>- Monitor tmp_table_size and max_heap_table_size settings</p>


<p><strong>Best Practices:</strong></p>

<p>- Explicitly drop temporary tables when done: `DROP TEMPORARY TABLE temp_table_name;`</p>
<p>- Use meaningful names with temp_ prefix</p>
<p>- Index temporary tables for complex joins</p>
<p>- Consider CTEs as alternative for simpler cases</p>


<p>---</p>

<h2 id="-354-what-are-database-events-and-how-do-you-schedule-them-">**354. What are database events and how do you schedule them?**</h2>

<p><strong>Answer:</strong> Database events are scheduled tasks that run automatically at specified times, similar to cron jobs but managed within MySQL.</p>

<p><strong>Event Scheduler Setup:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20event%20scheduler%0ASET%20GLOBAL%20event_scheduler%20%3D%20ON%3B%0A%0A--%20Check%20if%20enabled%0ASHOW%20VARIABLES%20LIKE%20'event_scheduler'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable event scheduler
SET GLOBAL event_scheduler = ON;

-- Check if enabled
SHOW VARIABLES LIKE 'event_scheduler';
</code></pre>
</div>

<p><strong>Event Types:</strong></p>

<p><strong>1. One-Time Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Run%20once%20at%20specific%20time%0ACREATE%20EVENT%20cleanup_temp_data%0AON%20SCHEDULE%20AT%20'2024-12-31%2023%3A59%3A59'%0ADO%0A%20%20%20%20DELETE%20FROM%20temp_logs%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Run once at specific time
CREATE EVENT cleanup_temp_data
ON SCHEDULE AT '2024-12-31 23:59:59'
DO
    DELETE FROM temp_logs WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 30 DAY);
</code></pre>
</div>

<p><strong>2. Recurring Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Daily%20cleanup%20at%202%20AM%0ACREATE%20EVENT%20daily_cleanup%0AON%20SCHEDULE%20EVERY%201%20DAY%0ASTARTS%20'2024-01-01%2002%3A00%3A00'%0ADO%0ABEGIN%0A%20%20%20%20--%20Clean%20old%20logs%0A%20%20%20%20DELETE%20FROM%20application_logs%20%0A%20%20%20%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20statistics%0A%20%20%20%20CALL%20UpdateDailyStatistics()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Optimize%20tables%0A%20%20%20%20OPTIMIZE%20TABLE%20users%2C%20orders%2C%20products%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Daily cleanup at 2 AM
CREATE EVENT daily_cleanup
ON SCHEDULE EVERY 1 DAY
STARTS '2024-01-01 02:00:00'
DO
BEGIN
    -- Clean old logs
    DELETE FROM application_logs 
    WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 90 DAY);
    
    -- Update statistics
    CALL UpdateDailyStatistics();
    
    -- Optimize tables
    OPTIMIZE TABLE users, orders, products;
END;
</code></pre>
</div>

<p><strong>3. Complex Scheduling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Weekly%20report%20generation%20every%20Monday%20at%209%20AM%0ACREATE%20EVENT%20weekly_sales_report%0AON%20SCHEDULE%20EVERY%201%20WEEK%0ASTARTS%20'2024-01-01%2009%3A00%3A00'%20%20--%20First%20Monday%0AON%20COMPLETION%20PRESERVE%0AENABLE%0ACOMMENT%20'Generate%20weekly%20sales%20reports'%0ADO%0ABEGIN%0A%20%20%20%20DECLARE%20report_date%20DATE%20DEFAULT%20DATE_SUB(CURDATE()%2C%20INTERVAL%201%20WEEK)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20report%20data%0A%20%20%20%20INSERT%20INTO%20weekly_reports%20(report_date%2C%20total_sales%2C%20order_count%2C%20avg_order_value)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20report_date%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_sales%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20orders%20%0A%20%20%20%20WHERE%20DATE(created_at)%20BETWEEN%20report_date%20AND%20DATE_ADD(report_date%2C%20INTERVAL%206%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Send%20notification%20(would%20typically%20call%20external%20procedure)%0A%20%20%20%20INSERT%20INTO%20notifications%20(type%2C%20message%2C%20created_at)%0A%20%20%20%20VALUES%20('report_generated'%2C%20CONCAT('Weekly%20report%20for%20'%2C%20report_date%2C%20'%20completed')%2C%20NOW())%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Weekly report generation every Monday at 9 AM
CREATE EVENT weekly_sales_report
ON SCHEDULE EVERY 1 WEEK
STARTS '2024-01-01 09:00:00'  -- First Monday
ON COMPLETION PRESERVE
ENABLE
COMMENT 'Generate weekly sales reports'
DO
BEGIN
    DECLARE report_date DATE DEFAULT DATE_SUB(CURDATE(), INTERVAL 1 WEEK);
    
    -- Generate report data
    INSERT INTO weekly_reports (report_date, total_sales, order_count, avg_order_value)
    SELECT 
        report_date,
        SUM(total) as total_sales,
        COUNT(*) as order_count,
        AVG(total) as avg_order_value
    FROM orders 
    WHERE DATE(created_at) BETWEEN report_date AND DATE_ADD(report_date, INTERVAL 6 DAY);
    
    -- Send notification (would typically call external procedure)
    INSERT INTO notifications (type, message, created_at)
    VALUES ('report_generated', CONCAT('Weekly report for ', report_date, ' completed'), NOW());
END;
</code></pre>
</div>

<p><strong>Event Management:</strong></p>

<p><strong>1. View Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Show%20all%20events%0ASHOW%20EVENTS%3B%0A%0A--%20Detailed%20event%20information%0ASELECT%20%0A%20%20%20%20event_name%2C%0A%20%20%20%20event_definition%2C%0A%20%20%20%20interval_value%2C%0A%20%20%20%20interval_field%2C%0A%20%20%20%20status%2C%0A%20%20%20%20last_executed%2C%0A%20%20%20%20next_execution%0AFROM%20information_schema.events%0AWHERE%20event_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Show all events
SHOW EVENTS;

-- Detailed event information
SELECT 
    event_name,
    event_definition,
    interval_value,
    interval_field,
    status,
    last_executed,
    next_execution
FROM information_schema.events
WHERE event_schema = 'your_database';
</code></pre>
</div>

<p><strong>2. Modify Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Disable%20event%0AALTER%20EVENT%20daily_cleanup%20DISABLE%3B%0A%0A--%20Enable%20event%0AALTER%20EVENT%20daily_cleanup%20ENABLE%3B%0A%0A--%20Change%20schedule%0AALTER%20EVENT%20daily_cleanup%0AON%20SCHEDULE%20EVERY%202%20DAY%0ASTARTS%20'2024-01-01%2003%3A00%3A00'%3B%0A%0A--%20Drop%20event%0ADROP%20EVENT%20IF%20EXISTS%20old_cleanup_event%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Disable event
ALTER EVENT daily_cleanup DISABLE;

-- Enable event
ALTER EVENT daily_cleanup ENABLE;

-- Change schedule
ALTER EVENT daily_cleanup
ON SCHEDULE EVERY 2 DAY
STARTS '2024-01-01 03:00:00';

-- Drop event
DROP EVENT IF EXISTS old_cleanup_event;
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Database Maintenance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20EVENT%20monthly_maintenance%0AON%20SCHEDULE%20EVERY%201%20MONTH%0ASTARTS%20'2024-01-01%2001%3A00%3A00'%0ADO%0ABEGIN%0A%20%20%20%20--%20Update%20table%20statistics%0A%20%20%20%20ANALYZE%20TABLE%20users%2C%20orders%2C%20products%2C%20order_items%3B%0A%20%20%20%20%0A%20%20%20%20--%20Rebuild%20fragmented%20indexes%0A%20%20%20%20OPTIMIZE%20TABLE%20users%2C%20orders%2C%20products%2C%20order_items%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clean%20up%20old%20data%0A%20%20%20%20DELETE%20FROM%20audit_logs%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%3B%0A%20%20%20%20DELETE%20FROM%20session_data%20WHERE%20expires_at%20%3C%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20maintenance%20completion%0A%20%20%20%20INSERT%20INTO%20maintenance_log%20(task%2C%20completed_at%2C%20status)%0A%20%20%20%20VALUES%20('monthly_maintenance'%2C%20NOW()%2C%20'completed')%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE EVENT monthly_maintenance
ON SCHEDULE EVERY 1 MONTH
STARTS '2024-01-01 01:00:00'
DO
BEGIN
    -- Update table statistics
    ANALYZE TABLE users, orders, products, order_items;
    
    -- Rebuild fragmented indexes
    OPTIMIZE TABLE users, orders, products, order_items;
    
    -- Clean up old data
    DELETE FROM audit_logs WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 1 YEAR);
    DELETE FROM session_data WHERE expires_at &lt; NOW();
    
    -- Log maintenance completion
    INSERT INTO maintenance_log (task, completed_at, status)
    VALUES ('monthly_maintenance', NOW(), 'completed');
END;
</code></pre>
</div>

<p><strong>2. Data Aggregation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20EVENT%20hourly_metrics_aggregation%0AON%20SCHEDULE%20EVERY%201%20HOUR%0ADO%0ABEGIN%0A%20%20%20%20DECLARE%20current_hour%20DATETIME%20DEFAULT%20DATE_FORMAT(NOW()%2C%20'%25Y-%25m-%25d%20%25H%3A00%3A00')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20hourly%20metrics%0A%20%20%20%20INSERT%20INTO%20hourly_metrics%20(hour%2C%20page_views%2C%20unique_visitors%2C%20orders%2C%20revenue)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20current_hour%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20page_views%2C%0A%20%20%20%20%20%20%20%20COUNT(DISTINCT%20user_id)%20as%20unique_visitors%2C%0A%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20event_type%20%3D%20'order'%20THEN%201%20ELSE%200%20END)%20as%20orders%2C%0A%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20event_type%20%3D%20'order'%20THEN%20event_value%20ELSE%200%20END)%20as%20revenue%0A%20%20%20%20FROM%20user_events%20%0A%20%20%20%20WHERE%20created_at%20%3E%3D%20DATE_SUB(current_hour%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20created_at%20%3C%20current_hour%0A%20%20%20%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20page_views%20%3D%20VALUES(page_views)%2C%0A%20%20%20%20%20%20%20%20unique_visitors%20%3D%20VALUES(unique_visitors)%2C%0A%20%20%20%20%20%20%20%20orders%20%3D%20VALUES(orders)%2C%0A%20%20%20%20%20%20%20%20revenue%20%3D%20VALUES(revenue)%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE EVENT hourly_metrics_aggregation
ON SCHEDULE EVERY 1 HOUR
DO
BEGIN
    DECLARE current_hour DATETIME DEFAULT DATE_FORMAT(NOW(), '%Y-%m-%d %H:00:00');
    
    -- Aggregate hourly metrics
    INSERT INTO hourly_metrics (hour, page_views, unique_visitors, orders, revenue)
    SELECT 
        current_hour,
        COUNT(*) as page_views,
        COUNT(DISTINCT user_id) as unique_visitors,
        SUM(CASE WHEN event_type = 'order' THEN 1 ELSE 0 END) as orders,
        SUM(CASE WHEN event_type = 'order' THEN event_value ELSE 0 END) as revenue
    FROM user_events 
    WHERE created_at &gt;= DATE_SUB(current_hour, INTERVAL 1 HOUR)
    AND created_at &lt; current_hour
    ON DUPLICATE KEY UPDATE
        page_views = VALUES(page_views),
        unique_visitors = VALUES(unique_visitors),
        orders = VALUES(orders),
        revenue = VALUES(revenue);
END;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use ON COMPLETION PRESERVE to keep event definition after execution</p>
<p>- Include error handling in event procedures</p>
<p>- Log event execution for monitoring</p>
<p>- Test events thoroughly before deployment</p>
<p>- Monitor event scheduler performance impact</p>
<p>- Use appropriate privileges for event creation</p>


<p>---</p>

<h2 id="-355-how-do-you-implement-database-partitioning-">**355. How do you implement database partitioning?**</h2>

<p><strong>Answer:</strong> Database partitioning divides large tables into smaller, more manageable pieces while maintaining logical unity.</p>

<p><strong>Types of Partitioning:</strong></p>

<p><strong>1. Range Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20date%20ranges%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20order_date)%20%20--%20Partition%20key%20must%20be%20in%20primary%20key%0A)%20PARTITION%20BY%20RANGE%20(YEAR(order_date))%20(%0A%20%20%20%20PARTITION%20p2021%20VALUES%20LESS%20THAN%20(2022)%2C%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by date ranges
CREATE TABLE orders (
    id INT NOT NULL,
    customer_id INT,
    order_date DATE NOT NULL,
    total DECIMAL(10,2),
    status VARCHAR(20),
    PRIMARY KEY (id, order_date)  -- Partition key must be in primary key
) PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>2. List Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20specific%20values%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20region%20VARCHAR(20)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20region)%0A)%20PARTITION%20BY%20LIST%20COLUMNS(region)%20(%0A%20%20%20%20PARTITION%20p_north%20VALUES%20IN%20('north'%2C%20'northeast'%2C%20'northwest')%2C%0A%20%20%20%20PARTITION%20p_south%20VALUES%20IN%20('south'%2C%20'southeast'%2C%20'southwest')%2C%0A%20%20%20%20PARTITION%20p_east%20VALUES%20IN%20('east'%2C%20'central_east')%2C%0A%20%20%20%20PARTITION%20p_west%20VALUES%20IN%20('west'%2C%20'central_west')%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by specific values
CREATE TABLE users (
    id INT NOT NULL,
    name VARCHAR(100),
    region VARCHAR(20),
    email VARCHAR(255),
    PRIMARY KEY (id, region)
) PARTITION BY LIST COLUMNS(region) (
    PARTITION p_north VALUES IN ('north', 'northeast', 'northwest'),
    PARTITION p_south VALUES IN ('south', 'southeast', 'southwest'),
    PARTITION p_east VALUES IN ('east', 'central_east'),
    PARTITION p_west VALUES IN ('west', 'central_west')
);
</code></pre>
</div>

<p><strong>3. Hash Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Distribute%20data%20evenly%20across%20partitions%0ACREATE%20TABLE%20user_sessions%20(%0A%20%20%20%20id%20BIGINT%20NOT%20NULL%2C%0A%20%20%20%20user_id%20INT%2C%0A%20%20%20%20session_data%20TEXT%2C%0A%20%20%20%20created_at%20TIMESTAMP%2C%0A%20%20%20%20PRIMARY%20KEY%20(id)%0A)%20PARTITION%20BY%20HASH(id)%20PARTITIONS%208%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Distribute data evenly across partitions
CREATE TABLE user_sessions (
    id BIGINT NOT NULL,
    user_id INT,
    session_data TEXT,
    created_at TIMESTAMP,
    PRIMARY KEY (id)
) PARTITION BY HASH(id) PARTITIONS 8;
</code></pre>
</div>

<p><strong>4. Key Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20chooses%20hash%20function%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20category%20VARCHAR(100)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id)%0A)%20PARTITION%20BY%20KEY()%20PARTITIONS%204%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL chooses hash function
CREATE TABLE products (
    id INT NOT NULL,
    name VARCHAR(255),
    category VARCHAR(100),
    price DECIMAL(10,2),
    PRIMARY KEY (id)
) PARTITION BY KEY() PARTITIONS 4;
</code></pre>
</div>

<p><strong>Subpartitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Combine%20partitioning%20methods%0ACREATE%20TABLE%20sales_data%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20sale_date%20DATE%2C%0A%20%20%20%20region%20VARCHAR(20)%2C%0A%20%20%20%20amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20sale_date%2C%20region)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(sale_date))%0ASUBPARTITION%20BY%20HASH(CRC32(region))%0ASUBPARTITIONS%204%20(%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Combine partitioning methods
CREATE TABLE sales_data (
    id INT NOT NULL,
    sale_date DATE,
    region VARCHAR(20),
    amount DECIMAL(10,2),
    PRIMARY KEY (id, sale_date, region)
) PARTITION BY RANGE (YEAR(sale_date))
SUBPARTITION BY HASH(CRC32(region))
SUBPARTITIONS 4 (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>Partition Management:</strong></p>

<p><strong>1. Add Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Add%20new%20partition%20for%202025%0AALTER%20TABLE%20orders%20%0AADD%20PARTITION%20(PARTITION%20p2025%20VALUES%20LESS%20THAN%20(2026))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Add new partition for 2025
ALTER TABLE orders 
ADD PARTITION (PARTITION p2025 VALUES LESS THAN (2026));
</code></pre>
</div>

<p><strong>2. Drop Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Remove%20old%20data%20by%20dropping%20partition%0AALTER%20TABLE%20orders%20DROP%20PARTITION%20p2021%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Remove old data by dropping partition
ALTER TABLE orders DROP PARTITION p2021;
</code></pre>
</div>

<p><strong>3. Reorganize Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Split%20partition%0AALTER%20TABLE%20orders%20%0AREORGANIZE%20PARTITION%20p_future%20INTO%20(%0A%20%20%20%20PARTITION%20p2025%20VALUES%20LESS%20THAN%20(2026)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Split partition
ALTER TABLE orders 
REORGANIZE PARTITION p_future INTO (
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>4. Partition Information:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20partition%20information%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20partition_name%2C%0A%20%20%20%20partition_method%2C%0A%20%20%20%20partition_expression%2C%0A%20%20%20%20table_rows%2C%0A%20%20%20%20data_length%2C%0A%20%20%20%20index_length%0AFROM%20information_schema.partitions%0AWHERE%20table_schema%20%3D%20'your_database'%20%0AAND%20table_name%20%3D%20'orders'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View partition information
SELECT 
    table_name,
    partition_name,
    partition_method,
    partition_expression,
    table_rows,
    data_length,
    index_length
FROM information_schema.partitions
WHERE table_schema = 'your_database' 
AND table_name = 'orders';
</code></pre>
</div>

<p><strong>Query Optimization with Partitions:</strong></p>

<p><strong>1. Partition Pruning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20hits%20only%20relevant%20partitions%0ASELECT%20*%20FROM%20orders%20%0AWHERE%20order_date%20BETWEEN%20'2024-01-01'%20AND%20'2024-12-31'%3B%0A--%20Only%20accesses%20p2024%20partition%0A%0AEXPLAIN%20PARTITIONS%20%0ASELECT%20*%20FROM%20orders%20WHERE%20order_date%20%3D%20'2024-06-15'%3B%0A--%20Shows%20which%20partitions%20are%20accessed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query hits only relevant partitions
SELECT * FROM orders 
WHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';
-- Only accesses p2024 partition

EXPLAIN PARTITIONS 
SELECT * FROM orders WHERE order_date = '2024-06-15';
-- Shows which partitions are accessed
</code></pre>
</div>

<p><strong>2. Partition-wise Joins:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Both%20tables%20partitioned%20the%20same%20way%0ASELECT%20o.*%2C%20od.product_id%2C%20od.quantity%0AFROM%20orders%20o%0AJOIN%20order_details%20od%20ON%20o.id%20%3D%20od.order_id%0AWHERE%20o.order_date%20%3D%20'2024-06-15'%3B%0A--%20Can%20join%20partition-to-partition%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Both tables partitioned the same way
SELECT o.*, od.product_id, od.quantity
FROM orders o
JOIN order_details od ON o.id = od.order_id
WHERE o.order_date = '2024-06-15';
-- Can join partition-to-partition
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Choose partition key based on query patterns</p>
<p>- Include partition key in WHERE clauses for pruning</p>
<p>- Partition key must be part of PRIMARY KEY or UNIQUE indexes</p>
<p>- Monitor partition sizes and balance</p>
<p>- Plan for partition maintenance (adding/dropping)</p>
<p>- Test query performance with EXPLAIN PARTITIONS</p>


<p><strong>When to Use Partitioning:</strong></p>

<p>- Tables larger than 2GB</p>
<p>- Clear partitioning strategy (date, region, etc.)</p>
<p>- Queries frequently filter on partition key</p>
<p>- Need to archive/purge old data efficiently</p>
<p>- Parallel processing benefits</p>


<h2 id="-356-what-are-database-constraints-and-their-types-">**356. What are database constraints and their types?**</h2>

<p><strong>Answer:</strong> Database constraints are rules that enforce data integrity and business logic at the database level.</p>

<p><strong>Types of Constraints:</strong></p>

<p><strong>1. PRIMARY KEY Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%20%20--%20Single%20column%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%0A)%3B%0A%0A--%20Composite%20primary%20key%0ACREATE%20TABLE%20order_items%20(%0A%20%20%20%20order_id%20INT%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20quantity%20INT%2C%0A%20%20%20%20PRIMARY%20KEY%20(order_id%2C%20product_id)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,  -- Single column
    email VARCHAR(255) NOT NULL
);

-- Composite primary key
CREATE TABLE order_items (
    order_id INT,
    product_id INT,
    quantity INT,
    PRIMARY KEY (order_id, product_id)
);
</code></pre>
</div>

<p><strong>2. FOREIGN KEY Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_id)%20REFERENCES%20customers(id)%0A%20%20%20%20%20%20%20%20ON%20DELETE%20CASCADE%0A%20%20%20%20%20%20%20%20ON%20UPDATE%20RESTRICT%0A)%3B%0A%0A--%20Named%20foreign%20key%20with%20custom%20actions%0AALTER%20TABLE%20orders%20%0AADD%20CONSTRAINT%20fk_customer%20%0AFOREIGN%20KEY%20(customer_id)%20REFERENCES%20customers(id)%0AON%20DELETE%20SET%20NULL%0AON%20UPDATE%20CASCADE%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE orders (
    id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    FOREIGN KEY (customer_id) REFERENCES customers(id)
        ON DELETE CASCADE
        ON UPDATE RESTRICT
);

-- Named foreign key with custom actions
ALTER TABLE orders 
ADD CONSTRAINT fk_customer 
FOREIGN KEY (customer_id) REFERENCES customers(id)
ON DELETE SET NULL
ON UPDATE CASCADE;
</code></pre>
</div>

<p><strong>3. UNIQUE Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20email%20VARCHAR(255)%20UNIQUE%2C%20%20%20%20%20%20%20%20%20%20%20--%20Column-level%0A%20%20%20%20username%20VARCHAR(50)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_username%20(username)%2C%20%20%20--%20Table-level%0A%20%20%20%20UNIQUE%20KEY%20uk_phone_email%20(phone%2C%20email)%20%20--%20Composite%20unique%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT PRIMARY KEY,
    email VARCHAR(255) UNIQUE,           -- Column-level
    username VARCHAR(50),
    phone VARCHAR(20),
    UNIQUE KEY uk_username (username),   -- Table-level
    UNIQUE KEY uk_phone_email (phone, email)  -- Composite unique
);
</code></pre>
</div>

<p><strong>4. CHECK Constraint (MySQL 8.0+):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20discount_percent%20DECIMAL(5%2C2)%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'discontinued')%2C%0A%20%20%20%20CONSTRAINT%20chk_price%20CHECK%20(price%20%3E%200)%2C%0A%20%20%20%20CONSTRAINT%20chk_discount%20CHECK%20(discount_percent%20BETWEEN%200%20AND%20100)%2C%0A%20%20%20%20CONSTRAINT%20chk_discounted_price%20CHECK%20(price%20*%20(1%20-%20discount_percent%2F100)%20%3E%200)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10,2),
    discount_percent DECIMAL(5,2),
    status ENUM('active', 'inactive', 'discontinued'),
    CONSTRAINT chk_price CHECK (price &gt; 0),
    CONSTRAINT chk_discount CHECK (discount_percent BETWEEN 0 AND 100),
    CONSTRAINT chk_discounted_price CHECK (price * (1 - discount_percent/100) &gt; 0)
);
</code></pre>
</div>

<p><strong>5. NOT NULL Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Nullable%0A%20%20%20%20created_at%20TIMESTAMP%20NOT%20NULL%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE customers (
    id INT PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    phone VARCHAR(20),              -- Nullable
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);
</code></pre>
</div>

<p><strong>Constraint Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Add%20constraint%20to%20existing%20table%0AALTER%20TABLE%20products%20%0AADD%20CONSTRAINT%20chk_positive_price%20CHECK%20(price%20%3E%200)%3B%0A%0A--%20Drop%20constraint%0AALTER%20TABLE%20products%20DROP%20CHECK%20chk_positive_price%3B%0A%0A--%20Disable%2FEnable%20foreign%20key%20checks%20(temporarily)%0ASET%20FOREIGN_KEY_CHECKS%20%3D%200%3B%20%20--%20Disable%0ASET%20FOREIGN_KEY_CHECKS%20%3D%201%3B%20%20--%20Enable%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Add constraint to existing table
ALTER TABLE products 
ADD CONSTRAINT chk_positive_price CHECK (price &gt; 0);

-- Drop constraint
ALTER TABLE products DROP CHECK chk_positive_price;

-- Disable/Enable foreign key checks (temporarily)
SET FOREIGN_KEY_CHECKS = 0;  -- Disable
SET FOREIGN_KEY_CHECKS = 1;  -- Enable
</code></pre>
</div>

<p><strong>Benefits:</strong></p>

<p>- <strong>Data Integrity:</strong> Prevents invalid data entry</p>
<p>- <strong>Referential Integrity:</strong> Maintains relationships</p>
<p>- <strong>Business Rules:</strong> Enforces domain-specific logic</p>
<p>- <strong>Performance:</strong> Optimizer uses constraints for query planning</p>


<p>---</p>

<h2 id="-357-how-do-you-work-with-database-transactions-and-isolation-levels-">**357. How do you work with database transactions and isolation levels?**</h2>

<p><strong>Answer:</strong> Transactions ensure ACID properties, while isolation levels control how concurrent transactions interact.</p>

<p><strong>Transaction Basics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Explicit%20transaction%0ASTART%20TRANSACTION%3B%0A%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20100%20WHERE%20id%20%3D%202%3B%0A%0A--%20Check%20if%20everything%20is%20correct%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20IN%20(1%2C%202)%3B%0A%0ACOMMIT%3B%20%20--%20or%20ROLLBACK%20if%20there's%20an%20issue%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Explicit transaction
START TRANSACTION;

UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;

-- Check if everything is correct
SELECT balance FROM accounts WHERE id IN (1, 2);

COMMIT;  -- or ROLLBACK if there's an issue
</code></pre>
</div>

<p><strong>Transaction with Error Handling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20TransferMoney(%0A%20%20%20%20IN%20from_account%20INT%2C%0A%20%20%20%20IN%20to_account%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%20%20--%20Re-throw%20the%20error%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20sufficient%20balance%0A%20%20%20%20IF%20(SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20from_account)%20%3C%20amount%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Insufficient%20balance'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20transfer%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_account%3B%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_account%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE TransferMoney(
    IN from_account INT,
    IN to_account INT,
    IN amount DECIMAL(10,2)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;  -- Re-throw the error
    END;
    
    START TRANSACTION;
    
    -- Check sufficient balance
    IF (SELECT balance FROM accounts WHERE id = from_account) &lt; amount THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Insufficient balance';
    END IF;
    
    -- Perform transfer
    UPDATE accounts SET balance = balance - amount WHERE id = from_account;
    UPDATE accounts SET balance = balance + amount WHERE id = to_account;
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Isolation Levels:</strong></p>

<p><strong>1. READ UNCOMMITTED:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20READ%20UNCOMMITTED%3B%0A--%20Allows%20dirty%20reads%2C%20non-repeatable%20reads%2C%20phantom%20reads%0A--%20Fastest%20but%20least%20consistent%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20May%20see%20uncommitted%20changes%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
-- Allows dirty reads, non-repeatable reads, phantom reads
-- Fastest but least consistent

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- May see uncommitted changes
COMMIT;
</code></pre>
</div>

<p><strong>2. READ COMMITTED:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20READ%20COMMITTED%3B%0A--%20Prevents%20dirty%20reads%2C%20allows%20non-repeatable%20reads%20and%20phantom%20reads%0A--%20Default%20in%20many%20databases%20(not%20MySQL)%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20100%0A--%20Another%20transaction%20commits%20a%20change%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20150%20(non-repeatable%20read)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;
-- Prevents dirty reads, allows non-repeatable reads and phantom reads
-- Default in many databases (not MySQL)

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- 100
-- Another transaction commits a change
SELECT balance FROM accounts WHERE id = 1;  -- 150 (non-repeatable read)
COMMIT;
</code></pre>
</div>

<p><strong>3. REPEATABLE READ (MySQL Default):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20REPEATABLE%20READ%3B%0A--%20Prevents%20dirty%20reads%20and%20non-repeatable%20reads%2C%20allows%20phantom%20reads%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20100%0A--%20Another%20transaction%20commits%20a%20change%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Still%20100%20(repeatable)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
-- Prevents dirty reads and non-repeatable reads, allows phantom reads

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- 100
-- Another transaction commits a change
SELECT balance FROM accounts WHERE id = 1;  -- Still 100 (repeatable)
COMMIT;
</code></pre>
</div>

<p><strong>4. SERIALIZABLE:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20SERIALIZABLE%3B%0A--%20Prevents%20all%20phenomena%2C%20highest%20consistency%2C%20lowest%20performance%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20*%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%0A--%20Locks%20prevent%20other%20transactions%20from%20inserting%2Fupdating%20matching%20rows%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;
-- Prevents all phenomena, highest consistency, lowest performance

START TRANSACTION;
SELECT * FROM accounts WHERE balance &gt; 1000;
-- Locks prevent other transactions from inserting/updating matching rows
COMMIT;
</code></pre>
</div>

<p><strong>Concurrency Issues:</strong></p>

<p><strong>1. Dirty Read Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20500%20WHERE%20id%20%3D%201%3B%0A--%20Don't%20commit%20yet%0A%0A--%20Transaction%202%20(READ%20UNCOMMITTED)%3A%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Sees%20500%20(dirty%20read)%0A%0A--%20Transaction%201%3A%0AROLLBACK%3B%20%20--%20Transaction%202%20saw%20data%20that%20never%20existed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
UPDATE accounts SET balance = 500 WHERE id = 1;
-- Don't commit yet

-- Transaction 2 (READ UNCOMMITTED):
SELECT balance FROM accounts WHERE id = 1;  -- Sees 500 (dirty read)

-- Transaction 1:
ROLLBACK;  -- Transaction 2 saw data that never existed
</code></pre>
</div>

<p><strong>2. Phantom Read Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0ASELECT%20COUNT(*)%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%20%20--%20Returns%205%0A%0A--%20Transaction%202%3A%0AINSERT%20INTO%20accounts%20(id%2C%20balance)%20VALUES%20(100%2C%201500)%3B%0ACOMMIT%3B%0A%0A--%20Transaction%201%3A%0ASELECT%20COUNT(*)%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%20%20--%20Returns%206%20(phantom)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
SELECT COUNT(*) FROM accounts WHERE balance &gt; 1000;  -- Returns 5

-- Transaction 2:
INSERT INTO accounts (id, balance) VALUES (100, 1500);
COMMIT;

-- Transaction 1:
SELECT COUNT(*) FROM accounts WHERE balance &gt; 1000;  -- Returns 6 (phantom)
COMMIT;
</code></pre>
</div>

<p><strong>Locking Mechanisms:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Shared%20lock%20(read%20lock)%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20LOCK%20IN%20SHARE%20MODE%3B%0A%0A--%20Exclusive%20lock%20(write%20lock)%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20FOR%20UPDATE%3B%0A%0A--%20Skip%20locked%20rows%20(MySQL%208.0%2B)%0ASELECT%20*%20FROM%20queue_items%20WHERE%20processed%20%3D%200%20%0AFOR%20UPDATE%20SKIP%20LOCKED%20LIMIT%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Shared lock (read lock)
SELECT * FROM accounts WHERE id = 1 LOCK IN SHARE MODE;

-- Exclusive lock (write lock)
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;

-- Skip locked rows (MySQL 8.0+)
SELECT * FROM queue_items WHERE processed = 0 
FOR UPDATE SKIP LOCKED LIMIT 10;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use appropriate isolation level for your use case</p>
<p>- Keep transactions short to reduce lock contention</p>
<p>- Handle deadlocks with retry logic</p>
<p>- Use explicit locking sparingly</p>
<p>- Monitor transaction performance and blocking</p>


<p>---</p>

<h2 id="-358-what-are-database-triggers-for-auditing-and-logging-">**358. What are database triggers for auditing and logging?**</h2>

<p><strong>Answer:</strong> Audit triggers automatically track data changes, providing comprehensive logging for compliance and debugging.</p>

<p><strong>Basic Audit Table Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20audit_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(64)%20NOT%20NULL%2C%0A%20%20%20%20operation%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_by%20VARCHAR(100)%2C%0A%20%20%20%20changed_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20INDEX%20idx_table_operation%20(table_name%2C%20operation)%2C%0A%20%20%20%20INDEX%20idx_record_id%20(record_id)%2C%0A%20%20%20%20INDEX%20idx_changed_at%20(changed_at)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE audit_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64) NOT NULL,
    operation ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    old_values JSON,
    new_values JSON,
    changed_by VARCHAR(100),
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address VARCHAR(45),
    user_agent TEXT,
    INDEX idx_table_operation (table_name, operation),
    INDEX idx_record_id (record_id),
    INDEX idx_changed_at (changed_at)
);
</code></pre>
</div>

<p><strong>Comprehensive Audit Triggers:</strong></p>

<p><strong>1. INSERT Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_insert%0AAFTER%20INSERT%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20new_values%2C%0A%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20'INSERT'%2C%0A%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'id'%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20NEW.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20NEW.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20NEW.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20NEW.created_at%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_insert
AFTER INSERT ON users
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        table_name,
        operation,
        record_id,
        new_values,
        changed_by,
        ip_address
    ) VALUES (
        'users',
        'INSERT',
        NEW.id,
        JSON_OBJECT(
            'id', NEW.id,
            'name', NEW.name,
            'email', NEW.email,
            'status', NEW.status,
            'created_at', NEW.created_at
        ),
        COALESCE(@audit_user, USER()),
        COALESCE(@audit_ip, CONNECTION_ID())
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. UPDATE Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_update%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Only%20log%20if%20data%20actually%20changed%0A%20%20%20%20IF%20NOT%20(OLD.name%20%3C%3D%3E%20NEW.name%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20%20OLD.email%20%3C%3D%3E%20NEW.email%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20%20OLD.status%20%3C%3D%3E%20NEW.status)%20THEN%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20old_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20new_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20OLD.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20OLD.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20OLD.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20OLD.updated_at%0A%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20NEW.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20NEW.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20NEW.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20NEW.updated_at%0A%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_update
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    -- Only log if data actually changed
    IF NOT (OLD.name &lt;=&gt; NEW.name AND 
            OLD.email &lt;=&gt; NEW.email AND 
            OLD.status &lt;=&gt; NEW.status) THEN
        
        INSERT INTO audit_log (
            table_name,
            operation,
            record_id,
            old_values,
            new_values,
            changed_by,
            ip_address
        ) VALUES (
            'users',
            'UPDATE',
            NEW.id,
            JSON_OBJECT(
                'name', OLD.name,
                'email', OLD.email,
                'status', OLD.status,
                'updated_at', OLD.updated_at
            ),
            JSON_OBJECT(
                'name', NEW.name,
                'email', NEW.email,
                'status', NEW.status,
                'updated_at', NEW.updated_at
            ),
            COALESCE(@audit_user, USER()),
            COALESCE(@audit_ip, CONNECTION_ID())
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. DELETE Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_delete%0ABEFORE%20DELETE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20old_values%2C%0A%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20'DELETE'%2C%0A%20%20%20%20%20%20%20%20OLD.id%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'id'%2C%20OLD.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20OLD.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20OLD.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20OLD.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20OLD.created_at%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20OLD.updated_at%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_delete
BEFORE DELETE ON users
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        table_name,
        operation,
        record_id,
        old_values,
        changed_by,
        ip_address
    ) VALUES (
        'users',
        'DELETE',
        OLD.id,
        JSON_OBJECT(
            'id', OLD.id,
            'name', OLD.name,
            'email', OLD.email,
            'status', OLD.status,
            'created_at', OLD.created_at,
            'updated_at', OLD.updated_at
        ),
        COALESCE(@audit_user, USER()),
        COALESCE(@audit_ip, CONNECTION_ID())
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Advanced Audit Features:</strong></p>

<p><strong>1. Field-Level Change Tracking:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20detailed_user_audit%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20DECLARE%20changes%20JSON%20DEFAULT%20JSON_OBJECT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Track%20individual%20field%20changes%0A%20%20%20%20IF%20OLD.name%20!%3D%20NEW.name%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.name'%2C%20JSON_OBJECT('old'%2C%20OLD.name%2C%20'new'%2C%20NEW.name))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20OLD.email%20!%3D%20NEW.email%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.email'%2C%20JSON_OBJECT('old'%2C%20OLD.email%2C%20'new'%2C%20NEW.email))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20OLD.status%20!%3D%20NEW.status%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.status'%2C%20JSON_OBJECT('old'%2C%20OLD.status%2C%20'new'%2C%20NEW.status))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Only%20insert%20if%20there%20are%20actual%20changes%0A%20%20%20%20IF%20JSON_LENGTH(changes)%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20detailed_audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20field_changes%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_at%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changes%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER detailed_user_audit
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    DECLARE changes JSON DEFAULT JSON_OBJECT();
    
    -- Track individual field changes
    IF OLD.name != NEW.name THEN
        SET changes = JSON_SET(changes, '$.name', JSON_OBJECT('old', OLD.name, 'new', NEW.name));
    END IF;
    
    IF OLD.email != NEW.email THEN
        SET changes = JSON_SET(changes, '$.email', JSON_OBJECT('old', OLD.email, 'new', NEW.email));
    END IF;
    
    IF OLD.status != NEW.status THEN
        SET changes = JSON_SET(changes, '$.status', JSON_OBJECT('old', OLD.status, 'new', NEW.status));
    END IF;
    
    -- Only insert if there are actual changes
    IF JSON_LENGTH(changes) &gt; 0 THEN
        INSERT INTO detailed_audit_log (
            table_name,
            record_id,
            field_changes,
            changed_by,
            changed_at
        ) VALUES (
            'users',
            NEW.id,
            changes,
            COALESCE(@audit_user, USER()),
            NOW()
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Conditional Auditing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20sensitive_data_audit%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Only%20audit%20sensitive%20field%20changes%0A%20%20%20%20IF%20OLD.email%20!%3D%20NEW.email%20OR%20%0A%20%20%20%20%20%20%20OLD.phone%20!%3D%20NEW.phone%20OR%20%0A%20%20%20%20%20%20%20OLD.ssn%20!%3D%20NEW.ssn%20THEN%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20security_audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20sensitive_change%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20old_hash%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20new_hash%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20requires_review%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'PII_UPDATE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SHA2(CONCAT(OLD.email%2C%20OLD.phone%2C%20OLD.ssn)%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SHA2(CONCAT(NEW.email%2C%20NEW.phone%2C%20NEW.ssn)%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TRUE%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER sensitive_data_audit
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    -- Only audit sensitive field changes
    IF OLD.email != NEW.email OR 
       OLD.phone != NEW.phone OR 
       OLD.ssn != NEW.ssn THEN
        
        INSERT INTO security_audit_log (
            table_name,
            record_id,
            sensitive_change,
            old_hash,
            new_hash,
            changed_by,
            requires_review
        ) VALUES (
            'users',
            NEW.id,
            'PII_UPDATE',
            SHA2(CONCAT(OLD.email, OLD.phone, OLD.ssn), 256),
            SHA2(CONCAT(NEW.email, NEW.phone, NEW.ssn), 256),
            COALESCE(@audit_user, USER()),
            TRUE
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Setting Audit Context:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20audit%20context%20before%20operations%0ASET%20%40audit_user%20%3D%20'john.doe%40company.com'%3B%0ASET%20%40audit_ip%20%3D%20'192.168.1.100'%3B%0ASET%20%40audit_reason%20%3D%20'User%20profile%20update'%3B%0A%0A--%20Perform%20operations%0AUPDATE%20users%20SET%20email%20%3D%20'newemail%40example.com'%20WHERE%20id%20%3D%20123%3B%0A%0A--%20Clear%20context%0ASET%20%40audit_user%20%3D%20NULL%3B%0ASET%20%40audit_ip%20%3D%20NULL%3B%0ASET%20%40audit_reason%20%3D%20NULL%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set audit context before operations
SET @audit_user = 'john.doe@company.com';
SET @audit_ip = '192.168.1.100';
SET @audit_reason = 'User profile update';

-- Perform operations
UPDATE users SET email = 'newemail@example.com' WHERE id = 123;

-- Clear context
SET @audit_user = NULL;
SET @audit_ip = NULL;
SET @audit_reason = NULL;
</code></pre>
</div>

<p><strong>Audit Query Examples:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20all%20changes%20to%20a%20specific%20user%0ASELECT%20*%20FROM%20audit_log%20%0AWHERE%20table_name%20%3D%20'users'%20AND%20record_id%20%3D%20'123'%0AORDER%20BY%20changed_at%20DESC%3B%0A%0A--%20Find%20all%20changes%20by%20a%20specific%20user%0ASELECT%20table_name%2C%20operation%2C%20COUNT(*)%20as%20change_count%0AFROM%20audit_log%20%0AWHERE%20changed_by%20%3D%20'john.doe%40company.com'%0AAND%20changed_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20table_name%2C%20operation%3B%0A%0A--%20Find%20recent%20sensitive%20changes%0ASELECT%20al.*%2C%20u.name%2C%20u.email%0AFROM%20audit_log%20al%0AJOIN%20users%20u%20ON%20al.record_id%20%3D%20u.id%0AWHERE%20al.table_name%20%3D%20'users'%0AAND%20JSON_CONTAINS_PATH(al.new_values%2C%20'one'%2C%20'%24.email'%2C%20'%24.phone')%0AAND%20al.changed_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%207%20DAY)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find all changes to a specific user
SELECT * FROM audit_log 
WHERE table_name = 'users' AND record_id = '123'
ORDER BY changed_at DESC;

-- Find all changes by a specific user
SELECT table_name, operation, COUNT(*) as change_count
FROM audit_log 
WHERE changed_by = 'john.doe@company.com'
AND changed_at &gt;= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY table_name, operation;

-- Find recent sensitive changes
SELECT al.*, u.name, u.email
FROM audit_log al
JOIN users u ON al.record_id = u.id
WHERE al.table_name = 'users'
AND JSON_CONTAINS_PATH(al.new_values, 'one', '$.email', '$.phone')
AND al.changed_at &gt;= DATE_SUB(NOW(), INTERVAL 7 DAY);
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Use separate audit database for high-volume systems</p>
<p>- Implement audit log rotation/archiving</p>
<p>- Index audit tables appropriately</p>
<p>- Consider async audit logging for performance-critical systems</p>
<p>- Monitor audit table growth and storage requirements</p>


<p>---</p>

<h2 id="-359-how-do-you-implement-database-replication-">**359. How do you implement database replication?**</h2>

<p><strong>Answer:</strong> Database replication creates copies of data across multiple servers for high availability, load distribution, and disaster recovery.</p>

<p><strong>Types of Replication:</strong></p>

<p><strong>1. Master-Slave Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Master%20Configuration%20(my.cnf)%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Alog-bin%20%3D%20mysql-bin%0Abinlog-format%20%3D%20ROW%0Abinlog-do-db%20%3D%20production_db%0Aexpire-logs-days%20%3D%207%0A%0A--%20Create%20replication%20user%20on%20master%0ACREATE%20USER%20'replication'%40'slave_ip'%20IDENTIFIED%20BY%20'strong_password'%3B%0AGRANT%20REPLICATION%20SLAVE%20ON%20*.*%20TO%20'replication'%40'slave_ip'%3B%0AFLUSH%20PRIVILEGES%3B%0A%0A--%20Get%20master%20status%0ASHOW%20MASTER%20STATUS%3B%0A--%20Note%3A%20File%20and%20Position%20values%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Master Configuration (my.cnf)
[mysqld]
server-id = 1
log-bin = mysql-bin
binlog-format = ROW
binlog-do-db = production_db
expire-logs-days = 7

-- Create replication user on master
CREATE USER 'replication'@'slave_ip' IDENTIFIED BY 'strong_password';
GRANT REPLICATION SLAVE ON *.* TO 'replication'@'slave_ip';
FLUSH PRIVILEGES;

-- Get master status
SHOW MASTER STATUS;
-- Note: File and Position values
</code></pre>
</div>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Slave%20Configuration%20(my.cnf)%0A%5Bmysqld%5D%0Aserver-id%20%3D%202%0Arelay-log%20%3D%20relay-bin%0Aread-only%20%3D%201%0Areplicate-do-db%20%3D%20production_db%0A%0A--%20Configure%20slave%0ACHANGE%20MASTER%20TO%0A%20%20%20%20MASTER_HOST%20%3D%20'master_ip'%2C%0A%20%20%20%20MASTER_USER%20%3D%20'replication'%2C%0A%20%20%20%20MASTER_PASSWORD%20%3D%20'strong_password'%2C%0A%20%20%20%20MASTER_LOG_FILE%20%3D%20'mysql-bin.000001'%2C%20%20--%20From%20SHOW%20MASTER%20STATUS%0A%20%20%20%20MASTER_LOG_POS%20%3D%20154%3B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20From%20SHOW%20MASTER%20STATUS%0A%0A--%20Start%20replication%0ASTART%20SLAVE%3B%0A%0A--%20Check%20slave%20status%0ASHOW%20SLAVE%20STATUS%5CG%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Slave Configuration (my.cnf)
[mysqld]
server-id = 2
relay-log = relay-bin
read-only = 1
replicate-do-db = production_db

-- Configure slave
CHANGE MASTER TO
    MASTER_HOST = 'master_ip',
    MASTER_USER = 'replication',
    MASTER_PASSWORD = 'strong_password',
    MASTER_LOG_FILE = 'mysql-bin.000001',  -- From SHOW MASTER STATUS
    MASTER_LOG_POS = 154;                  -- From SHOW MASTER STATUS

-- Start replication
START SLAVE;

-- Check slave status
SHOW SLAVE STATUS\G
</code></pre>
</div>

<p><strong>2. Master-Master Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Server%201%20Configuration%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Alog-bin%20%3D%20mysql-bin%0Aauto-increment-increment%20%3D%202%0Aauto-increment-offset%20%3D%201%0Abinlog-format%20%3D%20ROW%0A%0A--%20Server%202%20Configuration%0A%5Bmysqld%5D%0Aserver-id%20%3D%202%0Alog-bin%20%3D%20mysql-bin%0Aauto-increment-increment%20%3D%202%0Aauto-increment-offset%20%3D%202%0Abinlog-format%20%3D%20ROW%0A%0A--%20Each%20server%20acts%20as%20master%20and%20slave%20to%20the%20other%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Server 1 Configuration
[mysqld]
server-id = 1
log-bin = mysql-bin
auto-increment-increment = 2
auto-increment-offset = 1
binlog-format = ROW

-- Server 2 Configuration
[mysqld]
server-id = 2
log-bin = mysql-bin
auto-increment-increment = 2
auto-increment-offset = 2
binlog-format = ROW

-- Each server acts as master and slave to the other
</code></pre>
</div>

<p><strong>3. Group Replication (MySQL 5.7+):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Install%20Group%20Replication%20plugin%0AINSTALL%20PLUGIN%20group_replication%20SONAME%20'group_replication.so'%3B%0A%0A--%20Configuration%20for%20each%20node%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Agtid-mode%20%3D%20ON%0Aenforce-gtid-consistency%20%3D%20ON%0Abinlog-format%20%3D%20ROW%0Alog-slave-updates%20%3D%20ON%0Abinlog-checksum%20%3D%20NONE%0Aslave-sql-verify-checksum%20%3D%200%0A%0A--%20Group%20Replication%20specific%0Aloose-group_replication_group_name%20%3D%20%22aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa%22%0Aloose-group_replication_start_on_boot%20%3D%20OFF%0Aloose-group_replication_local_address%20%3D%20%22node1%3A33061%22%0Aloose-group_replication_group_seeds%20%3D%20%22node1%3A33061%2Cnode2%3A33061%2Cnode3%3A33061%22%0Aloose-group_replication_bootstrap_group%20%3D%20OFF%0A%0A--%20Start%20Group%20Replication%20on%20first%20node%0ASET%20GLOBAL%20group_replication_bootstrap_group%3DON%3B%0ASTART%20GROUP_REPLICATION%3B%0ASET%20GLOBAL%20group_replication_bootstrap_group%3DOFF%3B%0A%0A--%20Join%20other%20nodes%0ASTART%20GROUP_REPLICATION%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Install Group Replication plugin
INSTALL PLUGIN group_replication SONAME 'group_replication.so';

-- Configuration for each node
[mysqld]
server-id = 1
gtid-mode = ON
enforce-gtid-consistency = ON
binlog-format = ROW
log-slave-updates = ON
binlog-checksum = NONE
slave-sql-verify-checksum = 0

-- Group Replication specific
loose-group_replication_group_name = "aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"
loose-group_replication_start_on_boot = OFF
loose-group_replication_local_address = "node1:33061"
loose-group_replication_group_seeds = "node1:33061,node2:33061,node3:33061"
loose-group_replication_bootstrap_group = OFF

-- Start Group Replication on first node
SET GLOBAL group_replication_bootstrap_group=ON;
START GROUP_REPLICATION;
SET GLOBAL group_replication_bootstrap_group=OFF;

-- Join other nodes
START GROUP_REPLICATION;
</code></pre>
</div>

<p><strong>Monitoring Replication:</strong></p>

<p><strong>1. Slave Status Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20replication%20health%0ASHOW%20SLAVE%20STATUS%5CG%0A%0A--%20Key%20metrics%20to%20monitor%3A%0A--%20Slave_IO_Running%3A%20Yes%0A--%20Slave_SQL_Running%3A%20Yes%0A--%20Seconds_Behind_Master%3A%20Should%20be%20low%0A--%20Last_Error%3A%20Should%20be%20empty%0A%0A--%20Detailed%20replication%20info%0ASELECT%20%0A%20%20%20%20CHANNEL_NAME%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20PORT%2C%0A%20%20%20%20USER%2C%0A%20%20%20%20SOURCE_LOG_FILE%2C%0A%20%20%20%20READ_MASTER_LOG_POS%2C%0A%20%20%20%20RELAY_LOG_FILE%2C%0A%20%20%20%20RELAY_LOG_POS%2C%0A%20%20%20%20SERVICE_STATE%0AFROM%20performance_schema.replication_connection_status%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check replication health
SHOW SLAVE STATUS\G

-- Key metrics to monitor:
-- Slave_IO_Running: Yes
-- Slave_SQL_Running: Yes
-- Seconds_Behind_Master: Should be low
-- Last_Error: Should be empty

-- Detailed replication info
SELECT 
    CHANNEL_NAME,
    HOST,
    PORT,
    USER,
    SOURCE_LOG_FILE,
    READ_MASTER_LOG_POS,
    RELAY_LOG_FILE,
    RELAY_LOG_POS,
    SERVICE_STATE
FROM performance_schema.replication_connection_status;
</code></pre>
</div>

<p><strong>2. Replication Lag Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20heartbeat%20table%20on%20master%0ACREATE%20TABLE%20heartbeat%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20ts%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Update%20heartbeat%20regularly%20(via%20cron%2Fevent)%0AINSERT%20INTO%20heartbeat%20(id%2C%20ts)%20VALUES%20(1%2C%20NOW())%20%0AON%20DUPLICATE%20KEY%20UPDATE%20ts%20%3D%20NOW()%3B%0A%0A--%20Check%20lag%20on%20slave%0ASELECT%20%0A%20%20%20%20TIMESTAMPDIFF(SECOND%2C%20ts%2C%20NOW())%20as%20lag_seconds%0AFROM%20heartbeat%20WHERE%20id%20%3D%201%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create heartbeat table on master
CREATE TABLE heartbeat (
    id INT PRIMARY KEY,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Update heartbeat regularly (via cron/event)
INSERT INTO heartbeat (id, ts) VALUES (1, NOW()) 
ON DUPLICATE KEY UPDATE ts = NOW();

-- Check lag on slave
SELECT 
    TIMESTAMPDIFF(SECOND, ts, NOW()) as lag_seconds
FROM heartbeat WHERE id = 1;
</code></pre>
</div>

<p><strong>Replication Troubleshooting:</strong></p>

<p><strong>1. Skip Replication Errors:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Skip%20single%20error%20(use%20carefully)%0ASTOP%20SLAVE%3B%0ASET%20GLOBAL%20sql_slave_skip_counter%20%3D%201%3B%0ASTART%20SLAVE%3B%0A%0A--%20Skip%20specific%20error%20types%0ASET%20GLOBAL%20slave_skip_errors%20%3D%20'1062%2C1053'%3B%20%20--%20Duplicate%20key%2C%20server%20shutdown%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Skip single error (use carefully)
STOP SLAVE;
SET GLOBAL sql_slave_skip_counter = 1;
START SLAVE;

-- Skip specific error types
SET GLOBAL slave_skip_errors = '1062,1053';  -- Duplicate key, server shutdown
</code></pre>
</div>

<p><strong>2. Reset Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20On%20slave%0ASTOP%20SLAVE%3B%0ARESET%20SLAVE%20ALL%3B%0A%0A--%20Reconfigure%20from%20current%20master%20position%0ASHOW%20MASTER%20STATUS%3B%20%20--%20On%20master%0ACHANGE%20MASTER%20TO%20...%3B%20%20--%20Use%20new%20position%0ASTART%20SLAVE%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- On slave
STOP SLAVE;
RESET SLAVE ALL;

-- Reconfigure from current master position
SHOW MASTER STATUS;  -- On master
CHANGE MASTER TO ...;  -- Use new position
START SLAVE;
</code></pre>
</div>

<p><strong>3. Point-in-Time Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20specific%20position%20in%20binlog%0ASHOW%20BINLOG%20EVENTS%20IN%20'mysql-bin.000001'%20FROM%20154%3B%0A%0A--%20Start%20slave%20from%20specific%20position%0ACHANGE%20MASTER%20TO%0A%20%20%20%20MASTER_LOG_FILE%20%3D%20'mysql-bin.000001'%2C%0A%20%20%20%20MASTER_LOG_POS%20%3D%201234%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find specific position in binlog
SHOW BINLOG EVENTS IN 'mysql-bin.000001' FROM 154;

-- Start slave from specific position
CHANGE MASTER TO
    MASTER_LOG_FILE = 'mysql-bin.000001',
    MASTER_LOG_POS = 1234;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use GTID (Global Transaction Identifiers) for easier failover</p>
<p>- Monitor replication lag continuously</p>
<p>- Implement automated failover procedures</p>
<p>- Regular backup of both master and slaves</p>
<p>- Test failover procedures regularly</p>
<p>- Use semi-synchronous replication for critical data</p>
<p>- Implement proper network security between servers</p>


<p>---</p>

<h2 id="-360-what-are-database-locks-and-deadlock-handling-">**360. What are database locks and deadlock handling?**</h2>

<p><strong>Answer:</strong> Database locks control concurrent access to data, while deadlock handling resolves circular waiting situations between transactions.</p>

<p><strong>Types of Locks:</strong></p>

<p><strong>1. Shared Locks (S-locks):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multiple%20transactions%20can%20hold%20shared%20locks%20simultaneously%0A--%20Prevents%20writes%2C%20allows%20reads%0A%0A--%20Explicit%20shared%20lock%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20LOCK%20IN%20SHARE%20MODE%3B%0A%0A--%20Implicit%20shared%20locks%20during%20SELECT%20(depending%20on%20isolation%20level)%0ASET%20TRANSACTION%20ISOLATION%20LEVEL%20REPEATABLE%20READ%3B%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Acquires%20shared%20lock%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multiple transactions can hold shared locks simultaneously
-- Prevents writes, allows reads

-- Explicit shared lock
SELECT * FROM accounts WHERE id = 1 LOCK IN SHARE MODE;

-- Implicit shared locks during SELECT (depending on isolation level)
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- Acquires shared lock
</code></pre>
</div>

<p><strong>2. Exclusive Locks (X-locks):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Only%20one%20transaction%20can%20hold%20exclusive%20lock%0A--%20Prevents%20both%20reads%20and%20writes%20by%20other%20transactions%0A%0A--%20Explicit%20exclusive%20lock%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20FOR%20UPDATE%3B%0A%0A--%20Implicit%20exclusive%20locks%20during%20modifications%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%20%20--%20X-lock%20on%20row%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Only one transaction can hold exclusive lock
-- Prevents both reads and writes by other transactions

-- Explicit exclusive lock
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;

-- Implicit exclusive locks during modifications
UPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- X-lock on row
</code></pre>
</div>

<p><strong>3. Intention Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20uses%20intention%20locks%20automatically%0A--%20IS%20(Intention%20Shared)%20-%20intends%20to%20acquire%20S-locks%20on%20rows%0A--%20IX%20(Intention%20Exclusive)%20-%20intends%20to%20acquire%20X-locks%20on%20rows%0A%0A--%20These%20are%20acquired%20automatically%20by%20InnoDB%0A--%20No%20explicit%20syntax%20needed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB uses intention locks automatically
-- IS (Intention Shared) - intends to acquire S-locks on rows
-- IX (Intention Exclusive) - intends to acquire X-locks on rows

-- These are acquired automatically by InnoDB
-- No explicit syntax needed
</code></pre>
</div>

<p><strong>Lock Granularity:</strong></p>

<p><strong>1. Row-Level Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20default%20-%20locks%20individual%20rows%0AUPDATE%20users%20SET%20last_login%20%3D%20NOW()%20WHERE%20id%20%3D%20123%3B%0A--%20Only%20locks%20the%20specific%20row%20with%20id%20%3D%20123%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB default - locks individual rows
UPDATE users SET last_login = NOW() WHERE id = 123;
-- Only locks the specific row with id = 123
</code></pre>
</div>

<p><strong>2. Table-Level Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Explicit%20table%20locking%0ALOCK%20TABLES%20users%20READ%3B%20%20%20%20--%20Shared%20table%20lock%0ASELECT%20*%20FROM%20users%3B%0AUNLOCK%20TABLES%3B%0A%0ALOCK%20TABLES%20users%20WRITE%3B%20%20%20--%20Exclusive%20table%20lock%0AUPDATE%20users%20SET%20status%20%3D%20'inactive'%20WHERE%20last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%3B%0AUNLOCK%20TABLES%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Explicit table locking
LOCK TABLES users READ;    -- Shared table lock
SELECT * FROM users;
UNLOCK TABLES;

LOCK TABLES users WRITE;   -- Exclusive table lock
UPDATE users SET status = 'inactive' WHERE last_login &lt; DATE_SUB(NOW(), INTERVAL 1 YEAR);
UNLOCK TABLES;
</code></pre>
</div>

<p><strong>3. Gap Locks and Next-Key Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20uses%20these%20to%20prevent%20phantom%20reads%0A--%20Gap%20lock%3A%20locks%20the%20gap%20between%20index%20records%0A--%20Next-key%20lock%3A%20combination%20of%20record%20lock%20and%20gap%20lock%0A%0A--%20Example%20with%20REPEATABLE%20READ%20isolation%0ASTART%20TRANSACTION%3B%0ASELECT%20*%20FROM%20users%20WHERE%20age%20BETWEEN%2025%20AND%2035%20FOR%20UPDATE%3B%0A--%20Locks%20existing%20rows%20AND%20gaps%20to%20prevent%20new%20rows%20in%20range%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB uses these to prevent phantom reads
-- Gap lock: locks the gap between index records
-- Next-key lock: combination of record lock and gap lock

-- Example with REPEATABLE READ isolation
START TRANSACTION;
SELECT * FROM users WHERE age BETWEEN 25 AND 35 FOR UPDATE;
-- Locks existing rows AND gaps to prevent new rows in range
</code></pre>
</div>

<p><strong>Deadlock Examples and Resolution:</strong></p>

<p><strong>1. Classic Deadlock Scenario:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%20%20--%20Locks%20account%201%0A--%20...%20some%20processing%20time%20...%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20100%20WHERE%20id%20%3D%202%3B%20%20--%20Waits%20for%20account%202%0A%0A--%20Transaction%202%20(simultaneously)%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%2050%20WHERE%20id%20%3D%202%3B%20%20%20--%20Locks%20account%202%0A--%20...%20some%20processing%20time%20...%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%2050%20WHERE%20id%20%3D%201%3B%20%20%20--%20Waits%20for%20account%201%0A%0A--%20Result%3A%20Deadlock!%20Each%20transaction%20waits%20for%20the%20other's%20lock%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- Locks account 1
-- ... some processing time ...
UPDATE accounts SET balance = balance + 100 WHERE id = 2;  -- Waits for account 2

-- Transaction 2 (simultaneously):
START TRANSACTION;
UPDATE accounts SET balance = balance - 50 WHERE id = 2;   -- Locks account 2
-- ... some processing time ...
UPDATE accounts SET balance = balance + 50 WHERE id = 1;   -- Waits for account 1

-- Result: Deadlock! Each transaction waits for the other's lock
</code></pre>
</div>

<p><strong>2. Deadlock Detection and Resolution:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20automatically%20detects%20deadlocks%20and%20rolls%20back%20one%20transaction%0A--%20The%20rolled-back%20transaction%20receives%20error%201213%0A%0A--%20Check%20deadlock%20information%0ASHOW%20ENGINE%20INNODB%20STATUS%3B%0A--%20Look%20for%20%22LATEST%20DETECTED%20DEADLOCK%22%20section%0A%0A--%20Deadlock%20history%20(MySQL%208.0%2B)%0ASELECT%20*%20FROM%20performance_schema.events_statements_history%0AWHERE%20sql_text%20LIKE%20'%25deadlock%25'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL automatically detects deadlocks and rolls back one transaction
-- The rolled-back transaction receives error 1213

-- Check deadlock information
SHOW ENGINE INNODB STATUS;
-- Look for "LATEST DETECTED DEADLOCK" section

-- Deadlock history (MySQL 8.0+)
SELECT * FROM performance_schema.events_statements_history
WHERE sql_text LIKE '%deadlock%';
</code></pre>
</div>

<p><strong>Deadlock Prevention Strategies:</strong></p>

<p><strong>1. Consistent Lock Ordering:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Always%20acquire%20locks%20in%20the%20same%20order%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20SafeTransfer(%0A%20%20%20%20IN%20from_id%20INT%2C%0A%20%20%20%20IN%20to_id%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20first_id%20INT%3B%0A%20%20%20%20DECLARE%20second_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Always%20lock%20lower%20ID%20first%0A%20%20%20%20IF%20from_id%20%3C%20to_id%20THEN%0A%20%20%20%20%20%20%20%20SET%20first_id%20%3D%20from_id%3B%0A%20%20%20%20%20%20%20%20SET%20second_id%20%3D%20to_id%3B%0A%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20SET%20first_id%20%3D%20to_id%3B%0A%20%20%20%20%20%20%20%20SET%20second_id%20%3D%20from_id%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Lock%20in%20consistent%20order%0A%20%20%20%20SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20first_id%20FOR%20UPDATE%3B%0A%20%20%20%20SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20second_id%20FOR%20UPDATE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20transfer%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_id%3B%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_id%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Always acquire locks in the same order
DELIMITER //
CREATE PROCEDURE SafeTransfer(
    IN from_id INT,
    IN to_id INT,
    IN amount DECIMAL(10,2)
)
BEGIN
    DECLARE first_id INT;
    DECLARE second_id INT;
    
    -- Always lock lower ID first
    IF from_id &lt; to_id THEN
        SET first_id = from_id;
        SET second_id = to_id;
    ELSE
        SET first_id = to_id;
        SET second_id = from_id;
    END IF;
    
    START TRANSACTION;
    
    -- Lock in consistent order
    SELECT balance FROM accounts WHERE id = first_id FOR UPDATE;
    SELECT balance FROM accounts WHERE id = second_id FOR UPDATE;
    
    -- Perform transfer
    UPDATE accounts SET balance = balance - amount WHERE id = from_id;
    UPDATE accounts SET balance = balance + amount WHERE id = to_id;
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Timeout-Based Approach:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20lock%20wait%20timeout%0ASET%20SESSION%20innodb_lock_wait_timeout%20%3D%205%3B%20%20--%205%20seconds%0A%0A--%20Application-level%20retry%20logic%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20TransferWithRetry(%0A%20%20%20%20IN%20from_id%20INT%2C%0A%20%20%20%20IN%20to_id%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20IN%20max_retries%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20retry_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%201213%2C%201205%20%20--%20Deadlock%2C%20lock%20timeout%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20SET%20retry_count%20%3D%20retry_count%20%2B%201%3B%0A%20%20%20%20%20%20%20%20IF%20retry_count%20%3E%3D%20max_retries%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20--%20Wait%20before%20retry%0A%20%20%20%20%20%20%20%20DO%20SLEEP(RAND()%20*%200.1)%3B%20%20--%20Random%20delay%200-100ms%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20NOT%20done%20AND%20retry_count%20%3C%20max_retries%20DO%0A%20%20%20%20%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Perform%20transfer%20logic%20here%0A%20%20%20%20%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_id%3B%0A%20%20%20%20%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20COMMIT%3B%0A%20%20%20%20%20%20%20%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20END%20WHILE%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set lock wait timeout
SET SESSION innodb_lock_wait_timeout = 5;  -- 5 seconds

-- Application-level retry logic
DELIMITER //
CREATE PROCEDURE TransferWithRetry(
    IN from_id INT,
    IN to_id INT,
    IN amount DECIMAL(10,2),
    IN max_retries INT
)
BEGIN
    DECLARE retry_count INT DEFAULT 0;
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE CONTINUE HANDLER FOR 1213, 1205  -- Deadlock, lock timeout
    BEGIN
        SET retry_count = retry_count + 1;
        IF retry_count &gt;= max_retries THEN
            SET done = TRUE;
            RESIGNAL;
        END IF;
        -- Wait before retry
        DO SLEEP(RAND() * 0.1);  -- Random delay 0-100ms
    END;
    
    WHILE NOT done AND retry_count &lt; max_retries DO
        START TRANSACTION;
        
        -- Perform transfer logic here
        UPDATE accounts SET balance = balance - amount WHERE id = from_id;
        UPDATE accounts SET balance = balance + amount WHERE id = to_id;
        
        COMMIT;
        SET done = TRUE;
    END WHILE;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Lock Monitoring:</strong></p>

<p><strong>1. Current Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20current%20locks%20(MySQL%208.0%2B)%0ASELECT%20%0A%20%20%20%20r.trx_id%2C%0A%20%20%20%20r.trx_mysql_thread_id%2C%0A%20%20%20%20r.trx_query%2C%0A%20%20%20%20b.blocking_trx_id%2C%0A%20%20%20%20b.blocking_pid%2C%0A%20%20%20%20l.lock_table%2C%0A%20%20%20%20l.lock_type%2C%0A%20%20%20%20l.lock_mode%0AFROM%20information_schema.innodb_lock_waits%20w%0AJOIN%20information_schema.innodb_trx%20r%20ON%20r.trx_id%20%3D%20w.requesting_trx_id%0AJOIN%20information_schema.innodb_trx%20b%20ON%20b.trx_id%20%3D%20w.blocking_trx_id%0AJOIN%20information_schema.innodb_locks%20l%20ON%20l.lock_trx_id%20%3D%20w.blocking_trx_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View current locks (MySQL 8.0+)
SELECT 
    r.trx_id,
    r.trx_mysql_thread_id,
    r.trx_query,
    b.blocking_trx_id,
    b.blocking_pid,
    l.lock_table,
    l.lock_type,
    l.lock_mode
FROM information_schema.innodb_lock_waits w
JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id
JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
JOIN information_schema.innodb_locks l ON l.lock_trx_id = w.blocking_trx_id;
</code></pre>
</div>

<p><strong>2. Lock Wait Statistics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Performance%20schema%20lock%20statistics%0ASELECT%20%0A%20%20%20%20object_schema%2C%0A%20%20%20%20object_name%2C%0A%20%20%20%20count_read%2C%0A%20%20%20%20count_write%2C%0A%20%20%20%20sum_timer_wait%2F1000000000%20as%20total_wait_sec%0AFROM%20performance_schema.table_lock_waits_summary_by_table%0AWHERE%20object_schema%20%3D%20'your_database'%0AORDER%20BY%20sum_timer_wait%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Performance schema lock statistics
SELECT 
    object_schema,
    object_name,
    count_read,
    count_write,
    sum_timer_wait/1000000000 as total_wait_sec
FROM performance_schema.table_lock_waits_summary_by_table
WHERE object_schema = 'your_database'
ORDER BY sum_timer_wait DESC;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Keep transactions short and focused</p>
<p>- Access resources in consistent order</p>
<p>- Use appropriate isolation levels</p>
<p>- Implement retry logic for deadlock handling</p>
<p>- Monitor lock contention regularly</p>
<p>- Consider application-level locking for complex scenarios</p>
<p>- Use SELECT ... FOR UPDATE sparingly</p>

<h2 id="-361-what-are-database-synonyms-and-aliases-">**361. What are database synonyms and aliases?**</h2>

<p><strong>Answer:</strong> Database synonyms and aliases provide alternative names for database objects, improving code readability and abstraction.</p>

<p><strong>Table Aliases in Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Simple%20aliases%20for%20readability%0ASELECT%20u.name%2C%20u.email%2C%20o.total%2C%20o.order_date%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AWHERE%20u.status%20%3D%20'active'%3B%0A%0A--%20Complex%20query%20with%20multiple%20aliases%0ASELECT%20%0A%20%20%20%20c.company_name%2C%0A%20%20%20%20u.name%20as%20contact_name%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20SUM(o.total)%20as%20total_revenue%2C%0A%20%20%20%20AVG(o.total)%20as%20avg_order_value%0AFROM%20customers%20c%0AJOIN%20users%20u%20ON%20c.primary_contact_id%20%3D%20u.id%0ALEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0AWHERE%20o.order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%0AGROUP%20BY%20c.id%2C%20c.company_name%2C%20u.name%0AHAVING%20total_revenue%20%3E%2010000%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Simple aliases for readability
SELECT u.name, u.email, o.total, o.order_date
FROM users u
JOIN orders o ON u.id = o.customer_id
WHERE u.status = 'active';

-- Complex query with multiple aliases
SELECT 
    c.company_name,
    u.name as contact_name,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_revenue,
    AVG(o.total) as avg_order_value
FROM customers c
JOIN users u ON c.primary_contact_id = u.id
LEFT JOIN orders o ON c.id = o.customer_id
WHERE o.order_date &gt;= DATE_SUB(NOW(), INTERVAL 1 YEAR)
GROUP BY c.id, c.company_name, u.name
HAVING total_revenue &gt; 10000;
</code></pre>
</div>

<p><strong>Column Aliases:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Descriptive%20column%20names%20in%20results%0ASELECT%20%0A%20%20%20%20CONCAT(first_name%2C%20'%20'%2C%20last_name)%20AS%20full_name%2C%0A%20%20%20%20DATE_FORMAT(created_at%2C%20'%25Y-%25m-%25d')%20AS%20registration_date%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20last_login%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%20THEN%20'Active'%0A%20%20%20%20%20%20%20%20WHEN%20last_login%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%20THEN%20'Inactive'%0A%20%20%20%20%20%20%20%20ELSE%20'Dormant'%0A%20%20%20%20END%20AS%20user_status%2C%0A%20%20%20%20TIMESTAMPDIFF(DAY%2C%20created_at%2C%20NOW())%20AS%20days_since_registration%0AFROM%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Descriptive column names in results
SELECT 
    CONCAT(first_name, ' ', last_name) AS full_name,
    DATE_FORMAT(created_at, '%Y-%m-%d') AS registration_date,
    CASE 
        WHEN last_login &gt; DATE_SUB(NOW(), INTERVAL 30 DAY) THEN 'Active'
        WHEN last_login &gt; DATE_SUB(NOW(), INTERVAL 90 DAY) THEN 'Inactive'
        ELSE 'Dormant'
    END AS user_status,
    TIMESTAMPDIFF(DAY, created_at, NOW()) AS days_since_registration
FROM users;
</code></pre>
</div>

<p><strong>View Aliases (MySQL doesn't have true synonyms, but views serve similar purpose):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20view%20as%20alias%20for%20complex%20table%20structure%0ACREATE%20VIEW%20customer_summary%20AS%0ASELECT%20%0A%20%20%20%20c.id%2C%0A%20%20%20%20c.company_name%2C%0A%20%20%20%20c.industry%2C%0A%20%20%20%20u.name%20as%20primary_contact%2C%0A%20%20%20%20u.email%20as%20contact_email%2C%0A%20%20%20%20COUNT(o.id)%20as%20total_orders%2C%0A%20%20%20%20SUM(o.total)%20as%20lifetime_value%2C%0A%20%20%20%20MAX(o.order_date)%20as%20last_order_date%0AFROM%20customers%20c%0AJOIN%20users%20u%20ON%20c.primary_contact_id%20%3D%20u.id%0ALEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0AGROUP%20BY%20c.id%2C%20c.company_name%2C%20c.industry%2C%20u.name%2C%20u.email%3B%0A%0A--%20Use%20view%20as%20if%20it%20were%20a%20table%0ASELECT%20*%20FROM%20customer_summary%20%0AWHERE%20lifetime_value%20%3E%2050000%0AORDER%20BY%20lifetime_value%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create view as alias for complex table structure
CREATE VIEW customer_summary AS
SELECT 
    c.id,
    c.company_name,
    c.industry,
    u.name as primary_contact,
    u.email as contact_email,
    COUNT(o.id) as total_orders,
    SUM(o.total) as lifetime_value,
    MAX(o.order_date) as last_order_date
FROM customers c
JOIN users u ON c.primary_contact_id = u.id
LEFT JOIN orders o ON c.id = o.customer_id
GROUP BY c.id, c.company_name, c.industry, u.name, u.email;

-- Use view as if it were a table
SELECT * FROM customer_summary 
WHERE lifetime_value &gt; 50000
ORDER BY lifetime_value DESC;
</code></pre>
</div>

<p><strong>Temporary Aliases with CTEs:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Common%20Table%20Expression%20as%20temporary%20alias%0AWITH%20monthly_sales%20AS%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20DATE_FORMAT(order_date%2C%20'%25Y-%25m')%20as%20month%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20monthly_total%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%0A%20%20%20%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2012%20MONTH)%0A%20%20%20%20GROUP%20BY%20DATE_FORMAT(order_date%2C%20'%25Y-%25m')%0A)%2C%0Asales_growth%20AS%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20month%2C%0A%20%20%20%20%20%20%20%20monthly_total%2C%0A%20%20%20%20%20%20%20%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month)%20as%20prev_month_total%2C%0A%20%20%20%20%20%20%20%20((monthly_total%20-%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month))%20%2F%20%0A%20%20%20%20%20%20%20%20%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month))%20*%20100%20as%20growth_rate%0A%20%20%20%20FROM%20monthly_sales%0A)%0ASELECT%20*%20FROM%20sales_growth%20WHERE%20growth_rate%20%3E%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Common Table Expression as temporary alias
WITH monthly_sales AS (
    SELECT 
        DATE_FORMAT(order_date, '%Y-%m') as month,
        SUM(total) as monthly_total,
        COUNT(*) as order_count
    FROM orders
    WHERE order_date &gt;= DATE_SUB(NOW(), INTERVAL 12 MONTH)
    GROUP BY DATE_FORMAT(order_date, '%Y-%m')
),
sales_growth AS (
    SELECT 
        month,
        monthly_total,
        LAG(monthly_total) OVER (ORDER BY month) as prev_month_total,
        ((monthly_total - LAG(monthly_total) OVER (ORDER BY month)) / 
         LAG(monthly_total) OVER (ORDER BY month)) * 100 as growth_rate
    FROM monthly_sales
)
SELECT * FROM sales_growth WHERE growth_rate &gt; 10;
</code></pre>
</div>

<p><strong>Benefits:</strong></p>

<p>- <strong>Readability:</strong> Shorter, more meaningful names</p>
<p>- <strong>Abstraction:</strong> Hide complex table structures</p>
<p>- <strong>Maintainability:</strong> Change underlying structure without affecting queries</p>
<p>- <strong>Reusability:</strong> Common aliases across multiple queries</p>


<p>---</p>

<h2 id="-362-how-do-you-work-with-database-sequences-and-auto-increment-">**362. How do you work with database sequences and auto-increment?**</h2>

<p><strong>Answer:</strong> Sequences and auto-increment provide automatic generation of unique numeric values, typically for primary keys.</p>

<p><strong>AUTO_INCREMENT in MySQL:</strong></p>

<p><strong>1. Basic Auto-Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20without%20specifying%20ID%0AINSERT%20INTO%20users%20(name%2C%20email)%20VALUES%20%0A('John%20Doe'%2C%20'john%40example.com')%2C%0A('Jane%20Smith'%2C%20'jane%40example.com')%3B%0A%0A--%20IDs%20are%20automatically%20assigned%3A%201%2C%202%2C%203%2C%20...%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert without specifying ID
INSERT INTO users (name, email) VALUES 
('John Doe', 'john@example.com'),
('Jane Smith', 'jane@example.com');

-- IDs are automatically assigned: 1, 2, 3, ...
</code></pre>
</div>

<p><strong>2. Custom Auto-Increment Starting Value:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20starting%20value%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%0A)%20AUTO_INCREMENT%20%3D%201000%3B%0A%0A--%20Or%20alter%20existing%20table%0AALTER%20TABLE%20products%20AUTO_INCREMENT%20%3D%205000%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set starting value
CREATE TABLE products (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10,2)
) AUTO_INCREMENT = 1000;

-- Or alter existing table
ALTER TABLE products AUTO_INCREMENT = 5000;
</code></pre>
</div>

<p><strong>3. Auto-Increment with Custom Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Global%20setting%20(affects%20all%20tables)%0ASET%20%40%40auto_increment_increment%20%3D%2010%3B%20%20--%20Increment%20by%2010%0ASET%20%40%40auto_increment_offset%20%3D%201%3B%20%20%20%20%20%20--%20Start%20at%201%0A%0A--%20Results%20in%3A%201%2C%2011%2C%2021%2C%2031%2C%2041%2C%20...%0A%0A--%20Session-specific%20setting%0ASET%20SESSION%20auto_increment_increment%20%3D%205%3B%0ASET%20SESSION%20auto_increment_offset%20%3D%202%3B%0A--%20Results%20in%3A%202%2C%207%2C%2012%2C%2017%2C%2022%2C%20...%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Global setting (affects all tables)
SET @@auto_increment_increment = 10;  -- Increment by 10
SET @@auto_increment_offset = 1;      -- Start at 1

-- Results in: 1, 11, 21, 31, 41, ...

-- Session-specific setting
SET SESSION auto_increment_increment = 5;
SET SESSION auto_increment_offset = 2;
-- Results in: 2, 7, 12, 17, 22, ...
</code></pre>
</div>

<p><strong>Managing Auto-Increment Values:</strong></p>

<p><strong>1. Get Current Auto-Increment Value:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20auto-increment%20value%0ASHOW%20TABLE%20STATUS%20LIKE%20'users'%3B%0A--%20Look%20at%20'Auto_increment'%20column%0A%0A--%20Or%20query%20information%20schema%0ASELECT%20AUTO_INCREMENT%20%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%20%0AAND%20table_name%20%3D%20'users'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current auto-increment value
SHOW TABLE STATUS LIKE 'users';
-- Look at 'Auto_increment' column

-- Or query information schema
SELECT AUTO_INCREMENT 
FROM information_schema.tables 
WHERE table_schema = 'your_database' 
AND table_name = 'users';
</code></pre>
</div>

<p><strong>2. Reset Auto-Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Reset%20to%20specific%20value%0AALTER%20TABLE%20users%20AUTO_INCREMENT%20%3D%201%3B%0A%0A--%20Reset%20to%20next%20available%20value%20after%20max%20existing%20ID%0AALTER%20TABLE%20users%20AUTO_INCREMENT%20%3D%201%3B%0A--%20MySQL%20automatically%20adjusts%20to%20MAX(id)%20%2B%201%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Reset to specific value
ALTER TABLE users AUTO_INCREMENT = 1;

-- Reset to next available value after max existing ID
ALTER TABLE users AUTO_INCREMENT = 1;
-- MySQL automatically adjusts to MAX(id) + 1
</code></pre>
</div>

<p><strong>3. Handle Auto-Increment Gaps:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Gaps%20occur%20due%20to%3A%0A--%20-%20Rolled%20back%20transactions%0A--%20-%20DELETE%20operations%0A--%20-%20Failed%20INSERT%20attempts%0A%0A--%20Find%20gaps%20in%20sequence%0ASELECT%20%0A%20%20%20%20t1.id%20%2B%201%20as%20gap_start%2C%0A%20%20%20%20MIN(t2.id)%20-%201%20as%20gap_end%0AFROM%20users%20t1%0ALEFT%20JOIN%20users%20t2%20ON%20t1.id%20%2B%201%20%3D%20t2.id%0AWHERE%20t2.id%20IS%20NULL%0AAND%20t1.id%20%3C%20(SELECT%20MAX(id)%20FROM%20users)%0AGROUP%20BY%20t1.id%0AHAVING%20gap_start%20%3C%3D%20gap_end%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Gaps occur due to:
-- - Rolled back transactions
-- - DELETE operations
-- - Failed INSERT attempts

-- Find gaps in sequence
SELECT 
    t1.id + 1 as gap_start,
    MIN(t2.id) - 1 as gap_end
FROM users t1
LEFT JOIN users t2 ON t1.id + 1 = t2.id
WHERE t2.id IS NULL
AND t1.id &lt; (SELECT MAX(id) FROM users)
GROUP BY t1.id
HAVING gap_start &lt;= gap_end;
</code></pre>
</div>

<p><strong>Sequence-Like Behavior (MySQL doesn't have native sequences):</strong></p>

<p><strong>1. Custom Sequence Table:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20sequence%20table%0ACREATE%20TABLE%20sequences%20(%0A%20%20%20%20name%20VARCHAR(50)%20PRIMARY%20KEY%2C%0A%20%20%20%20current_value%20BIGINT%20NOT%20NULL%20DEFAULT%200%2C%0A%20%20%20%20increment_by%20INT%20NOT%20NULL%20DEFAULT%201%0A)%3B%0A%0A--%20Initialize%20sequences%0AINSERT%20INTO%20sequences%20(name%2C%20current_value%2C%20increment_by)%20VALUES%0A('order_number'%2C%2010000%2C%201)%2C%0A('invoice_number'%2C%202024001%2C%201)%2C%0A('customer_code'%2C%201000%2C%2010)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create sequence table
CREATE TABLE sequences (
    name VARCHAR(50) PRIMARY KEY,
    current_value BIGINT NOT NULL DEFAULT 0,
    increment_by INT NOT NULL DEFAULT 1
);

-- Initialize sequences
INSERT INTO sequences (name, current_value, increment_by) VALUES
('order_number', 10000, 1),
('invoice_number', 2024001, 1),
('customer_code', 1000, 10);
</code></pre>
</div>

<p><strong>2. Sequence Generation Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20NextSequenceValue(seq_name%20VARCHAR(50))%0ARETURNS%20BIGINT%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20next_val%20BIGINT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20and%20increment%20sequence%20value%20atomically%0A%20%20%20%20UPDATE%20sequences%20%0A%20%20%20%20SET%20current_value%20%3D%20current_value%20%2B%20increment_by%0A%20%20%20%20WHERE%20name%20%3D%20seq_name%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20the%20new%20value%0A%20%20%20%20SELECT%20current_value%20INTO%20next_val%0A%20%20%20%20FROM%20sequences%20%0A%20%20%20%20WHERE%20name%20%3D%20seq_name%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20next_val%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%0ASELECT%20NextSequenceValue('order_number')%20as%20new_order_number%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION NextSequenceValue(seq_name VARCHAR(50))
RETURNS BIGINT
MODIFIES SQL DATA
BEGIN
    DECLARE next_val BIGINT;
    
    -- Get and increment sequence value atomically
    UPDATE sequences 
    SET current_value = current_value + increment_by
    WHERE name = seq_name;
    
    -- Return the new value
    SELECT current_value INTO next_val
    FROM sequences 
    WHERE name = seq_name;
    
    RETURN next_val;
END //
DELIMITER ;

-- Usage
SELECT NextSequenceValue('order_number') as new_order_number;
</code></pre>
</div>

<p><strong>3. UUID Alternative:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Use%20UUIDs%20for%20distributed%20systems%0ACREATE%20TABLE%20distributed_orders%20(%0A%20%20%20%20id%20CHAR(36)%20PRIMARY%20KEY%20DEFAULT%20(UUID())%2C%0A%20%20%20%20order_number%20VARCHAR(20)%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20with%20automatic%20UUID%0AINSERT%20INTO%20distributed_orders%20(order_number%2C%20customer_id%2C%20total)%0AVALUES%20('ORD-2024-001'%2C%20123%2C%20299.99)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Use UUIDs for distributed systems
CREATE TABLE distributed_orders (
    id CHAR(36) PRIMARY KEY DEFAULT (UUID()),
    order_number VARCHAR(20),
    customer_id INT,
    total DECIMAL(10,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert with automatic UUID
INSERT INTO distributed_orders (order_number, customer_id, total)
VALUES ('ORD-2024-001', 123, 299.99);
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use AUTO_INCREMENT for single-server applications</p>
<p>- Consider UUIDs for distributed systems</p>
<p>- Don't rely on AUTO_INCREMENT values being consecutive</p>
<p>- Reserve ranges for bulk operations</p>
<p>- Monitor AUTO_INCREMENT limits (INT max: 2.1 billion, BIGINT max: 9.2 quintillion)</p>
<p>- Use BIGINT for high-volume tables</p>


<p>---</p>

<h2 id="-363-what-are-database-collations-and-character-sets-">**363. What are database collations and character sets?**</h2>

<p><strong>Answer:</strong> Character sets define which characters can be stored, while collations define how characters are compared and sorted.</p>

<p><strong>Character Sets:</strong></p>

<p><strong>1. Common Character Sets:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20available%20character%20sets%0ASHOW%20CHARACTER%20SET%3B%0A%0A--%20Common%20character%20sets%3A%0A--%20utf8mb4%3A%20Full%20UTF-8%20support%20(recommended)%0A--%20utf8%3A%20Limited%20UTF-8%20(deprecated%2C%20max%203%20bytes%20per%20character)%0A--%20latin1%3A%20Western%20European%20characters%0A--%20ascii%3A%20Basic%20ASCII%20characters%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View available character sets
SHOW CHARACTER SET;

-- Common character sets:
-- utf8mb4: Full UTF-8 support (recommended)
-- utf8: Limited UTF-8 (deprecated, max 3 bytes per character)
-- latin1: Western European characters
-- ascii: Basic ASCII characters
</code></pre>
</div>

<p><strong>2. Setting Character Sets:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Database%20level%0ACREATE%20DATABASE%20myapp%20%0ACHARACTER%20SET%20utf8mb4%20%0ACOLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Table%20level%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20bio%20TEXT%0A)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Column%20level%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20description%20TEXT%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_general_ci%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Database level
CREATE DATABASE myapp 
CHARACTER SET utf8mb4 
COLLATE utf8mb4_unicode_ci;

-- Table level
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    bio TEXT
) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- Column level
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    description TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci
);
</code></pre>
</div>

<p><strong>Collations:</strong></p>

<p><strong>1. Common Collations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20available%20collations%0ASHOW%20COLLATION%20LIKE%20'utf8mb4%25'%3B%0A%0A--%20Common%20UTF-8%20collations%3A%0A--%20utf8mb4_unicode_ci%3A%20Unicode%20standard%2C%20accurate%20sorting%0A--%20utf8mb4_general_ci%3A%20Faster%20but%20less%20accurate%0A--%20utf8mb4_bin%3A%20Binary%20comparison%20(case-sensitive)%0A--%20utf8mb4_0900_ai_ci%3A%20MySQL%208.0%20default%20(accent-insensitive)%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View available collations
SHOW COLLATION LIKE 'utf8mb4%';

-- Common UTF-8 collations:
-- utf8mb4_unicode_ci: Unicode standard, accurate sorting
-- utf8mb4_general_ci: Faster but less accurate
-- utf8mb4_bin: Binary comparison (case-sensitive)
-- utf8mb4_0900_ai_ci: MySQL 8.0 default (accent-insensitive)
</code></pre>
</div>

<p><strong>2. Collation Impact on Comparisons:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Case-insensitive%20comparison%20(utf8mb4_general_ci)%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'john'%3B%20%20--%20Matches%20'John'%2C%20'JOHN'%2C%20'john'%0A%0A--%20Case-sensitive%20comparison%20(utf8mb4_bin)%0AALTER%20TABLE%20users%20MODIFY%20name%20VARCHAR(100)%20COLLATE%20utf8mb4_bin%3B%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'john'%3B%20%20--%20Only%20matches%20exact%20'john'%0A%0A--%20Accent-insensitive%20comparison%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'Jos%C3%A9'%3B%20%20--%20May%20match%20'Jose'%20depending%20on%20collation%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Case-insensitive comparison (utf8mb4_general_ci)
SELECT * FROM users WHERE name = 'john';  -- Matches 'John', 'JOHN', 'john'

-- Case-sensitive comparison (utf8mb4_bin)
ALTER TABLE users MODIFY name VARCHAR(100) COLLATE utf8mb4_bin;
SELECT * FROM users WHERE name = 'john';  -- Only matches exact 'john'

-- Accent-insensitive comparison
SELECT * FROM users WHERE name = 'JosÃ©';  -- May match 'Jose' depending on collation
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Multi-language Support:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20supporting%20multiple%20languages%0ACREATE%20TABLE%20content%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20language_code%20CHAR(2)%2C%0A%20%20%20%20title%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20content%20TEXT%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20content%20in%20different%20languages%0AINSERT%20INTO%20content%20(language_code%2C%20title%2C%20content)%20VALUES%0A('en'%2C%20'Hello%20World'%2C%20'This%20is%20English%20content')%2C%0A('es'%2C%20'Hola%20Mundo'%2C%20'Este%20es%20contenido%20en%20espa%C3%B1ol')%2C%0A('fr'%2C%20'Bonjour%20le%20Monde'%2C%20'Ceci%20est%20du%20contenu%20fran%C3%A7ais')%2C%0A('ja'%2C%20'%E3%81%93%E3%82%93%E3%81%AB%E3%81%A1%E3%81%AF%E4%B8%96%E7%95%8C'%2C%20'%E3%81%93%E3%82%8C%E3%81%AF%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%81%AE%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%81%A7%E3%81%99')%2C%0A('ar'%2C%20'%D9%85%D8%B1%D8%AD%D8%A8%D8%A7%20%D8%A8%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85'%2C%20'%D9%87%D8%B0%D8%A7%20%D9%85%D8%AD%D8%AA%D9%88%D9%89%20%D8%A8%D8%A7%D9%84%D9%84%D8%BA%D8%A9%20%D8%A7%D9%84%D8%B9%D8%B1%D8%A8%D9%8A%D8%A9')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table supporting multiple languages
CREATE TABLE content (
    id INT PRIMARY KEY,
    language_code CHAR(2),
    title VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    content TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert content in different languages
INSERT INTO content (language_code, title, content) VALUES
('en', 'Hello World', 'This is English content'),
('es', 'Hola Mundo', 'Este es contenido en espaÃ±ol'),
('fr', 'Bonjour le Monde', 'Ceci est du contenu franÃ§ais'),
('ja', 'ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ', 'ã“ã‚Œã¯æ—¥æœ¬èªžã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™'),
('ar', 'Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…', 'Ù‡Ø°Ø§ Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©');
</code></pre>
</div>

<p><strong>2. Sorting with Different Collations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20test%20data%0ACREATE%20TABLE%20names%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%0A)%20CHARACTER%20SET%20utf8mb4%3B%0A%0AINSERT%20INTO%20names%20(name)%20VALUES%20%0A('Apple')%2C%20('%C3%84pfel')%2C%20('Zebra')%2C%20('Z%C3%BCrich')%2C%20('caf%C3%A9')%2C%20('Caf%C3%A9')%3B%0A%0A--%20Sort%20with%20different%20collations%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_unicode_ci%3B%0A--%20Result%3A%20Apple%2C%20%C3%84pfel%2C%20caf%C3%A9%2C%20Caf%C3%A9%2C%20Zebra%2C%20Z%C3%BCrich%0A%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_bin%3B%0A--%20Result%3A%20Apple%2C%20Caf%C3%A9%2C%20Zebra%2C%20caf%C3%A9%2C%20%C3%84pfel%2C%20Z%C3%BCrich%20(ASCII%20order)%0A%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_general_ci%3B%0A--%20Result%3A%20Apple%2C%20%C3%84pfel%2C%20caf%C3%A9%2C%20Caf%C3%A9%2C%20Zebra%2C%20Z%C3%BCrich%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create test data
CREATE TABLE names (
    id INT PRIMARY KEY,
    name VARCHAR(100)
) CHARACTER SET utf8mb4;

INSERT INTO names (name) VALUES 
('Apple'), ('Ã„pfel'), ('Zebra'), ('ZÃ¼rich'), ('cafÃ©'), ('CafÃ©');

-- Sort with different collations
SELECT name FROM names ORDER BY name COLLATE utf8mb4_unicode_ci;
-- Result: Apple, Ã„pfel, cafÃ©, CafÃ©, Zebra, ZÃ¼rich

SELECT name FROM names ORDER BY name COLLATE utf8mb4_bin;
-- Result: Apple, CafÃ©, Zebra, cafÃ©, Ã„pfel, ZÃ¼rich (ASCII order)

SELECT name FROM names ORDER BY name COLLATE utf8mb4_general_ci;
-- Result: Apple, Ã„pfel, cafÃ©, CafÃ©, Zebra, ZÃ¼rich
</code></pre>
</div>

<p><strong>3. Performance Considerations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Binary%20collation%20for%20exact%20matching%20(fastest)%0ACREATE%20TABLE%20tokens%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20token%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_bin%2C%0A%20%20%20%20expires_at%20TIMESTAMP%2C%0A%20%20%20%20INDEX%20idx_token%20(token)%0A)%3B%0A%0A--%20Case-insensitive%20search%20with%20performance%20optimization%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20email%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20email_lower%20VARCHAR(255)%20GENERATED%20ALWAYS%20AS%20(LOWER(email))%20STORED%2C%0A%20%20%20%20INDEX%20idx_email_lower%20(email_lower)%0A)%3B%0A%0A--%20Search%20using%20generated%20column%0ASELECT%20*%20FROM%20users%20WHERE%20email_lower%20%3D%20LOWER('John.Doe%40Example.COM')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Binary collation for exact matching (fastest)
CREATE TABLE tokens (
    id INT PRIMARY KEY,
    token VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin,
    expires_at TIMESTAMP,
    INDEX idx_token (token)
);

-- Case-insensitive search with performance optimization
CREATE TABLE users (
    id INT PRIMARY KEY,
    email VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    email_lower VARCHAR(255) GENERATED ALWAYS AS (LOWER(email)) STORED,
    INDEX idx_email_lower (email_lower)
);

-- Search using generated column
SELECT * FROM users WHERE email_lower = LOWER('John.Doe@Example.COM');
</code></pre>
</div>

<p><strong>Migration and Conversion:</strong></p>

<p><strong>1. Convert Existing Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20character%20set%20and%20collation%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20table_collation%2C%0A%20%20%20%20table_comment%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A%0A--%20Convert%20table%20character%20set%0AALTER%20TABLE%20users%20CONVERT%20TO%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Convert%20specific%20column%0AALTER%20TABLE%20users%20MODIFY%20COLUMN%20name%20VARCHAR(100)%20%0ACHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current character set and collation
SELECT 
    table_name,
    table_collation,
    table_comment
FROM information_schema.tables 
WHERE table_schema = 'your_database';

-- Convert table character set
ALTER TABLE users CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- Convert specific column
ALTER TABLE users MODIFY COLUMN name VARCHAR(100) 
CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
</code></pre>
</div>

<p><strong>2. Handle Conversion Issues:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20for%20problematic%20data%20before%20conversion%0ASELECT%20id%2C%20name%2C%20LENGTH(name)%20as%20byte_length%2C%20CHAR_LENGTH(name)%20as%20char_length%0AFROM%20users%20%0AWHERE%20LENGTH(name)%20!%3D%20CHAR_LENGTH(name)%3B%20%20--%20Multi-byte%20characters%0A%0A--%20Backup%20before%20conversion%0ACREATE%20TABLE%20users_backup%20AS%20SELECT%20*%20FROM%20users%3B%0A%0A--%20Test%20conversion%20on%20small%20subset%0ACREATE%20TABLE%20users_test%20AS%20SELECT%20*%20FROM%20users%20LIMIT%20100%3B%0AALTER%20TABLE%20users_test%20CONVERT%20TO%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check for problematic data before conversion
SELECT id, name, LENGTH(name) as byte_length, CHAR_LENGTH(name) as char_length
FROM users 
WHERE LENGTH(name) != CHAR_LENGTH(name);  -- Multi-byte characters

-- Backup before conversion
CREATE TABLE users_backup AS SELECT * FROM users;

-- Test conversion on small subset
CREATE TABLE users_test AS SELECT * FROM users LIMIT 100;
ALTER TABLE users_test CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Always use utf8mb4 for new applications</p>
<p>- Use utf8mb4_unicode_ci for accurate sorting</p>
<p>- Use utf8mb4_bin for case-sensitive comparisons</p>
<p>- Set character set at database creation time</p>
<p>- Test collation behavior with your specific data</p>
<p>- Consider performance impact of different collations</p>
<p>- Plan character set migrations carefully</p>


<p>---</p>

<h2 id="-364-how-do-you-implement-database-connection-pooling-">**364. How do you implement database connection pooling?**</h2>

<p><strong>Answer:</strong> Connection pooling manages a cache of database connections to improve performance and resource utilization.</p>

<p><strong>Connection Pool Concepts:</strong></p>

<p><strong>1. Pool Configuration Parameters:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20configuration%20(my.cnf)%0A%5Bmysqld%5D%0Amax_connections%20%3D%201000%20%20%20%20%20%20%20%20%20%20--%20Maximum%20total%20connections%0Amax_user_connections%20%3D%2050%20%20%20%20%20%20%20--%20Per-user%20connection%20limit%0Aconnect_timeout%20%3D%2010%20%20%20%20%20%20%20%20%20%20%20%20--%20Connection%20timeout%0Await_timeout%20%3D%2028800%20%20%20%20%20%20%20%20%20%20%20--%20Idle%20connection%20timeout%0Ainteractive_timeout%20%3D%2028800%20%20%20%20--%20Interactive%20session%20timeout%0Athread_cache_size%20%3D%20100%20%20%20%20%20%20%20%20--%20Thread%20cache%20for%20connections%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL configuration (my.cnf)
[mysqld]
max_connections = 1000          -- Maximum total connections
max_user_connections = 50       -- Per-user connection limit
connect_timeout = 10            -- Connection timeout
wait_timeout = 28800           -- Idle connection timeout
interactive_timeout = 28800    -- Interactive session timeout
thread_cache_size = 100        -- Thread cache for connections
</code></pre>
</div>

<p><strong>2. Application-Level Pool Settings:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Node.js%20example%20with%20mysql2%0Aconst%20mysql%20%3D%20require('mysql2')%3B%0A%0Aconst%20pool%20%3D%20mysql.createPool(%7B%0A%20%20%20%20host%3A%20'localhost'%2C%0A%20%20%20%20user%3A%20'app_user'%2C%0A%20%20%20%20password%3A%20'password'%2C%0A%20%20%20%20database%3A%20'myapp'%2C%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Pool%20configuration%0A%20%20%20%20connectionLimit%3A%2020%2C%20%20%20%20%20%20%20%20%2F%2F%20Maximum%20connections%20in%20pool%0A%20%20%20%20acquireTimeout%3A%2060000%2C%20%20%20%20%20%20%2F%2F%20Timeout%20to%20get%20connection%20(ms)%0A%20%20%20%20timeout%3A%2060000%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Query%20timeout%20(ms)%0A%20%20%20%20reconnect%3A%20true%2C%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Auto-reconnect%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Connection%20management%0A%20%20%20%20idleTimeout%3A%20300000%2C%20%20%20%20%20%20%20%20%2F%2F%20Close%20idle%20connections%20after%205%20minutes%0A%20%20%20%20maxIdle%3A%2010%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Maximum%20idle%20connections%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Health%20checks%0A%20%20%20%20enableKeepAlive%3A%20true%2C%0A%20%20%20%20keepAliveInitialDelay%3A%200%0A%7D)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Node.js example with mysql2
const mysql = require('mysql2');

const pool = mysql.createPool({
    host: 'localhost',
    user: 'app_user',
    password: 'password',
    database: 'myapp',
    
    // Pool configuration
    connectionLimit: 20,        // Maximum connections in pool
    acquireTimeout: 60000,      // Timeout to get connection (ms)
    timeout: 60000,             // Query timeout (ms)
    reconnect: true,            // Auto-reconnect
    
    // Connection management
    idleTimeout: 300000,        // Close idle connections after 5 minutes
    maxIdle: 10,                // Maximum idle connections
    
    // Health checks
    enableKeepAlive: true,
    keepAliveInitialDelay: 0
});
</code></pre>
</div>

<p><strong>Pool Monitoring and Management:</strong></p>

<p><strong>1. Monitor Connection Usage:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20connections%0ASHOW%20PROCESSLIST%3B%0A%0A--%20Connection%20statistics%0ASHOW%20STATUS%20LIKE%20'Connections'%3B%0ASHOW%20STATUS%20LIKE%20'Threads_connected'%3B%0ASHOW%20STATUS%20LIKE%20'Threads_running'%3B%0ASHOW%20STATUS%20LIKE%20'Max_used_connections'%3B%0A%0A--%20Detailed%20connection%20information%0ASELECT%20%0A%20%20%20%20ID%2C%0A%20%20%20%20USER%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20DB%2C%0A%20%20%20%20COMMAND%2C%0A%20%20%20%20TIME%2C%0A%20%20%20%20STATE%2C%0A%20%20%20%20INFO%0AFROM%20information_schema.processlist%0AWHERE%20COMMAND%20!%3D%20'Sleep'%0AORDER%20BY%20TIME%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current connections
SHOW PROCESSLIST;

-- Connection statistics
SHOW STATUS LIKE 'Connections';
SHOW STATUS LIKE 'Threads_connected';
SHOW STATUS LIKE 'Threads_running';
SHOW STATUS LIKE 'Max_used_connections';

-- Detailed connection information
SELECT 
    ID,
    USER,
    HOST,
    DB,
    COMMAND,
    TIME,
    STATE,
    INFO
FROM information_schema.processlist
WHERE COMMAND != 'Sleep'
ORDER BY TIME DESC;
</code></pre>
</div>

<p><strong>2. Connection Pool Health Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Pool%20event%20monitoring%0Apool.on('connection'%2C%20function%20(connection)%20%7B%0A%20%20%20%20console.log('New%20connection%20established%20as%20id%20'%20%2B%20connection.threadId)%3B%0A%7D)%3B%0A%0Apool.on('error'%2C%20function(err)%20%7B%0A%20%20%20%20console.error('Database%20pool%20error%3A'%2C%20err)%3B%0A%20%20%20%20if(err.code%20%3D%3D%3D%20'PROTOCOL_CONNECTION_LOST')%20%7B%0A%20%20%20%20%20%20%20%20%2F%2F%20Handle%20connection%20lost%0A%20%20%20%20%20%20%20%20handleDisconnect()%3B%0A%20%20%20%20%7D%0A%7D)%3B%0A%0A%2F%2F%20Pool%20statistics%0Afunction%20getPoolStats()%20%7B%0A%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20totalConnections%3A%20pool._allConnections.length%2C%0A%20%20%20%20%20%20%20%20freeConnections%3A%20pool._freeConnections.length%2C%0A%20%20%20%20%20%20%20%20acquiringConnections%3A%20pool._acquiringConnections.length%2C%0A%20%20%20%20%20%20%20%20queuedRequests%3A%20pool._connectionQueue.length%0A%20%20%20%20%7D%3B%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Pool event monitoring
pool.on('connection', function (connection) {
    console.log('New connection established as id ' + connection.threadId);
});

pool.on('error', function(err) {
    console.error('Database pool error:', err);
    if(err.code === 'PROTOCOL_CONNECTION_LOST') {
        // Handle connection lost
        handleDisconnect();
    }
});

// Pool statistics
function getPoolStats() {
    return {
        totalConnections: pool._allConnections.length,
        freeConnections: pool._freeConnections.length,
        acquiringConnections: pool._acquiringConnections.length,
        queuedRequests: pool._connectionQueue.length
    };
}
</code></pre>
</div>

<p><strong>Optimal Pool Sizing:</strong></p>

<p><strong>1. Calculate Pool Size:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Formula%3A%20Pool%20Size%20%3D%20Tn%20%C3%97%20(Cm%20-%201)%20%2B%201%0A--%20Where%3A%0A--%20Tn%20%3D%20Maximum%20number%20of%20threads%0A--%20Cm%20%3D%20Maximum%20number%20of%20simultaneous%20connections%20per%20thread%0A%0A--%20For%20web%20application%3A%0A--%20If%20you%20have%20100%20concurrent%20users%0A--%20Each%20request%20uses%201%20connection%20for%20average%20100ms%0A--%20Request%20rate%3A%2010%20requests%2Fsecond%20per%20user%0A--%20Pool%20size%20%3D%20100%20users%20%C3%97%201%20connection%20%C3%97%200.1%20seconds%20%3D%2010%20connections%0A%0A--%20Add%20buffer%20for%20spikes%3A%2010%20%C3%97%201.5%20%3D%2015%20connections%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Formula: Pool Size = Tn Ã— (Cm - 1) + 1
-- Where:
-- Tn = Maximum number of threads
-- Cm = Maximum number of simultaneous connections per thread

-- For web application:
-- If you have 100 concurrent users
-- Each request uses 1 connection for average 100ms
-- Request rate: 10 requests/second per user
-- Pool size = 100 users Ã— 1 connection Ã— 0.1 seconds = 10 connections

-- Add buffer for spikes: 10 Ã— 1.5 = 15 connections
</code></pre>
</div>

<p><strong>2. Dynamic Pool Sizing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Adaptive%20pool%20sizing%20based%20on%20load%0Aclass%20AdaptiveConnectionPool%20%7B%0A%20%20%20%20constructor(baseConfig)%20%7B%0A%20%20%20%20%20%20%20%20this.baseConfig%20%3D%20baseConfig%3B%0A%20%20%20%20%20%20%20%20this.currentLoad%20%3D%200%3B%0A%20%20%20%20%20%20%20%20this.pool%20%3D%20mysql.createPool(baseConfig)%3B%0A%20%20%20%20%20%20%20%20this.monitorLoad()%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20monitorLoad()%20%7B%0A%20%20%20%20%20%20%20%20setInterval(()%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20const%20stats%20%3D%20this.getPoolStats()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20const%20utilization%20%3D%20(stats.totalConnections%20-%20stats.freeConnections)%20%2F%20stats.totalConnections%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(utilization%20%3E%200.8%20%26%26%20stats.totalConnections%20%3C%2050)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Scale%20up%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.scalePool(Math.min(stats.totalConnections%20%2B%205%2C%2050))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20else%20if%20(utilization%20%3C%200.3%20%26%26%20stats.totalConnections%20%3E%2010)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Scale%20down%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.scalePool(Math.max(stats.totalConnections%20-%202%2C%2010))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%2C%2030000)%3B%20%2F%2F%20Check%20every%2030%20seconds%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20scalePool(newSize)%20%7B%0A%20%20%20%20%20%20%20%20console.log(%60Scaling%20pool%20to%20%24%7BnewSize%7D%20connections%60)%3B%0A%20%20%20%20%20%20%20%20%2F%2F%20Implementation%20depends%20on%20pool%20library%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Adaptive pool sizing based on load
class AdaptiveConnectionPool {
    constructor(baseConfig) {
        this.baseConfig = baseConfig;
        this.currentLoad = 0;
        this.pool = mysql.createPool(baseConfig);
        this.monitorLoad();
    }
    
    monitorLoad() {
        setInterval(() =&gt; {
            const stats = this.getPoolStats();
            const utilization = (stats.totalConnections - stats.freeConnections) / stats.totalConnections;
            
            if (utilization &gt; 0.8 && stats.totalConnections &lt; 50) {
                // Scale up
                this.scalePool(Math.min(stats.totalConnections + 5, 50));
            } else if (utilization &lt; 0.3 && stats.totalConnections &gt; 10) {
                // Scale down
                this.scalePool(Math.max(stats.totalConnections - 2, 10));
            }
        }, 30000); // Check every 30 seconds
    }
    
    scalePool(newSize) {
        console.log(`Scaling pool to ${newSize} connections`);
        // Implementation depends on pool library
    }
}
</code></pre>
</div>

<p><strong>Connection Pool Best Practices:</strong></p>

<p><strong>1. Proper Connection Lifecycle:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Correct%20usage%20pattern%0Aasync%20function%20getUserData(userId)%20%7B%0A%20%20%20%20let%20connection%3B%0A%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20connection%20%3D%20await%20pool.getConnection()%3B%0A%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20connection.execute(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20users%20WHERE%20id%20%3D%20%3F'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%5BuserId%5D%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20return%20rows%5B0%5D%3B%0A%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20console.error('Database%20error%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20throw%20error%3B%0A%20%20%20%20%7D%20finally%20%7B%0A%20%20%20%20%20%20%20%20if%20(connection)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20connection.release()%3B%20%2F%2F%20Return%20to%20pool%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%2F%2F%20Using%20pool%20directly%20(recommended)%0Aasync%20function%20getUserDataDirect(userId)%20%7B%0A%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20pool.execute(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20users%20WHERE%20id%20%3D%20%3F'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%5BuserId%5D%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20return%20rows%5B0%5D%3B%0A%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20console.error('Database%20error%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20throw%20error%3B%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Correct usage pattern
async function getUserData(userId) {
    let connection;
    try {
        connection = await pool.getConnection();
        const [rows] = await connection.execute(
            'SELECT * FROM users WHERE id = ?', 
            [userId]
        );
        return rows[0];
    } catch (error) {
        console.error('Database error:', error);
        throw error;
    } finally {
        if (connection) {
            connection.release(); // Return to pool
        }
    }
}

// Using pool directly (recommended)
async function getUserDataDirect(userId) {
    try {
        const [rows] = await pool.execute(
            'SELECT * FROM users WHERE id = ?', 
            [userId]
        );
        return rows[0];
    } catch (error) {
        console.error('Database error:', error);
        throw error;
    }
}
</code></pre>
</div>

<p><strong>2. Handle Connection Failures:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Robust%20connection%20handling%0Aclass%20DatabaseManager%20%7B%0A%20%20%20%20constructor()%20%7B%0A%20%20%20%20%20%20%20%20this.createPool()%3B%0A%20%20%20%20%20%20%20%20this.setupErrorHandling()%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20createPool()%20%7B%0A%20%20%20%20%20%20%20%20this.pool%20%3D%20mysql.createPool(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20...%20configuration%0A%20%20%20%20%20%20%20%20%20%20%20%20reconnect%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20maxReconnects%3A%203%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20reconnectDelay%3A%202000%0A%20%20%20%20%20%20%20%20%7D)%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20setupErrorHandling()%20%7B%0A%20%20%20%20%20%20%20%20this.pool.on('error'%2C%20(err)%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(err.code%20%3D%3D%3D%20'PROTOCOL_CONNECTION_LOST')%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.log('Database%20connection%20lost%2C%20reconnecting...')%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.handleDisconnect()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20else%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.error('Database%20pool%20error%3A'%2C%20err)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D)%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20async%20handleDisconnect()%20%7B%0A%20%20%20%20%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20this.pool.end()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20this.createPool()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20console.log('Database%20pool%20recreated')%3B%0A%20%20%20%20%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20console.error('Failed%20to%20recreate%20pool%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20setTimeout(()%20%3D%3E%20this.handleDisconnect()%2C%205000)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20async%20query(sql%2C%20params)%20%7B%0A%20%20%20%20%20%20%20%20const%20maxRetries%20%3D%203%3B%0A%20%20%20%20%20%20%20%20let%20retries%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20while%20(retries%20%3C%20maxRetries)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20this.pool.execute(sql%2C%20params)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20rows%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20retries%2B%2B%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20(retries%20%3E%3D%20maxRetries)%20throw%20error%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.log(%60Query%20failed%2C%20retrying%20(%24%7Bretries%7D%2F%24%7BmaxRetries%7D)%60)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20await%20new%20Promise(resolve%20%3D%3E%20setTimeout(resolve%2C%201000%20*%20retries))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Robust connection handling
class DatabaseManager {
    constructor() {
        this.createPool();
        this.setupErrorHandling();
    }
    
    createPool() {
        this.pool = mysql.createPool({
            // ... configuration
            reconnect: true,
            maxReconnects: 3,
            reconnectDelay: 2000
        });
    }
    
    setupErrorHandling() {
        this.pool.on('error', (err) =&gt; {
            if (err.code === 'PROTOCOL_CONNECTION_LOST') {
                console.log('Database connection lost, reconnecting...');
                this.handleDisconnect();
            } else {
                console.error('Database pool error:', err);
            }
        });
    }
    
    async handleDisconnect() {
        try {
            await this.pool.end();
            this.createPool();
            console.log('Database pool recreated');
        } catch (error) {
            console.error('Failed to recreate pool:', error);
            setTimeout(() =&gt; this.handleDisconnect(), 5000);
        }
    }
    
    async query(sql, params) {
        const maxRetries = 3;
        let retries = 0;
        
        while (retries &lt; maxRetries) {
            try {
                const [rows] = await this.pool.execute(sql, params);
                return rows;
            } catch (error) {
                retries++;
                if (retries &gt;= maxRetries) throw error;
                
                console.log(`Query failed, retrying (${retries}/${maxRetries})`);
                await new Promise(resolve =&gt; setTimeout(resolve, 1000 * retries));
            }
        }
    }
}
</code></pre>
</div>

<p><strong>Performance Optimization:</strong></p>

<p>- Size pool based on actual concurrent load, not total users</p>
<p>- Monitor pool utilization and adjust accordingly</p>
<p>- Use connection validation to detect stale connections</p>
<p>- Implement proper timeout settings</p>
<p>- Consider read/write pool separation for high-load applications</p>
<p>- Use prepared statements to reduce parsing overhead</p>


<p>---</p>

<h2 id="-365-what-are-database-hints-and-optimizer-directives-">**365. What are database hints and optimizer directives?**</h2>

<p><strong>Answer:</strong> Database hints and optimizer directives provide explicit instructions to the query optimizer, overriding its automatic decisions.</p>

<p><strong>MySQL Optimizer Hints (8.0+):</strong></p>

<p><strong>1. Index Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20specific%20index%20usage%0ASELECT%20%2F*%2B%20USE_INDEX(users%20idx_email)%20*%2F%20%0A%20%20%20%20name%2C%20email%20%0AFROM%20users%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A%0A--%20Ignore%20specific%20index%0ASELECT%20%2F*%2B%20IGNORE_INDEX(users%20idx_name)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AWHERE%20name%20%3D%20'John'%20AND%20status%20%3D%20'active'%3B%0A%0A--%20Force%20index%20for%20ORDER%20BY%0ASELECT%20%2F*%2B%20USE_INDEX_FOR_ORDER_BY(users%20idx_created_at)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AORDER%20BY%20created_at%20DESC%20%0ALIMIT%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force specific index usage
SELECT /*+ USE_INDEX(users idx_email) */ 
    name, email 
FROM users 
WHERE email = 'john@example.com';

-- Ignore specific index
SELECT /*+ IGNORE_INDEX(users idx_name) */ 
    * 
FROM users 
WHERE name = 'John' AND status = 'active';

-- Force index for ORDER BY
SELECT /*+ USE_INDEX_FOR_ORDER_BY(users idx_created_at) */ 
    * 
FROM users 
ORDER BY created_at DESC 
LIMIT 10;
</code></pre>
</div>

<p><strong>2. Join Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20join%20order%0ASELECT%20%2F*%2B%20STRAIGHT_JOIN%20*%2F%20%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AWHERE%20u.status%20%3D%20'active'%3B%0A%0A--%20Force%20specific%20join%20algorithm%0ASELECT%20%2F*%2B%20USE_NL(u%2C%20o)%20*%2F%20%20--%20Nested%20Loop%20Join%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A%0ASELECT%20%2F*%2B%20USE_BNL(u%2C%20o)%20*%2F%20%20--%20Block%20Nested%20Loop%20Join%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force join order
SELECT /*+ STRAIGHT_JOIN */ 
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id
WHERE u.status = 'active';

-- Force specific join algorithm
SELECT /*+ USE_NL(u, o) */  -- Nested Loop Join
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id;

SELECT /*+ USE_BNL(u, o) */  -- Block Nested Loop Join
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id;
</code></pre>
</div>

<p><strong>3. Subquery Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20subquery%20materialization%0ASELECT%20%2F*%2B%20SUBQUERY(MATERIALIZATION)%20*%2F%0A%20%20%20%20*%0AFROM%20users%20u%0AWHERE%20u.id%20IN%20(%0A%20%20%20%20SELECT%20customer_id%20%0A%20%20%20%20FROM%20orders%20%0A%20%20%20%20WHERE%20total%20%3E%201000%0A)%3B%0A%0A--%20Force%20subquery%20to%20semi-join%20conversion%0ASELECT%20%2F*%2B%20SEMIJOIN(FIRSTMATCH)%20*%2F%0A%20%20%20%20*%0AFROM%20users%20u%0AWHERE%20EXISTS%20(%0A%20%20%20%20SELECT%201%20%0A%20%20%20%20FROM%20orders%20o%20%0A%20%20%20%20WHERE%20o.customer_id%20%3D%20u.id%20AND%20o.total%20%3E%201000%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force subquery materialization
SELECT /*+ SUBQUERY(MATERIALIZATION) */
    *
FROM users u
WHERE u.id IN (
    SELECT customer_id 
    FROM orders 
    WHERE total &gt; 1000
);

-- Force subquery to semi-join conversion
SELECT /*+ SEMIJOIN(FIRSTMATCH) */
    *
FROM users u
WHERE EXISTS (
    SELECT 1 
    FROM orders o 
    WHERE o.customer_id = u.id AND o.total &gt; 1000
);
</code></pre>
</div>

<p><strong>Legacy Index Hints (Still Supported):</strong></p>

<p><strong>1. USE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Suggest%20index%20usage%20(optimizer%20can%20ignore)%0ASELECT%20*%20%0AFROM%20users%20USE%20INDEX%20(idx_email%2C%20idx_status)%0AWHERE%20email%20%3D%20'john%40example.com'%20OR%20status%20%3D%20'active'%3B%0A%0A--%20Force%20index%20usage%20for%20specific%20operations%0ASELECT%20*%20%0AFROM%20users%20%0AUSE%20INDEX%20FOR%20JOIN%20(idx_customer_id)%0AUSE%20INDEX%20FOR%20ORDER%20BY%20(idx_created_at)%0AWHERE%20customer_id%20%3D%20123%0AORDER%20BY%20created_at%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Suggest index usage (optimizer can ignore)
SELECT * 
FROM users USE INDEX (idx_email, idx_status)
WHERE email = 'john@example.com' OR status = 'active';

-- Force index usage for specific operations
SELECT * 
FROM users 
USE INDEX FOR JOIN (idx_customer_id)
USE INDEX FOR ORDER BY (idx_created_at)
WHERE customer_id = 123
ORDER BY created_at DESC;
</code></pre>
</div>

<p><strong>2. FORCE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20index%20usage%20(optimizer%20must%20comply)%0ASELECT%20*%20%0AFROM%20orders%20FORCE%20INDEX%20(idx_order_date)%0AWHERE%20order_date%20BETWEEN%20'2024-01-01'%20AND%20'2024-12-31'%3B%0A%0A--%20Force%20multiple%20indexes%0ASELECT%20*%20%0AFROM%20products%20FORCE%20INDEX%20(idx_category%2C%20idx_price)%0AWHERE%20category%20%3D%20'electronics'%20AND%20price%20BETWEEN%20100%20AND%20500%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force index usage (optimizer must comply)
SELECT * 
FROM orders FORCE INDEX (idx_order_date)
WHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';

-- Force multiple indexes
SELECT * 
FROM products FORCE INDEX (idx_category, idx_price)
WHERE category = 'electronics' AND price BETWEEN 100 AND 500;
</code></pre>
</div>

<p><strong>3. IGNORE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Prevent%20index%20usage%0ASELECT%20*%20%0AFROM%20users%20IGNORE%20INDEX%20(idx_name)%0AWHERE%20name%20LIKE%20'%25john%25'%20AND%20status%20%3D%20'active'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Prevent index usage
SELECT * 
FROM users IGNORE INDEX (idx_name)
WHERE name LIKE '%john%' AND status = 'active';
</code></pre>
</div>

<p><strong>Advanced Optimizer Control:</strong></p>

<p><strong>1. Memory and Resource Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Control%20memory%20usage%20for%20sorting%0ASELECT%20%2F*%2B%20SET_VAR(sort_buffer_size%20%3D%202097152)%20*%2F%0A%20%20%20%20*%0AFROM%20large_table%0AORDER%20BY%20complex_calculation(column1%2C%20column2)%3B%0A%0A--%20Control%20join%20buffer%20size%0ASELECT%20%2F*%2B%20SET_VAR(join_buffer_size%20%3D%201048576)%20*%2F%0A%20%20%20%20u.*%2C%20o.*%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Control memory usage for sorting
SELECT /*+ SET_VAR(sort_buffer_size = 2097152) */
    *
FROM large_table
ORDER BY complex_calculation(column1, column2);

-- Control join buffer size
SELECT /*+ SET_VAR(join_buffer_size = 1048576) */
    u.*, o.*
FROM users u
JOIN orders o ON u.id = o.customer_id;
</code></pre>
</div>

<p><strong>2. Parallel Execution Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20doesn't%20support%20parallel%20query%20execution%20natively%0A--%20But%20you%20can%20hint%20for%20specific%20algorithms%20that%20may%20be%20more%20efficient%0A%0A--%20Force%20hash%20join%20(if%20available)%0ASELECT%20%2F*%2B%20HASH_JOIN(u%2C%20o)%20*%2F%0A%20%20%20%20u.name%2C%20COUNT(o.id)%20as%20order_count%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AGROUP%20BY%20u.id%2C%20u.name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL doesn't support parallel query execution natively
-- But you can hint for specific algorithms that may be more efficient

-- Force hash join (if available)
SELECT /*+ HASH_JOIN(u, o) */
    u.name, COUNT(o.id) as order_count
FROM users u
LEFT JOIN orders o ON u.id = o.customer_id
GROUP BY u.id, u.name;
</code></pre>
</div>

<p><strong>When to Use Hints:</strong></p>

<p><strong>1. Optimizer Mistakes:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20When%20optimizer%20chooses%20wrong%20index%0AEXPLAIN%20SELECT%20*%20FROM%20orders%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%3B%0A--%20If%20it%20uses%20idx_status%20instead%20of%20idx_customer_id%0A%0A--%20Force%20better%20index%0ASELECT%20%2F*%2B%20USE_INDEX(orders%20idx_customer_id)%20*%2F%0A%20%20%20%20*%0AFROM%20orders%20%0AWHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- When optimizer chooses wrong index
EXPLAIN SELECT * FROM orders WHERE customer_id = 123 AND status = 'pending';
-- If it uses idx_status instead of idx_customer_id

-- Force better index
SELECT /*+ USE_INDEX(orders idx_customer_id) */
    *
FROM orders 
WHERE customer_id = 123 AND status = 'pending';
</code></pre>
</div>

<p><strong>2. Complex Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multi-table%20joins%20where%20optimizer%20struggles%0ASELECT%20%2F*%2B%20STRAIGHT_JOIN%20USE_INDEX(o%20idx_date)%20USE_INDEX(u%20idx_status)%20*%2F%0A%20%20%20%20u.name%2C%20o.total%2C%20p.name%20as%20product_name%0AFROM%20orders%20o%0AJOIN%20users%20u%20ON%20o.customer_id%20%3D%20u.id%0AJOIN%20order_items%20oi%20ON%20o.id%20%3D%20oi.order_id%0AJOIN%20products%20p%20ON%20oi.product_id%20%3D%20p.id%0AWHERE%20o.order_date%20%3E%3D%20'2024-01-01'%0AAND%20u.status%20%3D%20'premium'%0AAND%20p.category%20%3D%20'electronics'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multi-table joins where optimizer struggles
SELECT /*+ STRAIGHT_JOIN USE_INDEX(o idx_date) USE_INDEX(u idx_status) */
    u.name, o.total, p.name as product_name
FROM orders o
JOIN users u ON o.customer_id = u.id
JOIN order_items oi ON o.id = oi.order_id
JOIN products p ON oi.product_id = p.id
WHERE o.order_date &gt;= '2024-01-01'
AND u.status = 'premium'
AND p.category = 'electronics';
</code></pre>
</div>

<p><strong>Monitoring Hint Effectiveness:</strong></p>

<p><strong>1. Compare Execution Plans:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Without%20hint%0AEXPLAIN%20FORMAT%3DJSON%20%0ASELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'john%40example.com'%3B%0A%0A--%20With%20hint%0AEXPLAIN%20FORMAT%3DJSON%20%0ASELECT%20%2F*%2B%20USE_INDEX(users%20idx_email)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Without hint
EXPLAIN FORMAT=JSON 
SELECT * FROM users WHERE email = 'john@example.com';

-- With hint
EXPLAIN FORMAT=JSON 
SELECT /*+ USE_INDEX(users idx_email) */ 
    * 
FROM users 
WHERE email = 'john@example.com';
</code></pre>
</div>

<p><strong>2. Performance Testing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Measure%20query%20performance%0ASELECT%20BENCHMARK(1000%2C%20(%0A%20%20%20%20SELECT%20COUNT(*)%20FROM%20users%20WHERE%20status%20%3D%20'active'%0A))%3B%0A%0A--%20Compare%20with%20hint%0ASELECT%20BENCHMARK(1000%2C%20(%0A%20%20%20%20SELECT%20%2F*%2B%20USE_INDEX(users%20idx_status)%20*%2F%20%0A%20%20%20%20%20%20%20%20COUNT(*)%20%0A%20%20%20%20FROM%20users%20%0A%20%20%20%20WHERE%20status%20%3D%20'active'%0A))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Measure query performance
SELECT BENCHMARK(1000, (
    SELECT COUNT(*) FROM users WHERE status = 'active'
));

-- Compare with hint
SELECT BENCHMARK(1000, (
    SELECT /*+ USE_INDEX(users idx_status) */ 
        COUNT(*) 
    FROM users 
    WHERE status = 'active'
));
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use hints sparingly - optimizer is usually correct</p>
<p>- Document why hints are necessary</p>
<p>- Test hint effectiveness with EXPLAIN</p>
<p>- Review hints after MySQL upgrades</p>
<p>- Monitor query performance regularly</p>
<p>- Consider query rewriting before using hints</p>
<p>- Remove hints that no longer provide benefit</p>


<p><strong>Common Pitfalls:</strong></p>

<p>- Over-relying on hints instead of proper indexing</p>
<p>- Using outdated hints after schema changes</p>
<p>- Hints that hurt performance in different data distributions</p>
<p>- Ignoring optimizer improvements in newer MySQL versions</p>

<h2 id="-366-what-are-database-cursors-and-how-do-you-use-them-">**366. What are database cursors and how do you use them?**</h2>

<p><strong>Answer:</strong> Database cursors provide a mechanism to traverse result sets row by row, useful for complex row-by-row processing that can't be handled with set-based operations.</p>

<p><strong>Cursor Types in MySQL:</strong></p>

<p><strong>1. Basic Cursor Declaration and Usage:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20ProcessLargeOrders()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20order_id%20INT%3B%0A%20%20%20%20DECLARE%20customer_id%20INT%3B%0A%20%20%20%20DECLARE%20total%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Declare%20cursor%0A%20%20%20%20DECLARE%20order_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20customer_id%2C%20total%0A%20%20%20%20%20%20%20%20FROM%20orders%0A%20%20%20%20%20%20%20%20WHERE%20total%20%3E%201000%0A%20%20%20%20%20%20%20%20ORDER%20BY%20total%20DESC%3B%0A%20%20%20%20%0A%20%20%20%20--%20Declare%20handler%20for%20end%20of%20cursor%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Open%20cursor%0A%20%20%20%20OPEN%20order_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Loop%20through%20results%0A%20%20%20%20order_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20order_cursor%20INTO%20order_id%2C%20customer_id%2C%20total%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20order_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Process%20each%20row%0A%20%20%20%20%20%20%20%20CALL%20ProcessLargeOrder(order_id%2C%20customer_id%2C%20total)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20order%20status%0A%20%20%20%20%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'processed'%2C%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20order_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Close%20cursor%0A%20%20%20%20CLOSE%20order_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE ProcessLargeOrders()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE order_id INT;
    DECLARE customer_id INT;
    DECLARE total DECIMAL(10,2);
    
    -- Declare cursor
    DECLARE order_cursor CURSOR FOR
        SELECT id, customer_id, total
        FROM orders
        WHERE total &gt; 1000
        ORDER BY total DESC;
    
    -- Declare handler for end of cursor
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Open cursor
    OPEN order_cursor;
    
    -- Loop through results
    order_loop: LOOP
        FETCH order_cursor INTO order_id, customer_id, total;
        
        IF done THEN
            LEAVE order_loop;
        END IF;
        
        -- Process each row
        CALL ProcessLargeOrder(order_id, customer_id, total);
        
        -- Update order status
        UPDATE orders 
        SET status = 'processed', processed_at = NOW()
        WHERE id = order_id;
        
    END LOOP;
    
    -- Close cursor
    CLOSE order_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Cursor with Complex Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20CalculateCustomerLoyaltyPoints()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20cust_id%20INT%3B%0A%20%20%20%20DECLARE%20total_spent%20DECIMAL(12%2C2)%3B%0A%20%20%20%20DECLARE%20order_count%20INT%3B%0A%20%20%20%20DECLARE%20loyalty_points%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20customer_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20c.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(SUM(o.total)%2C%200)%20as%20total_spent%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20order_count%0A%20%20%20%20%20%20%20%20FROM%20customers%20c%0A%20%20%20%20%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0A%20%20%20%20%20%20%20%20WHERE%20c.status%20%3D%20'active'%0A%20%20%20%20%20%20%20%20GROUP%20BY%20c.id%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20customer_cursor%3B%0A%20%20%20%20%0A%20%20%20%20customer_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20customer_cursor%20INTO%20cust_id%2C%20total_spent%2C%20order_count%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20customer_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20loyalty%20points%20based%20on%20business%20rules%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Base%20points%20from%20spending%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20FLOOR(total_spent%20%2F%2010)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Bonus%20points%20for%20frequent%20orders%0A%20%20%20%20%20%20%20%20IF%20order_count%20%3E%3D%2010%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20100%3B%0A%20%20%20%20%20%20%20%20ELSEIF%20order_count%20%3E%3D%205%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%2050%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20VIP%20bonus%20for%20high%20spenders%0A%20%20%20%20%20%20%20%20IF%20total_spent%20%3E%3D%205000%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20200%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20customer%20record%0A%20%20%20%20%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20loyalty_tier%20%3D%20CASE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%201000%20THEN%20'platinum'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%20500%20THEN%20'gold'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%20200%20THEN%20'silver'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'bronze'%0A%20%20%20%20%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20last_points_calculation%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20cust_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20customer_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20completion%0A%20%20%20%20INSERT%20INTO%20process_log%20(process_name%2C%20completed_at%2C%20records_processed)%0A%20%20%20%20SELECT%20'loyalty_calculation'%2C%20NOW()%2C%20COUNT(*)%20FROM%20customers%20WHERE%20status%20%3D%20'active'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE CalculateCustomerLoyaltyPoints()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE cust_id INT;
    DECLARE total_spent DECIMAL(12,2);
    DECLARE order_count INT;
    DECLARE loyalty_points INT DEFAULT 0;
    
    DECLARE customer_cursor CURSOR FOR
        SELECT 
            c.id,
            COALESCE(SUM(o.total), 0) as total_spent,
            COUNT(o.id) as order_count
        FROM customers c
        LEFT JOIN orders o ON c.id = o.customer_id
        WHERE c.status = 'active'
        GROUP BY c.id;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN customer_cursor;
    
    customer_loop: LOOP
        FETCH customer_cursor INTO cust_id, total_spent, order_count;
        
        IF done THEN
            LEAVE customer_loop;
        END IF;
        
        -- Calculate loyalty points based on business rules
        SET loyalty_points = 0;
        
        -- Base points from spending
        SET loyalty_points = loyalty_points + FLOOR(total_spent / 10);
        
        -- Bonus points for frequent orders
        IF order_count &gt;= 10 THEN
            SET loyalty_points = loyalty_points + 100;
        ELSEIF order_count &gt;= 5 THEN
            SET loyalty_points = loyalty_points + 50;
        END IF;
        
        -- VIP bonus for high spenders
        IF total_spent &gt;= 5000 THEN
            SET loyalty_points = loyalty_points + 200;
        END IF;
        
        -- Update customer record
        UPDATE customers 
        SET loyalty_points = loyalty_points,
            loyalty_tier = CASE
                WHEN loyalty_points &gt;= 1000 THEN 'platinum'
                WHEN loyalty_points &gt;= 500 THEN 'gold'
                WHEN loyalty_points &gt;= 200 THEN 'silver'
                ELSE 'bronze'
            END,
            last_points_calculation = NOW()
        WHERE id = cust_id;
        
    END LOOP;
    
    CLOSE customer_cursor;
    
    -- Log completion
    INSERT INTO process_log (process_name, completed_at, records_processed)
    SELECT 'loyalty_calculation', NOW(), COUNT(*) FROM customers WHERE status = 'active';
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Cursor Performance Considerations:</strong></p>

<p><strong>1. Memory-Efficient Cursor:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20ProcessLargeDataset()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20batch_size%20INT%20DEFAULT%201000%3B%0A%20%20%20%20DECLARE%20processed_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20record_id%20INT%3B%0A%20%20%20%20DECLARE%20record_data%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20in%20batches%20to%20avoid%20memory%20issues%0A%20%20%20%20DECLARE%20batch_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20data_column%0A%20%20%20%20%20%20%20%20FROM%20large_table%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%200%0A%20%20%20%20%20%20%20%20ORDER%20BY%20id%0A%20%20%20%20%20%20%20%20LIMIT%20batch_size%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20batch_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20SET%20done%20%3D%20FALSE%3B%0A%20%20%20%20%20%20%20%20OPEN%20batch_cursor%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20record_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20%20%20%20%20FETCH%20batch_cursor%20INTO%20record_id%2C%20record_data%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20record_loop%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Process%20individual%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20ProcessRecord(record_id%2C%20record_data)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20%20%20%20%20UPDATE%20large_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20processed%20%3D%201%2C%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20record_id%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20processed_count%20%3D%20processed_count%20%2B%201%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20CLOSE%20batch_cursor%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Exit%20if%20no%20more%20records%20to%20process%0A%20%20%20%20%20%20%20%20IF%20processed_count%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20batch_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Reset%20counter%20for%20next%20batch%0A%20%20%20%20%20%20%20%20SET%20processed_count%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE ProcessLargeDataset()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE batch_size INT DEFAULT 1000;
    DECLARE processed_count INT DEFAULT 0;
    DECLARE record_id INT;
    DECLARE record_data TEXT;
    
    -- Process in batches to avoid memory issues
    DECLARE batch_cursor CURSOR FOR
        SELECT id, data_column
        FROM large_table
        WHERE processed = 0
        ORDER BY id
        LIMIT batch_size;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    batch_loop: LOOP
        SET done = FALSE;
        OPEN batch_cursor;
        
        record_loop: LOOP
            FETCH batch_cursor INTO record_id, record_data;
            
            IF done THEN
                LEAVE record_loop;
            END IF;
            
            -- Process individual record
            CALL ProcessRecord(record_id, record_data);
            
            -- Mark as processed
            UPDATE large_table 
            SET processed = 1, processed_at = NOW()
            WHERE id = record_id;
            
            SET processed_count = processed_count + 1;
            
        END LOOP;
        
        CLOSE batch_cursor;
        
        -- Exit if no more records to process
        IF processed_count = 0 THEN
            LEAVE batch_loop;
        END IF;
        
        -- Reset counter for next batch
        SET processed_count = 0;
        
    END LOOP;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>When to Use Cursors:</strong></p>

<p>- Complex row-by-row calculations that can't be done with SQL</p>
<p>- Sequential processing requirements</p>
<p>- When you need to call stored procedures for each row</p>
<p>- Migrating data with complex transformation logic</p>


<p><strong>Alternatives to Cursors:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20cursor%20for%20simple%20updates%3A%0A--%20BAD%20(using%20cursor)%3A%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20UpdatePricesWithCursor()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20prod_id%20INT%3B%0A%20%20%20%20DECLARE%20current_price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20price_cursor%20CURSOR%20FOR%20SELECT%20id%2C%20price%20FROM%20products%3B%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20price_cursor%3B%0A%20%20%20%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20price_cursor%20INTO%20prod_id%2C%20current_price%3B%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%20LEAVE%3B%20END%20IF%3B%0A%20%20%20%20%20%20%20%20UPDATE%20products%20SET%20price%20%3D%20current_price%20*%201.1%20WHERE%20id%20%3D%20prod_id%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20CLOSE%20price_cursor%3B%0AEND%20%2F%2F%0A%0A--%20GOOD%20(set-based%20operation)%3A%0AUPDATE%20products%20SET%20price%20%3D%20price%20*%201.1%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of cursor for simple updates:
-- BAD (using cursor):
DELIMITER //
CREATE PROCEDURE UpdatePricesWithCursor()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE prod_id INT;
    DECLARE current_price DECIMAL(10,2);
    
    DECLARE price_cursor CURSOR FOR SELECT id, price FROM products;
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN price_cursor;
    LOOP
        FETCH price_cursor INTO prod_id, current_price;
        IF done THEN LEAVE; END IF;
        UPDATE products SET price = current_price * 1.1 WHERE id = prod_id;
    END LOOP;
    CLOSE price_cursor;
END //

-- GOOD (set-based operation):
UPDATE products SET price = price * 1.1;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Avoid cursors when set-based operations can achieve the same result</p>
<p>- Use cursors only for complex row-by-row processing</p>
<p>- Process in batches for large datasets</p>
<p>- Always close cursors to free resources</p>
<p>- Handle NOT FOUND conditions properly</p>
<p>- Consider performance impact on concurrent operations</p>


<p>---</p>

<h2 id="-367-what-are-database-packages-and-modules-">**367. What are database packages and modules?**</h2>

<p><strong>Answer:</strong> MySQL doesn't have native packages like Oracle or PostgreSQL, but you can organize related procedures, functions, and logic using naming conventions and modular design patterns.</p>

<p><strong>Organizing Related Procedures:</strong></p>

<p><strong>1. Naming Convention Approach:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20User%20management%20%22package%22%0ADELIMITER%20%2F%2F%0A%0A--%20User%20creation%0ACREATE%20PROCEDURE%20user_pkg_create_user(%0A%20%20%20%20IN%20p_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_email%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_password%20VARCHAR(255)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20user_exists%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20if%20user%20already%20exists%0A%20%20%20%20SELECT%20COUNT(*)%20INTO%20user_exists%20%0A%20%20%20%20FROM%20users%20WHERE%20email%20%3D%20p_email%3B%0A%20%20%20%20%0A%20%20%20%20IF%20user_exists%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'User%20already%20exists'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20users%20(name%2C%20email%2C%20password_hash%2C%20created_at)%0A%20%20%20%20VALUES%20(p_name%2C%20p_email%2C%20SHA2(p_password%2C%20256)%2C%20NOW())%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20LAST_INSERT_ID()%20as%20user_id%3B%0AEND%20%2F%2F%0A%0A--%20User%20authentication%0ACREATE%20FUNCTION%20user_pkg_authenticate(%0A%20%20%20%20p_email%20VARCHAR(255)%2C%0A%20%20%20%20p_password%20VARCHAR(255)%0A)%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20user_id%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20id%20INTO%20user_id%0A%20%20%20%20FROM%20users%20%0A%20%20%20%20WHERE%20email%20%3D%20p_email%20%0A%20%20%20%20AND%20password_hash%20%3D%20SHA2(p_password%2C%20256)%0A%20%20%20%20AND%20status%20%3D%20'active'%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20COALESCE(user_id%2C%200)%3B%0AEND%20%2F%2F%0A%0A--%20User%20profile%20update%0ACREATE%20PROCEDURE%20user_pkg_update_profile(%0A%20%20%20%20IN%20p_user_id%20INT%2C%0A%20%20%20%20IN%20p_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_phone%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20p_name%2C%20%0A%20%20%20%20%20%20%20%20phone%20%3D%20p_phone%2C%0A%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_user_id%3B%0A%20%20%20%20%0A%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'User%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0A%0A--%20User%20deactivation%0ACREATE%20PROCEDURE%20user_pkg_deactivate_user(IN%20p_user_id%20INT)%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20status%20%3D%20'inactive'%2C%20%0A%20%20%20%20%20%20%20%20deactivated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_user_id%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- User management "package"
DELIMITER //

-- User creation
CREATE PROCEDURE user_pkg_create_user(
    IN p_name VARCHAR(100),
    IN p_email VARCHAR(255),
    IN p_password VARCHAR(255)
)
BEGIN
    DECLARE user_exists INT DEFAULT 0;
    
    -- Check if user already exists
    SELECT COUNT(*) INTO user_exists 
    FROM users WHERE email = p_email;
    
    IF user_exists &gt; 0 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'User already exists';
    END IF;
    
    INSERT INTO users (name, email, password_hash, created_at)
    VALUES (p_name, p_email, SHA2(p_password, 256), NOW());
    
    SELECT LAST_INSERT_ID() as user_id;
END //

-- User authentication
CREATE FUNCTION user_pkg_authenticate(
    p_email VARCHAR(255),
    p_password VARCHAR(255)
)
RETURNS INT
READS SQL DATA
BEGIN
    DECLARE user_id INT DEFAULT 0;
    
    SELECT id INTO user_id
    FROM users 
    WHERE email = p_email 
    AND password_hash = SHA2(p_password, 256)
    AND status = 'active';
    
    RETURN COALESCE(user_id, 0);
END //

-- User profile update
CREATE PROCEDURE user_pkg_update_profile(
    IN p_user_id INT,
    IN p_name VARCHAR(100),
    IN p_phone VARCHAR(20)
)
BEGIN
    UPDATE users 
    SET name = p_name, 
        phone = p_phone,
        updated_at = NOW()
    WHERE id = p_user_id;
    
    IF ROW_COUNT() = 0 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'User not found';
    END IF;
END //

-- User deactivation
CREATE PROCEDURE user_pkg_deactivate_user(IN p_user_id INT)
BEGIN
    UPDATE users 
    SET status = 'inactive', 
        deactivated_at = NOW()
    WHERE id = p_user_id;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>2. Order Management "Package":</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Create%20order%0ACREATE%20PROCEDURE%20order_pkg_create_order(%0A%20%20%20%20IN%20p_customer_id%20INT%2C%0A%20%20%20%20IN%20p_items%20JSON%2C%0A%20%20%20%20OUT%20p_order_id%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20total_amount%20DECIMAL(10%2C2)%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20item_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20product_id%20INT%3B%0A%20%20%20%20DECLARE%20quantity%20INT%3B%0A%20%20%20%20DECLARE%20price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Start%20transaction%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20order%20record%0A%20%20%20%20INSERT%20INTO%20orders%20(customer_id%2C%20status%2C%20created_at)%0A%20%20%20%20VALUES%20(p_customer_id%2C%20'pending'%2C%20NOW())%3B%0A%20%20%20%20%0A%20%20%20%20SET%20p_order_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20order%20items%0A%20%20%20%20SET%20item_count%20%3D%20JSON_LENGTH(p_items)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20item_count%20DO%0A%20%20%20%20%20%20%20%20SET%20product_id%20%3D%20JSON_EXTRACT(p_items%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.product_id'))%3B%0A%20%20%20%20%20%20%20%20SET%20quantity%20%3D%20JSON_EXTRACT(p_items%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.quantity'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20product%20price%0A%20%20%20%20%20%20%20%20SELECT%20price%20INTO%20price%20FROM%20products%20WHERE%20id%20%3D%20product_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20order%20item%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20order_items%20(order_id%2C%20product_id%2C%20quantity%2C%20price)%0A%20%20%20%20%20%20%20%20VALUES%20(p_order_id%2C%20product_id%2C%20quantity%2C%20price)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Add%20to%20total%0A%20%20%20%20%20%20%20%20SET%20total_amount%20%3D%20total_amount%20%2B%20(quantity%20*%20price)%3B%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20order%20total%0A%20%20%20%20UPDATE%20orders%20SET%20total%20%3D%20total_amount%20WHERE%20id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0A%0A--%20Calculate%20order%20total%0ACREATE%20FUNCTION%20order_pkg_calculate_total(p_order_id%20INT)%0ARETURNS%20DECIMAL(10%2C2)%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20order_total%20DECIMAL(10%2C2)%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20SUM(quantity%20*%20price)%20INTO%20order_total%0A%20%20%20%20FROM%20order_items%0A%20%20%20%20WHERE%20order_id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20COALESCE(order_total%2C%200)%3B%0AEND%20%2F%2F%0A%0A--%20Update%20order%20status%0ACREATE%20PROCEDURE%20order_pkg_update_status(%0A%20%20%20%20IN%20p_order_id%20INT%2C%0A%20%20%20%20IN%20p_status%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20valid_status%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Validate%20status%0A%20%20%20%20IF%20p_status%20IN%20('pending'%2C%20'confirmed'%2C%20'shipped'%2C%20'delivered'%2C%20'cancelled')%20THEN%0A%20%20%20%20%20%20%20%20SET%20valid_status%20%3D%20TRUE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20NOT%20valid_status%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Invalid%20order%20status'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20SET%20status%20%3D%20p_status%2C%0A%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20status%20change%0A%20%20%20%20INSERT%20INTO%20order_status_log%20(order_id%2C%20old_status%2C%20new_status%2C%20changed_at)%0A%20%20%20%20SELECT%20p_order_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20(SELECT%20status%20FROM%20orders%20WHERE%20id%20%3D%20p_order_id)%2C%0A%20%20%20%20%20%20%20%20%20%20%20p_status%2C%0A%20%20%20%20%20%20%20%20%20%20%20NOW()%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Create order
CREATE PROCEDURE order_pkg_create_order(
    IN p_customer_id INT,
    IN p_items JSON,
    OUT p_order_id INT
)
BEGIN
    DECLARE total_amount DECIMAL(10,2) DEFAULT 0;
    DECLARE item_count INT DEFAULT 0;
    DECLARE i INT DEFAULT 0;
    DECLARE product_id INT;
    DECLARE quantity INT;
    DECLARE price DECIMAL(10,2);
    
    -- Start transaction
    START TRANSACTION;
    
    -- Create order record
    INSERT INTO orders (customer_id, status, created_at)
    VALUES (p_customer_id, 'pending', NOW());
    
    SET p_order_id = LAST_INSERT_ID();
    
    -- Process order items
    SET item_count = JSON_LENGTH(p_items);
    
    WHILE i &lt; item_count DO
        SET product_id = JSON_EXTRACT(p_items, CONCAT('$[', i, '].product_id'));
        SET quantity = JSON_EXTRACT(p_items, CONCAT('$[', i, '].quantity'));
        
        -- Get product price
        SELECT price INTO price FROM products WHERE id = product_id;
        
        -- Insert order item
        INSERT INTO order_items (order_id, product_id, quantity, price)
        VALUES (p_order_id, product_id, quantity, price);
        
        -- Add to total
        SET total_amount = total_amount + (quantity * price);
        SET i = i + 1;
    END WHILE;
    
    -- Update order total
    UPDATE orders SET total = total_amount WHERE id = p_order_id;
    
    COMMIT;
END //

-- Calculate order total
CREATE FUNCTION order_pkg_calculate_total(p_order_id INT)
RETURNS DECIMAL(10,2)
READS SQL DATA
BEGIN
    DECLARE order_total DECIMAL(10,2) DEFAULT 0;
    
    SELECT SUM(quantity * price) INTO order_total
    FROM order_items
    WHERE order_id = p_order_id;
    
    RETURN COALESCE(order_total, 0);
END //

-- Update order status
CREATE PROCEDURE order_pkg_update_status(
    IN p_order_id INT,
    IN p_status VARCHAR(20)
)
BEGIN
    DECLARE valid_status BOOLEAN DEFAULT FALSE;
    
    -- Validate status
    IF p_status IN ('pending', 'confirmed', 'shipped', 'delivered', 'cancelled') THEN
        SET valid_status = TRUE;
    END IF;
    
    IF NOT valid_status THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Invalid order status';
    END IF;
    
    UPDATE orders 
    SET status = p_status,
        updated_at = NOW()
    WHERE id = p_order_id;
    
    -- Log status change
    INSERT INTO order_status_log (order_id, old_status, new_status, changed_at)
    SELECT p_order_id, 
           (SELECT status FROM orders WHERE id = p_order_id),
           p_status,
           NOW();
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Reporting "Package":</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Sales%20report%0ACREATE%20PROCEDURE%20report_pkg_sales_summary(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20DATE(o.created_at)%20as%20sale_date%2C%0A%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(o.total)%20as%20total_sales%2C%0A%20%20%20%20%20%20%20%20AVG(o.total)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20COUNT(DISTINCT%20o.customer_id)%20as%20unique_customers%0A%20%20%20%20FROM%20orders%20o%0A%20%20%20%20WHERE%20DATE(o.created_at)%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20AND%20o.status%20!%3D%20'cancelled'%0A%20%20%20%20GROUP%20BY%20DATE(o.created_at)%0A%20%20%20%20ORDER%20BY%20sale_date%3B%0AEND%20%2F%2F%0A%0A--%20Customer%20analytics%0ACREATE%20PROCEDURE%20report_pkg_customer_analytics(IN%20p_customer_id%20INT)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20c.name%2C%0A%20%20%20%20%20%20%20%20c.email%2C%0A%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20total_orders%2C%0A%20%20%20%20%20%20%20%20SUM(o.total)%20as%20lifetime_value%2C%0A%20%20%20%20%20%20%20%20AVG(o.total)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20MIN(o.created_at)%20as%20first_order%2C%0A%20%20%20%20%20%20%20%20MAX(o.created_at)%20as%20last_order%2C%0A%20%20%20%20%20%20%20%20DATEDIFF(NOW()%2C%20MAX(o.created_at))%20as%20days_since_last_order%0A%20%20%20%20FROM%20customers%20c%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0A%20%20%20%20WHERE%20c.id%20%3D%20p_customer_id%0A%20%20%20%20GROUP%20BY%20c.id%2C%20c.name%2C%20c.email%3B%0AEND%20%2F%2F%0A%0A--%20Product%20performance%0ACREATE%20FUNCTION%20report_pkg_product_performance(%0A%20%20%20%20p_product_id%20INT%2C%0A%20%20%20%20p_days%20INT%0A)%0ARETURNS%20JSON%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20result%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'product_id'%2C%20p.id%2C%0A%20%20%20%20%20%20%20%20'product_name'%2C%20p.name%2C%0A%20%20%20%20%20%20%20%20'total_sold'%2C%20COALESCE(SUM(oi.quantity)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'total_revenue'%2C%20COALESCE(SUM(oi.quantity%20*%20oi.price)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'avg_price'%2C%20COALESCE(AVG(oi.price)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'order_count'%2C%20COUNT(DISTINCT%20oi.order_id)%0A%20%20%20%20)%20INTO%20result%0A%20%20%20%20FROM%20products%20p%0A%20%20%20%20LEFT%20JOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0A%20%20%20%20WHERE%20p.id%20%3D%20p_product_id%0A%20%20%20%20AND%20(p_days%20%3D%200%20OR%20o.created_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%20p_days%20DAY))%0A%20%20%20%20GROUP%20BY%20p.id%2C%20p.name%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20result%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Sales report
CREATE PROCEDURE report_pkg_sales_summary(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    SELECT 
        DATE(o.created_at) as sale_date,
        COUNT(o.id) as order_count,
        SUM(o.total) as total_sales,
        AVG(o.total) as avg_order_value,
        COUNT(DISTINCT o.customer_id) as unique_customers
    FROM orders o
    WHERE DATE(o.created_at) BETWEEN p_start_date AND p_end_date
    AND o.status != 'cancelled'
    GROUP BY DATE(o.created_at)
    ORDER BY sale_date;
END //

-- Customer analytics
CREATE PROCEDURE report_pkg_customer_analytics(IN p_customer_id INT)
BEGIN
    SELECT 
        c.name,
        c.email,
        COUNT(o.id) as total_orders,
        SUM(o.total) as lifetime_value,
        AVG(o.total) as avg_order_value,
        MIN(o.created_at) as first_order,
        MAX(o.created_at) as last_order,
        DATEDIFF(NOW(), MAX(o.created_at)) as days_since_last_order
    FROM customers c
    LEFT JOIN orders o ON c.id = o.customer_id
    WHERE c.id = p_customer_id
    GROUP BY c.id, c.name, c.email;
END //

-- Product performance
CREATE FUNCTION report_pkg_product_performance(
    p_product_id INT,
    p_days INT
)
RETURNS JSON
READS SQL DATA
BEGIN
    DECLARE result JSON;
    
    SELECT JSON_OBJECT(
        'product_id', p.id,
        'product_name', p.name,
        'total_sold', COALESCE(SUM(oi.quantity), 0),
        'total_revenue', COALESCE(SUM(oi.quantity * oi.price), 0),
        'avg_price', COALESCE(AVG(oi.price), 0),
        'order_count', COUNT(DISTINCT oi.order_id)
    ) INTO result
    FROM products p
    LEFT JOIN order_items oi ON p.id = oi.product_id
    LEFT JOIN orders o ON oi.order_id = o.id
    WHERE p.id = p_product_id
    AND (p_days = 0 OR o.created_at &gt;= DATE_SUB(NOW(), INTERVAL p_days DAY))
    GROUP BY p.id, p.name;
    
    RETURN result;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Package Documentation and Management:</strong></p>

<p><strong>1. Create Documentation Table:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20procedure_documentation%20(%0A%20%20%20%20procedure_name%20VARCHAR(100)%20PRIMARY%20KEY%2C%0A%20%20%20%20package_name%20VARCHAR(50)%2C%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20parameters%20JSON%2C%0A%20%20%20%20return_type%20VARCHAR(50)%2C%0A%20%20%20%20example_usage%20TEXT%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Document%20procedures%0AINSERT%20INTO%20procedure_documentation%20VALUES%0A('user_pkg_create_user'%2C%20'user_management'%2C%20%0A%20'Creates%20a%20new%20user%20account%20with%20validation'%2C%0A%20'%7B%22p_name%22%3A%20%22VARCHAR(100)%22%2C%20%22p_email%22%3A%20%22VARCHAR(255)%22%2C%20%22p_password%22%3A%20%22VARCHAR(255)%22%7D'%2C%0A%20'INT%20(user_id)'%2C%0A%20'CALL%20user_pkg_create_user(%5C'John%20Doe%5C'%2C%20%5C'john%40example.com%5C'%2C%20%5C'password123%5C')%3B'%2C%0A%20'admin'%2C%20NOW()%2C%20NOW())%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE procedure_documentation (
    procedure_name VARCHAR(100) PRIMARY KEY,
    package_name VARCHAR(50),
    description TEXT,
    parameters JSON,
    return_type VARCHAR(50),
    example_usage TEXT,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Document procedures
INSERT INTO procedure_documentation VALUES
('user_pkg_create_user', 'user_management', 
 'Creates a new user account with validation',
 '{"p_name": "VARCHAR(100)", "p_email": "VARCHAR(255)", "p_password": "VARCHAR(255)"}',
 'INT (user_id)',
 'CALL user_pkg_create_user(\'John Doe\', \'john@example.com\', \'password123\');',
 'admin', NOW(), NOW());
</code></pre>
</div>

<p><strong>2. Package Deployment Script:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Package%20deployment%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20deploy_package(IN%20package_name%20VARCHAR(50))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20proc_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20proc_definition%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20package_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20routine_name%2C%20routine_definition%0A%20%20%20%20%20%20%20%20FROM%20information_schema.routines%0A%20%20%20%20%20%20%20%20WHERE%20routine_schema%20%3D%20DATABASE()%0A%20%20%20%20%20%20%20%20AND%20routine_name%20LIKE%20CONCAT(package_name%2C%20'_pkg_%25')%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20CONCAT('Deploying%20package%3A%20'%2C%20package_name)%20as%20status%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20package_cursor%3B%0A%20%20%20%20%0A%20%20%20%20deploy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20package_cursor%20INTO%20proc_name%2C%20proc_definition%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20deploy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20CONCAT('Deployed%3A%20'%2C%20proc_name)%20as%20procedure_status%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20package_cursor%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20'Package%20deployment%20completed'%20as%20final_status%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Package deployment procedure
DELIMITER //
CREATE PROCEDURE deploy_package(IN package_name VARCHAR(50))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE proc_name VARCHAR(100);
    DECLARE proc_definition TEXT;
    
    DECLARE package_cursor CURSOR FOR
        SELECT routine_name, routine_definition
        FROM information_schema.routines
        WHERE routine_schema = DATABASE()
        AND routine_name LIKE CONCAT(package_name, '_pkg_%');
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    SELECT CONCAT('Deploying package: ', package_name) as status;
    
    OPEN package_cursor;
    
    deploy_loop: LOOP
        FETCH package_cursor INTO proc_name, proc_definition;
        
        IF done THEN
            LEAVE deploy_loop;
        END IF;
        
        SELECT CONCAT('Deployed: ', proc_name) as procedure_status;
        
    END LOOP;
    
    CLOSE package_cursor;
    
    SELECT 'Package deployment completed' as final_status;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices for MySQL "Packages":</strong></p>

<p>- Use consistent naming conventions (package_name_function_name)</p>
<p>- Group related functionality together</p>
<p>- Document all procedures and functions</p>
<p>- Implement proper error handling</p>
<p>- Use transactions where appropriate</p>
<p>- Version control your stored procedures</p>
<p>- Create deployment and rollback scripts</p>


<p>---</p>

<h2 id="-368-how-do-you-implement-database-auditing-and-compliance-">**368. How do you implement database auditing and compliance?**</h2>

<p><strong>Answer:</strong> Database auditing and compliance involve tracking data access, changes, and ensuring adherence to regulatory requirements like GDPR, HIPAA, or SOX.</p>

<p><strong>Comprehensive Audit Framework:</strong></p>

<p><strong>1. Audit Infrastructure Setup:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20audit%20log%20table%0ACREATE%20TABLE%20audit_trail%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20event_id%20VARCHAR(36)%20NOT%20NULL%20DEFAULT%20(UUID())%2C%0A%20%20%20%20event_type%20ENUM('SELECT'%2C%20'INSERT'%2C%20'UPDATE'%2C%20'DELETE'%2C%20'LOGIN'%2C%20'LOGOUT'%2C%20'SCHEMA_CHANGE')%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(64)%2C%0A%20%20%20%20record_id%20VARCHAR(255)%2C%0A%20%20%20%20user_id%20VARCHAR(100)%2C%0A%20%20%20%20session_id%20VARCHAR(100)%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20application_name%20VARCHAR(100)%2C%0A%20%20%20%20sql_statement%20TEXT%2C%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20affected_rows%20INT%2C%0A%20%20%20%20execution_time_ms%20INT%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20compliance_tags%20JSON%2C%0A%20%20%20%20risk_level%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'LOW'%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_table_name%20(table_name)%2C%0A%20%20%20%20INDEX%20idx_user_id%20(user_id)%2C%0A%20%20%20%20INDEX%20idx_timestamp%20(event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_risk_level%20(risk_level)%2C%0A%20%20%20%20INDEX%20idx_compliance_tags%20((CAST(compliance_tags%20AS%20CHAR(255)%20ARRAY)))%0A)%3B%0A%0A--%20Sensitive%20data%20access%20log%0ACREATE%20TABLE%20sensitive_data_access%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20audit_id%20BIGINT%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%20NOT%20NULL%2C%0A%20%20%20%20data_category%20VARCHAR(50)%2C%20--%20PII%2C%20PHI%2C%20Financial%2C%20etc.%0A%20%20%20%20field_name%20VARCHAR(100)%2C%0A%20%20%20%20access_reason%20VARCHAR(255)%2C%0A%20%20%20%20approval_required%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20approval_status%20ENUM('PENDING'%2C%20'APPROVED'%2C%20'DENIED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20approved_by%20VARCHAR(100)%2C%0A%20%20%20%20approved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20retention_period%20INT%2C%20--%20Days%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(audit_id)%20REFERENCES%20audit_trail(id)%2C%0A%20%20%20%20INDEX%20idx_classification%20(data_classification)%2C%0A%20%20%20%20INDEX%20idx_category%20(data_category)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main audit log table
CREATE TABLE audit_trail (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    event_id VARCHAR(36) NOT NULL DEFAULT (UUID()),
    event_type ENUM('SELECT', 'INSERT', 'UPDATE', 'DELETE', 'LOGIN', 'LOGOUT', 'SCHEMA_CHANGE') NOT NULL,
    table_name VARCHAR(64),
    record_id VARCHAR(255),
    user_id VARCHAR(100),
    session_id VARCHAR(100),
    ip_address VARCHAR(45),
    user_agent TEXT,
    application_name VARCHAR(100),
    sql_statement TEXT,
    old_values JSON,
    new_values JSON,
    affected_rows INT,
    execution_time_ms INT,
    event_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    compliance_tags JSON,
    risk_level ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'LOW',
    
    INDEX idx_event_type (event_type),
    INDEX idx_table_name (table_name),
    INDEX idx_user_id (user_id),
    INDEX idx_timestamp (event_timestamp),
    INDEX idx_risk_level (risk_level),
    INDEX idx_compliance_tags ((CAST(compliance_tags AS CHAR(255) ARRAY)))
);

-- Sensitive data access log
CREATE TABLE sensitive_data_access (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    audit_id BIGINT,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED') NOT NULL,
    data_category VARCHAR(50), -- PII, PHI, Financial, etc.
    field_name VARCHAR(100),
    access_reason VARCHAR(255),
    approval_required BOOLEAN DEFAULT FALSE,
    approval_status ENUM('PENDING', 'APPROVED', 'DENIED') DEFAULT 'PENDING',
    approved_by VARCHAR(100),
    approved_at TIMESTAMP NULL,
    retention_period INT, -- Days
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (audit_id) REFERENCES audit_trail(id),
    INDEX idx_classification (data_classification),
    INDEX idx_category (data_category),
    INDEX idx_approval_status (approval_status)
);
</code></pre>
</div>

<p><strong>2. Comprehensive Audit Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generic%20audit%20trigger%20for%20sensitive%20tables%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_audit_trigger(%0A%20%20%20%20IN%20table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20sensitive_columns%20JSON%0A)%0ABEGIN%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('%0A%20%20%20%20CREATE%20TRIGGER%20'%2C%20table_name%2C%20'_audit_insert%0A%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20table_name%2C%20'%0A%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20CALL%20log_audit_event(''INSERT''%2C%20'''%2C%20table_name%2C%20'''%2C%20NEW.id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NULL%2C%20NEW%2C%20%40audit_user%2C%20%40audit_session%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40audit_ip%2C%20%40audit_app%2C%20%40audit_sql)%3B%0A%20%20%20%20%20%20%20%20CALL%20log_sensitive_access('''%2C%20table_name%2C%20'''%2C%20NEW.id%2C%20''INSERT''%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20sensitive_columns%2C%20''')%3B%0A%20%20%20%20END')%3B%0A%20%20%20%20%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Similar%20for%20UPDATE%20and%20DELETE%20triggers%0AEND%20%2F%2F%0A%0A--%20Audit%20logging%20procedure%0ACREATE%20PROCEDURE%20log_audit_event(%0A%20%20%20%20IN%20p_event_type%20VARCHAR(20)%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_old_values%20JSON%2C%0A%20%20%20%20IN%20p_new_values%20JSON%2C%0A%20%20%20%20IN%20p_user_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_session_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_ip_address%20VARCHAR(45)%2C%0A%20%20%20%20IN%20p_application%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_sql_statement%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20risk_level%20VARCHAR(20)%20DEFAULT%20'LOW'%3B%0A%20%20%20%20DECLARE%20compliance_tags%20JSON%20DEFAULT%20JSON_ARRAY()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Determine%20risk%20level%20based%20on%20table%20and%20operation%0A%20%20%20%20IF%20p_table_name%20IN%20('users'%2C%20'customers'%2C%20'payments')%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'HIGH'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('PII'%2C%20'GDPR')%3B%0A%20%20%20%20ELSEIF%20p_table_name%20LIKE%20'%25financial%25'%20OR%20p_table_name%20LIKE%20'%25payment%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('FINANCIAL'%2C%20'SOX'%2C%20'PCI_DSS')%3B%0A%20%20%20%20ELSEIF%20p_table_name%20LIKE%20'%25medical%25'%20OR%20p_table_name%20LIKE%20'%25health%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('PHI'%2C%20'HIPAA')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20audit_trail%20(%0A%20%20%20%20%20%20%20%20event_type%2C%20table_name%2C%20record_id%2C%20user_id%2C%20session_id%2C%0A%20%20%20%20%20%20%20%20ip_address%2C%20application_name%2C%20sql_statement%2C%20old_values%2C%20%0A%20%20%20%20%20%20%20%20new_values%2C%20risk_level%2C%20compliance_tags%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_event_type%2C%20p_table_name%2C%20p_record_id%2C%20p_user_id%2C%20p_session_id%2C%0A%20%20%20%20%20%20%20%20p_ip_address%2C%20p_application%2C%20p_sql_statement%2C%20p_old_values%2C%0A%20%20%20%20%20%20%20%20p_new_values%2C%20risk_level%2C%20compliance_tags%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generic audit trigger for sensitive tables
DELIMITER //
CREATE PROCEDURE create_audit_trigger(
    IN table_name VARCHAR(64),
    IN sensitive_columns JSON
)
BEGIN
    SET @sql = CONCAT('
    CREATE TRIGGER ', table_name, '_audit_insert
    AFTER INSERT ON ', table_name, '
    FOR EACH ROW
    BEGIN
        CALL log_audit_event(''INSERT'', ''', table_name, ''', NEW.id, 
                             NULL, NEW, @audit_user, @audit_session, 
                             @audit_ip, @audit_app, @audit_sql);
        CALL log_sensitive_access(''', table_name, ''', NEW.id, ''INSERT'', 
                                 ''', sensitive_columns, ''');
    END');
    
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Similar for UPDATE and DELETE triggers
END //

-- Audit logging procedure
CREATE PROCEDURE log_audit_event(
    IN p_event_type VARCHAR(20),
    IN p_table_name VARCHAR(64),
    IN p_record_id VARCHAR(255),
    IN p_old_values JSON,
    IN p_new_values JSON,
    IN p_user_id VARCHAR(100),
    IN p_session_id VARCHAR(100),
    IN p_ip_address VARCHAR(45),
    IN p_application VARCHAR(100),
    IN p_sql_statement TEXT
)
BEGIN
    DECLARE risk_level VARCHAR(20) DEFAULT 'LOW';
    DECLARE compliance_tags JSON DEFAULT JSON_ARRAY();
    
    -- Determine risk level based on table and operation
    IF p_table_name IN ('users', 'customers', 'payments') THEN
        SET risk_level = 'HIGH';
        SET compliance_tags = JSON_ARRAY('PII', 'GDPR');
    ELSEIF p_table_name LIKE '%financial%' OR p_table_name LIKE '%payment%' THEN
        SET risk_level = 'CRITICAL';
        SET compliance_tags = JSON_ARRAY('FINANCIAL', 'SOX', 'PCI_DSS');
    ELSEIF p_table_name LIKE '%medical%' OR p_table_name LIKE '%health%' THEN
        SET risk_level = 'CRITICAL';
        SET compliance_tags = JSON_ARRAY('PHI', 'HIPAA');
    END IF;
    
    INSERT INTO audit_trail (
        event_type, table_name, record_id, user_id, session_id,
        ip_address, application_name, sql_statement, old_values, 
        new_values, risk_level, compliance_tags
    ) VALUES (
        p_event_type, p_table_name, p_record_id, p_user_id, p_session_id,
        p_ip_address, p_application, p_sql_statement, p_old_values,
        p_new_values, risk_level, compliance_tags
    );
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. GDPR Compliance Features:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20GDPR%20data%20subject%20rights%20implementation%0ADELIMITER%20%2F%2F%0A%0A--%20Right%20to%20be%20informed%20(audit%20trail)%0ACREATE%20PROCEDURE%20gdpr_data_processing_log(%0A%20%20%20%20IN%20p_subject_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_processing_purpose%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_legal_basis%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_categories%20JSON%0A)%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20gdpr_processing_log%20(%0A%20%20%20%20%20%20%20%20data_subject_id%2C%20processing_purpose%2C%20legal_basis%2C%0A%20%20%20%20%20%20%20%20data_categories%2C%20processed_at%2C%20retention_period%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_subject_id%2C%20p_processing_purpose%2C%20p_legal_basis%2C%0A%20%20%20%20%20%20%20%20p_data_categories%2C%20NOW()%2C%20%0A%20%20%20%20%20%20%20%20CASE%20p_legal_basis%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'consent'%20THEN%20365%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'contract'%20THEN%202555%20%20--%207%20years%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'legal_obligation'%20THEN%202555%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%201095%20%20--%203%20years%20default%0A%20%20%20%20%20%20%20%20END%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0A%0A--%20Right%20of%20access%20(data%20export)%0ACREATE%20PROCEDURE%20gdpr_export_personal_data(IN%20p_subject_id%20VARCHAR(255))%0ABEGIN%0A%20%20%20%20--%20Export%20all%20personal%20data%20for%20the%20subject%0A%20%20%20%20SELECT%20'users'%20as%20table_name%2C%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'id'%2C%20id%2C%20'name'%2C%20name%2C%20'email'%2C%20email%2C%20'phone'%2C%20phone%2C%0A%20%20%20%20%20%20%20%20'address'%2C%20address%2C%20'created_at'%2C%20created_at%0A%20%20%20%20)%20as%20data%0A%20%20%20%20FROM%20users%20WHERE%20id%20%3D%20p_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'orders'%20as%20table_name%2C%20JSON_ARRAYAGG(JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'id'%2C%20id%2C%20'total'%2C%20total%2C%20'order_date'%2C%20order_date%2C%0A%20%20%20%20%20%20%20%20'shipping_address'%2C%20shipping_address%0A%20%20%20%20))%20as%20data%0A%20%20%20%20FROM%20orders%20WHERE%20customer_id%20%3D%20p_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'audit_trail'%20as%20table_name%2C%20JSON_ARRAYAGG(JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'event_type'%2C%20event_type%2C%20'timestamp'%2C%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20'table_name'%2C%20table_name%2C%20'ip_address'%2C%20ip_address%0A%20%20%20%20))%20as%20data%0A%20%20%20%20FROM%20audit_trail%20WHERE%20user_id%20%3D%20p_subject_id%3B%0AEND%20%2F%2F%0A%0A--%20Right%20to%20erasure%20(right%20to%20be%20forgotten)%0ACREATE%20PROCEDURE%20gdpr_erase_personal_data(%0A%20%20%20%20IN%20p_subject_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_erasure_reason%20VARCHAR(255)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20erasure%20request%0A%20%20%20%20INSERT%20INTO%20gdpr_erasure_log%20(%0A%20%20%20%20%20%20%20%20data_subject_id%2C%20erasure_reason%2C%20requested_at%2C%20status%0A%20%20%20%20)%20VALUES%20(p_subject_id%2C%20p_erasure_reason%2C%20NOW()%2C%20'IN_PROGRESS')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20instead%20of%20delete%20to%20maintain%20referential%20integrity%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20email%20%3D%20CONCAT('erased_'%2C%20id%2C%20'%40deleted.local')%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20address%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20date_of_birth%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20related%20records%0A%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20SET%20shipping_address%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20billing_address%20%3D%20'ERASED'%0A%20%20%20%20WHERE%20customer_id%20%3D%20p_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20erasure%20log%0A%20%20%20%20UPDATE%20gdpr_erasure_log%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%20completed_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20data_subject_id%20%3D%20p_subject_id%20%0A%20%20%20%20AND%20status%20%3D%20'IN_PROGRESS'%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- GDPR data subject rights implementation
DELIMITER //

-- Right to be informed (audit trail)
CREATE PROCEDURE gdpr_data_processing_log(
    IN p_subject_id VARCHAR(255),
    IN p_processing_purpose VARCHAR(255),
    IN p_legal_basis VARCHAR(100),
    IN p_data_categories JSON
)
BEGIN
    INSERT INTO gdpr_processing_log (
        data_subject_id, processing_purpose, legal_basis,
        data_categories, processed_at, retention_period
    ) VALUES (
        p_subject_id, p_processing_purpose, p_legal_basis,
        p_data_categories, NOW(), 
        CASE p_legal_basis
            WHEN 'consent' THEN 365
            WHEN 'contract' THEN 2555  -- 7 years
            WHEN 'legal_obligation' THEN 2555
            ELSE 1095  -- 3 years default
        END
    );
END //

-- Right of access (data export)
CREATE PROCEDURE gdpr_export_personal_data(IN p_subject_id VARCHAR(255))
BEGIN
    -- Export all personal data for the subject
    SELECT 'users' as table_name, JSON_OBJECT(
        'id', id, 'name', name, 'email', email, 'phone', phone,
        'address', address, 'created_at', created_at
    ) as data
    FROM users WHERE id = p_subject_id
    
    UNION ALL
    
    SELECT 'orders' as table_name, JSON_ARRAYAGG(JSON_OBJECT(
        'id', id, 'total', total, 'order_date', order_date,
        'shipping_address', shipping_address
    )) as data
    FROM orders WHERE customer_id = p_subject_id
    
    UNION ALL
    
    SELECT 'audit_trail' as table_name, JSON_ARRAYAGG(JSON_OBJECT(
        'event_type', event_type, 'timestamp', event_timestamp,
        'table_name', table_name, 'ip_address', ip_address
    )) as data
    FROM audit_trail WHERE user_id = p_subject_id;
END //

-- Right to erasure (right to be forgotten)
CREATE PROCEDURE gdpr_erase_personal_data(
    IN p_subject_id VARCHAR(255),
    IN p_erasure_reason VARCHAR(255)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Log erasure request
    INSERT INTO gdpr_erasure_log (
        data_subject_id, erasure_reason, requested_at, status
    ) VALUES (p_subject_id, p_erasure_reason, NOW(), 'IN_PROGRESS');
    
    -- Anonymize instead of delete to maintain referential integrity
    UPDATE users 
    SET name = 'ERASED',
        email = CONCAT('erased_', id, '@deleted.local'),
        phone = NULL,
        address = NULL,
        date_of_birth = NULL,
        erased_at = NOW()
    WHERE id = p_subject_id;
    
    -- Update related records
    UPDATE orders 
    SET shipping_address = 'ERASED',
        billing_address = 'ERASED'
    WHERE customer_id = p_subject_id;
    
    -- Update erasure log
    UPDATE gdpr_erasure_log 
    SET status = 'COMPLETED', completed_at = NOW()
    WHERE data_subject_id = p_subject_id 
    AND status = 'IN_PROGRESS';
    
    COMMIT;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Compliance Monitoring and Reporting:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Compliance%20dashboard%20views%0ACREATE%20VIEW%20compliance_summary%20AS%0ASELECT%20%0A%20%20%20%20DATE(event_timestamp)%20as%20audit_date%2C%0A%20%20%20%20event_type%2C%0A%20%20%20%20risk_level%2C%0A%20%20%20%20COUNT(*)%20as%20event_count%2C%0A%20%20%20%20COUNT(DISTINCT%20user_id)%20as%20unique_users%2C%0A%20%20%20%20COUNT(DISTINCT%20table_name)%20as%20tables_affected%0AFROM%20audit_trail%0AWHERE%20event_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20DATE(event_timestamp)%2C%20event_type%2C%20risk_level%3B%0A%0A--%20Suspicious%20activity%20detection%0ACREATE%20VIEW%20suspicious_activity%20AS%0ASELECT%20%0A%20%20%20%20user_id%2C%0A%20%20%20%20ip_address%2C%0A%20%20%20%20COUNT(*)%20as%20event_count%2C%0A%20%20%20%20COUNT(DISTINCT%20table_name)%20as%20tables_accessed%2C%0A%20%20%20%20MIN(event_timestamp)%20as%20first_event%2C%0A%20%20%20%20MAX(event_timestamp)%20as%20last_event%2C%0A%20%20%20%20GROUP_CONCAT(DISTINCT%20event_type)%20as%20event_types%0AFROM%20audit_trail%0AWHERE%20event_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0AGROUP%20BY%20user_id%2C%20ip_address%0AHAVING%20event_count%20%3E%20100%20%20--%20Threshold%20for%20suspicious%20activity%0AOR%20tables_accessed%20%3E%2010%3B%0A%0A--%20Data%20retention%20compliance%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20cleanup_expired_audit_data()%0ABEGIN%0A%20%20%20%20DECLARE%20records_deleted%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20audit%20records%20older%20than%20retention%20period%0A%20%20%20%20DELETE%20FROM%20audit_trail%20%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%207%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('LOW'%2C%20'MEDIUM')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_deleted%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20cleanup%20activity%0A%20%20%20%20INSERT%20INTO%20maintenance_log%20(%0A%20%20%20%20%20%20%20%20activity%2C%20records_affected%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'audit_data_cleanup'%2C%20records_deleted%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20high-risk%20records%20instead%20of%20deleting%0A%20%20%20%20INSERT%20INTO%20audit_archive%20%0A%20%20%20%20SELECT%20*%20FROM%20audit_trail%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('HIGH'%2C%20'CRITICAL')%3B%0A%20%20%20%20%0A%20%20%20%20DELETE%20FROM%20audit_trail%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('HIGH'%2C%20'CRITICAL')%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Compliance dashboard views
CREATE VIEW compliance_summary AS
SELECT 
    DATE(event_timestamp) as audit_date,
    event_type,
    risk_level,
    COUNT(*) as event_count,
    COUNT(DISTINCT user_id) as unique_users,
    COUNT(DISTINCT table_name) as tables_affected
FROM audit_trail
WHERE event_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY DATE(event_timestamp), event_type, risk_level;

-- Suspicious activity detection
CREATE VIEW suspicious_activity AS
SELECT 
    user_id,
    ip_address,
    COUNT(*) as event_count,
    COUNT(DISTINCT table_name) as tables_accessed,
    MIN(event_timestamp) as first_event,
    MAX(event_timestamp) as last_event,
    GROUP_CONCAT(DISTINCT event_type) as event_types
FROM audit_trail
WHERE event_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
GROUP BY user_id, ip_address
HAVING event_count &gt; 100  -- Threshold for suspicious activity
OR tables_accessed &gt; 10;

-- Data retention compliance
DELIMITER //
CREATE PROCEDURE cleanup_expired_audit_data()
BEGIN
    DECLARE records_deleted INT DEFAULT 0;
    
    -- Delete audit records older than retention period
    DELETE FROM audit_trail 
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 7 YEAR)
    AND risk_level IN ('LOW', 'MEDIUM');
    
    SET records_deleted = ROW_COUNT();
    
    -- Log cleanup activity
    INSERT INTO maintenance_log (
        activity, records_affected, completed_at
    ) VALUES (
        'audit_data_cleanup', records_deleted, NOW()
    );
    
    -- Archive high-risk records instead of deleting
    INSERT INTO audit_archive 
    SELECT * FROM audit_trail
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND risk_level IN ('HIGH', 'CRITICAL');
    
    DELETE FROM audit_trail
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND risk_level IN ('HIGH', 'CRITICAL');
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Implement audit trails for all sensitive data access</p>
<p>- Use immutable audit logs (append-only)</p>
<p>- Encrypt audit data at rest and in transit</p>
<p>- Regular compliance reporting and monitoring</p>
<p>- Implement data retention and purging policies</p>
<p>- Separate audit database from operational database</p>
<p>- Monitor for suspicious access patterns</p>
<p>- Document all compliance procedures</p>


<p>---</p>

<h2 id="-369-what-are-database-federation-and-distributed-queries-">**369. What are database federation and distributed queries?**</h2>

<p><strong>Answer:</strong> Database federation allows querying across multiple databases as if they were a single system, while distributed queries execute across multiple database instances.</p>

<p><strong>MySQL Federation Setup:</strong></p>

<p><strong>1. FEDERATED Storage Engine:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20FEDERATED%20storage%20engine%20(if%20not%20already%20enabled)%0A--%20Add%20to%20my.cnf%3A%20federated%0A%0A--%20Create%20federated%20table%20pointing%20to%20remote%20database%0ACREATE%20TABLE%20remote_customers%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20created_at%20TIMESTAMP%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fusername%3Apassword%40remote_host%3A3306%2Fremote_db%2Fcustomers'%3B%0A%0A--%20Query%20federated%20table%20as%20if%20it%20were%20local%0ASELECT%20*%20FROM%20remote_customers%20WHERE%20region%20%3D%20'US'%3B%0A%0A--%20Join%20local%20and%20remote%20data%0ASELECT%20%0A%20%20%20%20lc.id%2C%0A%20%20%20%20lc.name%2C%0A%20%20%20%20rc.region%2C%0A%20%20%20%20COUNT(lo.id)%20as%20local_orders%0AFROM%20local_customers%20lc%0AJOIN%20remote_customers%20rc%20ON%20lc.email%20%3D%20rc.email%0ALEFT%20JOIN%20local_orders%20lo%20ON%20lc.id%20%3D%20lo.customer_id%0AGROUP%20BY%20lc.id%2C%20lc.name%2C%20rc.region%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable FEDERATED storage engine (if not already enabled)
-- Add to my.cnf: federated

-- Create federated table pointing to remote database
CREATE TABLE remote_customers (
    id INT NOT NULL,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50),
    created_at TIMESTAMP
) ENGINE=FEDERATED
CONNECTION='mysql://username:password@remote_host:3306/remote_db/customers';

-- Query federated table as if it were local
SELECT * FROM remote_customers WHERE region = 'US';

-- Join local and remote data
SELECT 
    lc.id,
    lc.name,
    rc.region,
    COUNT(lo.id) as local_orders
FROM local_customers lc
JOIN remote_customers rc ON lc.email = rc.email
LEFT JOIN local_orders lo ON lc.id = lo.customer_id
GROUP BY lc.id, lc.name, rc.region;
</code></pre>
</div>

<p><strong>2. Multi-Database Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20across%20multiple%20databases%20on%20same%20server%0ASELECT%20%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20COUNT(sales_db.orders.id)%20as%20order_count%2C%0A%20%20%20%20SUM(sales_db.orders.total)%20as%20total_spent%2C%0A%20%20%20%20MAX(analytics_db.user_sessions.last_activity)%20as%20last_activity%0AFROM%20user_db.users%20u%0ALEFT%20JOIN%20sales_db.orders%20ON%20u.id%20%3D%20sales_db.orders.customer_id%0ALEFT%20JOIN%20analytics_db.user_sessions%20ON%20u.id%20%3D%20analytics_db.user_sessions.user_id%0AWHERE%20u.status%20%3D%20'active'%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query across multiple databases on same server
SELECT 
    u.name,
    u.email,
    COUNT(sales_db.orders.id) as order_count,
    SUM(sales_db.orders.total) as total_spent,
    MAX(analytics_db.user_sessions.last_activity) as last_activity
FROM user_db.users u
LEFT JOIN sales_db.orders ON u.id = sales_db.orders.customer_id
LEFT JOIN analytics_db.user_sessions ON u.id = analytics_db.user_sessions.user_id
WHERE u.status = 'active'
GROUP BY u.id, u.name, u.email;
</code></pre>
</div>

<p><strong>Distributed Query Patterns:</strong></p>

<p><strong>1. Horizontal Partitioning (Sharding):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Shard%20customers%20by%20region%0A--%20Shard%201%3A%20US%20customers%0ACREATE%20TABLE%20us_customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%20DEFAULT%20'US'%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Shard%202%3A%20EU%20customers%20%20%0ACREATE%20TABLE%20eu_customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%20DEFAULT%20'EU'%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Federated%20view%20combining%20shards%0ACREATE%20TABLE%20all_customers%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40shard1%3A3306%2Fdb%2Fus_customers'%3B%0A%0A--%20Union%20view%20for%20querying%20all%20shards%0ACREATE%20VIEW%20global_customers%20AS%0ASELECT%20id%2C%20name%2C%20email%2C%20region%2C%20'shard1'%20as%20shard_location%20FROM%20us_customers%0AUNION%20ALL%0ASELECT%20id%2C%20name%2C%20email%2C%20region%2C%20'shard2'%20as%20shard_location%20FROM%20eu_customers%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Shard customers by region
-- Shard 1: US customers
CREATE TABLE us_customers (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50) DEFAULT 'US'
) ENGINE=InnoDB;

-- Shard 2: EU customers  
CREATE TABLE eu_customers (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50) DEFAULT 'EU'
) ENGINE=InnoDB;

-- Federated view combining shards
CREATE TABLE all_customers (
    id INT NOT NULL,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@shard1:3306/db/us_customers';

-- Union view for querying all shards
CREATE VIEW global_customers AS
SELECT id, name, email, region, 'shard1' as shard_location FROM us_customers
UNION ALL
SELECT id, name, email, region, 'shard2' as shard_location FROM eu_customers;
</code></pre>
</div>

<p><strong>2. Application-Level Federation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Stored%20procedure%20for%20distributed%20queries%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20query_distributed_orders(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20--%20Create%20temporary%20table%20for%20results%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20temp_distributed_results%20(%0A%20%20%20%20%20%20%20%20shard_name%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20order_count%20INT%2C%0A%20%20%20%20%20%20%20%20total_revenue%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%20%20%20%20avg_order_value%20DECIMAL(10%2C2)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Query%20Shard%201%20(US)%0A%20%20%20%20INSERT%20INTO%20temp_distributed_results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'US_SHARD'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20federated_us_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Query%20Shard%202%20(EU)%0A%20%20%20%20INSERT%20INTO%20temp_distributed_results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'EU_SHARD'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20federated_eu_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20aggregated%20results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20shard_name%2C%0A%20%20%20%20%20%20%20%20order_count%2C%0A%20%20%20%20%20%20%20%20total_revenue%2C%0A%20%20%20%20%20%20%20%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20(total_revenue%20%2F%20SUM(total_revenue)%20OVER())%20*%20100%20as%20revenue_percentage%0A%20%20%20%20FROM%20temp_distributed_results%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'TOTAL'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20SUM(order_count)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total_revenue)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(avg_order_value)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20100.0%20as%20revenue_percentage%0A%20%20%20%20FROM%20temp_distributed_results%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20temp_distributed_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Stored procedure for distributed queries
DELIMITER //
CREATE PROCEDURE query_distributed_orders(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    -- Create temporary table for results
    CREATE TEMPORARY TABLE temp_distributed_results (
        shard_name VARCHAR(50),
        order_count INT,
        total_revenue DECIMAL(12,2),
        avg_order_value DECIMAL(10,2)
    );
    
    -- Query Shard 1 (US)
    INSERT INTO temp_distributed_results
    SELECT 
        'US_SHARD' as shard_name,
        COUNT(*) as order_count,
        SUM(total) as total_revenue,
        AVG(total) as avg_order_value
    FROM federated_us_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date;
    
    -- Query Shard 2 (EU)
    INSERT INTO temp_distributed_results
    SELECT 
        'EU_SHARD' as shard_name,
        COUNT(*) as order_count,
        SUM(total) as total_revenue,
        AVG(total) as avg_order_value
    FROM federated_eu_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date;
    
    -- Return aggregated results
    SELECT 
        shard_name,
        order_count,
        total_revenue,
        avg_order_value,
        (total_revenue / SUM(total_revenue) OVER()) * 100 as revenue_percentage
    FROM temp_distributed_results
    
    UNION ALL
    
    SELECT 
        'TOTAL' as shard_name,
        SUM(order_count) as order_count,
        SUM(total_revenue) as total_revenue,
        AVG(avg_order_value) as avg_order_value,
        100.0 as revenue_percentage
    FROM temp_distributed_results;
    
    DROP TEMPORARY TABLE temp_distributed_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Cross-Database Analytics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Federated%20analytics%20across%20multiple%20systems%0ACREATE%20TABLE%20federated_sales_data%20(%0A%20%20%20%20sale_id%20INT%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20sale_amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20sale_date%20DATE%2C%0A%20%20%20%20source_system%20VARCHAR(50)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40analytics_server%3A3306%2Fwarehouse%2Fsales_data'%3B%0A%0ACREATE%20TABLE%20federated_customer_data%20(%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20lifetime_value%20DECIMAL(12%2C2)%2C%0A%20%20%20%20acquisition_channel%20VARCHAR(100)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40crm_server%3A3306%2Fcrm%2Fcustomer_profiles'%3B%0A%0A--%20Cross-system%20analytics%20query%0ASELECT%20%0A%20%20%20%20cd.customer_segment%2C%0A%20%20%20%20cd.acquisition_channel%2C%0A%20%20%20%20COUNT(DISTINCT%20sd.customer_id)%20as%20active_customers%2C%0A%20%20%20%20SUM(sd.sale_amount)%20as%20total_revenue%2C%0A%20%20%20%20AVG(sd.sale_amount)%20as%20avg_transaction%2C%0A%20%20%20%20AVG(cd.lifetime_value)%20as%20avg_lifetime_value%0AFROM%20federated_sales_data%20sd%0AJOIN%20federated_customer_data%20cd%20ON%20sd.customer_id%20%3D%20cd.customer_id%0AWHERE%20sd.sale_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%0AGROUP%20BY%20cd.customer_segment%2C%20cd.acquisition_channel%0AORDER%20BY%20total_revenue%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Federated analytics across multiple systems
CREATE TABLE federated_sales_data (
    sale_id INT,
    product_id INT,
    customer_id INT,
    sale_amount DECIMAL(10,2),
    sale_date DATE,
    source_system VARCHAR(50)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@analytics_server:3306/warehouse/sales_data';

CREATE TABLE federated_customer_data (
    customer_id INT,
    customer_segment VARCHAR(50),
    lifetime_value DECIMAL(12,2),
    acquisition_channel VARCHAR(100)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@crm_server:3306/crm/customer_profiles';

-- Cross-system analytics query
SELECT 
    cd.customer_segment,
    cd.acquisition_channel,
    COUNT(DISTINCT sd.customer_id) as active_customers,
    SUM(sd.sale_amount) as total_revenue,
    AVG(sd.sale_amount) as avg_transaction,
    AVG(cd.lifetime_value) as avg_lifetime_value
FROM federated_sales_data sd
JOIN federated_customer_data cd ON sd.customer_id = cd.customer_id
WHERE sd.sale_date &gt;= DATE_SUB(NOW(), INTERVAL 90 DAY)
GROUP BY cd.customer_segment, cd.acquisition_channel
ORDER BY total_revenue DESC;
</code></pre>
</div>

<p><strong>Performance Optimization for Distributed Queries:</strong></p>

<p><strong>1. Query Pushdown Optimization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Push%20filtering%20to%20remote%20servers%0A--%20BAD%3A%20Brings%20all%20data%20locally%20then%20filters%0ASELECT%20*%20FROM%20(%0A%20%20%20%20SELECT%20*%20FROM%20remote_orders%0A)%20filtered%20WHERE%20order_date%20%3E%3D%20'2024-01-01'%3B%0A%0A--%20GOOD%3A%20Filter%20is%20pushed%20to%20remote%20server%0ASELECT%20*%20FROM%20remote_orders%20%0AWHERE%20order_date%20%3E%3D%20'2024-01-01'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Push filtering to remote servers
-- BAD: Brings all data locally then filters
SELECT * FROM (
    SELECT * FROM remote_orders
) filtered WHERE order_date &gt;= '2024-01-01';

-- GOOD: Filter is pushed to remote server
SELECT * FROM remote_orders 
WHERE order_date &gt;= '2024-01-01';
</code></pre>
</div>

<p><strong>2. Distributed Aggregation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Efficient%20distributed%20aggregation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20distributed_sales_summary(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20--%20Pre-aggregate%20on%20each%20shard%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20shard_summaries%20(%0A%20%20%20%20%20%20%20%20shard_id%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20daily_date%20DATE%2C%0A%20%20%20%20%20%20%20%20order_count%20INT%2C%0A%20%20%20%20%20%20%20%20total_revenue%20DECIMAL(12%2C2)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20from%20US%20shard%0A%20%20%20%20INSERT%20INTO%20shard_summaries%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'US'%20as%20shard_id%2C%0A%20%20%20%20%20%20%20%20DATE(order_date)%20as%20daily_date%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%0A%20%20%20%20FROM%20federated_us_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20GROUP%20BY%20DATE(order_date)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20from%20EU%20shard%0A%20%20%20%20INSERT%20INTO%20shard_summaries%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'EU'%20as%20shard_id%2C%0A%20%20%20%20%20%20%20%20DATE(order_date)%20as%20daily_date%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%0A%20%20%20%20FROM%20federated_eu_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20GROUP%20BY%20DATE(order_date)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Final%20aggregation%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20daily_date%2C%0A%20%20%20%20%20%20%20%20SUM(order_count)%20as%20total_orders%2C%0A%20%20%20%20%20%20%20%20SUM(total_revenue)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total_revenue%2Forder_count)%20as%20avg_order_value%0A%20%20%20%20FROM%20shard_summaries%0A%20%20%20%20GROUP%20BY%20daily_date%0A%20%20%20%20ORDER%20BY%20daily_date%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20shard_summaries%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Efficient distributed aggregation
DELIMITER //
CREATE PROCEDURE distributed_sales_summary(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    -- Pre-aggregate on each shard
    CREATE TEMPORARY TABLE shard_summaries (
        shard_id VARCHAR(50),
        daily_date DATE,
        order_count INT,
        total_revenue DECIMAL(12,2)
    );
    
    -- Aggregate from US shard
    INSERT INTO shard_summaries
    SELECT 
        'US' as shard_id,
        DATE(order_date) as daily_date,
        COUNT(*) as order_count,
        SUM(total) as total_revenue
    FROM federated_us_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date
    GROUP BY DATE(order_date);
    
    -- Aggregate from EU shard
    INSERT INTO shard_summaries
    SELECT 
        'EU' as shard_id,
        DATE(order_date) as daily_date,
        COUNT(*) as order_count,
        SUM(total) as total_revenue
    FROM federated_eu_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date
    GROUP BY DATE(order_date);
    
    -- Final aggregation
    SELECT 
        daily_date,
        SUM(order_count) as total_orders,
        SUM(total_revenue) as total_revenue,
        AVG(total_revenue/order_count) as avg_order_value
    FROM shard_summaries
    GROUP BY daily_date
    ORDER BY daily_date;
    
    DROP TEMPORARY TABLE shard_summaries;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Challenges and Solutions:</strong></p>

<p><strong>1. Transaction Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Distributed%20transaction%20simulation%20(MySQL%20doesn't%20support%20XA%20fully)%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20distributed_transfer(%0A%20%20%20%20IN%20p_from_account%20INT%2C%0A%20%20%20%20IN%20p_to_account%20INT%2C%0A%20%20%20%20IN%20p_amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20--%20Rollback%20all%20shards%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20CALL%20rollback_shard1_transaction()%3B%0A%20%20%20%20%20%20%20%20CALL%20rollback_shard2_transaction()%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Phase%201%3A%20Prepare%20all%20shards%0A%20%20%20%20CALL%20prepare_shard1_debit(p_from_account%2C%20p_amount)%3B%0A%20%20%20%20CALL%20prepare_shard2_credit(p_to_account%2C%20p_amount)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Phase%202%3A%20Commit%20all%20shards%0A%20%20%20%20CALL%20commit_shard1_transaction()%3B%0A%20%20%20%20CALL%20commit_shard2_transaction()%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Distributed transaction simulation (MySQL doesn't support XA fully)
DELIMITER //
CREATE PROCEDURE distributed_transfer(
    IN p_from_account INT,
    IN p_to_account INT,
    IN p_amount DECIMAL(10,2)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        -- Rollback all shards
        ROLLBACK;
        CALL rollback_shard1_transaction();
        CALL rollback_shard2_transaction();
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Phase 1: Prepare all shards
    CALL prepare_shard1_debit(p_from_account, p_amount);
    CALL prepare_shard2_credit(p_to_account, p_amount);
    
    -- Phase 2: Commit all shards
    CALL commit_shard1_transaction();
    CALL commit_shard2_transaction();
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Minimize cross-shard queries</p>
<p>- Use connection pooling for federated tables</p>
<p>- Implement proper error handling for network failures</p>
<p>- Cache frequently accessed remote data locally</p>
<p>- Monitor network latency and query performance</p>
<p>- Consider eventual consistency for distributed systems</p>
<p>- Use appropriate indexing on federated tables</p>


<p>---</p>

<h2 id="-370-how-do-you-implement-database-monitoring-and-alerting-">**370. How do you implement database monitoring and alerting?**</h2>

<p><strong>Answer:</strong> Database monitoring and alerting involve tracking performance metrics, resource usage, and system health to proactively identify and resolve issues.</p>

<p><strong>Performance Schema Monitoring:</strong></p>

<p><strong>1. Key Metrics Collection:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20performance%20monitoring%0ASELECT%20%0A%20%20%20%20DIGEST_TEXT%20as%20query_pattern%2C%0A%20%20%20%20COUNT_STAR%20as%20execution_count%2C%0A%20%20%20%20AVG_TIMER_WAIT%2F1000000000%20as%20avg_execution_time_sec%2C%0A%20%20%20%20MAX_TIMER_WAIT%2F1000000000%20as%20max_execution_time_sec%2C%0A%20%20%20%20SUM_ROWS_EXAMINED%2FCOUNT_STAR%20as%20avg_rows_examined%2C%0A%20%20%20%20SUM_ROWS_SENT%2FCOUNT_STAR%20as%20avg_rows_returned%2C%0A%20%20%20%20FIRST_SEEN%2C%0A%20%20%20%20LAST_SEEN%0AFROM%20performance_schema.events_statements_summary_by_digest%0AWHERE%20DIGEST_TEXT%20IS%20NOT%20NULL%0AORDER%20BY%20AVG_TIMER_WAIT%20DESC%0ALIMIT%2020%3B%0A%0A--%20Connection%20monitoring%0ASELECT%20%0A%20%20%20%20USER%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20COUNT(*)%20as%20connection_count%2C%0A%20%20%20%20SUM(CASE%20WHEN%20COMMAND%20%3D%20'Sleep'%20THEN%201%20ELSE%200%20END)%20as%20idle_connections%2C%0A%20%20%20%20AVG(TIME)%20as%20avg_connection_time%0AFROM%20information_schema.processlist%0AGROUP%20BY%20USER%2C%20HOST%0AORDER%20BY%20connection_count%20DESC%3B%0A%0A--%20Table%20I%2FO%20statistics%0ASELECT%20%0A%20%20%20%20OBJECT_SCHEMA%2C%0A%20%20%20%20OBJECT_NAME%2C%0A%20%20%20%20COUNT_READ%2C%0A%20%20%20%20COUNT_WRITE%2C%0A%20%20%20%20COUNT_FETCH%2C%0A%20%20%20%20SUM_TIMER_READ%2F1000000000%20as%20total_read_time_sec%2C%0A%20%20%20%20SUM_TIMER_WRITE%2F1000000000%20as%20total_write_time_sec%0AFROM%20performance_schema.table_io_waits_summary_by_table%0AWHERE%20OBJECT_SCHEMA%20NOT%20IN%20('mysql'%2C%20'performance_schema'%2C%20'information_schema')%0AORDER%20BY%20(COUNT_READ%20%2B%20COUNT_WRITE)%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query performance monitoring
SELECT 
    DIGEST_TEXT as query_pattern,
    COUNT_STAR as execution_count,
    AVG_TIMER_WAIT/1000000000 as avg_execution_time_sec,
    MAX_TIMER_WAIT/1000000000 as max_execution_time_sec,
    SUM_ROWS_EXAMINED/COUNT_STAR as avg_rows_examined,
    SUM_ROWS_SENT/COUNT_STAR as avg_rows_returned,
    FIRST_SEEN,
    LAST_SEEN
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
ORDER BY AVG_TIMER_WAIT DESC
LIMIT 20;

-- Connection monitoring
SELECT 
    USER,
    HOST,
    COUNT(*) as connection_count,
    SUM(CASE WHEN COMMAND = 'Sleep' THEN 1 ELSE 0 END) as idle_connections,
    AVG(TIME) as avg_connection_time
FROM information_schema.processlist
GROUP BY USER, HOST
ORDER BY connection_count DESC;

-- Table I/O statistics
SELECT 
    OBJECT_SCHEMA,
    OBJECT_NAME,
    COUNT_READ,
    COUNT_WRITE,
    COUNT_FETCH,
    SUM_TIMER_READ/1000000000 as total_read_time_sec,
    SUM_TIMER_WRITE/1000000000 as total_write_time_sec
FROM performance_schema.table_io_waits_summary_by_table
WHERE OBJECT_SCHEMA NOT IN ('mysql', 'performance_schema', 'information_schema')
ORDER BY (COUNT_READ + COUNT_WRITE) DESC;
</code></pre>
</div>

<p><strong>2. Custom Monitoring Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20System%20metrics%20collection%0ACREATE%20TABLE%20system_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_unit%20VARCHAR(20)%2C%0A%20%20%20%20server_name%20VARCHAR(100)%2C%0A%20%20%20%20collected_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_time%20(metric_name%2C%20collected_at)%2C%0A%20%20%20%20INDEX%20idx_server_time%20(server_name%2C%20collected_at)%0A)%3B%0A%0A--%20Performance%20baselines%0ACREATE%20TABLE%20performance_baselines%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20baseline_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_warning%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_critical%20DECIMAL(15%2C4)%2C%0A%20%20%20%20measurement_period%20ENUM('1min'%2C%20'5min'%2C%20'15min'%2C%20'1hour'%2C%20'1day')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_metric_period%20(metric_name%2C%20measurement_period)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- System metrics collection
CREATE TABLE system_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(15,4),
    metric_unit VARCHAR(20),
    server_name VARCHAR(100),
    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_time (metric_name, collected_at),
    INDEX idx_server_time (server_name, collected_at)
);

-- Performance baselines
CREATE TABLE performance_baselines (
    id INT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    baseline_value DECIMAL(15,4),
    threshold_warning DECIMAL(15,4),
    threshold_critical DECIMAL(15,4),
    measurement_period ENUM('1min', '5min', '15min', '1hour', '1day'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_metric_period (metric_name, measurement_period)
);
</code></pre>
</div>

<p><strong>3. Automated Metrics Collection:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Collect%20system%20metrics%0ACREATE%20PROCEDURE%20collect_system_metrics()%0ABEGIN%0A%20%20%20%20DECLARE%20server_name%20VARCHAR(100)%20DEFAULT%20%40%40hostname%3B%0A%20%20%20%20%0A%20%20%20%20--%20Connection%20metrics%0A%20%20%20%20INSERT%20INTO%20system_metrics%20(metric_name%2C%20metric_value%2C%20metric_unit%2C%20server_name)%0A%20%20%20%20SELECT%20'connections_current'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'connections_max_used'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Max_used_connections'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Query%20metrics%0A%20%20%20%20SELECT%20'queries_per_second'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20VARIABLE_VALUE%20%2F%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Uptime')%2C%0A%20%20%20%20%20%20%20%20%20%20%20'qps'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Questions'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20InnoDB%20metrics%0A%20%20%20%20SELECT%20'innodb_buffer_pool_hit_rate'%2C%0A%20%20%20%20%20%20%20%20%20%20%20(1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20*%20100%2C%0A%20%20%20%20%20%20%20%20%20%20%20'percent'%2C%20server_name%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Slow%20query%20metrics%0A%20%20%20%20SELECT%20'slow_queries'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Slow_queries'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Check%20performance%20thresholds%0ACREATE%20PROCEDURE%20check_performance_thresholds()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20metric_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20current_value%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20warning_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20critical_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20alert_level%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20threshold_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.metric_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20AVG(sm.metric_value)%20as%20current_avg%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.threshold_warning%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.threshold_critical%0A%20%20%20%20%20%20%20%20FROM%20performance_baselines%20pb%0A%20%20%20%20%20%20%20%20JOIN%20system_metrics%20sm%20ON%20pb.metric_name%20%3D%20sm.metric_name%0A%20%20%20%20%20%20%20%20WHERE%20sm.collected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%205%20MINUTE)%0A%20%20%20%20%20%20%20%20GROUP%20BY%20pb.metric_name%2C%20pb.threshold_warning%2C%20pb.threshold_critical%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20threshold_cursor%3B%0A%20%20%20%20%0A%20%20%20%20check_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20threshold_cursor%20INTO%20metric_name%2C%20current_value%2C%20warning_threshold%2C%20critical_threshold%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20check_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Determine%20alert%20level%0A%20%20%20%20%20%20%20%20IF%20current_value%20%3E%3D%20critical_threshold%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20ELSEIF%20current_value%20%3E%3D%20warning_threshold%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'WARNING'%3B%0A%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'OK'%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Generate%20alert%20if%20needed%0A%20%20%20%20%20%20%20%20IF%20alert_level%20!%3D%20'OK'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20generate_alert(metric_name%2C%20current_value%2C%20alert_level)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20threshold_cursor%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Collect system metrics
CREATE PROCEDURE collect_system_metrics()
BEGIN
    DECLARE server_name VARCHAR(100) DEFAULT @@hostname;
    
    -- Connection metrics
    INSERT INTO system_metrics (metric_name, metric_value, metric_unit, server_name)
    SELECT 'connections_current', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected'
    
    UNION ALL
    
    SELECT 'connections_max_used', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Max_used_connections'
    
    UNION ALL
    
    -- Query metrics
    SELECT 'queries_per_second', 
           VARIABLE_VALUE / (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Uptime'),
           'qps', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Questions'
    
    UNION ALL
    
    -- InnoDB metrics
    SELECT 'innodb_buffer_pool_hit_rate',
           (1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) * 100,
           'percent', server_name
    
    UNION ALL
    
    -- Slow query metrics
    SELECT 'slow_queries', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Slow_queries';
    
END //

-- Check performance thresholds
CREATE PROCEDURE check_performance_thresholds()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE metric_name VARCHAR(100);
    DECLARE current_value DECIMAL(15,4);
    DECLARE warning_threshold DECIMAL(15,4);
    DECLARE critical_threshold DECIMAL(15,4);
    DECLARE alert_level VARCHAR(20);
    
    DECLARE threshold_cursor CURSOR FOR
        SELECT 
            pb.metric_name,
            AVG(sm.metric_value) as current_avg,
            pb.threshold_warning,
            pb.threshold_critical
        FROM performance_baselines pb
        JOIN system_metrics sm ON pb.metric_name = sm.metric_name
        WHERE sm.collected_at &gt;= DATE_SUB(NOW(), INTERVAL 5 MINUTE)
        GROUP BY pb.metric_name, pb.threshold_warning, pb.threshold_critical;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN threshold_cursor;
    
    check_loop: LOOP
        FETCH threshold_cursor INTO metric_name, current_value, warning_threshold, critical_threshold;
        
        IF done THEN
            LEAVE check_loop;
        END IF;
        
        -- Determine alert level
        IF current_value &gt;= critical_threshold THEN
            SET alert_level = 'CRITICAL';
        ELSEIF current_value &gt;= warning_threshold THEN
            SET alert_level = 'WARNING';
        ELSE
            SET alert_level = 'OK';
        END IF;
        
        -- Generate alert if needed
        IF alert_level != 'OK' THEN
            CALL generate_alert(metric_name, current_value, alert_level);
        END IF;
        
    END LOOP;
    
    CLOSE threshold_cursor;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Alert Management System:</strong></p>

<p><strong>1. Alert Infrastructure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Alert%20definitions%0ACREATE%20TABLE%20alert_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20condition_operator%20ENUM('%3E'%2C%20'%3C'%2C%20'%3E%3D'%2C%20'%3C%3D'%2C%20'%3D'%2C%20'!%3D')%20NOT%20NULL%2C%0A%20%20%20%20threshold_value%20DECIMAL(15%2C4)%20NOT%20NULL%2C%0A%20%20%20%20severity%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20NOT%20NULL%2C%0A%20%20%20%20evaluation_period%20INT%20DEFAULT%20300%2C%20--%20seconds%0A%20%20%20%20notification_channels%20JSON%2C%0A%20%20%20%20enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_enabled%20(metric_name%2C%20enabled)%0A)%3B%0A%0A--%20Alert%20history%0ACREATE%20TABLE%20alert_history%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_id%20INT%2C%0A%20%20%20%20alert_level%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%2C%0A%20%20%20%20current_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20message%20TEXT%2C%0A%20%20%20%20status%20ENUM('ACTIVE'%2C%20'RESOLVED'%2C%20'ACKNOWLEDGED')%20DEFAULT%20'ACTIVE'%2C%0A%20%20%20%20triggered_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20acknowledged_by%20VARCHAR(100)%2C%0A%20%20%20%20acknowledged_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(rule_id)%20REFERENCES%20alert_rules(id)%2C%0A%20%20%20%20INDEX%20idx_status_triggered%20(status%2C%20triggered_at)%2C%0A%20%20%20%20INDEX%20idx_metric_status%20(metric_name%2C%20status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Alert definitions
CREATE TABLE alert_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    condition_operator ENUM('&gt;', '&lt;', '&gt;=', '&lt;=', '=', '!=') NOT NULL,
    threshold_value DECIMAL(15,4) NOT NULL,
    severity ENUM('INFO', 'WARNING', 'CRITICAL') NOT NULL,
    evaluation_period INT DEFAULT 300, -- seconds
    notification_channels JSON,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_enabled (metric_name, enabled)
);

-- Alert history
CREATE TABLE alert_history (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    rule_id INT,
    alert_level ENUM('INFO', 'WARNING', 'CRITICAL') NOT NULL,
    metric_name VARCHAR(100),
    current_value DECIMAL(15,4),
    threshold_value DECIMAL(15,4),
    message TEXT,
    status ENUM('ACTIVE', 'RESOLVED', 'ACKNOWLEDGED') DEFAULT 'ACTIVE',
    triggered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP NULL,
    acknowledged_by VARCHAR(100),
    acknowledged_at TIMESTAMP NULL,
    
    FOREIGN KEY (rule_id) REFERENCES alert_rules(id),
    INDEX idx_status_triggered (status, triggered_at),
    INDEX idx_metric_status (metric_name, status)
);
</code></pre>
</div>

<p><strong>2. Alert Generation and Notification:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Generate%20alert%0ACREATE%20PROCEDURE%20generate_alert(%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_current_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20IN%20p_alert_level%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20rule_id%20INT%3B%0A%20%20%20%20DECLARE%20threshold_val%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20notification_channels%20JSON%3B%0A%20%20%20%20DECLARE%20alert_message%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20alert%20rule%20details%0A%20%20%20%20SELECT%20id%2C%20threshold_value%2C%20notification_channels%0A%20%20%20%20INTO%20rule_id%2C%20threshold_val%2C%20notification_channels%0A%20%20%20%20FROM%20alert_rules%0A%20%20%20%20WHERE%20metric_name%20%3D%20p_metric_name%0A%20%20%20%20AND%20severity%20%3D%20p_alert_level%0A%20%20%20%20AND%20enabled%20%3D%20TRUE%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20IF%20rule_id%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20--%20Check%20if%20alert%20already%20exists%20and%20is%20active%0A%20%20%20%20%20%20%20%20IF%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20alert_history%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20rule_id%20%3D%20rule_id%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20triggered_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20%20%20%20%20)%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20alert%20message%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_message%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'ALERT%3A%20'%2C%20p_metric_name%2C%20'%20is%20'%2C%20p_current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20(threshold%3A%20'%2C%20threshold_val%2C%20')'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20-%20Severity%3A%20'%2C%20p_alert_level%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20alert%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20alert_history%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20alert_level%2C%20metric_name%2C%20current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_value%2C%20message%2C%20status%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20p_alert_level%2C%20p_metric_name%2C%20p_current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_val%2C%20alert_message%2C%20'ACTIVE'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Send%20notifications%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20send_notifications(notification_channels%2C%20alert_message%2C%20p_alert_level)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0A%0A--%20Send%20notifications%20(placeholder%20-%20would%20integrate%20with%20external%20systems)%0ACREATE%20PROCEDURE%20send_notifications(%0A%20%20%20%20IN%20p_channels%20JSON%2C%0A%20%20%20%20IN%20p_message%20TEXT%2C%0A%20%20%20%20IN%20p_severity%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20channel_count%20INT%3B%0A%20%20%20%20DECLARE%20channel_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20channel_config%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20SET%20channel_count%20%3D%20JSON_LENGTH(p_channels)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20channel_count%20DO%0A%20%20%20%20%20%20%20%20SET%20channel_type%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_channels%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.type')))%3B%0A%20%20%20%20%20%20%20%20SET%20channel_config%20%3D%20JSON_EXTRACT(p_channels%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.config'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20notification%20attempt%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20notification_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20channel_type%2C%20message%2C%20severity%2C%20sent_at%2C%20status%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20channel_type%2C%20p_message%2C%20p_severity%2C%20NOW()%2C%20'SENT'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Generate alert
CREATE PROCEDURE generate_alert(
    IN p_metric_name VARCHAR(100),
    IN p_current_value DECIMAL(15,4),
    IN p_alert_level VARCHAR(20)
)
BEGIN
    DECLARE rule_id INT;
    DECLARE threshold_val DECIMAL(15,4);
    DECLARE notification_channels JSON;
    DECLARE alert_message TEXT;
    
    -- Get alert rule details
    SELECT id, threshold_value, notification_channels
    INTO rule_id, threshold_val, notification_channels
    FROM alert_rules
    WHERE metric_name = p_metric_name
    AND severity = p_alert_level
    AND enabled = TRUE
    LIMIT 1;
    
    IF rule_id IS NOT NULL THEN
        -- Check if alert already exists and is active
        IF NOT EXISTS (
            SELECT 1 FROM alert_history
            WHERE rule_id = rule_id
            AND status = 'ACTIVE'
            AND triggered_at &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
        ) THEN
            -- Create alert message
            SET alert_message = CONCAT(
                'ALERT: ', p_metric_name, ' is ', p_current_value,
                ' (threshold: ', threshold_val, ')',
                ' - Severity: ', p_alert_level
            );
            
            -- Insert alert
            INSERT INTO alert_history (
                rule_id, alert_level, metric_name, current_value,
                threshold_value, message, status
            ) VALUES (
                rule_id, p_alert_level, p_metric_name, p_current_value,
                threshold_val, alert_message, 'ACTIVE'
            );
            
            -- Send notifications
            CALL send_notifications(notification_channels, alert_message, p_alert_level);
        END IF;
    END IF;
END //

-- Send notifications (placeholder - would integrate with external systems)
CREATE PROCEDURE send_notifications(
    IN p_channels JSON,
    IN p_message TEXT,
    IN p_severity VARCHAR(20)
)
BEGIN
    DECLARE i INT DEFAULT 0;
    DECLARE channel_count INT;
    DECLARE channel_type VARCHAR(50);
    DECLARE channel_config JSON;
    
    SET channel_count = JSON_LENGTH(p_channels);
    
    WHILE i &lt; channel_count DO
        SET channel_type = JSON_UNQUOTE(JSON_EXTRACT(p_channels, CONCAT('$[', i, '].type')));
        SET channel_config = JSON_EXTRACT(p_channels, CONCAT('$[', i, '].config'));
        
        -- Log notification attempt
        INSERT INTO notification_log (
            channel_type, message, severity, sent_at, status
        ) VALUES (
            channel_type, p_message, p_severity, NOW(), 'SENT'
        );
        
        SET i = i + 1;
    END WHILE;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Monitoring Dashboard Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Real-time%20system%20overview%0ACREATE%20VIEW%20system_health_dashboard%20AS%0ASELECT%20%0A%20%20%20%20'Database%20Connections'%20as%20metric_category%2C%0A%20%20%20%20CONCAT(%0A%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected')%2C%0A%20%20%20%20%20%20%20%20'%20%2F%20'%2C%0A%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_variables%20WHERE%20VARIABLE_NAME%20%3D%20'max_connections')%0A%20%20%20%20)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_variables%20WHERE%20VARIABLE_NAME%20%3D%20'max_connections')%20%3E%200.8%0A%20%20%20%20%20%20%20%20THEN%20'WARNING'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0A%0AUNION%20ALL%0A%0ASELECT%20%0A%20%20%20%20'Buffer%20Pool%20Hit%20Rate'%20as%20metric_category%2C%0A%20%20%20%20CONCAT(%0A%20%20%20%20%20%20%20%20ROUND((1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20*%20100%2C%202)%2C%0A%20%20%20%20%20%20%20%20'%25'%0A%20%20%20%20)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20(1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20%3C%200.95%0A%20%20%20%20%20%20%20%20THEN%20'WARNING'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0A%0AUNION%20ALL%0A%0ASELECT%20%0A%20%20%20%20'Active%20Alerts'%20as%20metric_category%2C%0A%20%20%20%20CAST(COUNT(*)%20AS%20CHAR)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20COUNT(*)%20%3E%200%20THEN%20'CRITICAL'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0AFROM%20alert_history%0AWHERE%20status%20%3D%20'ACTIVE'%3B%0A%0A--%20Performance%20trends%0ASELECT%20%0A%20%20%20%20DATE(collected_at)%20as%20trend_date%2C%0A%20%20%20%20metric_name%2C%0A%20%20%20%20AVG(metric_value)%20as%20avg_value%2C%0A%20%20%20%20MIN(metric_value)%20as%20min_value%2C%0A%20%20%20%20MAX(metric_value)%20as%20max_value%2C%0A%20%20%20%20STDDEV(metric_value)%20as%20std_deviation%0AFROM%20system_metrics%0AWHERE%20collected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%207%20DAY)%0AGROUP%20BY%20DATE(collected_at)%2C%20metric_name%0AORDER%20BY%20trend_date%20DESC%2C%20metric_name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Real-time system overview
CREATE VIEW system_health_dashboard AS
SELECT 
    'Database Connections' as metric_category,
    CONCAT(
        (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected'),
        ' / ',
        (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections')
    ) as current_status,
    CASE 
        WHEN (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected') /
             (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections') &gt; 0.8
        THEN 'WARNING'
        ELSE 'OK'
    END as health_status

UNION ALL

SELECT 
    'Buffer Pool Hit Rate' as metric_category,
    CONCAT(
        ROUND((1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                   (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) * 100, 2),
        '%'
    ) as current_status,
    CASE 
        WHEN (1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                  (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) &lt; 0.95
        THEN 'WARNING'
        ELSE 'OK'
    END as health_status

UNION ALL

SELECT 
    'Active Alerts' as metric_category,
    CAST(COUNT(*) AS CHAR) as current_status,
    CASE 
        WHEN COUNT(*) &gt; 0 THEN 'CRITICAL'
        ELSE 'OK'
    END as health_status
FROM alert_history
WHERE status = 'ACTIVE';

-- Performance trends
SELECT 
    DATE(collected_at) as trend_date,
    metric_name,
    AVG(metric_value) as avg_value,
    MIN(metric_value) as min_value,
    MAX(metric_value) as max_value,
    STDDEV(metric_value) as std_deviation
FROM system_metrics
WHERE collected_at &gt;= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY DATE(collected_at), metric_name
ORDER BY trend_date DESC, metric_name;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Set up automated metric collection every 1-5 minutes</p>
<p>- Define appropriate thresholds based on historical data</p>
<p>- Implement alert escalation and notification channels</p>
<p>- Monitor both system and application-level metrics</p>
<p>- Use dashboards for real-time visibility</p>
<p>- Implement alert fatigue prevention (grouping, suppression)</p>
<p>- Regular review and tuning of monitoring rules</p>
<p>- Archive old metrics data to manage storage</p>

<h2 id="-371-what-are-data-warehousing-concepts-in-mysql-">**371. What are data warehousing concepts in MySQL?**</h2>

<p><strong>Answer:</strong> Data warehousing involves collecting, storing, and analyzing large volumes of data from multiple sources for business intelligence and reporting purposes.</p>

<p><strong>Data Warehouse Architecture:</strong></p>

<p><strong>1. Dimensional Modeling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Fact%20table%20(central%20table%20with%20metrics)%0ACREATE%20TABLE%20sales_fact%20(%0A%20%20%20%20sale_id%20BIGINT%20PRIMARY%20KEY%2C%0A%20%20%20%20date_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20store_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20quantity%20INT%20NOT%20NULL%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%20NOT%20NULL%2C%0A%20%20%20%20discount_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20tax_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Foreign%20keys%20to%20dimension%20tables%0A%20%20%20%20FOREIGN%20KEY%20(date_key)%20REFERENCES%20date_dimension(date_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_key)%20REFERENCES%20customer_dimension(customer_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_key)%20REFERENCES%20product_dimension(product_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(store_key)%20REFERENCES%20store_dimension(store_key)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Indexes%20for%20performance%0A%20%20%20%20INDEX%20idx_date%20(date_key)%2C%0A%20%20%20%20INDEX%20idx_customer%20(customer_key)%2C%0A%20%20%20%20INDEX%20idx_product%20(product_key)%2C%0A%20%20%20%20INDEX%20idx_store%20(store_key)%0A)%3B%0A%0A--%20Date%20dimension%20(time%20hierarchy)%0ACREATE%20TABLE%20date_dimension%20(%0A%20%20%20%20date_key%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20full_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20day_of_week%20INT%20NOT%20NULL%2C%0A%20%20%20%20day_name%20VARCHAR(10)%20NOT%20NULL%2C%0A%20%20%20%20day_of_month%20INT%20NOT%20NULL%2C%0A%20%20%20%20day_of_year%20INT%20NOT%20NULL%2C%0A%20%20%20%20week_of_year%20INT%20NOT%20NULL%2C%0A%20%20%20%20month_number%20INT%20NOT%20NULL%2C%0A%20%20%20%20month_name%20VARCHAR(10)%20NOT%20NULL%2C%0A%20%20%20%20quarter%20INT%20NOT%20NULL%2C%0A%20%20%20%20year%20INT%20NOT%20NULL%2C%0A%20%20%20%20is_weekend%20BOOLEAN%20NOT%20NULL%2C%0A%20%20%20%20is_holiday%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20fiscal_year%20INT%2C%0A%20%20%20%20fiscal_quarter%20INT%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_full_date%20(full_date)%2C%0A%20%20%20%20INDEX%20idx_year_month%20(year%2C%20month_number)%2C%0A%20%20%20%20INDEX%20idx_quarter%20(year%2C%20quarter)%0A)%3B%0A%0A--%20Customer%20dimension%20(slowly%20changing%20dimension)%0ACREATE%20TABLE%20customer_dimension%20(%0A%20%20%20%20customer_key%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%20NOT%20NULL%2C%20--%20Business%20key%0A%20%20%20%20customer_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20customer_type%20VARCHAR(50)%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20city%20VARCHAR(100)%2C%0A%20%20%20%20state%20VARCHAR(50)%2C%0A%20%20%20%20country%20VARCHAR(50)%2C%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SCD%20Type%202%20fields%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20is_current%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20version_number%20INT%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_current%20(is_current)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Fact table (central table with metrics)
CREATE TABLE sales_fact (
    sale_id BIGINT PRIMARY KEY,
    date_key INT NOT NULL,
    customer_key INT NOT NULL,
    product_key INT NOT NULL,
    store_key INT NOT NULL,
    quantity INT NOT NULL,
    unit_price DECIMAL(10,2) NOT NULL,
    total_amount DECIMAL(12,2) NOT NULL,
    discount_amount DECIMAL(10,2) DEFAULT 0,
    tax_amount DECIMAL(10,2) DEFAULT 0,
    
    -- Foreign keys to dimension tables
    FOREIGN KEY (date_key) REFERENCES date_dimension(date_key),
    FOREIGN KEY (customer_key) REFERENCES customer_dimension(customer_key),
    FOREIGN KEY (product_key) REFERENCES product_dimension(product_key),
    FOREIGN KEY (store_key) REFERENCES store_dimension(store_key),
    
    -- Indexes for performance
    INDEX idx_date (date_key),
    INDEX idx_customer (customer_key),
    INDEX idx_product (product_key),
    INDEX idx_store (store_key)
);

-- Date dimension (time hierarchy)
CREATE TABLE date_dimension (
    date_key INT PRIMARY KEY,
    full_date DATE NOT NULL,
    day_of_week INT NOT NULL,
    day_name VARCHAR(10) NOT NULL,
    day_of_month INT NOT NULL,
    day_of_year INT NOT NULL,
    week_of_year INT NOT NULL,
    month_number INT NOT NULL,
    month_name VARCHAR(10) NOT NULL,
    quarter INT NOT NULL,
    year INT NOT NULL,
    is_weekend BOOLEAN NOT NULL,
    is_holiday BOOLEAN DEFAULT FALSE,
    fiscal_year INT,
    fiscal_quarter INT,
    
    UNIQUE KEY uk_full_date (full_date),
    INDEX idx_year_month (year, month_number),
    INDEX idx_quarter (year, quarter)
);

-- Customer dimension (slowly changing dimension)
CREATE TABLE customer_dimension (
    customer_key INT AUTO_INCREMENT PRIMARY KEY,
    customer_id INT NOT NULL, -- Business key
    customer_name VARCHAR(255) NOT NULL,
    customer_type VARCHAR(50),
    customer_segment VARCHAR(50),
    city VARCHAR(100),
    state VARCHAR(50),
    country VARCHAR(50),
    region VARCHAR(50),
    
    -- SCD Type 2 fields
    effective_date DATE NOT NULL,
    expiry_date DATE DEFAULT '9999-12-31',
    is_current BOOLEAN DEFAULT TRUE,
    version_number INT DEFAULT 1,
    
    INDEX idx_customer_id (customer_id),
    INDEX idx_current (is_current),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. ETL Process Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Staging%20tables%20for%20data%20extraction%0ACREATE%20TABLE%20staging_sales%20(%0A%20%20%20%20source_system%20VARCHAR(50)%2C%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20transaction_date%20DATE%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20product_code%20VARCHAR(50)%2C%0A%20%20%20%20store_code%20VARCHAR(20)%2C%0A%20%20%20%20quantity%20INT%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%2C%0A%20%20%20%20extracted_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20processed%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_processed%20(processed)%2C%0A%20%20%20%20INDEX%20idx_extracted_at%20(extracted_at)%0A)%3B%0A%0A--%20ETL%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20etl_load_sales_data()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_transaction_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_transaction_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_customer_id%20INT%3B%0A%20%20%20%20DECLARE%20v_product_code%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_store_code%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_quantity%20INT%3B%0A%20%20%20%20DECLARE%20v_unit_price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20DECLARE%20v_total_amount%20DECIMAL(12%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Dimension%20keys%0A%20%20%20%20DECLARE%20v_date_key%20INT%3B%0A%20%20%20%20DECLARE%20v_customer_key%20INT%3B%0A%20%20%20%20DECLARE%20v_product_key%20INT%3B%0A%20%20%20%20DECLARE%20v_store_key%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20sales_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20transaction_id%2C%20transaction_date%2C%20customer_id%2C%20product_code%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20store_code%2C%20quantity%2C%20unit_price%2C%20total_amount%0A%20%20%20%20%20%20%20%20FROM%20staging_sales%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20sales_cursor%3B%0A%20%20%20%20%0A%20%20%20%20etl_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20sales_cursor%20INTO%20v_transaction_id%2C%20v_transaction_date%2C%20v_customer_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_product_code%2C%20v_store_code%2C%20v_quantity%2C%20v_unit_price%2C%20v_total_amount%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20etl_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Lookup%20dimension%20keys%0A%20%20%20%20%20%20%20%20SELECT%20date_key%20INTO%20v_date_key%20%0A%20%20%20%20%20%20%20%20FROM%20date_dimension%20WHERE%20full_date%20%3D%20v_transaction_date%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20customer_key%20INTO%20v_customer_key%0A%20%20%20%20%20%20%20%20FROM%20customer_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20customer_id%20%3D%20v_customer_id%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20product_key%20INTO%20v_product_key%0A%20%20%20%20%20%20%20%20FROM%20product_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20product_code%20%3D%20v_product_code%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20store_key%20INTO%20v_store_key%0A%20%20%20%20%20%20%20%20FROM%20store_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20store_code%20%3D%20v_store_code%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20into%20fact%20table%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20sales_fact%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20sale_id%2C%20date_key%2C%20customer_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20quantity%2C%20unit_price%2C%20total_amount%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_transaction_id%2C%20v_date_key%2C%20v_customer_key%2C%20v_product_key%2C%20v_store_key%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20v_quantity%2C%20v_unit_price%2C%20v_total_amount%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20UPDATE%20staging_sales%20%0A%20%20%20%20%20%20%20%20SET%20processed%20%3D%20TRUE%20%0A%20%20%20%20%20%20%20%20WHERE%20transaction_id%20%3D%20v_transaction_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20sales_cursor%3B%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20ETL%20completion%0A%20%20%20%20INSERT%20INTO%20etl_log%20(process_name%2C%20records_processed%2C%20completed_at)%0A%20%20%20%20SELECT%20'sales_etl'%2C%20COUNT(*)%2C%20NOW()%20%0A%20%20%20%20FROM%20staging_sales%20WHERE%20processed%20%3D%20TRUE%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Staging tables for data extraction
CREATE TABLE staging_sales (
    source_system VARCHAR(50),
    transaction_id VARCHAR(100),
    transaction_date DATE,
    customer_id INT,
    product_code VARCHAR(50),
    store_code VARCHAR(20),
    quantity INT,
    unit_price DECIMAL(10,2),
    total_amount DECIMAL(12,2),
    extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed BOOLEAN DEFAULT FALSE,
    
    INDEX idx_processed (processed),
    INDEX idx_extracted_at (extracted_at)
);

-- ETL procedure
DELIMITER //
CREATE PROCEDURE etl_load_sales_data()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_transaction_id VARCHAR(100);
    DECLARE v_transaction_date DATE;
    DECLARE v_customer_id INT;
    DECLARE v_product_code VARCHAR(50);
    DECLARE v_store_code VARCHAR(20);
    DECLARE v_quantity INT;
    DECLARE v_unit_price DECIMAL(10,2);
    DECLARE v_total_amount DECIMAL(12,2);
    
    -- Dimension keys
    DECLARE v_date_key INT;
    DECLARE v_customer_key INT;
    DECLARE v_product_key INT;
    DECLARE v_store_key INT;
    
    DECLARE sales_cursor CURSOR FOR
        SELECT transaction_id, transaction_date, customer_id, product_code,
               store_code, quantity, unit_price, total_amount
        FROM staging_sales
        WHERE processed = FALSE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    START TRANSACTION;
    
    OPEN sales_cursor;
    
    etl_loop: LOOP
        FETCH sales_cursor INTO v_transaction_id, v_transaction_date, v_customer_id,
                               v_product_code, v_store_code, v_quantity, v_unit_price, v_total_amount;
        
        IF done THEN
            LEAVE etl_loop;
        END IF;
        
        -- Lookup dimension keys
        SELECT date_key INTO v_date_key 
        FROM date_dimension WHERE full_date = v_transaction_date;
        
        SELECT customer_key INTO v_customer_key
        FROM customer_dimension 
        WHERE customer_id = v_customer_id AND is_current = TRUE;
        
        SELECT product_key INTO v_product_key
        FROM product_dimension 
        WHERE product_code = v_product_code AND is_current = TRUE;
        
        SELECT store_key INTO v_store_key
        FROM store_dimension 
        WHERE store_code = v_store_code;
        
        -- Insert into fact table
        INSERT INTO sales_fact (
            sale_id, date_key, customer_key, product_key, store_key,
            quantity, unit_price, total_amount
        ) VALUES (
            v_transaction_id, v_date_key, v_customer_key, v_product_key, v_store_key,
            v_quantity, v_unit_price, v_total_amount
        );
        
        -- Mark as processed
        UPDATE staging_sales 
        SET processed = TRUE 
        WHERE transaction_id = v_transaction_id;
        
    END LOOP;
    
    CLOSE sales_cursor;
    COMMIT;
    
    -- Log ETL completion
    INSERT INTO etl_log (process_name, records_processed, completed_at)
    SELECT 'sales_etl', COUNT(*), NOW() 
    FROM staging_sales WHERE processed = TRUE;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Slowly Changing Dimensions (SCD):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20SCD%20Type%202%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20update_customer_dimension(%0A%20%20%20%20IN%20p_customer_id%20INT%2C%0A%20%20%20%20IN%20p_customer_name%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_city%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_state%20VARCHAR(50)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_current_segment%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_current_city%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_current_state%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_customer_key%20INT%3B%0A%20%20%20%20DECLARE%20changes_detected%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20values%0A%20%20%20%20SELECT%20customer_key%2C%20customer_segment%2C%20city%2C%20state%0A%20%20%20%20INTO%20v_customer_key%2C%20v_current_segment%2C%20v_current_city%2C%20v_current_state%0A%20%20%20%20FROM%20customer_dimension%0A%20%20%20%20WHERE%20customer_id%20%3D%20p_customer_id%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20for%20changes%0A%20%20%20%20IF%20(v_current_segment%20!%3D%20p_customer_segment%20OR%20%0A%20%20%20%20%20%20%20%20v_current_city%20!%3D%20p_city%20OR%20%0A%20%20%20%20%20%20%20%20v_current_state%20!%3D%20p_state)%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes_detected%20%3D%20TRUE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20changes_detected%20THEN%0A%20%20%20%20%20%20%20%20--%20Close%20current%20record%0A%20%20%20%20%20%20%20%20UPDATE%20customer_dimension%0A%20%20%20%20%20%20%20%20SET%20expiry_date%20%3D%20CURDATE()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_current%20%3D%20FALSE%0A%20%20%20%20%20%20%20%20WHERE%20customer_key%20%3D%20v_customer_key%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20new%20record%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_dimension%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20customer_id%2C%20customer_name%2C%20customer_segment%2C%20city%2C%20state%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20effective_date%2C%20is_current%2C%20version_number%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_customer_id%2C%20p_customer_name%2C%20p_customer_segment%2C%20p_city%2C%20p_state%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CURDATE()%2C%20TRUE%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20MAX(version_number)%20%2B%201%20FROM%20customer_dimension%20WHERE%20customer_id%20%3D%20p_customer_id)%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20--%20Update%20current%20record%20(Type%201%20changes%20like%20name)%0A%20%20%20%20%20%20%20%20UPDATE%20customer_dimension%0A%20%20%20%20%20%20%20%20SET%20customer_name%20%3D%20p_customer_name%0A%20%20%20%20%20%20%20%20WHERE%20customer_key%20%3D%20v_customer_key%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- SCD Type 2 implementation
DELIMITER //
CREATE PROCEDURE update_customer_dimension(
    IN p_customer_id INT,
    IN p_customer_name VARCHAR(255),
    IN p_customer_segment VARCHAR(50),
    IN p_city VARCHAR(100),
    IN p_state VARCHAR(50)
)
BEGIN
    DECLARE v_current_segment VARCHAR(50);
    DECLARE v_current_city VARCHAR(100);
    DECLARE v_current_state VARCHAR(50);
    DECLARE v_customer_key INT;
    DECLARE changes_detected BOOLEAN DEFAULT FALSE;
    
    -- Get current values
    SELECT customer_key, customer_segment, city, state
    INTO v_customer_key, v_current_segment, v_current_city, v_current_state
    FROM customer_dimension
    WHERE customer_id = p_customer_id AND is_current = TRUE;
    
    -- Check for changes
    IF (v_current_segment != p_customer_segment OR 
        v_current_city != p_city OR 
        v_current_state != p_state) THEN
        SET changes_detected = TRUE;
    END IF;
    
    IF changes_detected THEN
        -- Close current record
        UPDATE customer_dimension
        SET expiry_date = CURDATE(),
            is_current = FALSE
        WHERE customer_key = v_customer_key;
        
        -- Insert new record
        INSERT INTO customer_dimension (
            customer_id, customer_name, customer_segment, city, state,
            effective_date, is_current, version_number
        ) VALUES (
            p_customer_id, p_customer_name, p_customer_segment, p_city, p_state,
            CURDATE(), TRUE, 
            (SELECT MAX(version_number) + 1 FROM customer_dimension WHERE customer_id = p_customer_id)
        );
    ELSE
        -- Update current record (Type 1 changes like name)
        UPDATE customer_dimension
        SET customer_name = p_customer_name
        WHERE customer_key = v_customer_key;
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Mart Creation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Sales%20data%20mart%20for%20specific%20department%0ACREATE%20TABLE%20sales_datamart%20AS%0ASELECT%20%0A%20%20%20%20d.year%2C%0A%20%20%20%20d.quarter%2C%0A%20%20%20%20d.month_name%2C%0A%20%20%20%20c.customer_segment%2C%0A%20%20%20%20c.region%2C%0A%20%20%20%20p.product_category%2C%0A%20%20%20%20p.product_subcategory%2C%0A%20%20%20%20s.store_type%2C%0A%20%20%20%20s.store_region%2C%0A%20%20%20%20SUM(f.quantity)%20as%20total_quantity%2C%0A%20%20%20%20SUM(f.total_amount)%20as%20total_sales%2C%0A%20%20%20%20AVG(f.unit_price)%20as%20avg_unit_price%2C%0A%20%20%20%20COUNT(DISTINCT%20f.customer_key)%20as%20unique_customers%2C%0A%20%20%20%20COUNT(*)%20as%20transaction_count%0AFROM%20sales_fact%20f%0AJOIN%20date_dimension%20d%20ON%20f.date_key%20%3D%20d.date_key%0AJOIN%20customer_dimension%20c%20ON%20f.customer_key%20%3D%20c.customer_key%0AJOIN%20product_dimension%20p%20ON%20f.product_key%20%3D%20p.product_key%0AJOIN%20store_dimension%20s%20ON%20f.store_key%20%3D%20s.store_key%0AWHERE%20d.year%20%3E%3D%20YEAR(CURDATE())%20-%202%20%20--%20Last%202%20years%0AGROUP%20BY%20d.year%2C%20d.quarter%2C%20d.month_name%2C%20c.customer_segment%2C%20c.region%2C%0A%20%20%20%20%20%20%20%20%20p.product_category%2C%20p.product_subcategory%2C%20s.store_type%2C%20s.store_region%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Sales data mart for specific department
CREATE TABLE sales_datamart AS
SELECT 
    d.year,
    d.quarter,
    d.month_name,
    c.customer_segment,
    c.region,
    p.product_category,
    p.product_subcategory,
    s.store_type,
    s.store_region,
    SUM(f.quantity) as total_quantity,
    SUM(f.total_amount) as total_sales,
    AVG(f.unit_price) as avg_unit_price,
    COUNT(DISTINCT f.customer_key) as unique_customers,
    COUNT(*) as transaction_count
FROM sales_fact f
JOIN date_dimension d ON f.date_key = d.date_key
JOIN customer_dimension c ON f.customer_key = c.customer_key
JOIN product_dimension p ON f.product_key = p.product_key
JOIN store_dimension s ON f.store_key = s.store_key
WHERE d.year &gt;= YEAR(CURDATE()) - 2  -- Last 2 years
GROUP BY d.year, d.quarter, d.month_name, c.customer_segment, c.region,
         p.product_category, p.product_subcategory, s.store_type, s.store_region;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use star or snowflake schema design</p>
<p>- Implement proper indexing on fact and dimension tables</p>
<p>- Use surrogate keys for dimension tables</p>
<p>- Handle slowly changing dimensions appropriately</p>
<p>- Implement data quality checks in ETL process</p>
<p>- Partition large fact tables by date</p>
<p>- Create aggregated summary tables for performance</p>


<p>---</p>

<h2 id="-372-how-do-you-implement-data-archiving-strategies-">**372. How do you implement data archiving strategies?**</h2>

<p><strong>Answer:</strong> Data archiving involves moving older, less frequently accessed data to separate storage while maintaining accessibility and compliance requirements.</p>

<p><strong>Archiving Strategy Design:</strong></p>

<p><strong>1. Time-Based Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20table%20structure%20(same%20as%20source%20but%20with%20archive%20suffix)%0ACREATE%20TABLE%20orders_archive%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20created_at%20TIMESTAMP%2C%0A%20%20%20%20archived_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_order_date%20(order_date)%2C%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_archived_at%20(archived_at)%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Automated%20archiving%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_old_orders(IN%20p_archive_months%20INT)%0ABEGIN%0A%20%20%20%20DECLARE%20archive_date%20DATE%3B%0A%20%20%20%20DECLARE%20records_archived%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20SET%20archive_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_archive_months%20MONTH)%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Copy%20old%20records%20to%20archive%20table%0A%20%20%20%20INSERT%20INTO%20orders_archive%20(%0A%20%20%20%20%20%20%20%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%0A%20%20%20%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3C%20archive_date%0A%20%20%20%20AND%20status%20IN%20('completed'%2C%20'cancelled'%2C%20'refunded')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_archived%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20archived%20records%20from%20main%20table%0A%20%20%20%20DELETE%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3C%20archive_date%0A%20%20%20%20AND%20status%20IN%20('completed'%2C%20'cancelled'%2C%20'refunded')%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20archiving%20activity%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_date%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'orders'%2C%20archive_date%2C%20records_archived%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20CONCAT('Archived%20'%2C%20records_archived%2C%20'%20orders%20older%20than%20'%2C%20archive_date)%20as%20result%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive table structure (same as source but with archive suffix)
CREATE TABLE orders_archive (
    id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    total DECIMAL(10,2),
    status VARCHAR(20),
    created_at TIMESTAMP,
    archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_order_date (order_date),
    INDEX idx_customer_id (customer_id),
    INDEX idx_archived_at (archived_at)
) ENGINE=InnoDB;

-- Automated archiving procedure
DELIMITER //
CREATE PROCEDURE archive_old_orders(IN p_archive_months INT)
BEGIN
    DECLARE archive_date DATE;
    DECLARE records_archived INT DEFAULT 0;
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    SET archive_date = DATE_SUB(CURDATE(), INTERVAL p_archive_months MONTH);
    
    START TRANSACTION;
    
    -- Copy old records to archive table
    INSERT INTO orders_archive (
        id, customer_id, order_date, total, status, created_at
    )
    SELECT id, customer_id, order_date, total, status, created_at
    FROM orders
    WHERE order_date &lt; archive_date
    AND status IN ('completed', 'cancelled', 'refunded');
    
    SET records_archived = ROW_COUNT();
    
    -- Delete archived records from main table
    DELETE FROM orders
    WHERE order_date &lt; archive_date
    AND status IN ('completed', 'cancelled', 'refunded');
    
    COMMIT;
    
    -- Log archiving activity
    INSERT INTO archive_log (
        table_name, archive_date, records_archived, archived_at
    ) VALUES (
        'orders', archive_date, records_archived, NOW()
    );
    
    SELECT CONCAT('Archived ', records_archived, ' orders older than ', archive_date) as result;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Conditional Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20based%20on%20business%20rules%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_inactive_customers()%0ABEGIN%0A%20%20%20%20DECLARE%20customers_archived%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20customers%20with%20no%20activity%20for%203%2B%20years%0A%20%20%20%20INSERT%20INTO%20customers_archive%20(%0A%20%20%20%20%20%20%20%20id%2C%20name%2C%20email%2C%20phone%2C%20address%2C%20status%2C%20%0A%20%20%20%20%20%20%20%20last_login%2C%20last_order_date%2C%20created_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20c.id%2C%20c.name%2C%20c.email%2C%20c.phone%2C%20c.address%2C%20c.status%2C%0A%20%20%20%20%20%20%20%20c.last_login%2C%20%0A%20%20%20%20%20%20%20%20(SELECT%20MAX(order_date)%20FROM%20orders%20WHERE%20customer_id%20%3D%20c.id)%20as%20last_order_date%2C%0A%20%20%20%20%20%20%20%20c.created_at%0A%20%20%20%20FROM%20customers%20c%0A%20%20%20%20WHERE%20c.status%20%3D%20'inactive'%0A%20%20%20%20AND%20c.last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20orders%20o%20%0A%20%20%20%20%20%20%20%20WHERE%20o.customer_id%20%3D%20c.id%20%0A%20%20%20%20%20%20%20%20AND%20o.order_date%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20customers_archived%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20archived%20customers%20from%20main%20table%0A%20%20%20%20DELETE%20c%20FROM%20customers%20c%0A%20%20%20%20WHERE%20c.status%20%3D%20'inactive'%0A%20%20%20%20AND%20c.last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20orders%20o%20%0A%20%20%20%20%20%20%20%20WHERE%20o.customer_id%20%3D%20c.id%20%0A%20%20%20%20%20%20%20%20AND%20o.order_date%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_criteria%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'customers'%2C%20'inactive_3_years'%2C%20customers_archived%2C%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive based on business rules
DELIMITER //
CREATE PROCEDURE archive_inactive_customers()
BEGIN
    DECLARE customers_archived INT DEFAULT 0;
    
    START TRANSACTION;
    
    -- Archive customers with no activity for 3+ years
    INSERT INTO customers_archive (
        id, name, email, phone, address, status, 
        last_login, last_order_date, created_at
    )
    SELECT 
        c.id, c.name, c.email, c.phone, c.address, c.status,
        c.last_login, 
        (SELECT MAX(order_date) FROM orders WHERE customer_id = c.id) as last_order_date,
        c.created_at
    FROM customers c
    WHERE c.status = 'inactive'
    AND c.last_login &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND NOT EXISTS (
        SELECT 1 FROM orders o 
        WHERE o.customer_id = c.id 
        AND o.order_date &gt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    );
    
    SET customers_archived = ROW_COUNT();
    
    -- Remove archived customers from main table
    DELETE c FROM customers c
    WHERE c.status = 'inactive'
    AND c.last_login &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND NOT EXISTS (
        SELECT 1 FROM orders o 
        WHERE o.customer_id = c.id 
        AND o.order_date &gt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    );
    
    COMMIT;
    
    INSERT INTO archive_log (
        table_name, archive_criteria, records_archived, archived_at
    ) VALUES (
        'customers', 'inactive_3_years', customers_archived, NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Partitioned Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20partitioned%20table%20for%20automatic%20archiving%0ACREATE%20TABLE%20user_activities%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%2C%0A%20%20%20%20user_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20activity_type%20VARCHAR(50)%2C%0A%20%20%20%20activity_data%20JSON%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20created_at%20TIMESTAMP%20NOT%20NULL%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20created_at)%2C%0A%20%20%20%20INDEX%20idx_user_id%20(user_id)%2C%0A%20%20%20%20INDEX%20idx_activity_type%20(activity_type)%0A)%20ENGINE%3DInnoDB%0APARTITION%20BY%20RANGE%20(YEAR(created_at))%20(%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_current%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A%0A--%20Archive%20old%20partitions%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_old_partitions()%0ABEGIN%0A%20%20%20%20DECLARE%20partition_name%20VARCHAR(64)%3B%0A%20%20%20%20DECLARE%20archive_year%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20partitions%20older%20than%202%20years%0A%20%20%20%20SET%20archive_year%20%3D%20YEAR(CURDATE())%20-%202%3B%0A%20%20%20%20SET%20partition_name%20%3D%20CONCAT('p'%2C%20archive_year)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%20for%20the%20partition%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('CREATE%20TABLE%20user_activities_archive_'%2C%20archive_year%2C%20'%20AS%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%20*%20FROM%20user_activities%20PARTITION%20('%2C%20partition_name%2C%20')')%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Drop%20the%20old%20partition%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('ALTER%20TABLE%20user_activities%20DROP%20PARTITION%20'%2C%20partition_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20the%20archiving%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_criteria%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'user_activities'%2C%20CONCAT('partition_'%2C%20partition_name)%2C%20%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(*)%20FROM%20user_activities_archive_2022)%2C%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create partitioned table for automatic archiving
CREATE TABLE user_activities (
    id BIGINT AUTO_INCREMENT,
    user_id INT NOT NULL,
    activity_type VARCHAR(50),
    activity_data JSON,
    ip_address VARCHAR(45),
    user_agent TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (id, created_at),
    INDEX idx_user_id (user_id),
    INDEX idx_activity_type (activity_type)
) ENGINE=InnoDB
PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_current VALUES LESS THAN MAXVALUE
);

-- Archive old partitions
DELIMITER //
CREATE PROCEDURE archive_old_partitions()
BEGIN
    DECLARE partition_name VARCHAR(64);
    DECLARE archive_year INT;
    
    -- Get partitions older than 2 years
    SET archive_year = YEAR(CURDATE()) - 2;
    SET partition_name = CONCAT('p', archive_year);
    
    -- Create archive table for the partition
    SET @sql = CONCAT('CREATE TABLE user_activities_archive_', archive_year, ' AS 
                      SELECT * FROM user_activities PARTITION (', partition_name, ')');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Drop the old partition
    SET @sql = CONCAT('ALTER TABLE user_activities DROP PARTITION ', partition_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log the archiving
    INSERT INTO archive_log (
        table_name, archive_criteria, records_archived, archived_at
    ) VALUES (
        'user_activities', CONCAT('partition_', partition_name), 
        (SELECT COUNT(*) FROM user_activities_archive_2022), NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Archive Access and Retrieval:</strong></p>

<p><strong>1. Unified View for Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20view%20that%20combines%20current%20and%20archived%20data%0ACREATE%20VIEW%20orders_complete%20AS%0ASELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%2C%20%0A%20%20%20%20%20%20%20'current'%20as%20data_source%0AFROM%20orders%0A%0AUNION%20ALL%0A%0ASELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%2C%0A%20%20%20%20%20%20%20'archived'%20as%20data_source%0AFROM%20orders_archive%3B%0A%0A--%20Query%20across%20current%20and%20archived%20data%0ASELECT%20%0A%20%20%20%20customer_id%2C%0A%20%20%20%20COUNT(*)%20as%20total_orders%2C%0A%20%20%20%20SUM(total)%20as%20total_spent%2C%0A%20%20%20%20MIN(order_date)%20as%20first_order%2C%0A%20%20%20%20MAX(order_date)%20as%20last_order%0AFROM%20orders_complete%0AWHERE%20customer_id%20%3D%2012345%0AGROUP%20BY%20customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create view that combines current and archived data
CREATE VIEW orders_complete AS
SELECT id, customer_id, order_date, total, status, created_at, 
       'current' as data_source
FROM orders

UNION ALL

SELECT id, customer_id, order_date, total, status, created_at,
       'archived' as data_source
FROM orders_archive;

-- Query across current and archived data
SELECT 
    customer_id,
    COUNT(*) as total_orders,
    SUM(total) as total_spent,
    MIN(order_date) as first_order,
    MAX(order_date) as last_order
FROM orders_complete
WHERE customer_id = 12345
GROUP BY customer_id;
</code></pre>
</div>

<p><strong>2. Archive Search Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20search_archived_data(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20p_search_criteria%20JSON%2C%0A%20%20%20%20IN%20p_date_range_start%20DATE%2C%0A%20%20%20%20IN%20p_date_range_end%20DATE%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20search_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20archive_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20archive_table%20%3D%20CONCAT(p_table_name%2C%20'_archive')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Build%20dynamic%20search%20query%0A%20%20%20%20SET%20search_sql%20%3D%20CONCAT('SELECT%20*%20FROM%20'%2C%20archive_table%2C%20'%20WHERE%201%3D1')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20date%20range%20filter%0A%20%20%20%20IF%20p_date_range_start%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20AND%20order_date%20%3E%3D%20'''%2C%20p_date_range_start%2C%20'''')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_date_range_end%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20AND%20order_date%20%3C%3D%20'''%2C%20p_date_range_end%2C%20'''')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20JSON-based%20criteria%0A%20%20%20%20IF%20JSON_LENGTH(p_search_criteria)%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20--%20Add%20custom%20search%20logic%20based%20on%20JSON%20criteria%0A%20%20%20%20%20%20%20%20--%20This%20would%20be%20expanded%20based%20on%20specific%20search%20requirements%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20ORDER%20BY%20order_date%20DESC%20LIMIT%201000')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20search_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE search_archived_data(
    IN p_table_name VARCHAR(64),
    IN p_search_criteria JSON,
    IN p_date_range_start DATE,
    IN p_date_range_end DATE
)
BEGIN
    DECLARE search_sql TEXT;
    DECLARE archive_table VARCHAR(100);
    
    SET archive_table = CONCAT(p_table_name, '_archive');
    
    -- Build dynamic search query
    SET search_sql = CONCAT('SELECT * FROM ', archive_table, ' WHERE 1=1');
    
    -- Add date range filter
    IF p_date_range_start IS NOT NULL THEN
        SET search_sql = CONCAT(search_sql, ' AND order_date &gt;= ''', p_date_range_start, '''');
    END IF;
    
    IF p_date_range_end IS NOT NULL THEN
        SET search_sql = CONCAT(search_sql, ' AND order_date &lt;= ''', p_date_range_end, '''');
    END IF;
    
    -- Add JSON-based criteria
    IF JSON_LENGTH(p_search_criteria) &gt; 0 THEN
        -- Add custom search logic based on JSON criteria
        -- This would be expanded based on specific search requirements
    END IF;
    
    SET search_sql = CONCAT(search_sql, ' ORDER BY order_date DESC LIMIT 1000');
    
    SET @sql = search_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Compliance and Retention Management:</strong></p>

<p><strong>1. Retention Policy Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Retention%20policy%20configuration%0ACREATE%20TABLE%20retention_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(64)%20NOT%20NULL%2C%0A%20%20%20%20retention_period_months%20INT%20NOT%20NULL%2C%0A%20%20%20%20archive_after_months%20INT%20NOT%20NULL%2C%0A%20%20%20%20delete_after_months%20INT%2C%0A%20%20%20%20compliance_requirement%20VARCHAR(100)%2C%0A%20%20%20%20policy_effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_policy%20(table_name%2C%20policy_effective_date)%0A)%3B%0A%0A--%20Insert%20retention%20policies%0AINSERT%20INTO%20retention_policies%20(%0A%20%20%20%20table_name%2C%20retention_period_months%2C%20archive_after_months%2C%20%0A%20%20%20%20delete_after_months%2C%20compliance_requirement%0A)%20VALUES%0A('orders'%2C%2084%2C%2024%2C%20NULL%2C%20'Business%20requirement%20-%207%20years')%2C%0A('user_activities'%2C%2036%2C%2012%2C%2084%2C%20'GDPR%20-%207%20years%20max%20retention')%2C%0A('audit_logs'%2C%2084%2C%2012%2C%20NULL%2C%20'SOX%20compliance%20-%207%20years')%2C%0A('payment_transactions'%2C%2084%2C%2024%2C%20NULL%2C%20'PCI%20DSS%20-%207%20years')%3B%0A%0A--%20Automated%20retention%20enforcement%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20enforce_retention_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(64)%3B%0A%20%20%20%20DECLARE%20v_archive_months%20INT%3B%0A%20%20%20%20DECLARE%20v_delete_months%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20archive_after_months%2C%20delete_after_months%0A%20%20%20%20%20%20%20%20FROM%20retention_policies%0A%20%20%20%20%20%20%20%20WHERE%20policy_effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_table_name%2C%20v_archive_months%2C%20v_delete_months%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Archive%20old%20data%0A%20%20%20%20%20%20%20%20CALL%20archive_table_data(v_table_name%2C%20v_archive_months)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Delete%20very%20old%20data%20if%20policy%20allows%0A%20%20%20%20%20%20%20%20IF%20v_delete_months%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20delete_old_archived_data(v_table_name%2C%20v_delete_months)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Retention policy configuration
CREATE TABLE retention_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64) NOT NULL,
    retention_period_months INT NOT NULL,
    archive_after_months INT NOT NULL,
    delete_after_months INT,
    compliance_requirement VARCHAR(100),
    policy_effective_date DATE NOT NULL,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_policy (table_name, policy_effective_date)
);

-- Insert retention policies
INSERT INTO retention_policies (
    table_name, retention_period_months, archive_after_months, 
    delete_after_months, compliance_requirement
) VALUES
('orders', 84, 24, NULL, 'Business requirement - 7 years'),
('user_activities', 36, 12, 84, 'GDPR - 7 years max retention'),
('audit_logs', 84, 12, NULL, 'SOX compliance - 7 years'),
('payment_transactions', 84, 24, NULL, 'PCI DSS - 7 years');

-- Automated retention enforcement
DELIMITER //
CREATE PROCEDURE enforce_retention_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(64);
    DECLARE v_archive_months INT;
    DECLARE v_delete_months INT;
    
    DECLARE policy_cursor CURSOR FOR
        SELECT table_name, archive_after_months, delete_after_months
        FROM retention_policies
        WHERE policy_effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_table_name, v_archive_months, v_delete_months;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Archive old data
        CALL archive_table_data(v_table_name, v_archive_months);
        
        -- Delete very old data if policy allows
        IF v_delete_months IS NOT NULL THEN
            CALL delete_old_archived_data(v_table_name, v_delete_months);
        END IF;
        
    END LOOP;
    
    CLOSE policy_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Performance Optimization:</strong></p>

<p>- Use separate storage engines for archives (MyISAM for read-only)</p>
<p>- Implement compression for archived data</p>
<p>- Create appropriate indexes on archive tables</p>
<p>- Use partitioning for large archive tables</p>
<p>- Regular maintenance of archive table statistics</p>
<p>- Consider external storage solutions for very old data</p>


<p>---</p>

<h2 id="-373-what-are-data-migration-best-practices-">**373. What are data migration best practices?**</h2>

<p><strong>Answer:</strong> Data migration involves transferring data between systems, databases, or formats while ensuring data integrity, minimal downtime, and business continuity.</p>

<p><strong>Migration Planning and Strategy:</strong></p>

<p><strong>1. Pre-Migration Assessment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20profiling%20and%20assessment%0ACREATE%20TABLE%20migration_assessment%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20record_count%20BIGINT%2C%0A%20%20%20%20data_size_mb%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_updated%20TIMESTAMP%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20complexity_level%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH')%2C%0A%20%20%20%20migration_priority%20INT%2C%0A%20%20%20%20estimated_duration_hours%20DECIMAL(5%2C2)%2C%0A%20%20%20%20dependencies%20TEXT%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Assess%20source%20data%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20assess_migration_data()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20record_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20data_size_mb%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20table_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20TABLE_NAME%0A%20%20%20%20%20%20%20%20FROM%20information_schema.tables%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20'source_database'%0A%20%20%20%20%20%20%20%20AND%20table_type%20%3D%20'BASE%20TABLE'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20assessment_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20table_cursor%20INTO%20table_name%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20assessment_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20record%20count%20and%20size%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20table_name)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20record_count%20variable%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20ROUND((data_length%20%2B%20index_length)%20%2F%201024%20%2F%201024%2C%202)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20FROM%20information_schema.tables%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20'''%2C%20table_name%2C%20'''')%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20data_size_mb%20variable%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20assessment%20data%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20migration_assessment%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20source_table%2C%20record_count%2C%20data_size_mb%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20complexity_level%2C%20migration_priority%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20record_count%2C%20data_size_mb%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20record_count%20%3E%2010000000%20THEN%20'HIGH'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20record_count%20%3E%201000000%20THEN%20'MEDIUM'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'LOW'%0A%20%20%20%20%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20table_name%20LIKE%20'%25user%25'%20OR%20table_name%20LIKE%20'%25customer%25'%20THEN%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20table_name%20LIKE%20'%25order%25'%20OR%20table_name%20LIKE%20'%25transaction%25'%20THEN%202%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%203%0A%20%20%20%20%20%20%20%20%20%20%20%20END%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20table_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data profiling and assessment
CREATE TABLE migration_assessment (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source_table VARCHAR(100),
    record_count BIGINT,
    data_size_mb DECIMAL(10,2),
    last_updated TIMESTAMP,
    data_quality_score DECIMAL(3,2),
    complexity_level ENUM('LOW', 'MEDIUM', 'HIGH'),
    migration_priority INT,
    estimated_duration_hours DECIMAL(5,2),
    dependencies TEXT,
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Assess source data
DELIMITER //
CREATE PROCEDURE assess_migration_data()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE table_name VARCHAR(100);
    DECLARE record_count BIGINT;
    DECLARE data_size_mb DECIMAL(10,2);
    
    DECLARE table_cursor CURSOR FOR
        SELECT TABLE_NAME
        FROM information_schema.tables
        WHERE table_schema = 'source_database'
        AND table_type = 'BASE TABLE';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN table_cursor;
    
    assessment_loop: LOOP
        FETCH table_cursor INTO table_name;
        
        IF done THEN
            LEAVE assessment_loop;
        END IF;
        
        -- Get record count and size
        SET @sql = CONCAT('SELECT COUNT(*) FROM ', table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in record_count variable
        
        SET @sql = CONCAT('SELECT ROUND((data_length + index_length) / 1024 / 1024, 2) 
                          FROM information_schema.tables 
                          WHERE table_name = ''', table_name, '''');
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in data_size_mb variable
        
        -- Insert assessment data
        INSERT INTO migration_assessment (
            source_table, record_count, data_size_mb, 
            complexity_level, migration_priority
        ) VALUES (
            table_name, record_count, data_size_mb,
            CASE 
                WHEN record_count &gt; 10000000 THEN 'HIGH'
                WHEN record_count &gt; 1000000 THEN 'MEDIUM'
                ELSE 'LOW'
            END,
            CASE 
                WHEN table_name LIKE '%user%' OR table_name LIKE '%customer%' THEN 1
                WHEN table_name LIKE '%order%' OR table_name LIKE '%transaction%' THEN 2
                ELSE 3
            END
        );
        
        DEALLOCATE PREPARE stmt;
        
    END LOOP;
    
    CLOSE table_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Migration Execution Framework:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Migration%20tracking%20table%0ACREATE%20TABLE%20migration_execution%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20migration_batch%20VARCHAR(50)%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20target_table%20VARCHAR(100)%2C%0A%20%20%20%20migration_type%20ENUM('FULL'%2C%20'INCREMENTAL'%2C%20'DELTA')%2C%0A%20%20%20%20status%20ENUM('PENDING'%2C%20'IN_PROGRESS'%2C%20'COMPLETED'%2C%20'FAILED'%2C%20'ROLLBACK')%2C%0A%20%20%20%20records_source%20BIGINT%2C%0A%20%20%20%20records_migrated%20BIGINT%2C%0A%20%20%20%20records_failed%20BIGINT%2C%0A%20%20%20%20start_time%20TIMESTAMP%2C%0A%20%20%20%20end_time%20TIMESTAMP%2C%0A%20%20%20%20duration_seconds%20INT%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20validation_status%20ENUM('PENDING'%2C%20'PASSED'%2C%20'FAILED')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Generic%20migration%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20migrate_table_data(%0A%20%20%20%20IN%20p_source_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_batch_size%20INT%2C%0A%20%20%20%20IN%20p_migration_type%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_migration_id%20INT%3B%0A%20%20%20%20DECLARE%20v_total_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_migrated_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_failed_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_batch_start%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_batch_end%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'FAILED'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20error_message%20%3D%20'Migration%20failed%20with%20SQL%20exception'%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Initialize%20migration%20record%0A%20%20%20%20INSERT%20INTO%20migration_execution%20(%0A%20%20%20%20%20%20%20%20source_table%2C%20target_table%2C%20migration_type%2C%20status%2C%20start_time%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_source_table%2C%20p_target_table%2C%20p_migration_type%2C%20'IN_PROGRESS'%2C%20v_start_time%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_migration_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20total%20record%20count%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_total_records%0A%20%20%20%20%0A%20%20%20%20--%20Update%20migration%20record%20with%20total%20count%0A%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20SET%20records_source%20%3D%20v_total_records%20%0A%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Migrate%20in%20batches%0A%20%20%20%20WHILE%20v_batch_start%20%3C%20v_total_records%20DO%0A%20%20%20%20%20%20%20%20SET%20v_batch_end%20%3D%20v_batch_start%20%2B%20p_batch_size%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Migrate%20batch%0A%20%20%20%20%20%20%20%20SET%20%40migrate_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_target_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20p_source_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_start%2C%20'%2C%20'%2C%20p_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20migrate_stmt%20FROM%20%40migrate_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20migrate_stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20migrate_stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_migrated_records%20%3D%20v_migrated_records%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20SET%20v_batch_start%20%3D%20v_batch_end%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20progress%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20records_migrated%20%3D%20v_migrated_records%20%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Complete%20migration%0A%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%0A%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20duration_seconds%20%3D%20TIMESTAMPDIFF(SECOND%2C%20v_start_time%2C%20NOW())%2C%0A%20%20%20%20%20%20%20%20records_migrated%20%3D%20v_migrated_records%0A%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Migration tracking table
CREATE TABLE migration_execution (
    id INT AUTO_INCREMENT PRIMARY KEY,
    migration_batch VARCHAR(50),
    source_table VARCHAR(100),
    target_table VARCHAR(100),
    migration_type ENUM('FULL', 'INCREMENTAL', 'DELTA'),
    status ENUM('PENDING', 'IN_PROGRESS', 'COMPLETED', 'FAILED', 'ROLLBACK'),
    records_source BIGINT,
    records_migrated BIGINT,
    records_failed BIGINT,
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    duration_seconds INT,
    error_message TEXT,
    validation_status ENUM('PENDING', 'PASSED', 'FAILED'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Generic migration procedure
DELIMITER //
CREATE PROCEDURE migrate_table_data(
    IN p_source_table VARCHAR(100),
    IN p_target_table VARCHAR(100),
    IN p_batch_size INT,
    IN p_migration_type VARCHAR(20)
)
BEGIN
    DECLARE v_migration_id INT;
    DECLARE v_total_records BIGINT DEFAULT 0;
    DECLARE v_migrated_records BIGINT DEFAULT 0;
    DECLARE v_failed_records BIGINT DEFAULT 0;
    DECLARE v_batch_start BIGINT DEFAULT 0;
    DECLARE v_batch_end BIGINT;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        UPDATE migration_execution 
        SET status = 'FAILED', 
            end_time = NOW(),
            error_message = 'Migration failed with SQL exception'
        WHERE id = v_migration_id;
        RESIGNAL;
    END;
    
    -- Initialize migration record
    INSERT INTO migration_execution (
        source_table, target_table, migration_type, status, start_time
    ) VALUES (
        p_source_table, p_target_table, p_migration_type, 'IN_PROGRESS', v_start_time
    );
    
    SET v_migration_id = LAST_INSERT_ID();
    
    -- Get total record count
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_total_records
    
    -- Update migration record with total count
    UPDATE migration_execution 
    SET records_source = v_total_records 
    WHERE id = v_migration_id;
    
    -- Migrate in batches
    WHILE v_batch_start &lt; v_total_records DO
        SET v_batch_end = v_batch_start + p_batch_size;
        
        -- Migrate batch
        SET @migrate_sql = CONCAT(
            'INSERT INTO ', p_target_table, ' ',
            'SELECT * FROM ', p_source_table, ' ',
            'LIMIT ', v_batch_start, ', ', p_batch_size
        );
        
        PREPARE migrate_stmt FROM @migrate_sql;
        EXECUTE migrate_stmt;
        DEALLOCATE PREPARE migrate_stmt;
        
        SET v_migrated_records = v_migrated_records + ROW_COUNT();
        SET v_batch_start = v_batch_end;
        
        -- Update progress
        UPDATE migration_execution 
        SET records_migrated = v_migrated_records 
        WHERE id = v_migration_id;
        
    END WHILE;
    
    -- Complete migration
    UPDATE migration_execution 
    SET status = 'COMPLETED',
        end_time = NOW(),
        duration_seconds = TIMESTAMPDIFF(SECOND, v_start_time, NOW()),
        records_migrated = v_migrated_records
    WHERE id = v_migration_id;
    
    DEALLOCATE PREPARE stmt;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Validation and Quality Checks:</strong></p>

<p><strong>1. Comprehensive Validation Framework:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Validation%20rules%20configuration%0ACREATE%20TABLE%20validation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20rule_type%20ENUM('NOT_NULL'%2C%20'UNIQUE'%2C%20'RANGE'%2C%20'FORMAT'%2C%20'REFERENCE'%2C%20'CUSTOM')%2C%0A%20%20%20%20rule_definition%20JSON%2C%0A%20%20%20%20severity%20ENUM('ERROR'%2C%20'WARNING'%2C%20'INFO')%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20validation%20rules%0AINSERT%20INTO%20validation_rules%20(table_name%2C%20column_name%2C%20rule_type%2C%20rule_definition%2C%20severity)%20VALUES%0A('customers'%2C%20'email'%2C%20'FORMAT'%2C%20'%7B%22pattern%22%3A%20%22%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C%5C.%5BA-Za-z%5D%7B2%2C%7D%24%22%7D'%2C%20'ERROR')%2C%0A('customers'%2C%20'phone'%2C%20'FORMAT'%2C%20'%7B%22pattern%22%3A%20%22%5E%5C%5C%2B%3F%5B1-9%5D%5C%5Cd%7B1%2C14%7D%24%22%7D'%2C%20'WARNING')%2C%0A('orders'%2C%20'total'%2C%20'RANGE'%2C%20'%7B%22min%22%3A%200%2C%20%22max%22%3A%20999999.99%7D'%2C%20'ERROR')%2C%0A('orders'%2C%20'customer_id'%2C%20'REFERENCE'%2C%20'%7B%22table%22%3A%20%22customers%22%2C%20%22column%22%3A%20%22id%22%7D'%2C%20'ERROR')%3B%0A%0A--%20Validation%20execution%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_migrated_data(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_rule_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_rule_definition%20JSON%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_error_count%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20validation_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20rule_type%2C%20rule_definition%2C%20severity%0A%20%20%20%20%20%20%20%20FROM%20validation_rules%0A%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20validation%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20validation_results%20(%0A%20%20%20%20%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20rule_type%20VARCHAR(20)%2C%0A%20%20%20%20%20%20%20%20severity%20VARCHAR(10)%2C%0A%20%20%20%20%20%20%20%20error_count%20INT%2C%0A%20%20%20%20%20%20%20%20sample_errors%20TEXT%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20validation_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20validation_cursor%20INTO%20v_column_name%2C%20v_rule_type%2C%20v_rule_definition%2C%20v_severity%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20validation_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20validation%20query%20based%20on%20rule%20type%0A%20%20%20%20%20%20%20%20CASE%20v_rule_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'NOT_NULL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20IS%20NULL'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'FORMAT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20NOT%20REGEXP%20'''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(v_rule_definition%2C%20'%24.pattern'))%2C%20''''%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'RANGE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20%3C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_rule_definition%2C%20'%24.min')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20OR%20'%2C%20v_column_name%2C%20'%20%3E%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_rule_definition%2C%20'%24.max')%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20NULL%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20validation%0A%20%20%20%20%20%20%20%20IF%20v_validation_sql%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Get%20result%20into%20v_error_count%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20validation%20result%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20validation_results%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p_table_name%2C%20v_column_name%2C%20v_rule_type%2C%20v_severity%2C%20v_error_count%2C%20NULL%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20validation%20results%0A%20%20%20%20SELECT%20*%20FROM%20validation_results%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20validation_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Validation rules configuration
CREATE TABLE validation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100),
    column_name VARCHAR(100),
    rule_type ENUM('NOT_NULL', 'UNIQUE', 'RANGE', 'FORMAT', 'REFERENCE', 'CUSTOM'),
    rule_definition JSON,
    severity ENUM('ERROR', 'WARNING', 'INFO'),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert validation rules
INSERT INTO validation_rules (table_name, column_name, rule_type, rule_definition, severity) VALUES
('customers', 'email', 'FORMAT', '{"pattern": "^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$"}', 'ERROR'),
('customers', 'phone', 'FORMAT', '{"pattern": "^\\+?[1-9]\\d{1,14}$"}', 'WARNING'),
('orders', 'total', 'RANGE', '{"min": 0, "max": 999999.99}', 'ERROR'),
('orders', 'customer_id', 'REFERENCE', '{"table": "customers", "column": "id"}', 'ERROR');

-- Validation execution procedure
DELIMITER //
CREATE PROCEDURE validate_migrated_data(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_rule_type VARCHAR(20);
    DECLARE v_rule_definition JSON;
    DECLARE v_severity VARCHAR(10);
    DECLARE v_validation_sql TEXT;
    DECLARE v_error_count INT;
    
    DECLARE validation_cursor CURSOR FOR
        SELECT column_name, rule_type, rule_definition, severity
        FROM validation_rules
        WHERE table_name = p_table_name AND is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create validation results table
    CREATE TEMPORARY TABLE validation_results (
        table_name VARCHAR(100),
        column_name VARCHAR(100),
        rule_type VARCHAR(20),
        severity VARCHAR(10),
        error_count INT,
        sample_errors TEXT
    );
    
    OPEN validation_cursor;
    
    validation_loop: LOOP
        FETCH validation_cursor INTO v_column_name, v_rule_type, v_rule_definition, v_severity;
        
        IF done THEN
            LEAVE validation_loop;
        END IF;
        
        -- Build validation query based on rule type
        CASE v_rule_type
            WHEN 'NOT_NULL' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name, 
                    ' WHERE ', v_column_name, ' IS NULL'
                );
            
            WHEN 'FORMAT' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name,
                    ' WHERE ', v_column_name, ' NOT REGEXP ''',
                    JSON_UNQUOTE(JSON_EXTRACT(v_rule_definition, '$.pattern')), ''''
                );
            
            WHEN 'RANGE' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name,
                    ' WHERE ', v_column_name, ' &lt; ',
                    JSON_EXTRACT(v_rule_definition, '$.min'),
                    ' OR ', v_column_name, ' &gt; ',
                    JSON_EXTRACT(v_rule_definition, '$.max')
                );
            
            ELSE
                SET v_validation_sql = NULL;
        END CASE;
        
        -- Execute validation
        IF v_validation_sql IS NOT NULL THEN
            SET @sql = v_validation_sql;
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            -- Get result into v_error_count
            DEALLOCATE PREPARE stmt;
            
            -- Insert validation result
            INSERT INTO validation_results VALUES (
                p_table_name, v_column_name, v_rule_type, v_severity, v_error_count, NULL
            );
        END IF;
        
    END LOOP;
    
    CLOSE validation_cursor;
    
    -- Return validation results
    SELECT * FROM validation_results;
    
    DROP TEMPORARY TABLE validation_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Reconciliation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Reconciliation%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20reconcile_migration_data(%0A%20%20%20%20IN%20p_source_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_source_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_target_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_source_checksum%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_target_checksum%20BIGINT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20comparison%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_source_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_target_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_target_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Checksum%20comparison%20(for%20numeric%20columns)%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20SUM(CRC32(CONCAT_WS(%22%7C%22%2C%20*)))%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_source_checksum%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20SUM(CRC32(CONCAT_WS(%22%7C%22%2C%20*)))%20FROM%20'%2C%20p_target_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_target_checksum%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Insert%20reconciliation%20results%0A%20%20%20%20INSERT%20INTO%20migration_reconciliation%20(%0A%20%20%20%20%20%20%20%20source_table%2C%20target_table%2C%20source_count%2C%20target_count%2C%0A%20%20%20%20%20%20%20%20source_checksum%2C%20target_checksum%2C%20%0A%20%20%20%20%20%20%20%20count_match%2C%20checksum_match%2C%20reconciled_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_source_table%2C%20p_target_table%2C%20v_source_count%2C%20v_target_count%2C%0A%20%20%20%20%20%20%20%20v_source_checksum%2C%20v_target_checksum%2C%0A%20%20%20%20%20%20%20%20(v_source_count%20%3D%20v_target_count)%2C%0A%20%20%20%20%20%20%20%20(v_source_checksum%20%3D%20v_target_checksum)%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Reconciliation procedure
DELIMITER //
CREATE PROCEDURE reconcile_migration_data(
    IN p_source_table VARCHAR(100),
    IN p_target_table VARCHAR(100)
)
BEGIN
    DECLARE v_source_count BIGINT;
    DECLARE v_target_count BIGINT;
    DECLARE v_source_checksum BIGINT;
    DECLARE v_target_checksum BIGINT;
    
    -- Count comparison
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_source_count
    DEALLOCATE PREPARE stmt;
    
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_target_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_target_count
    DEALLOCATE PREPARE stmt;
    
    -- Checksum comparison (for numeric columns)
    SET @sql = CONCAT('SELECT SUM(CRC32(CONCAT_WS("|", *))) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_source_checksum
    DEALLOCATE PREPARE stmt;
    
    SET @sql = CONCAT('SELECT SUM(CRC32(CONCAT_WS("|", *))) FROM ', p_target_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_target_checksum
    DEALLOCATE PREPARE stmt;
    
    -- Insert reconciliation results
    INSERT INTO migration_reconciliation (
        source_table, target_table, source_count, target_count,
        source_checksum, target_checksum, 
        count_match, checksum_match, reconciled_at
    ) VALUES (
        p_source_table, p_target_table, v_source_count, v_target_count,
        v_source_checksum, v_target_checksum,
        (v_source_count = v_target_count),
        (v_source_checksum = v_target_checksum),
        NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Rollback and Recovery:</strong></p>

<p><strong>1. Rollback Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Rollback%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20rollback_migration(IN%20p_migration_batch%20VARCHAR(50))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_target_table%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_backup_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20rollback_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20DISTINCT%20target_table%0A%20%20%20%20%20%20%20%20FROM%20migration_execution%0A%20%20%20%20%20%20%20%20WHERE%20migration_batch%20%3D%20p_migration_batch%0A%20%20%20%20%20%20%20%20AND%20status%20%3D%20'COMPLETED'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20rollback_cursor%3B%0A%20%20%20%20%0A%20%20%20%20rollback_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20rollback_cursor%20INTO%20v_target_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20rollback_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_backup_table%20%3D%20CONCAT(v_target_table%2C%20'_backup_'%2C%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Restore%20from%20backup%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('DROP%20TABLE%20IF%20EXISTS%20'%2C%20v_target_table)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('RENAME%20TABLE%20'%2C%20v_backup_table%2C%20'%20TO%20'%2C%20v_target_table)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20migration%20status%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'ROLLBACK'%0A%20%20%20%20%20%20%20%20WHERE%20migration_batch%20%3D%20p_migration_batch%0A%20%20%20%20%20%20%20%20AND%20target_table%20%3D%20v_target_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20rollback_cursor%3B%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Rollback procedure
DELIMITER //
CREATE PROCEDURE rollback_migration(IN p_migration_batch VARCHAR(50))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_target_table VARCHAR(100);
    DECLARE v_backup_table VARCHAR(100);
    
    DECLARE rollback_cursor CURSOR FOR
        SELECT DISTINCT target_table
        FROM migration_execution
        WHERE migration_batch = p_migration_batch
        AND status = 'COMPLETED';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    START TRANSACTION;
    
    OPEN rollback_cursor;
    
    rollback_loop: LOOP
        FETCH rollback_cursor INTO v_target_table;
        
        IF done THEN
            LEAVE rollback_loop;
        END IF;
        
        SET v_backup_table = CONCAT(v_target_table, '_backup_', DATE_FORMAT(NOW(), '%Y%m%d'));
        
        -- Restore from backup
        SET @sql = CONCAT('DROP TABLE IF EXISTS ', v_target_table);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        SET @sql = CONCAT('RENAME TABLE ', v_backup_table, ' TO ', v_target_table);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- Update migration status
        UPDATE migration_execution 
        SET status = 'ROLLBACK'
        WHERE migration_batch = p_migration_batch
        AND target_table = v_target_table;
        
    END LOOP;
    
    CLOSE rollback_cursor;
    COMMIT;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Always create backups before migration</p>
<p>- Test migration process on subset of data first</p>
<p>- Implement comprehensive validation and reconciliation</p>
<p>- Use batched processing for large datasets</p>
<p>- Monitor migration progress and performance</p>
<p>- Plan for rollback scenarios</p>
<p>- Document all migration steps and decisions</p>
<p>- Validate business logic after migration</p>

<h2 id="-374-how-do-you-implement-data-backup-and-recovery-strategies-">**374. How do you implement data backup and recovery strategies?**</h2>

<p><strong>Answer:</strong> Data backup and recovery strategies ensure business continuity and data protection through systematic backup procedures and tested recovery processes.</p>

<p><strong>Backup Strategy Types:</strong></p>

<p><strong>1. Full Backup Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Automated%20full%20backup%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_full_backup(IN%20p_backup_location%20VARCHAR(500))%0ABEGIN%0A%20%20%20%20DECLARE%20backup_filename%20VARCHAR(600)%3B%0A%20%20%20%20DECLARE%20backup_command%20TEXT%3B%0A%20%20%20%20DECLARE%20backup_start%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20SET%20backup_filename%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20p_backup_location%2C%20'%2F'%2C%0A%20%20%20%20%20%20%20%20DATABASE()%2C%20'_full_backup_'%2C%0A%20%20%20%20%20%20%20%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s')%2C%20'.sql'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20backup%20start%0A%20%20%20%20INSERT%20INTO%20backup_log%20(backup_type%2C%20backup_location%2C%20status%2C%20start_time)%0A%20%20%20%20VALUES%20('FULL'%2C%20backup_filename%2C%20'IN_PROGRESS'%2C%20backup_start)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20mysqldump%20command%20(would%20be%20done%20via%20external%20script)%0A%20%20%20%20SET%20backup_command%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'mysqldump%20--single-transaction%20--routines%20--triggers%20'%2C%0A%20%20%20%20%20%20%20%20'--host%3D'%2C%20%40%40hostname%2C%20'%20--user%3Dbackup_user%20'%2C%0A%20%20%20%20%20%20%20%20'--password%3Dbackup_password%20'%2C%20DATABASE()%2C%20%0A%20%20%20%20%20%20%20%20'%20%3E%20'%2C%20backup_filename%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20backup%20log%20on%20completion%0A%20%20%20%20UPDATE%20backup_log%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%20%0A%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20duration_minutes%20%3D%20TIMESTAMPDIFF(MINUTE%2C%20backup_start%2C%20NOW())%2C%0A%20%20%20%20%20%20%20%20file_size_mb%20%3D%20(SELECT%20ROUND(SUM(data_length%20%2B%20index_length)%20%2F%201024%20%2F%201024%2C%202)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20FROM%20information_schema.tables%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20DATABASE())%0A%20%20%20%20WHERE%20backup_location%20%3D%20backup_filename%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Automated full backup procedure
DELIMITER //
CREATE PROCEDURE create_full_backup(IN p_backup_location VARCHAR(500))
BEGIN
    DECLARE backup_filename VARCHAR(600);
    DECLARE backup_command TEXT;
    DECLARE backup_start TIMESTAMP DEFAULT NOW();
    
    SET backup_filename = CONCAT(
        p_backup_location, '/',
        DATABASE(), '_full_backup_',
        DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'), '.sql'
    );
    
    -- Log backup start
    INSERT INTO backup_log (backup_type, backup_location, status, start_time)
    VALUES ('FULL', backup_filename, 'IN_PROGRESS', backup_start);
    
    -- Execute mysqldump command (would be done via external script)
    SET backup_command = CONCAT(
        'mysqldump --single-transaction --routines --triggers ',
        '--host=', @@hostname, ' --user=backup_user ',
        '--password=backup_password ', DATABASE(), 
        ' &gt; ', backup_filename
    );
    
    -- Update backup log on completion
    UPDATE backup_log 
    SET status = 'COMPLETED', 
        end_time = NOW(),
        duration_minutes = TIMESTAMPDIFF(MINUTE, backup_start, NOW()),
        file_size_mb = (SELECT ROUND(SUM(data_length + index_length) / 1024 / 1024, 2)
                       FROM information_schema.tables 
                       WHERE table_schema = DATABASE())
    WHERE backup_location = backup_filename;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Incremental Backup Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Binary%20log-based%20incremental%20backup%0ACREATE%20TABLE%20backup_positions%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20backup_type%20ENUM('FULL'%2C%20'INCREMENTAL')%2C%0A%20%20%20%20binlog_file%20VARCHAR(255)%2C%0A%20%20%20%20binlog_position%20BIGINT%2C%0A%20%20%20%20backup_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20backup_location%20VARCHAR(500)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_incremental_backup()%0ABEGIN%0A%20%20%20%20DECLARE%20last_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20last_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20current_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20current_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20backup_location%20VARCHAR(500)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20last%20backup%20position%0A%20%20%20%20SELECT%20binlog_file%2C%20binlog_position%20%0A%20%20%20%20INTO%20last_binlog_file%2C%20last_binlog_position%0A%20%20%20%20FROM%20backup_positions%20%0A%20%20%20%20ORDER%20BY%20backup_timestamp%20DESC%20%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20master%20status%0A%20%20%20%20SELECT%20File%2C%20Position%20%0A%20%20%20%20INTO%20current_binlog_file%2C%20current_binlog_position%0A%20%20%20%20FROM%20(SHOW%20MASTER%20STATUS)%20ms%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20incremental%20backup%20filename%0A%20%20%20%20SET%20backup_location%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'%2Fbackups%2Fincremental%2F'%2C%0A%20%20%20%20%20%20%20%20DATABASE()%2C%20'_incremental_'%2C%0A%20%20%20%20%20%20%20%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s')%2C%20'.sql'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20binary%20log%20changes%20(would%20use%20mysqlbinlog%20externally)%0A%20%20%20%20--%20mysqlbinlog%20--start-position%3Dlast_position%20--stop-position%3Dcurrent_position%0A%20%20%20%20%0A%20%20%20%20--%20Record%20new%20backup%20position%0A%20%20%20%20INSERT%20INTO%20backup_positions%20(%0A%20%20%20%20%20%20%20%20backup_type%2C%20binlog_file%2C%20binlog_position%2C%20backup_location%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'INCREMENTAL'%2C%20current_binlog_file%2C%20current_binlog_position%2C%20backup_location%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Binary log-based incremental backup
CREATE TABLE backup_positions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    backup_type ENUM('FULL', 'INCREMENTAL'),
    binlog_file VARCHAR(255),
    binlog_position BIGINT,
    backup_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    backup_location VARCHAR(500)
);

DELIMITER //
CREATE PROCEDURE create_incremental_backup()
BEGIN
    DECLARE last_binlog_file VARCHAR(255);
    DECLARE last_binlog_position BIGINT;
    DECLARE current_binlog_file VARCHAR(255);
    DECLARE current_binlog_position BIGINT;
    DECLARE backup_location VARCHAR(500);
    
    -- Get last backup position
    SELECT binlog_file, binlog_position 
    INTO last_binlog_file, last_binlog_position
    FROM backup_positions 
    ORDER BY backup_timestamp DESC 
    LIMIT 1;
    
    -- Get current master status
    SELECT File, Position 
    INTO current_binlog_file, current_binlog_position
    FROM (SHOW MASTER STATUS) ms;
    
    -- Create incremental backup filename
    SET backup_location = CONCAT(
        '/backups/incremental/',
        DATABASE(), '_incremental_',
        DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'), '.sql'
    );
    
    -- Extract binary log changes (would use mysqlbinlog externally)
    -- mysqlbinlog --start-position=last_position --stop-position=current_position
    
    -- Record new backup position
    INSERT INTO backup_positions (
        backup_type, binlog_file, binlog_position, backup_location
    ) VALUES (
        'INCREMENTAL', current_binlog_file, current_binlog_position, backup_location
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Recovery Procedures:</strong></p>

<p><strong>1. Point-in-Time Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20point_in_time_recovery(%0A%20%20%20%20IN%20p_recovery_timestamp%20TIMESTAMP%2C%0A%20%20%20%20IN%20p_full_backup_file%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20recovery_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20recovery_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20recovery_commands%20TEXT%20DEFAULT%20''%3B%0A%20%20%20%20%0A%20%20%20%20--%20Find%20the%20appropriate%20backup%20point%0A%20%20%20%20SELECT%20binlog_file%2C%20binlog_position%0A%20%20%20%20INTO%20recovery_binlog_file%2C%20recovery_binlog_position%0A%20%20%20%20FROM%20backup_positions%0A%20%20%20%20WHERE%20backup_timestamp%20%3C%3D%20p_recovery_timestamp%0A%20%20%20%20ORDER%20BY%20backup_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20recovery%20start%0A%20%20%20%20INSERT%20INTO%20recovery_log%20(%0A%20%20%20%20%20%20%20%20recovery_type%2C%20target_timestamp%2C%20full_backup_file%2C%20%0A%20%20%20%20%20%20%20%20binlog_file%2C%20binlog_position%2C%20status%2C%20start_time%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'POINT_IN_TIME'%2C%20p_recovery_timestamp%2C%20p_full_backup_file%2C%0A%20%20%20%20%20%20%20%20recovery_binlog_file%2C%20recovery_binlog_position%2C%20'IN_PROGRESS'%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20recovery%20commands%20(would%20be%20executed%20externally)%0A%20%20%20%20SET%20recovery_commands%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'1.%20Stop%20MySQL%20service%5Cn'%2C%0A%20%20%20%20%20%20%20%20'2.%20Restore%20full%20backup%3A%20mysql%20%3C%20'%2C%20p_full_backup_file%2C%20'%5Cn'%2C%0A%20%20%20%20%20%20%20%20'3.%20Apply%20binary%20logs%3A%20mysqlbinlog%20--start-position%3D'%2C%20recovery_binlog_position%2C%0A%20%20%20%20%20%20%20%20'%20--stop-datetime%3D%22'%2C%20p_recovery_timestamp%2C%20'%22%20'%2C%20recovery_binlog_file%2C%20'%20%7C%20mysql%5Cn'%2C%0A%20%20%20%20%20%20%20%20'4.%20Start%20MySQL%20service%5Cn'%2C%0A%20%20%20%20%20%20%20%20'5.%20Verify%20data%20consistency'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20recovery%20log%20with%20commands%0A%20%20%20%20UPDATE%20recovery_log%20%0A%20%20%20%20SET%20recovery_commands%20%3D%20recovery_commands%2C%0A%20%20%20%20%20%20%20%20status%20%3D%20'READY_FOR_EXECUTION'%0A%20%20%20%20WHERE%20target_timestamp%20%3D%20p_recovery_timestamp%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE point_in_time_recovery(
    IN p_recovery_timestamp TIMESTAMP,
    IN p_full_backup_file VARCHAR(500)
)
BEGIN
    DECLARE recovery_binlog_file VARCHAR(255);
    DECLARE recovery_binlog_position BIGINT;
    DECLARE recovery_commands TEXT DEFAULT '';
    
    -- Find the appropriate backup point
    SELECT binlog_file, binlog_position
    INTO recovery_binlog_file, recovery_binlog_position
    FROM backup_positions
    WHERE backup_timestamp &lt;= p_recovery_timestamp
    ORDER BY backup_timestamp DESC
    LIMIT 1;
    
    -- Log recovery start
    INSERT INTO recovery_log (
        recovery_type, target_timestamp, full_backup_file, 
        binlog_file, binlog_position, status, start_time
    ) VALUES (
        'POINT_IN_TIME', p_recovery_timestamp, p_full_backup_file,
        recovery_binlog_file, recovery_binlog_position, 'IN_PROGRESS', NOW()
    );
    
    -- Generate recovery commands (would be executed externally)
    SET recovery_commands = CONCAT(
        '1. Stop MySQL service\n',
        '2. Restore full backup: mysql &lt; ', p_full_backup_file, '\n',
        '3. Apply binary logs: mysqlbinlog --start-position=', recovery_binlog_position,
        ' --stop-datetime="', p_recovery_timestamp, '" ', recovery_binlog_file, ' | mysql\n',
        '4. Start MySQL service\n',
        '5. Verify data consistency'
    );
    
    -- Update recovery log with commands
    UPDATE recovery_log 
    SET recovery_commands = recovery_commands,
        status = 'READY_FOR_EXECUTION'
    WHERE target_timestamp = p_recovery_timestamp;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Table-Level Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20recover_single_table(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_recovery_timestamp%20TIMESTAMP%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20temp_db_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20recovery_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20SET%20temp_db_name%20%3D%20CONCAT('recovery_'%2C%20UNIX_TIMESTAMP())%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20database%20for%20recovery%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('CREATE%20DATABASE%20'%2C%20temp_db_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Restore%20full%20backup%20to%20temporary%20database%0A%20%20%20%20--%20(External%20command%3A%20mysql%20temp_db%20%3C%20backup.sql)%0A%20%20%20%20%0A%20%20%20%20--%20Copy%20specific%20table%20data%0A%20%20%20%20SET%20recovery_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20DATABASE()%2C%20'.'%2C%20p_table_name%2C%20'_recovered%20'%2C%0A%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20temp_db_name%2C%20'.'%2C%20p_table_name%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20recovery_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clean%20up%20temporary%20database%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('DROP%20DATABASE%20'%2C%20temp_db_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20recovery%20completion%0A%20%20%20%20INSERT%20INTO%20recovery_log%20(%0A%20%20%20%20%20%20%20%20recovery_type%2C%20table_name%2C%20target_timestamp%2C%20status%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'TABLE_LEVEL'%2C%20p_table_name%2C%20p_recovery_timestamp%2C%20'COMPLETED'%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE recover_single_table(
    IN p_table_name VARCHAR(100),
    IN p_recovery_timestamp TIMESTAMP
)
BEGIN
    DECLARE temp_db_name VARCHAR(100);
    DECLARE recovery_sql TEXT;
    
    SET temp_db_name = CONCAT('recovery_', UNIX_TIMESTAMP());
    
    -- Create temporary database for recovery
    SET @sql = CONCAT('CREATE DATABASE ', temp_db_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Restore full backup to temporary database
    -- (External command: mysql temp_db &lt; backup.sql)
    
    -- Copy specific table data
    SET recovery_sql = CONCAT(
        'INSERT INTO ', DATABASE(), '.', p_table_name, '_recovered ',
        'SELECT * FROM ', temp_db_name, '.', p_table_name
    );
    
    SET @sql = recovery_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Clean up temporary database
    SET @sql = CONCAT('DROP DATABASE ', temp_db_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log recovery completion
    INSERT INTO recovery_log (
        recovery_type, table_name, target_timestamp, status, completed_at
    ) VALUES (
        'TABLE_LEVEL', p_table_name, p_recovery_timestamp, 'COMPLETED', NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-375-what-are-data-quality-management-techniques-">**375. What are data quality management techniques?**</h2>

<p><strong>Answer:</strong> Data quality management ensures data accuracy, completeness, consistency, and reliability through systematic validation, cleansing, and monitoring processes.</p>

<p><strong>Data Quality Framework:</strong></p>

<p><strong>1. Data Profiling and Assessment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20quality%20metrics%20table%0ACREATE%20TABLE%20data_quality_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20metric_type%20ENUM('COMPLETENESS'%2C%20'ACCURACY'%2C%20'CONSISTENCY'%2C%20'VALIDITY'%2C%20'UNIQUENESS')%2C%0A%20%20%20%20metric_value%20DECIMAL(5%2C2)%2C%0A%20%20%20%20total_records%20BIGINT%2C%0A%20%20%20%20quality_issues%20BIGINT%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_column%20(table_name%2C%20column_name)%2C%0A%20%20%20%20INDEX%20idx_metric_type%20(metric_type)%2C%0A%20%20%20%20INDEX%20idx_assessment_date%20(assessment_date)%0A)%3B%0A%0A--%20Data%20profiling%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20profile_data_quality(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_data_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_total_records%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_null_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_unique_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_completeness%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_uniqueness%20DECIMAL(5%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20column_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20data_type%0A%20%20%20%20%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20DATABASE()%0A%20%20%20%20%20%20%20%20AND%20table_name%20%3D%20p_table_name%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20total%20record%20count%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20v_total_records%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20column_cursor%3B%0A%20%20%20%20%0A%20%20%20%20profile_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20column_cursor%20INTO%20v_column_name%2C%20v_data_type%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20profile_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20completeness%20(non-null%20percentage)%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20IS%20NULL')%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20in%20v_null_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_completeness%20%3D%20((v_total_records%20-%20v_null_count)%20%2F%20v_total_records)%20*%20100%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20uniqueness%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(DISTINCT%20'%2C%20v_column_name%2C%20')%20FROM%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20in%20v_unique_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_uniqueness%20%3D%20(v_unique_count%20%2F%20v_total_records)%20*%20100%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20quality%20metrics%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_quality_metrics%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20column_name%2C%20metric_type%2C%20metric_value%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20total_records%2C%20quality_issues%0A%20%20%20%20%20%20%20%20)%20VALUES%20%0A%20%20%20%20%20%20%20%20(p_table_name%2C%20v_column_name%2C%20'COMPLETENESS'%2C%20v_completeness%2C%20v_total_records%2C%20v_null_count)%2C%0A%20%20%20%20%20%20%20%20(p_table_name%2C%20v_column_name%2C%20'UNIQUENESS'%2C%20v_uniqueness%2C%20v_total_records%2C%20v_total_records%20-%20v_unique_count)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20column_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data quality metrics table
CREATE TABLE data_quality_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100),
    column_name VARCHAR(100),
    metric_type ENUM('COMPLETENESS', 'ACCURACY', 'CONSISTENCY', 'VALIDITY', 'UNIQUENESS'),
    metric_value DECIMAL(5,2),
    total_records BIGINT,
    quality_issues BIGINT,
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_table_column (table_name, column_name),
    INDEX idx_metric_type (metric_type),
    INDEX idx_assessment_date (assessment_date)
);

-- Data profiling procedure
DELIMITER //
CREATE PROCEDURE profile_data_quality(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_data_type VARCHAR(50);
    DECLARE v_total_records BIGINT;
    DECLARE v_null_count BIGINT;
    DECLARE v_unique_count BIGINT;
    DECLARE v_completeness DECIMAL(5,2);
    DECLARE v_uniqueness DECIMAL(5,2);
    
    DECLARE column_cursor CURSOR FOR
        SELECT column_name, data_type
        FROM information_schema.columns
        WHERE table_schema = DATABASE()
        AND table_name = p_table_name;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Get total record count
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_table_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store result in v_total_records
    DEALLOCATE PREPARE stmt;
    
    OPEN column_cursor;
    
    profile_loop: LOOP
        FETCH column_cursor INTO v_column_name, v_data_type;
        
        IF done THEN
            LEAVE profile_loop;
        END IF;
        
        -- Calculate completeness (non-null percentage)
        SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_table_name, 
                         ' WHERE ', v_column_name, ' IS NULL');
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store in v_null_count
        DEALLOCATE PREPARE stmt;
        
        SET v_completeness = ((v_total_records - v_null_count) / v_total_records) * 100;
        
        -- Calculate uniqueness
        SET @sql = CONCAT('SELECT COUNT(DISTINCT ', v_column_name, ') FROM ', p_table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store in v_unique_count
        DEALLOCATE PREPARE stmt;
        
        SET v_uniqueness = (v_unique_count / v_total_records) * 100;
        
        -- Insert quality metrics
        INSERT INTO data_quality_metrics (
            table_name, column_name, metric_type, metric_value, 
            total_records, quality_issues
        ) VALUES 
        (p_table_name, v_column_name, 'COMPLETENESS', v_completeness, v_total_records, v_null_count),
        (p_table_name, v_column_name, 'UNIQUENESS', v_uniqueness, v_total_records, v_total_records - v_unique_count);
        
    END LOOP;
    
    CLOSE column_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Validation Rules:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Comprehensive%20validation%20framework%0ACREATE%20TABLE%20data_validation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20validation_type%20ENUM('FORMAT'%2C%20'RANGE'%2C%20'LOOKUP'%2C%20'BUSINESS_RULE'%2C%20'CROSS_FIELD')%2C%0A%20%20%20%20validation_expression%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20error_message%20VARCHAR(500)%2C%0A%20%20%20%20severity%20ENUM('ERROR'%2C%20'WARNING'%2C%20'INFO')%20DEFAULT%20'ERROR'%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20validation%20rules%0AINSERT%20INTO%20data_validation_rules%20(rule_name%2C%20table_name%2C%20column_name%2C%20validation_type%2C%20validation_expression%2C%20error_message)%20VALUES%0A('Email%20Format'%2C%20'customers'%2C%20'email'%2C%20'FORMAT'%2C%20'email%20REGEXP%20%22%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C%5C.%5BA-Za-z%5D%7B2%2C%7D%24%22'%2C%20'Invalid%20email%20format')%2C%0A('Phone%20Format'%2C%20'customers'%2C%20'phone'%2C%20'FORMAT'%2C%20'phone%20REGEXP%20%22%5E%5C%5C%2B%3F%5B1-9%5D%5C%5Cd%7B1%2C14%7D%24%22'%2C%20'Invalid%20phone%20number%20format')%2C%0A('Age%20Range'%2C%20'customers'%2C%20'age'%2C%20'RANGE'%2C%20'age%20BETWEEN%200%20AND%20120'%2C%20'Age%20must%20be%20between%200%20and%20120')%2C%0A('Order%20Total%20Positive'%2C%20'orders'%2C%20'total'%2C%20'RANGE'%2C%20'total%20%3E%200'%2C%20'Order%20total%20must%20be%20positive')%2C%0A('Customer%20Reference'%2C%20'orders'%2C%20'customer_id'%2C%20'LOOKUP'%2C%20'customer_id%20IN%20(SELECT%20id%20FROM%20customers)'%2C%20'Invalid%20customer%20reference')%3B%0A%0A--%20Validation%20execution%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_data_quality(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_validation_expression%20TEXT%3B%0A%20%20%20%20DECLARE%20v_error_message%20VARCHAR(500)%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_violation_count%20INT%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20validation_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20rule_name%2C%20column_name%2C%20validation_expression%2C%20error_message%2C%20severity%0A%20%20%20%20%20%20%20%20FROM%20data_validation_rules%0A%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20validation_results%20(%0A%20%20%20%20%20%20%20%20rule_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20violation_count%20INT%2C%0A%20%20%20%20%20%20%20%20error_message%20VARCHAR(500)%2C%0A%20%20%20%20%20%20%20%20severity%20VARCHAR(10)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20validation_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20validation_cursor%20INTO%20v_rule_name%2C%20v_column_name%2C%20v_validation_expression%2C%20v_error_message%2C%20v_severity%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20validation_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20validation%20query%0A%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20NOT%20('%2C%20v_validation_expression%2C%20')'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20validation%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20v_violation_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20result%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20validation_results%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_rule_name%2C%20v_column_name%2C%20v_violation_count%2C%20v_error_message%2C%20v_severity%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20results%0A%20%20%20%20SELECT%20*%20FROM%20validation_results%20WHERE%20violation_count%20%3E%200%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20validation_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Comprehensive validation framework
CREATE TABLE data_validation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    column_name VARCHAR(100),
    validation_type ENUM('FORMAT', 'RANGE', 'LOOKUP', 'BUSINESS_RULE', 'CROSS_FIELD'),
    validation_expression TEXT NOT NULL,
    error_message VARCHAR(500),
    severity ENUM('ERROR', 'WARNING', 'INFO') DEFAULT 'ERROR',
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert validation rules
INSERT INTO data_validation_rules (rule_name, table_name, column_name, validation_type, validation_expression, error_message) VALUES
('Email Format', 'customers', 'email', 'FORMAT', 'email REGEXP "^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$"', 'Invalid email format'),
('Phone Format', 'customers', 'phone', 'FORMAT', 'phone REGEXP "^\\+?[1-9]\\d{1,14}$"', 'Invalid phone number format'),
('Age Range', 'customers', 'age', 'RANGE', 'age BETWEEN 0 AND 120', 'Age must be between 0 and 120'),
('Order Total Positive', 'orders', 'total', 'RANGE', 'total &gt; 0', 'Order total must be positive'),
('Customer Reference', 'orders', 'customer_id', 'LOOKUP', 'customer_id IN (SELECT id FROM customers)', 'Invalid customer reference');

-- Validation execution
DELIMITER //
CREATE PROCEDURE validate_data_quality(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_name VARCHAR(100);
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_validation_expression TEXT;
    DECLARE v_error_message VARCHAR(500);
    DECLARE v_severity VARCHAR(10);
    DECLARE v_violation_count INT;
    DECLARE v_validation_sql TEXT;
    
    DECLARE validation_cursor CURSOR FOR
        SELECT rule_name, column_name, validation_expression, error_message, severity
        FROM data_validation_rules
        WHERE table_name = p_table_name AND is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create temporary results table
    CREATE TEMPORARY TABLE validation_results (
        rule_name VARCHAR(100),
        column_name VARCHAR(100),
        violation_count INT,
        error_message VARCHAR(500),
        severity VARCHAR(10)
    );
    
    OPEN validation_cursor;
    
    validation_loop: LOOP
        FETCH validation_cursor INTO v_rule_name, v_column_name, v_validation_expression, v_error_message, v_severity;
        
        IF done THEN
            LEAVE validation_loop;
        END IF;
        
        -- Build validation query
        SET v_validation_sql = CONCAT(
            'SELECT COUNT(*) FROM ', p_table_name, 
            ' WHERE NOT (', v_validation_expression, ')'
        );
        
        -- Execute validation
        SET @sql = v_validation_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in v_violation_count
        DEALLOCATE PREPARE stmt;
        
        -- Insert result
        INSERT INTO validation_results VALUES (
            v_rule_name, v_column_name, v_violation_count, v_error_message, v_severity
        );
        
    END LOOP;
    
    CLOSE validation_cursor;
    
    -- Return results
    SELECT * FROM validation_results WHERE violation_count &gt; 0;
    
    DROP TEMPORARY TABLE validation_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Cleansing Procedures:</strong></p>

<p><strong>1. Automated Data Cleansing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20cleanse_customer_data()%0ABEGIN%0A%20%20%20%20DECLARE%20records_updated%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Standardize%20email%20addresses%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20email%20%3D%20LOWER(TRIM(email))%0A%20%20%20%20WHERE%20email%20!%3D%20LOWER(TRIM(email))%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Standardize%20phone%20numbers%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20phone%20%3D%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%2B%5D'%2C%20'')%0A%20%20%20%20WHERE%20phone%20REGEXP%20'%5B%5E0-9%2B%5D'%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Fix%20common%20name%20issues%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20name%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20UPPER(SUBSTRING(TRIM(name)%2C%201%2C%201))%2C%0A%20%20%20%20%20%20%20%20LOWER(SUBSTRING(TRIM(name)%2C%202))%0A%20%20%20%20)%0A%20%20%20%20WHERE%20name%20!%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20UPPER(SUBSTRING(TRIM(name)%2C%201%2C%201))%2C%0A%20%20%20%20%20%20%20%20LOWER(SUBSTRING(TRIM(name)%2C%202))%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20duplicate%20spaces%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20address%20%3D%20REGEXP_REPLACE(address%2C%20'%20%2B'%2C%20'%20')%0A%20%20%20%20WHERE%20address%20REGEXP%20'%20%7B2%2C%7D'%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20cleansing%20activity%0A%20%20%20%20INSERT%20INTO%20data_cleansing_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20cleansing_type%2C%20records_affected%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'customers'%2C%20'STANDARDIZATION'%2C%20records_updated%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE cleanse_customer_data()
BEGIN
    DECLARE records_updated INT DEFAULT 0;
    
    START TRANSACTION;
    
    -- Standardize email addresses
    UPDATE customers 
    SET email = LOWER(TRIM(email))
    WHERE email != LOWER(TRIM(email));
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Standardize phone numbers
    UPDATE customers 
    SET phone = REGEXP_REPLACE(phone, '[^0-9+]', '')
    WHERE phone REGEXP '[^0-9+]';
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Fix common name issues
    UPDATE customers 
    SET name = CONCAT(
        UPPER(SUBSTRING(TRIM(name), 1, 1)),
        LOWER(SUBSTRING(TRIM(name), 2))
    )
    WHERE name != CONCAT(
        UPPER(SUBSTRING(TRIM(name), 1, 1)),
        LOWER(SUBSTRING(TRIM(name), 2))
    );
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Remove duplicate spaces
    UPDATE customers 
    SET address = REGEXP_REPLACE(address, ' +', ' ')
    WHERE address REGEXP ' {2,}';
    
    SET records_updated = records_updated + ROW_COUNT();
    
    COMMIT;
    
    -- Log cleansing activity
    INSERT INTO data_cleansing_log (
        table_name, cleansing_type, records_affected, completed_at
    ) VALUES (
        'customers', 'STANDARDIZATION', records_updated, NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-376-how-do-you-implement-data-lineage-tracking-">**376. How do you implement data lineage tracking?**</h2>

<p><strong>Answer:</strong> Data lineage tracking documents the flow and transformation of data from source to destination, providing visibility into data origins, transformations, and dependencies.</p>

<p><strong>Lineage Tracking Infrastructure:</strong></p>

<p><strong>1. Metadata Repository:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20sources%20registry%0ACREATE%20TABLE%20data_sources%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_type%20ENUM('DATABASE'%2C%20'FILE'%2C%20'API'%2C%20'STREAM')%20NOT%20NULL%2C%0A%20%20%20%20connection_string%20VARCHAR(500)%2C%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20owner%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_source_name%20(source_name)%0A)%3B%0A%0A--%20Data%20assets%20(tables%2C%20views%2C%20files)%0ACREATE%20TABLE%20data_assets%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20asset_type%20ENUM('TABLE'%2C%20'VIEW'%2C%20'FILE'%2C%20'REPORT')%20NOT%20NULL%2C%0A%20%20%20%20source_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20schema_definition%20JSON%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20technical_description%20TEXT%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(source_id)%20REFERENCES%20data_sources(id)%2C%0A%20%20%20%20INDEX%20idx_asset_type%20(asset_type)%2C%0A%20%20%20%20INDEX%20idx_source_id%20(source_id)%0A)%3B%0A%0A--%20Data%20lineage%20relationships%0ACREATE%20TABLE%20data_lineage%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_asset_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20target_asset_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20transformation_type%20ENUM('COPY'%2C%20'TRANSFORM'%2C%20'AGGREGATE'%2C%20'JOIN'%2C%20'FILTER'%2C%20'UNION')%2C%0A%20%20%20%20transformation_logic%20TEXT%2C%0A%20%20%20%20transformation_tool%20VARCHAR(100)%2C%0A%20%20%20%20dependency_type%20ENUM('DIRECT'%2C%20'INDIRECT')%20DEFAULT%20'DIRECT'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(source_asset_id)%20REFERENCES%20data_assets(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(target_asset_id)%20REFERENCES%20data_assets(id)%2C%0A%20%20%20%20INDEX%20idx_source_target%20(source_asset_id%2C%20target_asset_id)%2C%0A%20%20%20%20INDEX%20idx_transformation_type%20(transformation_type)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data sources registry
CREATE TABLE data_sources (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source_name VARCHAR(100) NOT NULL,
    source_type ENUM('DATABASE', 'FILE', 'API', 'STREAM') NOT NULL,
    connection_string VARCHAR(500),
    description TEXT,
    owner VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_source_name (source_name)
);

-- Data assets (tables, views, files)
CREATE TABLE data_assets (
    id INT AUTO_INCREMENT PRIMARY KEY,
    asset_name VARCHAR(200) NOT NULL,
    asset_type ENUM('TABLE', 'VIEW', 'FILE', 'REPORT') NOT NULL,
    source_id INT NOT NULL,
    schema_definition JSON,
    business_description TEXT,
    technical_description TEXT,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    FOREIGN KEY (source_id) REFERENCES data_sources(id),
    INDEX idx_asset_type (asset_type),
    INDEX idx_source_id (source_id)
);

-- Data lineage relationships
CREATE TABLE data_lineage (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_asset_id INT NOT NULL,
    target_asset_id INT NOT NULL,
    transformation_type ENUM('COPY', 'TRANSFORM', 'AGGREGATE', 'JOIN', 'FILTER', 'UNION'),
    transformation_logic TEXT,
    transformation_tool VARCHAR(100),
    dependency_type ENUM('DIRECT', 'INDIRECT') DEFAULT 'DIRECT',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    
    FOREIGN KEY (source_asset_id) REFERENCES data_assets(id),
    FOREIGN KEY (target_asset_id) REFERENCES data_assets(id),
    INDEX idx_source_target (source_asset_id, target_asset_id),
    INDEX idx_transformation_type (transformation_type)
);
</code></pre>
</div>

<p><strong>2. Automated Lineage Capture:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20process%20lineage%20tracking%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20track_etl_lineage(%0A%20%20%20%20IN%20p_process_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_source_tables%20JSON%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_transformation_sql%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_source_asset_id%20INT%3B%0A%20%20%20%20DECLARE%20v_target_asset_id%20INT%3B%0A%20%20%20%20DECLARE%20v_source_count%20INT%3B%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_source_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20target%20asset%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_target_asset_id%0A%20%20%20%20FROM%20data_assets%0A%20%20%20%20WHERE%20asset_name%20%3D%20p_target_table%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20each%20source%20table%0A%20%20%20%20SET%20v_source_count%20%3D%20JSON_LENGTH(p_source_tables)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20v_source_count%20DO%0A%20%20%20%20%20%20%20%20SET%20v_source_table%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_source_tables%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D')))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20source%20asset%20ID%0A%20%20%20%20%20%20%20%20SELECT%20id%20INTO%20v_source_asset_id%0A%20%20%20%20%20%20%20%20FROM%20data_assets%0A%20%20%20%20%20%20%20%20WHERE%20asset_name%20%3D%20v_source_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20lineage%20relationship%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_lineage%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20source_asset_id%2C%20target_asset_id%2C%20transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transformation_logic%2C%20transformation_tool%2C%20created_by%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_source_asset_id%2C%20v_target_asset_id%2C%20'TRANSFORM'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_transformation_sql%2C%20p_process_name%2C%20USER()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20lineage%20capture%0A%20%20%20%20INSERT%20INTO%20lineage_capture_log%20(%0A%20%20%20%20%20%20%20%20process_name%2C%20source_count%2C%20target_table%2C%20captured_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_process_name%2C%20v_source_count%2C%20p_target_table%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL process lineage tracking
DELIMITER //
CREATE PROCEDURE track_etl_lineage(
    IN p_process_name VARCHAR(100),
    IN p_source_tables JSON,
    IN p_target_table VARCHAR(100),
    IN p_transformation_sql TEXT
)
BEGIN
    DECLARE v_source_asset_id INT;
    DECLARE v_target_asset_id INT;
    DECLARE v_source_count INT;
    DECLARE i INT DEFAULT 0;
    DECLARE v_source_table VARCHAR(100);
    
    -- Get target asset ID
    SELECT id INTO v_target_asset_id
    FROM data_assets
    WHERE asset_name = p_target_table;
    
    -- Process each source table
    SET v_source_count = JSON_LENGTH(p_source_tables);
    
    WHILE i &lt; v_source_count DO
        SET v_source_table = JSON_UNQUOTE(JSON_EXTRACT(p_source_tables, CONCAT('$[', i, ']')));
        
        -- Get source asset ID
        SELECT id INTO v_source_asset_id
        FROM data_assets
        WHERE asset_name = v_source_table;
        
        -- Insert lineage relationship
        INSERT INTO data_lineage (
            source_asset_id, target_asset_id, transformation_type,
            transformation_logic, transformation_tool, created_by
        ) VALUES (
            v_source_asset_id, v_target_asset_id, 'TRANSFORM',
            p_transformation_sql, p_process_name, USER()
        );
        
        SET i = i + 1;
    END WHILE;
    
    -- Log lineage capture
    INSERT INTO lineage_capture_log (
        process_name, source_count, target_table, captured_at
    ) VALUES (
        p_process_name, v_source_count, p_target_table, NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Lineage Analysis and Reporting:</strong></p>

<p><strong>1. Impact Analysis:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20downstream%20dependencies%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20find_downstream_impact(IN%20p_asset_name%20VARCHAR(200))%0ABEGIN%0A%20%20%20%20WITH%20RECURSIVE%20downstream_lineage%20AS%20(%0A%20%20%20%20%20%20%20%20--%20Base%20case%3A%20direct%20dependencies%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%201%20as%20level%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CAST(da_target.asset_name%20AS%20CHAR(1000))%20as%20path%0A%20%20%20%20%20%20%20%20FROM%20data_assets%20da_source%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20da_source.id%20%3D%20dl.source_asset_id%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%0A%20%20%20%20%20%20%20%20WHERE%20da_source.asset_name%20%3D%20p_asset_name%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20indirect%20dependencies%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dsl.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(dsl.path%2C%20'%20-%3E%20'%2C%20da_target.asset_name)%0A%20%20%20%20%20%20%20%20FROM%20downstream_lineage%20dsl%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_source%20ON%20dsl.asset_name%20%3D%20da_source.asset_name%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20da_source.id%20%3D%20dl.source_asset_id%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%0A%20%20%20%20%20%20%20%20WHERE%20dsl.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20asset_name%2C%0A%20%20%20%20%20%20%20%20asset_type%2C%0A%20%20%20%20%20%20%20%20transformation_type%2C%0A%20%20%20%20%20%20%20%20level%2C%0A%20%20%20%20%20%20%20%20path%0A%20%20%20%20FROM%20downstream_lineage%0A%20%20%20%20ORDER%20BY%20level%2C%20asset_name%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find downstream dependencies
DELIMITER //
CREATE PROCEDURE find_downstream_impact(IN p_asset_name VARCHAR(200))
BEGIN
    WITH RECURSIVE downstream_lineage AS (
        -- Base case: direct dependencies
        SELECT 
            da_target.asset_name,
            da_target.asset_type,
            dl.transformation_type,
            1 as level,
            CAST(da_target.asset_name AS CHAR(1000)) as path
        FROM data_assets da_source
        JOIN data_lineage dl ON da_source.id = dl.source_asset_id
        JOIN data_assets da_target ON dl.target_asset_id = da_target.id
        WHERE da_source.asset_name = p_asset_name
        
        UNION ALL
        
        -- Recursive case: indirect dependencies
        SELECT 
            da_target.asset_name,
            da_target.asset_type,
            dl.transformation_type,
            dsl.level + 1,
            CONCAT(dsl.path, ' -&gt; ', da_target.asset_name)
        FROM downstream_lineage dsl
        JOIN data_assets da_source ON dsl.asset_name = da_source.asset_name
        JOIN data_lineage dl ON da_source.id = dl.source_asset_id
        JOIN data_assets da_target ON dl.target_asset_id = da_target.id
        WHERE dsl.level &lt; 10  -- Prevent infinite recursion
    )
    SELECT 
        asset_name,
        asset_type,
        transformation_type,
        level,
        path
    FROM downstream_lineage
    ORDER BY level, asset_name;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Lineage Visualization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generate%20lineage%20graph%20data%0ACREATE%20VIEW%20lineage_graph%20AS%0ASELECT%20%0A%20%20%20%20CONCAT('asset_'%2C%20dl.source_asset_id)%20as%20source_node%2C%0A%20%20%20%20CONCAT('asset_'%2C%20dl.target_asset_id)%20as%20target_node%2C%0A%20%20%20%20da_source.asset_name%20as%20source_name%2C%0A%20%20%20%20da_target.asset_name%20as%20target_name%2C%0A%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20dl.transformation_logic%2C%0A%20%20%20%20da_source.asset_type%20as%20source_type%2C%0A%20%20%20%20da_target.asset_type%20as%20target_type%0AFROM%20data_lineage%20dl%0AJOIN%20data_assets%20da_source%20ON%20dl.source_asset_id%20%3D%20da_source.id%0AJOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%3B%0A%0A--%20Lineage%20summary%20report%0ASELECT%20%0A%20%20%20%20ds.source_name%2C%0A%20%20%20%20da.asset_name%2C%0A%20%20%20%20da.asset_type%2C%0A%20%20%20%20COUNT(DISTINCT%20dl_in.source_asset_id)%20as%20input_dependencies%2C%0A%20%20%20%20COUNT(DISTINCT%20dl_out.target_asset_id)%20as%20output_dependencies%2C%0A%20%20%20%20da.data_classification%2C%0A%20%20%20%20da.updated_at%0AFROM%20data_assets%20da%0AJOIN%20data_sources%20ds%20ON%20da.source_id%20%3D%20ds.id%0ALEFT%20JOIN%20data_lineage%20dl_in%20ON%20da.id%20%3D%20dl_in.target_asset_id%0ALEFT%20JOIN%20data_lineage%20dl_out%20ON%20da.id%20%3D%20dl_out.source_asset_id%0AGROUP%20BY%20ds.source_name%2C%20da.asset_name%2C%20da.asset_type%2C%20da.data_classification%2C%20da.updated_at%0AORDER%20BY%20input_dependencies%20%2B%20output_dependencies%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generate lineage graph data
CREATE VIEW lineage_graph AS
SELECT 
    CONCAT('asset_', dl.source_asset_id) as source_node,
    CONCAT('asset_', dl.target_asset_id) as target_node,
    da_source.asset_name as source_name,
    da_target.asset_name as target_name,
    dl.transformation_type,
    dl.transformation_logic,
    da_source.asset_type as source_type,
    da_target.asset_type as target_type
FROM data_lineage dl
JOIN data_assets da_source ON dl.source_asset_id = da_source.id
JOIN data_assets da_target ON dl.target_asset_id = da_target.id;

-- Lineage summary report
SELECT 
    ds.source_name,
    da.asset_name,
    da.asset_type,
    COUNT(DISTINCT dl_in.source_asset_id) as input_dependencies,
    COUNT(DISTINCT dl_out.target_asset_id) as output_dependencies,
    da.data_classification,
    da.updated_at
FROM data_assets da
JOIN data_sources ds ON da.source_id = ds.id
LEFT JOIN data_lineage dl_in ON da.id = dl_in.target_asset_id
LEFT JOIN data_lineage dl_out ON da.id = dl_out.source_asset_id
GROUP BY ds.source_name, da.asset_name, da.asset_type, da.data_classification, da.updated_at
ORDER BY input_dependencies + output_dependencies DESC;
</code></pre>
</div>

<p>---</p>

<h2 id="-377-what-are-master-data-management-mdm-principles-">**377. What are master data management (MDM) principles?**</h2>

<p><strong>Answer:</strong> Master Data Management ensures consistent, accurate, and authoritative master data across the enterprise through centralized governance, standardization, and synchronization processes.</p>

<p><strong>MDM Architecture:</strong></p>

<p><strong>1. Golden Record Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Master%20customer%20record%0ACREATE%20TABLE%20master_customers%20(%0A%20%20%20%20master_id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20global_customer_id%20VARCHAR(50)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Core%20attributes%0A%20%20%20%20legal_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20common_name%20VARCHAR(255)%2C%0A%20%20%20%20customer_type%20ENUM('INDIVIDUAL'%2C%20'BUSINESS'%2C%20'GOVERNMENT')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Contact%20information%0A%20%20%20%20primary_email%20VARCHAR(255)%2C%0A%20%20%20%20primary_phone%20VARCHAR(20)%2C%0A%20%20%20%20primary_address%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20attributes%0A%20%20%20%20industry_code%20VARCHAR(10)%2C%0A%20%20%20%20credit_rating%20VARCHAR(10)%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20governance%0A%20%20%20%20data_steward%20VARCHAR(100)%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20last_verified%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Audit%20fields%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20updated_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_global_id%20(global_customer_id)%2C%0A%20%20%20%20INDEX%20idx_legal_name%20(legal_name)%2C%0A%20%20%20%20INDEX%20idx_customer_type%20(customer_type)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Source%20system%20mappings%0ACREATE%20TABLE%20customer_source_mappings%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20master_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(50)%20NOT%20NULL%2C%0A%20%20%20%20source_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_record%20JSON%2C%0A%20%20%20%20confidence_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20last_synchronized%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20sync_status%20ENUM('ACTIVE'%2C%20'INACTIVE'%2C%20'CONFLICT')%20DEFAULT%20'ACTIVE'%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(master_id)%20REFERENCES%20master_customers(master_id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_source_mapping%20(source_system%2C%20source_id)%2C%0A%20%20%20%20INDEX%20idx_master_id%20(master_id)%2C%0A%20%20%20%20INDEX%20idx_sync_status%20(sync_status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Master customer record
CREATE TABLE master_customers (
    master_id INT AUTO_INCREMENT PRIMARY KEY,
    global_customer_id VARCHAR(50) UNIQUE NOT NULL,
    
    -- Core attributes
    legal_name VARCHAR(255) NOT NULL,
    common_name VARCHAR(255),
    customer_type ENUM('INDIVIDUAL', 'BUSINESS', 'GOVERNMENT'),
    
    -- Contact information
    primary_email VARCHAR(255),
    primary_phone VARCHAR(20),
    primary_address JSON,
    
    -- Business attributes
    industry_code VARCHAR(10),
    credit_rating VARCHAR(10),
    customer_segment VARCHAR(50),
    
    -- Data governance
    data_steward VARCHAR(100),
    data_quality_score DECIMAL(3,2),
    last_verified TIMESTAMP,
    
    -- Audit fields
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    updated_by VARCHAR(100),
    
    INDEX idx_global_id (global_customer_id),
    INDEX idx_legal_name (legal_name),
    INDEX idx_customer_type (customer_type),
    INDEX idx_data_quality (data_quality_score)
);

-- Source system mappings
CREATE TABLE customer_source_mappings (
    id INT AUTO_INCREMENT PRIMARY KEY,
    master_id INT NOT NULL,
    source_system VARCHAR(50) NOT NULL,
    source_id VARCHAR(100) NOT NULL,
    source_record JSON,
    confidence_score DECIMAL(3,2),
    last_synchronized TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    sync_status ENUM('ACTIVE', 'INACTIVE', 'CONFLICT') DEFAULT 'ACTIVE',
    
    FOREIGN KEY (master_id) REFERENCES master_customers(master_id),
    UNIQUE KEY uk_source_mapping (source_system, source_id),
    INDEX idx_master_id (master_id),
    INDEX idx_sync_status (sync_status)
);
</code></pre>
</div>

<p><strong>2. Data Matching and Deduplication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Matching%20algorithm%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20match_customer_records()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_source_id%20INT%3B%0A%20%20%20%20DECLARE%20v_name%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_email%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_phone%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_match_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_master_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20staging_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20name%2C%20email%2C%20phone%0A%20%20%20%20%20%20%20%20FROM%20customer_staging%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20staging_cursor%3B%0A%20%20%20%20%0A%20%20%20%20matching_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20staging_cursor%20INTO%20v_source_id%2C%20v_name%2C%20v_email%2C%20v_phone%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20matching_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20match%20scores%20against%20existing%20master%20records%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Name%20similarity%20(using%20SOUNDEX%20and%20Levenshtein-like%20logic)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20SOUNDEX(legal_name)%20%3D%20SOUNDEX(v_name)%20THEN%2040%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20legal_name%20LIKE%20CONCAT('%25'%2C%20v_name%2C%20'%25')%20THEN%2020%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Email%20exact%20match%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20primary_email%20%3D%20v_email%20THEN%2040%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Phone%20match%20(normalized)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20REGEXP_REPLACE(primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20%3D%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REGEXP_REPLACE(v_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20THEN%2020%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20as%20match_score%0A%20%20%20%20%20%20%20%20INTO%20v_master_id%2C%20v_match_score%0A%20%20%20%20%20%20%20%20FROM%20master_customers%0A%20%20%20%20%20%20%20%20HAVING%20match_score%20%3E%3D%2070%20%20--%20Threshold%20for%20match%0A%20%20%20%20%20%20%20%20ORDER%20BY%20match_score%20DESC%0A%20%20%20%20%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20v_master_id%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Link%20to%20existing%20master%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_source_mappings%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%20source_system%2C%20source_id%2C%20confidence_score%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_master_id%2C%20'STAGING'%2C%20v_source_id%2C%20v_match_score%2F100%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20new%20master%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20master_customers%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20global_customer_id%2C%20legal_name%2C%20primary_email%2C%20primary_phone%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20data_quality_score%2C%20created_by%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT('CUST_'%2C%20LPAD(LAST_INSERT_ID()%2C%2010%2C%20'0'))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_name%2C%20v_email%2C%20v_phone%2C%200.8%2C%20'MDM_SYSTEM'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_master_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20source%20mapping%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_source_mappings%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%20source_system%2C%20source_id%2C%20confidence_score%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_master_id%2C%20'STAGING'%2C%20v_source_id%2C%201.0%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20UPDATE%20customer_staging%20SET%20processed%20%3D%20TRUE%20WHERE%20id%20%3D%20v_source_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20staging_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Matching algorithm implementation
DELIMITER //
CREATE PROCEDURE match_customer_records()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_source_id INT;
    DECLARE v_name VARCHAR(255);
    DECLARE v_email VARCHAR(255);
    DECLARE v_phone VARCHAR(20);
    DECLARE v_match_score DECIMAL(5,2);
    DECLARE v_master_id INT;
    
    DECLARE staging_cursor CURSOR FOR
        SELECT id, name, email, phone
        FROM customer_staging
        WHERE processed = FALSE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN staging_cursor;
    
    matching_loop: LOOP
        FETCH staging_cursor INTO v_source_id, v_name, v_email, v_phone;
        
        IF done THEN
            LEAVE matching_loop;
        END IF;
        
        -- Calculate match scores against existing master records
        SELECT 
            master_id,
            (
                -- Name similarity (using SOUNDEX and Levenshtein-like logic)
                CASE WHEN SOUNDEX(legal_name) = SOUNDEX(v_name) THEN 40
                     WHEN legal_name LIKE CONCAT('%', v_name, '%') THEN 20
                     ELSE 0 END +
                
                -- Email exact match
                CASE WHEN primary_email = v_email THEN 40
                     ELSE 0 END +
                
                -- Phone match (normalized)
                CASE WHEN REGEXP_REPLACE(primary_phone, '[^0-9]', '') = 
                          REGEXP_REPLACE(v_phone, '[^0-9]', '') THEN 20
                     ELSE 0 END
            ) as match_score
        INTO v_master_id, v_match_score
        FROM master_customers
        HAVING match_score &gt;= 70  -- Threshold for match
        ORDER BY match_score DESC
        LIMIT 1;
        
        IF v_master_id IS NOT NULL THEN
            -- Link to existing master record
            INSERT INTO customer_source_mappings (
                master_id, source_system, source_id, confidence_score
            ) VALUES (
                v_master_id, 'STAGING', v_source_id, v_match_score/100
            );
        ELSE
            -- Create new master record
            INSERT INTO master_customers (
                global_customer_id, legal_name, primary_email, primary_phone,
                data_quality_score, created_by
            ) VALUES (
                CONCAT('CUST_', LPAD(LAST_INSERT_ID(), 10, '0')),
                v_name, v_email, v_phone, 0.8, 'MDM_SYSTEM'
            );
            
            SET v_master_id = LAST_INSERT_ID();
            
            -- Create source mapping
            INSERT INTO customer_source_mappings (
                master_id, source_system, source_id, confidence_score
            ) VALUES (
                v_master_id, 'STAGING', v_source_id, 1.0
            );
        END IF;
        
        -- Mark as processed
        UPDATE customer_staging SET processed = TRUE WHERE id = v_source_id;
        
    END LOOP;
    
    CLOSE staging_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Governance and Quality:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20stewardship%20workflow%0ACREATE%20TABLE%20data_stewardship_tasks%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20task_type%20ENUM('DUPLICATE_REVIEW'%2C%20'QUALITY_ISSUE'%2C%20'MERGE_REQUEST'%2C%20'ATTRIBUTE_UPDATE')%2C%0A%20%20%20%20master_id%20INT%2C%0A%20%20%20%20related_master_id%20INT%2C%0A%20%20%20%20issue_description%20TEXT%2C%0A%20%20%20%20proposed_resolution%20JSON%2C%0A%20%20%20%20assigned_steward%20VARCHAR(100)%2C%0A%20%20%20%20priority%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'MEDIUM'%2C%0A%20%20%20%20status%20ENUM('OPEN'%2C%20'IN_PROGRESS'%2C%20'RESOLVED'%2C%20'REJECTED')%20DEFAULT%20'OPEN'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20resolution_notes%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(master_id)%20REFERENCES%20master_customers(master_id)%2C%0A%20%20%20%20INDEX%20idx_assigned_steward%20(assigned_steward)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%2C%0A%20%20%20%20INDEX%20idx_priority%20(priority)%0A)%3B%0A%0A--%20Automated%20quality%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_master_data_quality()%0ABEGIN%0A%20%20%20%20--%20Identify%20potential%20duplicates%0A%20%20%20%20INSERT%20INTO%20data_stewardship_tasks%20(%0A%20%20%20%20%20%20%20%20task_type%2C%20master_id%2C%20related_master_id%2C%20issue_description%2C%20assigned_steward%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'DUPLICATE_REVIEW'%2C%0A%20%20%20%20%20%20%20%20mc1.master_id%2C%0A%20%20%20%20%20%20%20%20mc2.master_id%2C%0A%20%20%20%20%20%20%20%20CONCAT('Potential%20duplicate%3A%20'%2C%20mc1.legal_name%2C%20'%20vs%20'%2C%20mc2.legal_name)%2C%0A%20%20%20%20%20%20%20%20'data_steward_team'%0A%20%20%20%20FROM%20master_customers%20mc1%0A%20%20%20%20JOIN%20master_customers%20mc2%20ON%20mc1.master_id%20%3C%20mc2.master_id%0A%20%20%20%20WHERE%20(%0A%20%20%20%20%20%20%20%20SOUNDEX(mc1.legal_name)%20%3D%20SOUNDEX(mc2.legal_name)%20OR%0A%20%20%20%20%20%20%20%20mc1.primary_email%20%3D%20mc2.primary_email%20OR%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(mc1.primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20%3D%20%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(mc2.primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%0A%20%20%20%20)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_stewardship_tasks%20dst%0A%20%20%20%20%20%20%20%20WHERE%20dst.master_id%20%3D%20mc1.master_id%20%0A%20%20%20%20%20%20%20%20AND%20dst.related_master_id%20%3D%20mc2.master_id%0A%20%20%20%20%20%20%20%20AND%20dst.task_type%20%3D%20'DUPLICATE_REVIEW'%0A%20%20%20%20%20%20%20%20AND%20dst.status%20IN%20('OPEN'%2C%20'IN_PROGRESS')%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Identify%20quality%20issues%0A%20%20%20%20INSERT%20INTO%20data_stewardship_tasks%20(%0A%20%20%20%20%20%20%20%20task_type%2C%20master_id%2C%20issue_description%2C%20assigned_steward%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'QUALITY_ISSUE'%2C%0A%20%20%20%20%20%20%20%20master_id%2C%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20primary_email%20IS%20NULL%20THEN%20'Missing%20primary%20email'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20primary_phone%20IS%20NULL%20THEN%20'Missing%20primary%20phone'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20data_quality_score%20%3C%200.7%20THEN%20'Low%20data%20quality%20score'%0A%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20'data_steward_team'%0A%20%20%20%20FROM%20master_customers%0A%20%20%20%20WHERE%20(primary_email%20IS%20NULL%20OR%20primary_phone%20IS%20NULL%20OR%20data_quality_score%20%3C%200.7)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_stewardship_tasks%20dst%0A%20%20%20%20%20%20%20%20WHERE%20dst.master_id%20%3D%20master_customers.master_id%0A%20%20%20%20%20%20%20%20AND%20dst.task_type%20%3D%20'QUALITY_ISSUE'%0A%20%20%20%20%20%20%20%20AND%20dst.status%20IN%20('OPEN'%2C%20'IN_PROGRESS')%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data stewardship workflow
CREATE TABLE data_stewardship_tasks (
    id INT AUTO_INCREMENT PRIMARY KEY,
    task_type ENUM('DUPLICATE_REVIEW', 'QUALITY_ISSUE', 'MERGE_REQUEST', 'ATTRIBUTE_UPDATE'),
    master_id INT,
    related_master_id INT,
    issue_description TEXT,
    proposed_resolution JSON,
    assigned_steward VARCHAR(100),
    priority ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'MEDIUM',
    status ENUM('OPEN', 'IN_PROGRESS', 'RESOLVED', 'REJECTED') DEFAULT 'OPEN',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP NULL,
    resolution_notes TEXT,
    
    FOREIGN KEY (master_id) REFERENCES master_customers(master_id),
    INDEX idx_assigned_steward (assigned_steward),
    INDEX idx_status (status),
    INDEX idx_priority (priority)
);

-- Automated quality monitoring
DELIMITER //
CREATE PROCEDURE monitor_master_data_quality()
BEGIN
    -- Identify potential duplicates
    INSERT INTO data_stewardship_tasks (
        task_type, master_id, related_master_id, issue_description, assigned_steward
    )
    SELECT 
        'DUPLICATE_REVIEW',
        mc1.master_id,
        mc2.master_id,
        CONCAT('Potential duplicate: ', mc1.legal_name, ' vs ', mc2.legal_name),
        'data_steward_team'
    FROM master_customers mc1
    JOIN master_customers mc2 ON mc1.master_id &lt; mc2.master_id
    WHERE (
        SOUNDEX(mc1.legal_name) = SOUNDEX(mc2.legal_name) OR
        mc1.primary_email = mc2.primary_email OR
        REGEXP_REPLACE(mc1.primary_phone, '[^0-9]', '') = 
        REGEXP_REPLACE(mc2.primary_phone, '[^0-9]', '')
    )
    AND NOT EXISTS (
        SELECT 1 FROM data_stewardship_tasks dst
        WHERE dst.master_id = mc1.master_id 
        AND dst.related_master_id = mc2.master_id
        AND dst.task_type = 'DUPLICATE_REVIEW'
        AND dst.status IN ('OPEN', 'IN_PROGRESS')
    );
    
    -- Identify quality issues
    INSERT INTO data_stewardship_tasks (
        task_type, master_id, issue_description, assigned_steward
    )
    SELECT 
        'QUALITY_ISSUE',
        master_id,
        CASE 
            WHEN primary_email IS NULL THEN 'Missing primary email'
            WHEN primary_phone IS NULL THEN 'Missing primary phone'
            WHEN data_quality_score &lt; 0.7 THEN 'Low data quality score'
        END,
        'data_steward_team'
    FROM master_customers
    WHERE (primary_email IS NULL OR primary_phone IS NULL OR data_quality_score &lt; 0.7)
    AND NOT EXISTS (
        SELECT 1 FROM data_stewardship_tasks dst
        WHERE dst.master_id = master_customers.master_id
        AND dst.task_type = 'QUALITY_ISSUE'
        AND dst.status IN ('OPEN', 'IN_PROGRESS')
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-378-how-do-you-implement-data-cataloging-and-metadata-management-">**378. How do you implement data cataloging and metadata management?**</h2>

<p><strong>Answer:</strong> Data cataloging and metadata management create a centralized inventory of data assets with comprehensive metadata to improve data discovery, understanding, and governance.</p>

<p><strong>Data Catalog Infrastructure:</strong></p>

<p><strong>1. Metadata Repository:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20catalog%20core%20tables%0ACREATE%20TABLE%20data_catalog%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20asset_type%20ENUM('TABLE'%2C%20'VIEW'%2C%20'PROCEDURE'%2C%20'FUNCTION'%2C%20'REPORT'%2C%20'DATASET')%20NOT%20NULL%2C%0A%20%20%20%20database_name%20VARCHAR(100)%2C%0A%20%20%20%20schema_name%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metadata%0A%20%20%20%20business_name%20VARCHAR(200)%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20business_owner%20VARCHAR(100)%2C%0A%20%20%20%20business_domain%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20metadata%0A%20%20%20%20technical_description%20TEXT%2C%0A%20%20%20%20data_type_info%20JSON%2C%0A%20%20%20%20size_info%20JSON%2C%0A%20%20%20%20performance_stats%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%20metadata%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20retention_policy%20VARCHAR(100)%2C%0A%20%20%20%20compliance_tags%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20metadata%0A%20%20%20%20usage_frequency%20ENUM('DAILY'%2C%20'WEEKLY'%2C%20'MONTHLY'%2C%20'RARELY'%2C%20'UNKNOWN')%2C%0A%20%20%20%20last_accessed%20TIMESTAMP%2C%0A%20%20%20%20access_count%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%20metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20deprecated_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_asset%20(database_name%2C%20schema_name%2C%20asset_name)%2C%0A%20%20%20%20INDEX%20idx_asset_type%20(asset_type)%2C%0A%20%20%20%20INDEX%20idx_business_domain%20(business_domain)%2C%0A%20%20%20%20INDEX%20idx_data_classification%20(data_classification)%2C%0A%20%20%20%20FULLTEXT%20idx_description%20(business_description%2C%20technical_description)%0A)%3B%0A%0A--%20Column-level%20metadata%0ACREATE%20TABLE%20data_catalog_columns%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20catalog_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_position%20INT%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20max_length%20INT%2C%0A%20%20%20%20is_nullable%20BOOLEAN%2C%0A%20%20%20%20default_value%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metadata%0A%20%20%20%20business_name%20VARCHAR(200)%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20business_rules%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%20metadata%0A%20%20%20%20completeness_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20uniqueness_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20validity_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Sensitivity%20metadata%0A%20%20%20%20is_pii%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20is_sensitive%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20masking_rule%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(catalog_id)%20REFERENCES%20data_catalog(id)%20ON%20DELETE%20CASCADE%2C%0A%20%20%20%20INDEX%20idx_catalog_id%20(catalog_id)%2C%0A%20%20%20%20INDEX%20idx_column_name%20(column_name)%2C%0A%20%20%20%20INDEX%20idx_is_pii%20(is_pii)%2C%0A%20%20%20%20FULLTEXT%20idx_column_description%20(business_description)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data catalog core tables
CREATE TABLE data_catalog (
    id INT AUTO_INCREMENT PRIMARY KEY,
    asset_name VARCHAR(200) NOT NULL,
    asset_type ENUM('TABLE', 'VIEW', 'PROCEDURE', 'FUNCTION', 'REPORT', 'DATASET') NOT NULL,
    database_name VARCHAR(100),
    schema_name VARCHAR(100),
    
    -- Business metadata
    business_name VARCHAR(200),
    business_description TEXT,
    business_owner VARCHAR(100),
    business_domain VARCHAR(100),
    
    -- Technical metadata
    technical_description TEXT,
    data_type_info JSON,
    size_info JSON,
    performance_stats JSON,
    
    -- Governance metadata
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    retention_policy VARCHAR(100),
    compliance_tags JSON,
    
    -- Usage metadata
    usage_frequency ENUM('DAILY', 'WEEKLY', 'MONTHLY', 'RARELY', 'UNKNOWN'),
    last_accessed TIMESTAMP,
    access_count BIGINT DEFAULT 0,
    
    -- Lifecycle metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deprecated_at TIMESTAMP NULL,
    
    UNIQUE KEY uk_asset (database_name, schema_name, asset_name),
    INDEX idx_asset_type (asset_type),
    INDEX idx_business_domain (business_domain),
    INDEX idx_data_classification (data_classification),
    FULLTEXT idx_description (business_description, technical_description)
);

-- Column-level metadata
CREATE TABLE data_catalog_columns (
    id INT AUTO_INCREMENT PRIMARY KEY,
    catalog_id INT NOT NULL,
    column_name VARCHAR(100) NOT NULL,
    column_position INT,
    data_type VARCHAR(50),
    max_length INT,
    is_nullable BOOLEAN,
    default_value TEXT,
    
    -- Business metadata
    business_name VARCHAR(200),
    business_description TEXT,
    business_rules TEXT,
    
    -- Data quality metadata
    completeness_score DECIMAL(5,2),
    uniqueness_score DECIMAL(5,2),
    validity_score DECIMAL(5,2),
    
    -- Sensitivity metadata
    is_pii BOOLEAN DEFAULT FALSE,
    is_sensitive BOOLEAN DEFAULT FALSE,
    masking_rule VARCHAR(100),
    
    FOREIGN KEY (catalog_id) REFERENCES data_catalog(id) ON DELETE CASCADE,
    INDEX idx_catalog_id (catalog_id),
    INDEX idx_column_name (column_name),
    INDEX idx_is_pii (is_pii),
    FULLTEXT idx_column_description (business_description)
);
</code></pre>
</div>

<p><strong>2. Automated Metadata Discovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Metadata%20harvesting%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20harvest_database_metadata(IN%20p_database_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_table_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_table_comment%20TEXT%3B%0A%20%20%20%20DECLARE%20v_catalog_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20table_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20table_type%2C%20table_comment%0A%20%20%20%20%20%20%20%20FROM%20information_schema.tables%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20p_database_name%0A%20%20%20%20%20%20%20%20AND%20table_type%20IN%20('BASE%20TABLE'%2C%20'VIEW')%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20harvest_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20table_cursor%20INTO%20v_table_name%2C%20v_table_type%2C%20v_table_comment%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20harvest_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20or%20update%20catalog%20entry%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_catalog%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20asset_name%2C%20asset_type%2C%20database_name%2C%20schema_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20technical_description%2C%20data_type_info%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20v_table_type%20WHEN%20'BASE%20TABLE'%20THEN%20'TABLE'%20ELSE%20'VIEW'%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_database_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'public'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('harvested_at'%2C%20NOW())%0A%20%20%20%20%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20%20%20%20%20technical_description%20%3D%20v_table_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_catalog_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Harvest%20column%20metadata%0A%20%20%20%20%20%20%20%20CALL%20harvest_column_metadata(v_catalog_id%2C%20p_database_name%2C%20v_table_name)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20harvesting%20completion%0A%20%20%20%20INSERT%20INTO%20metadata_harvest_log%20(%0A%20%20%20%20%20%20%20%20database_name%2C%20harvest_type%2C%20completed_at%2C%20tables_processed%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_database_name%2C%20'FULL_HARVEST'%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(*)%20FROM%20data_catalog%20WHERE%20database_name%20%3D%20p_database_name)%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ACREATE%20PROCEDURE%20harvest_column_metadata(%0A%20%20%20%20IN%20p_catalog_id%20INT%2C%0A%20%20%20%20IN%20p_database_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_data_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_is_nullable%20VARCHAR(3)%3B%0A%20%20%20%20DECLARE%20v_column_default%20TEXT%3B%0A%20%20%20%20DECLARE%20v_ordinal_position%20INT%3B%0A%20%20%20%20DECLARE%20v_column_comment%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20column_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20data_type%2C%20is_nullable%2C%20column_default%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ordinal_position%2C%20column_comment%0A%20%20%20%20%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20p_database_name%0A%20%20%20%20%20%20%20%20AND%20table_name%20%3D%20p_table_name%0A%20%20%20%20%20%20%20%20ORDER%20BY%20ordinal_position%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clear%20existing%20column%20metadata%0A%20%20%20%20DELETE%20FROM%20data_catalog_columns%20WHERE%20catalog_id%20%3D%20p_catalog_id%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20column_cursor%3B%0A%20%20%20%20%0A%20%20%20%20column_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20column_cursor%20INTO%20v_column_name%2C%20v_data_type%2C%20v_is_nullable%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_column_default%2C%20v_ordinal_position%2C%20v_column_comment%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20column_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20column%20metadata%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_catalog_columns%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20catalog_id%2C%20column_name%2C%20column_position%2C%20data_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_nullable%2C%20default_value%2C%20business_description%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_pii%2C%20is_sensitive%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_catalog_id%2C%20v_column_name%2C%20v_ordinal_position%2C%20v_data_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_is_nullable%20%3D%20'YES')%2C%20v_column_default%2C%20v_column_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Auto-detect%20PII%20based%20on%20column%20names%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_column_name%20REGEXP%20'(email%7Cphone%7Cssn%7Csocial%7Caddress%7Cname)')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_column_name%20REGEXP%20'(password%7Csecret%7Ckey%7Ctoken%7Ccredit%7Csalary)')%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20column_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Metadata harvesting procedure
DELIMITER //
CREATE PROCEDURE harvest_database_metadata(IN p_database_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_table_type VARCHAR(20);
    DECLARE v_table_comment TEXT;
    DECLARE v_catalog_id INT;
    
    DECLARE table_cursor CURSOR FOR
        SELECT table_name, table_type, table_comment
        FROM information_schema.tables
        WHERE table_schema = p_database_name
        AND table_type IN ('BASE TABLE', 'VIEW');
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN table_cursor;
    
    harvest_loop: LOOP
        FETCH table_cursor INTO v_table_name, v_table_type, v_table_comment;
        
        IF done THEN
            LEAVE harvest_loop;
        END IF;
        
        -- Insert or update catalog entry
        INSERT INTO data_catalog (
            asset_name, asset_type, database_name, schema_name,
            technical_description, data_type_info
        ) VALUES (
            v_table_name,
            CASE v_table_type WHEN 'BASE TABLE' THEN 'TABLE' ELSE 'VIEW' END,
            p_database_name,
            'public',
            v_table_comment,
            JSON_OBJECT('harvested_at', NOW())
        ) ON DUPLICATE KEY UPDATE
            technical_description = v_table_comment,
            updated_at = NOW();
        
        SET v_catalog_id = LAST_INSERT_ID();
        
        -- Harvest column metadata
        CALL harvest_column_metadata(v_catalog_id, p_database_name, v_table_name);
        
    END LOOP;
    
    CLOSE table_cursor;
    
    -- Log harvesting completion
    INSERT INTO metadata_harvest_log (
        database_name, harvest_type, completed_at, tables_processed
    ) VALUES (
        p_database_name, 'FULL_HARVEST', NOW(),
        (SELECT COUNT(*) FROM data_catalog WHERE database_name = p_database_name)
    );
    
END //

CREATE PROCEDURE harvest_column_metadata(
    IN p_catalog_id INT,
    IN p_database_name VARCHAR(100),
    IN p_table_name VARCHAR(100)
)
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_data_type VARCHAR(50);
    DECLARE v_is_nullable VARCHAR(3);
    DECLARE v_column_default TEXT;
    DECLARE v_ordinal_position INT;
    DECLARE v_column_comment TEXT;
    
    DECLARE column_cursor CURSOR FOR
        SELECT column_name, data_type, is_nullable, column_default, 
               ordinal_position, column_comment
        FROM information_schema.columns
        WHERE table_schema = p_database_name
        AND table_name = p_table_name
        ORDER BY ordinal_position;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Clear existing column metadata
    DELETE FROM data_catalog_columns WHERE catalog_id = p_catalog_id;
    
    OPEN column_cursor;
    
    column_loop: LOOP
        FETCH column_cursor INTO v_column_name, v_data_type, v_is_nullable, 
                                v_column_default, v_ordinal_position, v_column_comment;
        
        IF done THEN
            LEAVE column_loop;
        END IF;
        
        -- Insert column metadata
        INSERT INTO data_catalog_columns (
            catalog_id, column_name, column_position, data_type,
            is_nullable, default_value, business_description,
            is_pii, is_sensitive
        ) VALUES (
            p_catalog_id, v_column_name, v_ordinal_position, v_data_type,
            (v_is_nullable = 'YES'), v_column_default, v_column_comment,
            -- Auto-detect PII based on column names
            (v_column_name REGEXP '(email|phone|ssn|social|address|name)'),
            (v_column_name REGEXP '(password|secret|key|token|credit|salary)')
        );
        
    END LOOP;
    
    CLOSE column_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Discovery and Search:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Advanced%20search%20functionality%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20search_data_catalog(%0A%20%20%20%20IN%20p_search_term%20VARCHAR(500)%2C%0A%20%20%20%20IN%20p_asset_type%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_business_domain%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_classification%20VARCHAR(50)%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20dc.id%2C%0A%20%20%20%20%20%20%20%20dc.asset_name%2C%0A%20%20%20%20%20%20%20%20dc.asset_type%2C%0A%20%20%20%20%20%20%20%20dc.business_name%2C%0A%20%20%20%20%20%20%20%20dc.business_description%2C%0A%20%20%20%20%20%20%20%20dc.business_owner%2C%0A%20%20%20%20%20%20%20%20dc.business_domain%2C%0A%20%20%20%20%20%20%20%20dc.data_classification%2C%0A%20%20%20%20%20%20%20%20dc.usage_frequency%2C%0A%20%20%20%20%20%20%20%20dc.last_accessed%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Relevance%20scoring%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dc.asset_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%2010%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dc.business_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%208%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20MATCH(dc.business_description%2C%20dc.technical_description)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20THEN%205%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_catalog_columns%20dcc%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20THEN%203%20ELSE%200%20END%0A%20%20%20%20%20%20%20%20)%20as%20relevance_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Column%20matches%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20SELECT%20GROUP_CONCAT(dcc.column_name%20SEPARATOR%20'%2C%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20FROM%20data_catalog_columns%20dcc%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20)%20as%20matching_columns%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20FROM%20data_catalog%20dc%0A%20%20%20%20WHERE%20(p_search_term%20IS%20NULL%20OR%20%0A%20%20%20%20%20%20%20%20%20%20%20dc.asset_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20dc.business_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20MATCH(dc.business_description%2C%20dc.technical_description)%20%0A%20%20%20%20%20%20%20%20%20%20%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20OR%0A%20%20%20%20%20%20%20%20%20%20%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_catalog_columns%20dcc%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20%20%20%20))%0A%20%20%20%20AND%20(p_asset_type%20IS%20NULL%20OR%20dc.asset_type%20%3D%20p_asset_type)%0A%20%20%20%20AND%20(p_business_domain%20IS%20NULL%20OR%20dc.business_domain%20%3D%20p_business_domain)%0A%20%20%20%20AND%20(p_data_classification%20IS%20NULL%20OR%20dc.data_classification%20%3D%20p_data_classification)%0A%20%20%20%20AND%20dc.deprecated_at%20IS%20NULL%0A%20%20%20%20%0A%20%20%20%20HAVING%20relevance_score%20%3E%200%0A%20%20%20%20ORDER%20BY%20relevance_score%20DESC%2C%20dc.usage_frequency%20DESC%2C%20dc.last_accessed%20DESC%0A%20%20%20%20LIMIT%2050%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Advanced search functionality
DELIMITER //
CREATE PROCEDURE search_data_catalog(
    IN p_search_term VARCHAR(500),
    IN p_asset_type VARCHAR(50),
    IN p_business_domain VARCHAR(100),
    IN p_data_classification VARCHAR(50)
)
BEGIN
    SELECT 
        dc.id,
        dc.asset_name,
        dc.asset_type,
        dc.business_name,
        dc.business_description,
        dc.business_owner,
        dc.business_domain,
        dc.data_classification,
        dc.usage_frequency,
        dc.last_accessed,
        
        -- Relevance scoring
        (
            CASE WHEN dc.asset_name LIKE CONCAT('%', p_search_term, '%') THEN 10 ELSE 0 END +
            CASE WHEN dc.business_name LIKE CONCAT('%', p_search_term, '%') THEN 8 ELSE 0 END +
            CASE WHEN MATCH(dc.business_description, dc.technical_description) 
                      AGAINST(p_search_term IN NATURAL LANGUAGE MODE) THEN 5 ELSE 0 END +
            CASE WHEN EXISTS (
                SELECT 1 FROM data_catalog_columns dcc 
                WHERE dcc.catalog_id = dc.id 
                AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                     MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
            ) THEN 3 ELSE 0 END
        ) as relevance_score,
        
        -- Column matches
        (
            SELECT GROUP_CONCAT(dcc.column_name SEPARATOR ', ')
            FROM data_catalog_columns dcc
            WHERE dcc.catalog_id = dc.id
            AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                 MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
        ) as matching_columns
        
    FROM data_catalog dc
    WHERE (p_search_term IS NULL OR 
           dc.asset_name LIKE CONCAT('%', p_search_term, '%') OR
           dc.business_name LIKE CONCAT('%', p_search_term, '%') OR
           MATCH(dc.business_description, dc.technical_description) 
           AGAINST(p_search_term IN NATURAL LANGUAGE MODE) OR
           EXISTS (
               SELECT 1 FROM data_catalog_columns dcc 
               WHERE dcc.catalog_id = dc.id 
               AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                    MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
           ))
    AND (p_asset_type IS NULL OR dc.asset_type = p_asset_type)
    AND (p_business_domain IS NULL OR dc.business_domain = p_business_domain)
    AND (p_data_classification IS NULL OR dc.data_classification = p_data_classification)
    AND dc.deprecated_at IS NULL
    
    HAVING relevance_score &gt; 0
    ORDER BY relevance_score DESC, dc.usage_frequency DESC, dc.last_accessed DESC
    LIMIT 50;
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-379-what-are-data-governance-frameworks-and-policies-">**379. What are data governance frameworks and policies?**</h2>

<p><strong>Answer:</strong> Data governance frameworks establish policies, procedures, and controls to ensure data quality, security, compliance, and effective data management across the organization.</p>

<p><strong>Governance Framework Structure:</strong></p>

<p><strong>1. Data Governance Organization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Governance%20roles%20and%20responsibilities%0ACREATE%20TABLE%20governance_roles%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20role_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20role_type%20ENUM('EXECUTIVE'%2C%20'STEWARD'%2C%20'CUSTODIAN'%2C%20'USER')%20NOT%20NULL%2C%0A%20%20%20%20responsibilities%20TEXT%2C%0A%20%20%20%20authority_level%20ENUM('STRATEGIC'%2C%20'TACTICAL'%2C%20'OPERATIONAL')%20NOT%20NULL%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_role_name%20(role_name)%0A)%3B%0A%0A--%20Data%20domain%20assignments%0ACREATE%20TABLE%20data_domains%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_description%20TEXT%2C%0A%20%20%20%20business_owner%20VARCHAR(100)%2C%0A%20%20%20%20technical_owner%20VARCHAR(100)%2C%0A%20%20%20%20data_steward%20VARCHAR(100)%2C%0A%20%20%20%20criticality%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'MEDIUM'%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_criticality%20(criticality)%0A)%3B%0A%0A--%20Policy%20framework%0ACREATE%20TABLE%20data_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20policy_type%20ENUM('QUALITY'%2C%20'SECURITY'%2C%20'PRIVACY'%2C%20'RETENTION'%2C%20'ACCESS'%2C%20'USAGE')%2C%0A%20%20%20%20policy_category%20ENUM('MANDATORY'%2C%20'RECOMMENDED'%2C%20'GUIDELINE')%2C%0A%20%20%20%20policy_description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20policy_rules%20JSON%2C%0A%20%20%20%20applicable_domains%20JSON%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_date%20DATE%2C%0A%20%20%20%20approval_status%20ENUM('DRAFT'%2C%20'APPROVED'%2C%20'ACTIVE'%2C%20'DEPRECATED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20approved_by%20VARCHAR(100)%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_policy_type%20(policy_type)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Governance roles and responsibilities
CREATE TABLE governance_roles (
    id INT AUTO_INCREMENT PRIMARY KEY,
    role_name VARCHAR(100) NOT NULL,
    role_type ENUM('EXECUTIVE', 'STEWARD', 'CUSTODIAN', 'USER') NOT NULL,
    responsibilities TEXT,
    authority_level ENUM('STRATEGIC', 'TACTICAL', 'OPERATIONAL') NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_role_name (role_name)
);

-- Data domain assignments
CREATE TABLE data_domains (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_name VARCHAR(100) NOT NULL,
    domain_description TEXT,
    business_owner VARCHAR(100),
    technical_owner VARCHAR(100),
    data_steward VARCHAR(100),
    criticality ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'MEDIUM',
    
    UNIQUE KEY uk_domain_name (domain_name),
    INDEX idx_criticality (criticality)
);

-- Policy framework
CREATE TABLE data_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    policy_type ENUM('QUALITY', 'SECURITY', 'PRIVACY', 'RETENTION', 'ACCESS', 'USAGE'),
    policy_category ENUM('MANDATORY', 'RECOMMENDED', 'GUIDELINE'),
    policy_description TEXT NOT NULL,
    policy_rules JSON,
    applicable_domains JSON,
    effective_date DATE NOT NULL,
    review_date DATE,
    approval_status ENUM('DRAFT', 'APPROVED', 'ACTIVE', 'DEPRECATED') DEFAULT 'DRAFT',
    approved_by VARCHAR(100),
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_policy_type (policy_type),
    INDEX idx_approval_status (approval_status),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. Policy Implementation and Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Policy%20compliance%20tracking%0ACREATE%20TABLE%20policy_compliance%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20asset_id%20INT%2C%0A%20%20%20%20compliance_status%20ENUM('COMPLIANT'%2C%20'NON_COMPLIANT'%2C%20'PARTIAL'%2C%20'NOT_ASSESSED')%2C%0A%20%20%20%20compliance_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20assessment_method%20ENUM('AUTOMATED'%2C%20'MANUAL'%2C%20'AUDIT')%2C%0A%20%20%20%20findings%20TEXT%2C%0A%20%20%20%20remediation_plan%20TEXT%2C%0A%20%20%20%20remediation_due_date%20DATE%2C%0A%20%20%20%20assessed_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(policy_id)%20REFERENCES%20data_policies(id)%2C%0A%20%20%20%20INDEX%20idx_policy_status%20(policy_id%2C%20compliance_status)%2C%0A%20%20%20%20INDEX%20idx_assessment_date%20(assessment_date)%0A)%3B%0A%0A--%20Automated%20policy%20enforcement%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20enforce_data_quality_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_policy_id%20INT%3B%0A%20%20%20%20DECLARE%20v_policy_rules%20JSON%3B%0A%20%20%20%20DECLARE%20v_applicable_domains%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20policy_rules%2C%20applicable_domains%0A%20%20%20%20%20%20%20%20FROM%20data_policies%0A%20%20%20%20%20%20%20%20WHERE%20policy_type%20%3D%20'QUALITY'%0A%20%20%20%20%20%20%20%20AND%20approval_status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20AND%20effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20policy%20rules%20(example%3A%20completeness%20check)%0A%20%20%20%20%20%20%20%20IF%20JSON_EXTRACT(v_policy_rules%2C%20'%24.completeness_threshold')%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_completeness_policy(v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20other%20policy%20types%0A%20%20%20%20%20%20%20%20IF%20JSON_EXTRACT(v_policy_rules%2C%20'%24.uniqueness_threshold')%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_uniqueness_policy(v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0A%0ACREATE%20PROCEDURE%20check_completeness_policy(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_policy_rules%20JSON%2C%0A%20%20%20%20IN%20p_applicable_domains%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_threshold%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_completeness_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_compliance_status%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_threshold%20%3D%20JSON_EXTRACT(p_policy_rules%2C%20'%24.completeness_threshold')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20completeness%20for%20each%20applicable%20table%0A%20%20%20%20--%20This%20would%20iterate%20through%20tables%20in%20applicable%20domains%0A%20%20%20%20--%20and%20calculate%20completeness%20scores%0A%20%20%20%20%0A%20%20%20%20--%20Example%20implementation%20for%20a%20specific%20table%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20(COUNT(*)%20-%20COUNT(CASE%20WHEN%20email%20IS%20NULL%20THEN%201%20END))%20%2F%20COUNT(*)%20*%20100%0A%20%20%20%20INTO%20v_completeness_score%0A%20%20%20%20FROM%20customers%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_compliance_status%20%3D%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20v_completeness_score%20%3E%3D%20v_threshold%20THEN%20'COMPLIANT'%0A%20%20%20%20%20%20%20%20WHEN%20v_completeness_score%20%3E%3D%20v_threshold%20*%200.8%20THEN%20'PARTIAL'%0A%20%20%20%20%20%20%20%20ELSE%20'NON_COMPLIANT'%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Record%20compliance%20assessment%0A%20%20%20%20INSERT%20INTO%20policy_compliance%20(%0A%20%20%20%20%20%20%20%20policy_id%2C%20compliance_status%2C%20compliance_score%2C%0A%20%20%20%20%20%20%20%20assessment_method%2C%20findings%2C%20assessed_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_policy_id%2C%20v_compliance_status%2C%20v_completeness_score%2C%0A%20%20%20%20%20%20%20%20'AUTOMATED'%2C%20%0A%20%20%20%20%20%20%20%20CONCAT('Email%20completeness%3A%20'%2C%20v_completeness_score%2C%20'%25')%2C%0A%20%20%20%20%20%20%20%20'SYSTEM'%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Policy compliance tracking
CREATE TABLE policy_compliance (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    policy_id INT NOT NULL,
    asset_id INT,
    compliance_status ENUM('COMPLIANT', 'NON_COMPLIANT', 'PARTIAL', 'NOT_ASSESSED'),
    compliance_score DECIMAL(5,2),
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    assessment_method ENUM('AUTOMATED', 'MANUAL', 'AUDIT'),
    findings TEXT,
    remediation_plan TEXT,
    remediation_due_date DATE,
    assessed_by VARCHAR(100),
    
    FOREIGN KEY (policy_id) REFERENCES data_policies(id),
    INDEX idx_policy_status (policy_id, compliance_status),
    INDEX idx_assessment_date (assessment_date)
);

-- Automated policy enforcement
DELIMITER //
CREATE PROCEDURE enforce_data_quality_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_policy_id INT;
    DECLARE v_policy_rules JSON;
    DECLARE v_applicable_domains JSON;
    
    DECLARE policy_cursor CURSOR FOR
        SELECT id, policy_rules, applicable_domains
        FROM data_policies
        WHERE policy_type = 'QUALITY'
        AND approval_status = 'ACTIVE'
        AND effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_policy_id, v_policy_rules, v_applicable_domains;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Execute policy rules (example: completeness check)
        IF JSON_EXTRACT(v_policy_rules, '$.completeness_threshold') IS NOT NULL THEN
            CALL check_completeness_policy(v_policy_id, v_policy_rules, v_applicable_domains);
        END IF;
        
        -- Execute other policy types
        IF JSON_EXTRACT(v_policy_rules, '$.uniqueness_threshold') IS NOT NULL THEN
            CALL check_uniqueness_policy(v_policy_id, v_policy_rules, v_applicable_domains);
        END IF;
        
    END LOOP;
    
    CLOSE policy_cursor;
END //

CREATE PROCEDURE check_completeness_policy(
    IN p_policy_id INT,
    IN p_policy_rules JSON,
    IN p_applicable_domains JSON
)
BEGIN
    DECLARE v_threshold DECIMAL(5,2);
    DECLARE v_completeness_score DECIMAL(5,2);
    DECLARE v_compliance_status VARCHAR(20);
    
    SET v_threshold = JSON_EXTRACT(p_policy_rules, '$.completeness_threshold');
    
    -- Check completeness for each applicable table
    -- This would iterate through tables in applicable domains
    -- and calculate completeness scores
    
    -- Example implementation for a specific table
    SELECT 
        (COUNT(*) - COUNT(CASE WHEN email IS NULL THEN 1 END)) / COUNT(*) * 100
    INTO v_completeness_score
    FROM customers;
    
    SET v_compliance_status = CASE 
        WHEN v_completeness_score &gt;= v_threshold THEN 'COMPLIANT'
        WHEN v_completeness_score &gt;= v_threshold * 0.8 THEN 'PARTIAL'
        ELSE 'NON_COMPLIANT'
    END;
    
    -- Record compliance assessment
    INSERT INTO policy_compliance (
        policy_id, compliance_status, compliance_score,
        assessment_method, findings, assessed_by
    ) VALUES (
        p_policy_id, v_compliance_status, v_completeness_score,
        'AUTOMATED', 
        CONCAT('Email completeness: ', v_completeness_score, '%'),
        'SYSTEM'
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Access and Usage Governance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Access%20control%20policies%0ACREATE%20TABLE%20access_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20access_type%20ENUM('READ'%2C%20'WRITE'%2C%20'DELETE'%2C%20'ADMIN')%2C%0A%20%20%20%20allowed_roles%20JSON%2C%0A%20%20%20%20access_conditions%20JSON%2C%0A%20%20%20%20approval_required%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20approval_workflow%20VARCHAR(100)%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_data_classification%20(data_classification)%2C%0A%20%20%20%20INDEX%20idx_access_type%20(access_type)%0A)%3B%0A%0A--%20Usage%20monitoring%20and%20compliance%0ACREATE%20TABLE%20data_usage_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20user_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20access_type%20ENUM('READ'%2C%20'write'%2C%20'delete'%2C%20'export')%2C%0A%20%20%20%20access_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20application%20VARCHAR(100)%2C%0A%20%20%20%20purpose%20VARCHAR(500)%2C%0A%20%20%20%20data_volume%20BIGINT%2C%0A%20%20%20%20compliance_status%20ENUM('APPROVED'%2C%20'VIOLATION'%2C%20'UNDER_REVIEW')%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_user_timestamp%20(user_id%2C%20access_timestamp)%2C%0A%20%20%20%20INDEX%20idx_asset_access%20(asset_name%2C%20access_type)%2C%0A%20%20%20%20INDEX%20idx_compliance_status%20(compliance_status)%0A)%3B%0A%0A--%20Usage%20compliance%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_usage_compliance()%0ABEGIN%0A%20%20%20%20--%20Detect%20unusual%20access%20patterns%0A%20%20%20%20INSERT%20INTO%20compliance_violations%20(%0A%20%20%20%20%20%20%20%20violation_type%2C%20user_id%2C%20asset_name%2C%20violation_description%2C%0A%20%20%20%20%20%20%20%20severity%2C%20detected_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'UNUSUAL_ACCESS_PATTERN'%2C%0A%20%20%20%20%20%20%20%20user_id%2C%0A%20%20%20%20%20%20%20%20asset_name%2C%0A%20%20%20%20%20%20%20%20CONCAT('User%20accessed%20'%2C%20COUNT(*)%2C%20'%20records%20in%20last%20hour')%2C%0A%20%20%20%20%20%20%20%20'HIGH'%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20FROM%20data_usage_log%0A%20%20%20%20WHERE%20access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20access_type%20%3D%20'read'%0A%20%20%20%20GROUP%20BY%20user_id%2C%20asset_name%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%2010000%20%20--%20Threshold%20for%20unusual%20access%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20compliance_violations%20cv%0A%20%20%20%20%20%20%20%20WHERE%20cv.user_id%20%3D%20data_usage_log.user_id%0A%20%20%20%20%20%20%20%20AND%20cv.asset_name%20%3D%20data_usage_log.asset_name%0A%20%20%20%20%20%20%20%20AND%20cv.violation_type%20%3D%20'UNUSUAL_ACCESS_PATTERN'%0A%20%20%20%20%20%20%20%20AND%20cv.detected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Detect%20unauthorized%20access%20to%20restricted%20data%0A%20%20%20%20INSERT%20INTO%20compliance_violations%20(%0A%20%20%20%20%20%20%20%20violation_type%2C%20user_id%2C%20asset_name%2C%20violation_description%2C%0A%20%20%20%20%20%20%20%20severity%2C%20detected_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'UNAUTHORIZED_ACCESS'%2C%0A%20%20%20%20%20%20%20%20dul.user_id%2C%0A%20%20%20%20%20%20%20%20dul.asset_name%2C%0A%20%20%20%20%20%20%20%20'Access%20to%20restricted%20data%20without%20proper%20authorization'%2C%0A%20%20%20%20%20%20%20%20'CRITICAL'%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20FROM%20data_usage_log%20dul%0A%20%20%20%20JOIN%20data_catalog%20dc%20ON%20dul.asset_name%20%3D%20dc.asset_name%0A%20%20%20%20WHERE%20dc.data_classification%20%3D%20'RESTRICTED'%0A%20%20%20%20AND%20dul.access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20user_access_approvals%20uaa%0A%20%20%20%20%20%20%20%20WHERE%20uaa.user_id%20%3D%20dul.user_id%0A%20%20%20%20%20%20%20%20AND%20uaa.asset_name%20%3D%20dul.asset_name%0A%20%20%20%20%20%20%20%20AND%20uaa.approval_status%20%3D%20'APPROVED'%0A%20%20%20%20%20%20%20%20AND%20uaa.expiry_date%20%3E%3D%20CURDATE()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Access control policies
CREATE TABLE access_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    access_type ENUM('READ', 'WRITE', 'DELETE', 'ADMIN'),
    allowed_roles JSON,
    access_conditions JSON,
    approval_required BOOLEAN DEFAULT FALSE,
    approval_workflow VARCHAR(100),
    effective_date DATE NOT NULL,
    expiry_date DATE,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_data_classification (data_classification),
    INDEX idx_access_type (access_type)
);

-- Usage monitoring and compliance
CREATE TABLE data_usage_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL,
    asset_name VARCHAR(200) NOT NULL,
    access_type ENUM('READ', 'write', 'delete', 'export'),
    access_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address VARCHAR(45),
    application VARCHAR(100),
    purpose VARCHAR(500),
    data_volume BIGINT,
    compliance_status ENUM('APPROVED', 'VIOLATION', 'UNDER_REVIEW'),
    
    INDEX idx_user_timestamp (user_id, access_timestamp),
    INDEX idx_asset_access (asset_name, access_type),
    INDEX idx_compliance_status (compliance_status)
);

-- Usage compliance monitoring
DELIMITER //
CREATE PROCEDURE monitor_usage_compliance()
BEGIN
    -- Detect unusual access patterns
    INSERT INTO compliance_violations (
        violation_type, user_id, asset_name, violation_description,
        severity, detected_at
    )
    SELECT 
        'UNUSUAL_ACCESS_PATTERN',
        user_id,
        asset_name,
        CONCAT('User accessed ', COUNT(*), ' records in last hour'),
        'HIGH',
        NOW()
    FROM data_usage_log
    WHERE access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    AND access_type = 'read'
    GROUP BY user_id, asset_name
    HAVING COUNT(*) &gt; 10000  -- Threshold for unusual access
    AND NOT EXISTS (
        SELECT 1 FROM compliance_violations cv
        WHERE cv.user_id = data_usage_log.user_id
        AND cv.asset_name = data_usage_log.asset_name
        AND cv.violation_type = 'UNUSUAL_ACCESS_PATTERN'
        AND cv.detected_at &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    );
    
    -- Detect unauthorized access to restricted data
    INSERT INTO compliance_violations (
        violation_type, user_id, asset_name, violation_description,
        severity, detected_at
    )
    SELECT 
        'UNAUTHORIZED_ACCESS',
        dul.user_id,
        dul.asset_name,
        'Access to restricted data without proper authorization',
        'CRITICAL',
        NOW()
    FROM data_usage_log dul
    JOIN data_catalog dc ON dul.asset_name = dc.asset_name
    WHERE dc.data_classification = 'RESTRICTED'
    AND dul.access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    AND NOT EXISTS (
        SELECT 1 FROM user_access_approvals uaa
        WHERE uaa.user_id = dul.user_id
        AND uaa.asset_name = dul.asset_name
        AND uaa.approval_status = 'APPROVED'
        AND uaa.expiry_date &gt;= CURDATE()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-380-how-do-you-implement-data-privacy-and-gdpr-compliance-">**380. How do you implement data privacy and GDPR compliance?**</h2>

<p><strong>Answer:</strong> Data privacy and GDPR compliance require comprehensive data protection measures, consent management, and individual rights fulfillment through systematic processes and controls.</p>

<p><strong>GDPR Compliance Framework:</strong></p>

<p><strong>1. Data Subject Rights Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20subject%20registry%0ACREATE%20TABLE%20data_subjects%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20subject_identifier%20VARCHAR(255)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20subject_type%20ENUM('CUSTOMER'%2C%20'EMPLOYEE'%2C%20'PROSPECT'%2C%20'VENDOR')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Contact%20information%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Consent%20management%0A%20%20%20%20consent_status%20JSON%2C%0A%20%20%20%20consent_timestamp%20TIMESTAMP%2C%0A%20%20%20%20consent_source%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rights%20exercise%20tracking%0A%20%20%20%20rights_exercised%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20retention%0A%20%20%20%20retention_category%20VARCHAR(100)%2C%0A%20%20%20%20retention_expiry%20DATE%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_subject_identifier%20(subject_identifier)%2C%0A%20%20%20%20INDEX%20idx_email%20(email)%2C%0A%20%20%20%20INDEX%20idx_retention_expiry%20(retention_expiry)%0A)%3B%0A%0A--%20Data%20processing%20activities%0ACREATE%20TABLE%20processing_activities%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20activity_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20processing_purpose%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20legal_basis%20ENUM('CONSENT'%2C%20'CONTRACT'%2C%20'LEGAL_OBLIGATION'%2C%20'VITAL_INTERESTS'%2C%20'PUBLIC_TASK'%2C%20'LEGITIMATE_INTERESTS')%2C%0A%20%20%20%20data_categories%20JSON%2C%0A%20%20%20%20data_sources%20JSON%2C%0A%20%20%20%20recipients%20JSON%2C%0A%20%20%20%20retention_period%20INT%2C%20--%20months%0A%20%20%20%20cross_border_transfers%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20safeguards_applied%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20controller%20VARCHAR(200)%2C%0A%20%20%20%20processor%20VARCHAR(200)%2C%0A%20%20%20%20dpo_contact%20VARCHAR(200)%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_legal_basis%20(legal_basis)%2C%0A%20%20%20%20INDEX%20idx_controller%20(controller)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data subject registry
CREATE TABLE data_subjects (
    id INT AUTO_INCREMENT PRIMARY KEY,
    subject_identifier VARCHAR(255) UNIQUE NOT NULL,
    subject_type ENUM('CUSTOMER', 'EMPLOYEE', 'PROSPECT', 'VENDOR'),
    
    -- Contact information
    email VARCHAR(255),
    phone VARCHAR(20),
    
    -- Consent management
    consent_status JSON,
    consent_timestamp TIMESTAMP,
    consent_source VARCHAR(100),
    
    -- Rights exercise tracking
    rights_exercised JSON,
    
    -- Data retention
    retention_category VARCHAR(100),
    retention_expiry DATE,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_subject_identifier (subject_identifier),
    INDEX idx_email (email),
    INDEX idx_retention_expiry (retention_expiry)
);

-- Data processing activities
CREATE TABLE processing_activities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    activity_name VARCHAR(200) NOT NULL,
    processing_purpose TEXT NOT NULL,
    legal_basis ENUM('CONSENT', 'CONTRACT', 'LEGAL_OBLIGATION', 'VITAL_INTERESTS', 'PUBLIC_TASK', 'LEGITIMATE_INTERESTS'),
    data_categories JSON,
    data_sources JSON,
    recipients JSON,
    retention_period INT, -- months
    cross_border_transfers BOOLEAN DEFAULT FALSE,
    safeguards_applied JSON,
    
    controller VARCHAR(200),
    processor VARCHAR(200),
    dpo_contact VARCHAR(200),
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_legal_basis (legal_basis),
    INDEX idx_controller (controller)
);
</code></pre>
</div>

<p><strong>2. Right to Access Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20export%20for%20subject%20access%20requests%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20export_subject_data(IN%20p_subject_identifier%20VARCHAR(255))%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_subject_id%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_subject_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Data%20subject%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20comprehensive%20data%20export%0A%20%20%20%20SELECT%20'Personal%20Information'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'subject_id'%2C%20subject_identifier%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'phone'%2C%20phone%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'consent_status'%2C%20consent_status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'consent_timestamp'%2C%20consent_timestamp%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20created_at%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20id%20%3D%20v_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Customer%20data%0A%20%20%20%20SELECT%20'Customer%20Profile'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'address'%2C%20address%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'date_of_birth'%2C%20date_of_birth%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'preferences'%2C%20preferences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20created_at%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'last_updated'%2C%20updated_at%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20customers%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Transaction%20history%0A%20%20%20%20SELECT%20'Transaction%20History'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAYAGG(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'transaction_id'%2C%20id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'amount'%2C%20amount%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'transaction_date'%2C%20transaction_date%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'description'%2C%20description%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20transactions%0A%20%20%20%20WHERE%20customer_id%20%3D%20(SELECT%20customer_id%20FROM%20customers%20WHERE%20subject_id%20%3D%20v_subject_id)%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Communication%20history%0A%20%20%20%20SELECT%20'Communications'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAYAGG(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'communication_type'%2C%20communication_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'content'%2C%20content%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'sent_date'%2C%20sent_date%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'channel'%2C%20channel%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20communications%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20the%20access%20request%0A%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20requested_at%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_subject_id%2C%20'ACCESS'%2C%20'COMPLETED'%2C%20NOW()%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data export for subject access requests
DELIMITER //
CREATE PROCEDURE export_subject_data(IN p_subject_identifier VARCHAR(255))
BEGIN
    DECLARE v_subject_id INT;
    
    -- Get subject ID
    SELECT id INTO v_subject_id
    FROM data_subjects
    WHERE subject_identifier = p_subject_identifier;
    
    IF v_subject_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Data subject not found';
    END IF;
    
    -- Create comprehensive data export
    SELECT 'Personal Information' as data_category,
           JSON_OBJECT(
               'subject_id', subject_identifier,
               'email', email,
               'phone', phone,
               'consent_status', consent_status,
               'consent_timestamp', consent_timestamp,
               'created_at', created_at
           ) as data_content
    FROM data_subjects
    WHERE id = v_subject_id
    
    UNION ALL
    
    -- Customer data
    SELECT 'Customer Profile' as data_category,
           JSON_OBJECT(
               'name', name,
               'address', address,
               'date_of_birth', date_of_birth,
               'preferences', preferences,
               'created_at', created_at,
               'last_updated', updated_at
           ) as data_content
    FROM customers
    WHERE subject_id = v_subject_id
    
    UNION ALL
    
    -- Transaction history
    SELECT 'Transaction History' as data_category,
           JSON_ARRAYAGG(
               JSON_OBJECT(
                   'transaction_id', id,
                   'amount', amount,
                   'transaction_date', transaction_date,
                   'description', description
               )
           ) as data_content
    FROM transactions
    WHERE customer_id = (SELECT customer_id FROM customers WHERE subject_id = v_subject_id)
    
    UNION ALL
    
    -- Communication history
    SELECT 'Communications' as data_category,
           JSON_ARRAYAGG(
               JSON_OBJECT(
                   'communication_type', communication_type,
                   'content', content,
                   'sent_date', sent_date,
                   'channel', channel
               )
           ) as data_content
    FROM communications
    WHERE subject_id = v_subject_id;
    
    -- Log the access request
    INSERT INTO gdpr_requests (
        subject_id, request_type, status, requested_at, completed_at
    ) VALUES (
        v_subject_id, 'ACCESS', 'COMPLETED', NOW(), NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Right to Erasure (Right to be Forgotten):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20erasure%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20erase_subject_data(%0A%20%20%20%20IN%20p_subject_identifier%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_erasure_reason%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20DECLARE%20v_customer_id%20INT%3B%0A%20%20%20%20DECLARE%20erasure_timestamp%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20and%20customer%20IDs%0A%20%20%20%20SELECT%20ds.id%2C%20c.id%0A%20%20%20%20INTO%20v_subject_id%2C%20v_customer_id%0A%20%20%20%20FROM%20data_subjects%20ds%0A%20%20%20%20LEFT%20JOIN%20customers%20c%20ON%20ds.id%20%3D%20c.subject_id%0A%20%20%20%20WHERE%20ds.subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_subject_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Data%20subject%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20if%20erasure%20is%20legally%20permissible%0A%20%20%20%20IF%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20processing_activities%20pa%0A%20%20%20%20%20%20%20%20WHERE%20JSON_CONTAINS(pa.data_categories%2C%20'%22CUSTOMER_DATA%22')%0A%20%20%20%20%20%20%20%20AND%20pa.legal_basis%20IN%20('LEGAL_OBLIGATION'%2C%20'PUBLIC_TASK')%0A%20%20%20%20)%20THEN%0A%20%20%20%20%20%20%20%20--%20Cannot%20erase%20data%20required%20for%20legal%20obligations%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20reason%2C%20requested_at%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_subject_id%2C%20'ERASURE'%2C%20'REJECTED'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20'Data%20required%20for%20legal%20obligations'%2C%20NOW()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Erasure%20not%20permitted%20due%20to%20legal%20obligations'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20erasure%20(anonymization%20rather%20than%20deletion%20for%20referential%20integrity)%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20customer%20data%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20name%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20email%20%3D%20CONCAT('erased_'%2C%20id%2C%20'%40deleted.local')%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20address%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20date_of_birth%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20preferences%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%2C%0A%20%20%20%20%20%20%20%20erasure_reason%20%3D%20p_erasure_reason%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20communication%20data%0A%20%20%20%20UPDATE%20communications%0A%20%20%20%20SET%20content%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20personal_data_removed%20%3D%20TRUE%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20transaction%20data%20(keep%20for%20financial%20records%20but%20remove%20personal%20identifiers)%0A%20%20%20%20UPDATE%20transactions%0A%20%20%20%20SET%20customer_reference%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20personal_notes%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%0A%20%20%20%20WHERE%20customer_id%20%3D%20v_customer_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20data%20subject%20record%0A%20%20%20%20UPDATE%20data_subjects%0A%20%20%20%20SET%20email%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20consent_status%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%2C%0A%20%20%20%20%20%20%20%20erasure_reason%20%3D%20p_erasure_reason%0A%20%20%20%20WHERE%20id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20successful%20erasure%0A%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20reason%2C%20requested_at%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_subject_id%2C%20'ERASURE'%2C%20'COMPLETED'%2C%20p_erasure_reason%2C%20NOW()%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data erasure implementation
DELIMITER //
CREATE PROCEDURE erase_subject_data(
    IN p_subject_identifier VARCHAR(255),
    IN p_erasure_reason TEXT
)
BEGIN
    DECLARE v_subject_id INT;
    DECLARE v_customer_id INT;
    DECLARE erasure_timestamp TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Get subject and customer IDs
    SELECT ds.id, c.id
    INTO v_subject_id, v_customer_id
    FROM data_subjects ds
    LEFT JOIN customers c ON ds.id = c.subject_id
    WHERE ds.subject_identifier = p_subject_identifier;
    
    IF v_subject_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Data subject not found';
    END IF;
    
    -- Check if erasure is legally permissible
    IF EXISTS (
        SELECT 1 FROM processing_activities pa
        WHERE JSON_CONTAINS(pa.data_categories, '"CUSTOMER_DATA"')
        AND pa.legal_basis IN ('LEGAL_OBLIGATION', 'PUBLIC_TASK')
    ) THEN
        -- Cannot erase data required for legal obligations
        INSERT INTO gdpr_requests (
            subject_id, request_type, status, reason, requested_at
        ) VALUES (
            v_subject_id, 'ERASURE', 'REJECTED', 
            'Data required for legal obligations', NOW()
        );
        
        ROLLBACK;
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Erasure not permitted due to legal obligations';
    END IF;
    
    -- Perform erasure (anonymization rather than deletion for referential integrity)
    
    -- Anonymize customer data
    UPDATE customers 
    SET name = 'ERASED',
        email = CONCAT('erased_', id, '@deleted.local'),
        phone = NULL,
        address = NULL,
        date_of_birth = NULL,
        preferences = NULL,
        erased_at = erasure_timestamp,
        erasure_reason = p_erasure_reason
    WHERE subject_id = v_subject_id;
    
    -- Anonymize communication data
    UPDATE communications
    SET content = 'ERASED',
        personal_data_removed = TRUE,
        erased_at = erasure_timestamp
    WHERE subject_id = v_subject_id;
    
    -- Handle transaction data (keep for financial records but remove personal identifiers)
    UPDATE transactions
    SET customer_reference = 'ERASED',
        personal_notes = NULL,
        erased_at = erasure_timestamp
    WHERE customer_id = v_customer_id;
    
    -- Update data subject record
    UPDATE data_subjects
    SET email = NULL,
        phone = NULL,
        consent_status = NULL,
        erased_at = erasure_timestamp,
        erasure_reason = p_erasure_reason
    WHERE id = v_subject_id;
    
    -- Log successful erasure
    INSERT INTO gdpr_requests (
        subject_id, request_type, status, reason, requested_at, completed_at
    ) VALUES (
        v_subject_id, 'ERASURE', 'COMPLETED', p_erasure_reason, NOW(), NOW()
    );
    
    COMMIT;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>4. Consent Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Consent%20tracking%20and%20management%0ACREATE%20TABLE%20consent_records%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20subject_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20processing_purpose%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20consent_given%20BOOLEAN%20NOT%20NULL%2C%0A%20%20%20%20consent_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20consent_method%20ENUM('WEBSITE'%2C%20'EMAIL'%2C%20'PHONE'%2C%20'PAPER'%2C%20'API')%2C%0A%20%20%20%20consent_evidence%20JSON%2C%0A%20%20%20%20withdrawn_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20withdrawal_method%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Consent%20details%0A%20%20%20%20granular_consents%20JSON%2C%0A%20%20%20%20consent_version%20VARCHAR(20)%2C%0A%20%20%20%20privacy_policy_version%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(subject_id)%20REFERENCES%20data_subjects(id)%2C%0A%20%20%20%20INDEX%20idx_subject_purpose%20(subject_id%2C%20processing_purpose)%2C%0A%20%20%20%20INDEX%20idx_consent_timestamp%20(consent_timestamp)%0A)%3B%0A%0A--%20Consent%20validation%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_processing_consent(%0A%20%20%20%20IN%20p_subject_identifier%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_processing_purpose%20VARCHAR(200)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20DECLARE%20v_consent_valid%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_consent_timestamp%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_subject_id%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20for%20valid%20consent%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20consent_given%20AND%20withdrawn_at%20IS%20NULL%2C%0A%20%20%20%20%20%20%20%20consent_timestamp%0A%20%20%20%20INTO%20v_consent_valid%2C%20v_consent_timestamp%0A%20%20%20%20FROM%20consent_records%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%0A%20%20%20%20AND%20processing_purpose%20%3D%20p_processing_purpose%0A%20%20%20%20ORDER%20BY%20consent_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20consent%20status%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20v_consent_valid%20as%20consent_valid%2C%0A%20%20%20%20%20%20%20%20v_consent_timestamp%20as%20consent_date%2C%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20v_consent_valid%20THEN%20'VALID'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20v_consent_timestamp%20IS%20NULL%20THEN%20'NO_CONSENT'%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'WITHDRAWN'%0A%20%20%20%20%20%20%20%20END%20as%20consent_status%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Consent tracking and management
CREATE TABLE consent_records (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    subject_id INT NOT NULL,
    processing_purpose VARCHAR(200) NOT NULL,
    consent_given BOOLEAN NOT NULL,
    consent_timestamp TIMESTAMP NOT NULL,
    consent_method ENUM('WEBSITE', 'EMAIL', 'PHONE', 'PAPER', 'API'),
    consent_evidence JSON,
    withdrawn_at TIMESTAMP NULL,
    withdrawal_method VARCHAR(100),
    
    -- Consent details
    granular_consents JSON,
    consent_version VARCHAR(20),
    privacy_policy_version VARCHAR(20),
    
    FOREIGN KEY (subject_id) REFERENCES data_subjects(id),
    INDEX idx_subject_purpose (subject_id, processing_purpose),
    INDEX idx_consent_timestamp (consent_timestamp)
);

-- Consent validation procedure
DELIMITER //
CREATE PROCEDURE validate_processing_consent(
    IN p_subject_identifier VARCHAR(255),
    IN p_processing_purpose VARCHAR(200)
)
BEGIN
    DECLARE v_subject_id INT;
    DECLARE v_consent_valid BOOLEAN DEFAULT FALSE;
    DECLARE v_consent_timestamp TIMESTAMP;
    
    -- Get subject ID
    SELECT id INTO v_subject_id
    FROM data_subjects
    WHERE subject_identifier = p_subject_identifier;
    
    -- Check for valid consent
    SELECT 
        consent_given AND withdrawn_at IS NULL,
        consent_timestamp
    INTO v_consent_valid, v_consent_timestamp
    FROM consent_records
    WHERE subject_id = v_subject_id
    AND processing_purpose = p_processing_purpose
    ORDER BY consent_timestamp DESC
    LIMIT 1;
    
    -- Return consent status
    SELECT 
        v_consent_valid as consent_valid,
        v_consent_timestamp as consent_date,
        CASE 
            WHEN v_consent_valid THEN 'VALID'
            WHEN v_consent_timestamp IS NULL THEN 'NO_CONSENT'
            ELSE 'WITHDRAWN'
        END as consent_status;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>5. Data Breach Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20breach%20incident%20tracking%0ACREATE%20TABLE%20data_breaches%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20breach_reference%20VARCHAR(100)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20breach_type%20ENUM('CONFIDENTIALITY'%2C%20'INTEGRITY'%2C%20'AVAILABILITY')%2C%0A%20%20%20%20severity%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Incident%20details%0A%20%20%20%20discovered_at%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20occurred_at%20TIMESTAMP%2C%0A%20%20%20%20description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20affected_data_categories%20JSON%2C%0A%20%20%20%20estimated_affected_subjects%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Response%20tracking%0A%20%20%20%20containment_measures%20TEXT%2C%0A%20%20%20%20notification_required%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20authority_notified_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20subjects_notified_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Resolution%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20resolution_summary%20TEXT%2C%0A%20%20%20%20lessons_learned%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%0A%20%20%20%20reportable_to_authority%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20authority_reference%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_severity%20(severity)%2C%0A%20%20%20%20INDEX%20idx_discovered_at%20(discovered_at)%2C%0A%20%20%20%20INDEX%20idx_notification_required%20(notification_required)%0A)%3B%0A%0A--%20Automated%20breach%20detection%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20detect_potential_breaches()%0ABEGIN%0A%20%20%20%20--%20Detect%20unusual%20data%20access%20patterns%0A%20%20%20%20INSERT%20INTO%20potential_breaches%20(%0A%20%20%20%20%20%20%20%20breach_type%2C%20description%2C%20severity%2C%20detected_at%2C%20evidence%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'CONFIDENTIALITY'%2C%0A%20%20%20%20%20%20%20%20CONCAT('Unusual%20access%20pattern%20detected%20for%20user%3A%20'%2C%20user_id)%2C%0A%20%20%20%20%20%20%20%20'HIGH'%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'user_id'%2C%20user_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'access_count'%2C%20COUNT(*)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'time_period'%2C%20'1%20hour'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'assets_accessed'%2C%20COUNT(DISTINCT%20asset_name)%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20FROM%20data_usage_log%0A%20%20%20%20WHERE%20access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20GROUP%20BY%20user_id%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%201000%20OR%20COUNT(DISTINCT%20asset_name)%20%3E%2050%3B%0A%20%20%20%20%0A%20%20%20%20--%20Detect%20failed%20access%20attempts%0A%20%20%20%20INSERT%20INTO%20potential_breaches%20(%0A%20%20%20%20%20%20%20%20breach_type%2C%20description%2C%20severity%2C%20detected_at%2C%20evidence%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'CONFIDENTIALITY'%2C%0A%20%20%20%20%20%20%20%20CONCAT('Multiple%20failed%20access%20attempts%20from%20IP%3A%20'%2C%20ip_address)%2C%0A%20%20%20%20%20%20%20%20'MEDIUM'%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'ip_address'%2C%20ip_address%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'failed_attempts'%2C%20COUNT(*)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'time_period'%2C%20'15%20minutes'%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20FROM%20failed_access_log%0A%20%20%20%20WHERE%20attempt_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2015%20MINUTE)%0A%20%20%20%20GROUP%20BY%20ip_address%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%2010%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data breach incident tracking
CREATE TABLE data_breaches (
    id INT AUTO_INCREMENT PRIMARY KEY,
    breach_reference VARCHAR(100) UNIQUE NOT NULL,
    breach_type ENUM('CONFIDENTIALITY', 'INTEGRITY', 'AVAILABILITY'),
    severity ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL'),
    
    -- Incident details
    discovered_at TIMESTAMP NOT NULL,
    occurred_at TIMESTAMP,
    description TEXT NOT NULL,
    affected_data_categories JSON,
    estimated_affected_subjects INT,
    
    -- Response tracking
    containment_measures TEXT,
    notification_required BOOLEAN DEFAULT TRUE,
    authority_notified_at TIMESTAMP NULL,
    subjects_notified_at TIMESTAMP NULL,
    
    -- Resolution
    resolved_at TIMESTAMP NULL,
    resolution_summary TEXT,
    lessons_learned TEXT,
    
    -- Compliance
    reportable_to_authority BOOLEAN DEFAULT TRUE,
    authority_reference VARCHAR(100),
    
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_severity (severity),
    INDEX idx_discovered_at (discovered_at),
    INDEX idx_notification_required (notification_required)
);

-- Automated breach detection
DELIMITER //
CREATE PROCEDURE detect_potential_breaches()
BEGIN
    -- Detect unusual data access patterns
    INSERT INTO potential_breaches (
        breach_type, description, severity, detected_at, evidence
    )
    SELECT 
        'CONFIDENTIALITY',
        CONCAT('Unusual access pattern detected for user: ', user_id),
        'HIGH',
        NOW(),
        JSON_OBJECT(
            'user_id', user_id,
            'access_count', COUNT(*),
            'time_period', '1 hour',
            'assets_accessed', COUNT(DISTINCT asset_name)
        )
    FROM data_usage_log
    WHERE access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    GROUP BY user_id
    HAVING COUNT(*) &gt; 1000 OR COUNT(DISTINCT asset_name) &gt; 50;
    
    -- Detect failed access attempts
    INSERT INTO potential_breaches (
        breach_type, description, severity, detected_at, evidence
    )
    SELECT 
        'CONFIDENTIALITY',
        CONCAT('Multiple failed access attempts from IP: ', ip_address),
        'MEDIUM',
        NOW(),
        JSON_OBJECT(
            'ip_address', ip_address,
            'failed_attempts', COUNT(*),
            'time_period', '15 minutes'
        )
    FROM failed_access_log
    WHERE attempt_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 15 MINUTE)
    GROUP BY ip_address
    HAVING COUNT(*) &gt; 10;
    
END //
DELIMITER ;
</code></pre>
</div>

<h2 id="-381-what-are-data-retention-and-purging-strategies-">**381. What are data retention and purging strategies?**</h2>

<p><strong>Answer:</strong> Data retention and purging strategies manage data lifecycle by automatically removing or archiving data based on legal requirements, business needs, and storage optimization.</p>

<p><strong>Retention Policy Framework:</strong></p>

<p><strong>1. Retention Policy Configuration:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Retention%20policy%20definitions%0ACREATE%20TABLE%20retention_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20retention_period_days%20INT%20NOT%20NULL%2C%0A%20%20%20%20retention_criteria%20JSON%2C%0A%20%20%20%20purge_method%20ENUM('DELETE'%2C%20'ARCHIVE'%2C%20'ANONYMIZE')%20DEFAULT%20'DELETE'%2C%0A%20%20%20%20legal_basis%20VARCHAR(200)%2C%0A%20%20%20%20business_justification%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Policy%20metadata%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_date%20DATE%2C%0A%20%20%20%20policy_owner%20VARCHAR(100)%2C%0A%20%20%20%20approval_status%20ENUM('DRAFT'%2C%20'APPROVED'%2C%20'ACTIVE'%2C%20'SUSPENDED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_policy%20(table_name%2C%20policy_name)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%0A)%3B%0A%0A--%20Insert%20retention%20policies%0AINSERT%20INTO%20retention_policies%20(%0A%20%20%20%20policy_name%2C%20table_name%2C%20retention_period_days%2C%20retention_criteria%2C%0A%20%20%20%20purge_method%2C%20legal_basis%2C%20effective_date%2C%20policy_owner%2C%20approval_status%0A)%20VALUES%0A('Customer%20Data%20Retention'%2C%20'customers'%2C%202555%2C%20%0A%20'%7B%22date_column%22%3A%20%22last_activity%22%2C%20%22status_filter%22%3A%20%22inactive%22%7D'%2C%0A%20'ANONYMIZE'%2C%20'GDPR%20Article%205%20-%20Storage%20limitation'%2C%20CURDATE()%2C%20'data_officer'%2C%20'ACTIVE')%2C%0A%0A('Transaction%20Log%20Retention'%2C%20'transaction_logs'%2C%202555%2C%0A%20'%7B%22date_column%22%3A%20%22created_at%22%7D'%2C%0A%20'ARCHIVE'%2C%20'Financial%20regulations%20-%207%20years'%2C%20CURDATE()%2C%20'compliance_officer'%2C%20'ACTIVE')%2C%0A%0A('Session%20Data%20Retention'%2C%20'user_sessions'%2C%2090%2C%0A%20'%7B%22date_column%22%3A%20%22last_accessed%22%7D'%2C%0A%20'DELETE'%2C%20'Business%20requirement%20-%2090%20days'%2C%20CURDATE()%2C%20'security_officer'%2C%20'ACTIVE')%2C%0A%0A('Audit%20Log%20Retention'%2C%20'audit_logs'%2C%203650%2C%0A%20'%7B%22date_column%22%3A%20%22event_timestamp%22%2C%20%22severity_filter%22%3A%20%22HIGH%2CCRITICAL%22%7D'%2C%0A%20'ARCHIVE'%2C%20'SOX%20compliance%20-%2010%20years'%2C%20CURDATE()%2C%20'audit_manager'%2C%20'ACTIVE')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Retention policy definitions
CREATE TABLE retention_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    retention_period_days INT NOT NULL,
    retention_criteria JSON,
    purge_method ENUM('DELETE', 'ARCHIVE', 'ANONYMIZE') DEFAULT 'DELETE',
    legal_basis VARCHAR(200),
    business_justification TEXT,
    
    -- Policy metadata
    effective_date DATE NOT NULL,
    review_date DATE,
    policy_owner VARCHAR(100),
    approval_status ENUM('DRAFT', 'APPROVED', 'ACTIVE', 'SUSPENDED') DEFAULT 'DRAFT',
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_policy (table_name, policy_name),
    INDEX idx_effective_date (effective_date),
    INDEX idx_approval_status (approval_status)
);

-- Insert retention policies
INSERT INTO retention_policies (
    policy_name, table_name, retention_period_days, retention_criteria,
    purge_method, legal_basis, effective_date, policy_owner, approval_status
) VALUES
('Customer Data Retention', 'customers', 2555, 
 '{"date_column": "last_activity", "status_filter": "inactive"}',
 'ANONYMIZE', 'GDPR Article 5 - Storage limitation', CURDATE(), 'data_officer', 'ACTIVE'),

('Transaction Log Retention', 'transaction_logs', 2555,
 '{"date_column": "created_at"}',
 'ARCHIVE', 'Financial regulations - 7 years', CURDATE(), 'compliance_officer', 'ACTIVE'),

('Session Data Retention', 'user_sessions', 90,
 '{"date_column": "last_accessed"}',
 'DELETE', 'Business requirement - 90 days', CURDATE(), 'security_officer', 'ACTIVE'),

('Audit Log Retention', 'audit_logs', 3650,
 '{"date_column": "event_timestamp", "severity_filter": "HIGH,CRITICAL"}',
 'ARCHIVE', 'SOX compliance - 10 years', CURDATE(), 'audit_manager', 'ACTIVE');
</code></pre>
</div>

<p><strong>2. Automated Purging Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Purging%20execution%20log%0ACREATE%20TABLE%20purge_execution_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20execution_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20records_identified%20BIGINT%2C%0A%20%20%20%20records_processed%20BIGINT%2C%0A%20%20%20%20records_failed%20BIGINT%2C%0A%20%20%20%20execution_status%20ENUM('SUCCESS'%2C%20'PARTIAL'%2C%20'FAILED')%2C%0A%20%20%20%20execution_duration_seconds%20INT%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(policy_id)%20REFERENCES%20retention_policies(id)%2C%0A%20%20%20%20INDEX%20idx_execution_date%20(execution_date)%2C%0A%20%20%20%20INDEX%20idx_policy_status%20(policy_id%2C%20execution_status)%0A)%3B%0A%0A--%20Main%20purging%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_retention_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_policy_id%20INT%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_retention_days%20INT%3B%0A%20%20%20%20DECLARE%20v_retention_criteria%20JSON%3B%0A%20%20%20%20DECLARE%20v_purge_method%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_records_identified%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20table_name%2C%20retention_period_days%2C%20retention_criteria%2C%20purge_method%0A%20%20%20%20%20%20%20%20FROM%20retention_policies%0A%20%20%20%20%20%20%20%20WHERE%20approval_status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20AND%20effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_purge_method%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20purging%20based%20on%20method%0A%20%20%20%20%20%20%20%20CASE%20v_purge_method%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'DELETE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_deletion(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ARCHIVE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_archiving(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ANONYMIZE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_anonymization(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20execution%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20purge_execution_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20policy_id%2C%20records_identified%2C%20records_processed%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20execution_status%2C%20execution_duration_seconds%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_policy_id%2C%20v_records_identified%2C%20v_records_processed%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20v_records_processed%20%3D%20v_records_identified%20THEN%20'SUCCESS'%20ELSE%20'PARTIAL'%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(SECOND%2C%20v_start_time%2C%20NOW())%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Deletion-based%20purging%0ACREATE%20PROCEDURE%20purge_by_deletion(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_retention_days%20INT%2C%0A%20%20%20%20IN%20p_criteria%20JSON%2C%0A%20%20%20%20OUT%20p_identified%20BIGINT%2C%0A%20%20%20%20OUT%20p_processed%20BIGINT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_date_column%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_status_filter%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_cutoff_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_delete_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_count_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20criteria%0A%20%20%20%20SET%20v_date_column%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.date_column'))%3B%0A%20%20%20%20SET%20v_status_filter%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.status_filter'))%3B%0A%20%20%20%20SET%20v_cutoff_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_retention_days%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20records%20to%20be%20deleted%0A%20%20%20%20SET%20v_count_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_status_filter%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_count_sql%20%3D%20CONCAT(v_count_sql%2C%20'%20AND%20status%20IN%20('''%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REPLACE(v_status_filter%2C%20'%2C'%2C%20'''%2C''')%2C%20''')')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_count_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20p_identified%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20records%20in%20batches%0A%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'DELETE%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_status_filter%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(v_delete_sql%2C%20'%20AND%20status%20IN%20('''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REPLACE(v_status_filter%2C%20'%2C'%2C%20'''%2C''')%2C%20''')')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(v_delete_sql%2C%20'%20LIMIT%2010000')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20deletion%20in%20batches%0A%20%20%20%20deletion_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_delete_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20p_processed%20%3D%20p_processed%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20deletion_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Prevent%20long-running%20transactions%0A%20%20%20%20%20%20%20%20DO%20SLEEP(0.1)%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Purging execution log
CREATE TABLE purge_execution_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    policy_id INT NOT NULL,
    execution_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    records_identified BIGINT,
    records_processed BIGINT,
    records_failed BIGINT,
    execution_status ENUM('SUCCESS', 'PARTIAL', 'FAILED'),
    execution_duration_seconds INT,
    error_message TEXT,
    
    FOREIGN KEY (policy_id) REFERENCES retention_policies(id),
    INDEX idx_execution_date (execution_date),
    INDEX idx_policy_status (policy_id, execution_status)
);

-- Main purging procedure
DELIMITER //
CREATE PROCEDURE execute_retention_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_policy_id INT;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_retention_days INT;
    DECLARE v_retention_criteria JSON;
    DECLARE v_purge_method VARCHAR(20);
    DECLARE v_records_identified BIGINT DEFAULT 0;
    DECLARE v_records_processed BIGINT DEFAULT 0;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE policy_cursor CURSOR FOR
        SELECT id, table_name, retention_period_days, retention_criteria, purge_method
        FROM retention_policies
        WHERE approval_status = 'ACTIVE'
        AND effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_policy_id, v_table_name, v_retention_days, 
                                v_retention_criteria, v_purge_method;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Execute purging based on method
        CASE v_purge_method
            WHEN 'DELETE' THEN
                CALL purge_by_deletion(v_policy_id, v_table_name, v_retention_days, 
                                     v_retention_criteria, v_records_identified, v_records_processed);
            
            WHEN 'ARCHIVE' THEN
                CALL purge_by_archiving(v_policy_id, v_table_name, v_retention_days,
                                      v_retention_criteria, v_records_identified, v_records_processed);
            
            WHEN 'ANONYMIZE' THEN
                CALL purge_by_anonymization(v_policy_id, v_table_name, v_retention_days,
                                          v_retention_criteria, v_records_identified, v_records_processed);
        END CASE;
        
        -- Log execution
        INSERT INTO purge_execution_log (
            policy_id, records_identified, records_processed,
            execution_status, execution_duration_seconds
        ) VALUES (
            v_policy_id, v_records_identified, v_records_processed,
            CASE WHEN v_records_processed = v_records_identified THEN 'SUCCESS' ELSE 'PARTIAL' END,
            TIMESTAMPDIFF(SECOND, v_start_time, NOW())
        );
        
    END LOOP;
    
    CLOSE policy_cursor;
END //

-- Deletion-based purging
CREATE PROCEDURE purge_by_deletion(
    IN p_policy_id INT,
    IN p_table_name VARCHAR(100),
    IN p_retention_days INT,
    IN p_criteria JSON,
    OUT p_identified BIGINT,
    OUT p_processed BIGINT
)
BEGIN
    DECLARE v_date_column VARCHAR(100);
    DECLARE v_status_filter VARCHAR(200);
    DECLARE v_cutoff_date DATE;
    DECLARE v_delete_sql TEXT;
    DECLARE v_count_sql TEXT;
    
    -- Extract criteria
    SET v_date_column = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.date_column'));
    SET v_status_filter = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.status_filter'));
    SET v_cutoff_date = DATE_SUB(CURDATE(), INTERVAL p_retention_days DAY);
    
    -- Count records to be deleted
    SET v_count_sql = CONCAT(
        'SELECT COUNT(*) FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    
    IF v_status_filter IS NOT NULL THEN
        SET v_count_sql = CONCAT(v_count_sql, ' AND status IN (''', 
                                REPLACE(v_status_filter, ',', ''','''), ''')');
    END IF;
    
    SET @sql = v_count_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store result in p_identified
    DEALLOCATE PREPARE stmt;
    
    -- Delete records in batches
    SET v_delete_sql = CONCAT(
        'DELETE FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    
    IF v_status_filter IS NOT NULL THEN
        SET v_delete_sql = CONCAT(v_delete_sql, ' AND status IN (''',
                                 REPLACE(v_status_filter, ',', ''','''), ''')');
    END IF;
    
    SET v_delete_sql = CONCAT(v_delete_sql, ' LIMIT 10000');
    
    -- Execute deletion in batches
    deletion_loop: LOOP
        SET @sql = v_delete_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        SET p_processed = p_processed + ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        IF ROW_COUNT() = 0 THEN
            LEAVE deletion_loop;
        END IF;
        
        -- Prevent long-running transactions
        DO SLEEP(0.1);
    END LOOP;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Archival Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20table%20creation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_archive_table(IN%20p_source_table%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_archive_table%20VARCHAR(120)%3B%0A%20%20%20%20DECLARE%20v_create_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_archive_table%20%3D%20CONCAT(p_source_table%2C%20'_archive_'%2C%20YEAR(CURDATE()))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%20with%20same%20structure%0A%20%20%20%20SET%20v_create_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'CREATE%20TABLE%20IF%20NOT%20EXISTS%20'%2C%20v_archive_table%2C%20'%20AS%20'%2C%0A%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20p_source_table%2C%20'%20WHERE%201%3D0'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_create_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20archive-specific%20columns%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('ALTER%20TABLE%20'%2C%20v_archive_table%2C%20'%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ADD%20COLUMN%20IF%20NOT%20EXISTS%20archived_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ADD%20COLUMN%20IF%20NOT%20EXISTS%20archive_reason%20VARCHAR(200)')%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Archival%20procedure%0ACREATE%20PROCEDURE%20purge_by_archiving(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_retention_days%20INT%2C%0A%20%20%20%20IN%20p_criteria%20JSON%2C%0A%20%20%20%20OUT%20p_identified%20BIGINT%2C%0A%20%20%20%20OUT%20p_processed%20BIGINT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_archive_table%20VARCHAR(120)%3B%0A%20%20%20%20DECLARE%20v_date_column%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_cutoff_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_batch_size%20INT%20DEFAULT%2010000%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_archive_table%20%3D%20CONCAT(p_table_name%2C%20'_archive_'%2C%20YEAR(CURDATE()))%3B%0A%20%20%20%20SET%20v_date_column%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.date_column'))%3B%0A%20%20%20%20SET%20v_cutoff_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_retention_days%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%0A%20%20%20%20CALL%20create_archive_table(p_table_name)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20records%20to%20archive%0A%20%20%20%20SET%20%40count_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40count_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20p_identified%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20in%20batches%0A%20%20%20%20archive_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20--%20Insert%20batch%20into%20archive%0A%20%20%20%20%20%20%20%20SET%20%40archive_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20v_archive_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%2C%20NOW()%20as%20archived_at%2C%20''Retention%20policy''%20as%20archive_reason%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20'''%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40archive_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20p_processed%20%3D%20p_processed%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20archive_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Delete%20archived%20records%20from%20source%0A%20%20%20%20%20%20%20%20SET%20%40delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'DELETE%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20'''%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40delete_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20DO%20SLEEP(0.1)%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive table creation
DELIMITER //
CREATE PROCEDURE create_archive_table(IN p_source_table VARCHAR(100))
BEGIN
    DECLARE v_archive_table VARCHAR(120);
    DECLARE v_create_sql TEXT;
    
    SET v_archive_table = CONCAT(p_source_table, '_archive_', YEAR(CURDATE()));
    
    -- Create archive table with same structure
    SET v_create_sql = CONCAT(
        'CREATE TABLE IF NOT EXISTS ', v_archive_table, ' AS ',
        'SELECT * FROM ', p_source_table, ' WHERE 1=0'
    );
    
    SET @sql = v_create_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Add archive-specific columns
    SET @sql = CONCAT('ALTER TABLE ', v_archive_table, ' 
                      ADD COLUMN IF NOT EXISTS archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                      ADD COLUMN IF NOT EXISTS archive_reason VARCHAR(200)');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //

-- Archival procedure
CREATE PROCEDURE purge_by_archiving(
    IN p_policy_id INT,
    IN p_table_name VARCHAR(100),
    IN p_retention_days INT,
    IN p_criteria JSON,
    OUT p_identified BIGINT,
    OUT p_processed BIGINT
)
BEGIN
    DECLARE v_archive_table VARCHAR(120);
    DECLARE v_date_column VARCHAR(100);
    DECLARE v_cutoff_date DATE;
    DECLARE v_batch_size INT DEFAULT 10000;
    
    SET v_archive_table = CONCAT(p_table_name, '_archive_', YEAR(CURDATE()));
    SET v_date_column = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.date_column'));
    SET v_cutoff_date = DATE_SUB(CURDATE(), INTERVAL p_retention_days DAY);
    
    -- Create archive table
    CALL create_archive_table(p_table_name);
    
    -- Count records to archive
    SET @count_sql = CONCAT(
        'SELECT COUNT(*) FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    PREPARE stmt FROM @count_sql;
    EXECUTE stmt;
    -- Store in p_identified
    DEALLOCATE PREPARE stmt;
    
    -- Archive in batches
    archive_loop: LOOP
        -- Insert batch into archive
        SET @archive_sql = CONCAT(
            'INSERT INTO ', v_archive_table, ' ',
            'SELECT *, NOW() as archived_at, ''Retention policy'' as archive_reason ',
            'FROM ', p_table_name,
            ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''' ',
            'LIMIT ', v_batch_size
        );
        
        PREPARE stmt FROM @archive_sql;
        EXECUTE stmt;
        SET p_processed = p_processed + ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        IF ROW_COUNT() = 0 THEN
            LEAVE archive_loop;
        END IF;
        
        -- Delete archived records from source
        SET @delete_sql = CONCAT(
            'DELETE FROM ', p_table_name,
            ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''' ',
            'LIMIT ', v_batch_size
        );
        
        PREPARE stmt FROM @delete_sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        DO SLEEP(0.1);
    END LOOP;
    
END //

DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-382-how-do-you-implement-data-masking-and-anonymization-">**382. How do you implement data masking and anonymization?**</h2>

<p><strong>Answer:</strong> Data masking and anonymization protect sensitive data by replacing, encrypting, or obfuscating original values while maintaining data utility for testing and analytics.</p>

<p><strong>Data Masking Framework:</strong></p>

<p><strong>1. Masking Rules Configuration:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20rules%20repository%0ACREATE%20TABLE%20masking_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20masking_type%20ENUM('SUBSTITUTION'%2C%20'SHUFFLING'%2C%20'ENCRYPTION'%2C%20'TOKENIZATION'%2C%20'NULLING'%2C%20'PARTIAL_MASKING')%2C%0A%20%20%20%20masking_function%20VARCHAR(200)%2C%0A%20%20%20%20masking_parameters%20JSON%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20preserve_format%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20preserve_length%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Conditional%20masking%0A%20%20%20%20masking_condition%20TEXT%2C%0A%20%20%20%20environment%20ENUM('DEV'%2C%20'TEST'%2C%20'STAGING'%2C%20'PROD')%20DEFAULT%20'DEV'%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_column_env%20(table_name%2C%20column_name%2C%20environment)%2C%0A%20%20%20%20INDEX%20idx_masking_type%20(masking_type)%0A)%3B%0A%0A--%20Insert%20masking%20rules%0AINSERT%20INTO%20masking_rules%20(%0A%20%20%20%20rule_name%2C%20table_name%2C%20column_name%2C%20masking_type%2C%20%0A%20%20%20%20masking_function%2C%20masking_parameters%2C%20environment%0A)%20VALUES%0A('Email%20Masking'%2C%20'customers'%2C%20'email'%2C%20'PARTIAL_MASKING'%2C%20%0A%20'mask_email'%2C%20'%7B%22preserve_domain%22%3A%20false%7D'%2C%20'DEV')%2C%0A%0A('Phone%20Number%20Masking'%2C%20'customers'%2C%20'phone'%2C%20'SUBSTITUTION'%2C%0A%20'generate_fake_phone'%2C%20'%7B%22country_code%22%3A%20%22US%22%7D'%2C%20'DEV')%2C%0A%0A('SSN%20Tokenization'%2C%20'customers'%2C%20'ssn'%2C%20'TOKENIZATION'%2C%0A%20'tokenize_ssn'%2C%20'%7B%22algorithm%22%3A%20%22AES256%22%7D'%2C%20'DEV')%2C%0A%0A('Credit%20Card%20Masking'%2C%20'payments'%2C%20'card_number'%2C%20'PARTIAL_MASKING'%2C%0A%20'mask_credit_card'%2C%20'%7B%22show_last%22%3A%204%7D'%2C%20'DEV')%2C%0A%0A('Name%20Shuffling'%2C%20'customers'%2C%20'name'%2C%20'SHUFFLING'%2C%0A%20'shuffle_names'%2C%20'%7B%22maintain_gender%22%3A%20true%7D'%2C%20'TEST')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking rules repository
CREATE TABLE masking_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    column_name VARCHAR(100) NOT NULL,
    masking_type ENUM('SUBSTITUTION', 'SHUFFLING', 'ENCRYPTION', 'TOKENIZATION', 'NULLING', 'PARTIAL_MASKING'),
    masking_function VARCHAR(200),
    masking_parameters JSON,
    data_type VARCHAR(50),
    preserve_format BOOLEAN DEFAULT TRUE,
    preserve_length BOOLEAN DEFAULT TRUE,
    
    -- Conditional masking
    masking_condition TEXT,
    environment ENUM('DEV', 'TEST', 'STAGING', 'PROD') DEFAULT 'DEV',
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_column_env (table_name, column_name, environment),
    INDEX idx_masking_type (masking_type)
);

-- Insert masking rules
INSERT INTO masking_rules (
    rule_name, table_name, column_name, masking_type, 
    masking_function, masking_parameters, environment
) VALUES
('Email Masking', 'customers', 'email', 'PARTIAL_MASKING', 
 'mask_email', '{"preserve_domain": false}', 'DEV'),

('Phone Number Masking', 'customers', 'phone', 'SUBSTITUTION',
 'generate_fake_phone', '{"country_code": "US"}', 'DEV'),

('SSN Tokenization', 'customers', 'ssn', 'TOKENIZATION',
 'tokenize_ssn', '{"algorithm": "AES256"}', 'DEV'),

('Credit Card Masking', 'payments', 'card_number', 'PARTIAL_MASKING',
 'mask_credit_card', '{"show_last": 4}', 'DEV'),

('Name Shuffling', 'customers', 'name', 'SHUFFLING',
 'shuffle_names', '{"maintain_gender": true}', 'TEST');
</code></pre>
</div>

<p><strong>2. Masking Functions Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20utility%20functions%0ADELIMITER%20%2F%2F%0A%0A--%20Email%20masking%20function%0ACREATE%20FUNCTION%20mask_email(p_email%20VARCHAR(255)%2C%20p_preserve_domain%20BOOLEAN)%0ARETURNS%20VARCHAR(255)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_local_part%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_domain_part%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_masked_local%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_at_position%20INT%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_email%20IS%20NULL%20OR%20p_email%20%3D%20''%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20p_email%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_at_position%20%3D%20LOCATE('%40'%2C%20p_email)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_at_position%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20'invalid%40email.com'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_local_part%20%3D%20LEFT(p_email%2C%20v_at_position%20-%201)%3B%0A%20%20%20%20SET%20v_domain_part%20%3D%20SUBSTRING(p_email%2C%20v_at_position%20%2B%201)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Mask%20local%20part%0A%20%20%20%20SET%20v_masked_local%20%3D%20CASE%0A%20%20%20%20%20%20%20%20WHEN%20LENGTH(v_local_part)%20%3C%3D%202%20THEN%20REPEAT('*'%2C%20LENGTH(v_local_part))%0A%20%20%20%20%20%20%20%20ELSE%20CONCAT(LEFT(v_local_part%2C%201)%2C%20REPEAT('*'%2C%20LENGTH(v_local_part)%20-%202)%2C%20RIGHT(v_local_part%2C%201))%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20domain%20masking%0A%20%20%20%20IF%20NOT%20p_preserve_domain%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_domain_part%20%3D%20'example.com'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20CONCAT(v_masked_local%2C%20'%40'%2C%20v_domain_part)%3B%0AEND%20%2F%2F%0A%0A--%20Credit%20card%20masking%20function%0ACREATE%20FUNCTION%20mask_credit_card(p_card_number%20VARCHAR(20)%2C%20p_show_last%20INT)%0ARETURNS%20VARCHAR(20)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_clean_number%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_masked%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_card_number%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20non-numeric%20characters%0A%20%20%20%20SET%20v_clean_number%20%3D%20REGEXP_REPLACE(p_card_number%2C%20'%5B%5E0-9%5D'%2C%20'')%3B%0A%20%20%20%20%0A%20%20%20%20IF%20LENGTH(v_clean_number)%20%3C%208%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20REPEAT('*'%2C%20LENGTH(v_clean_number))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_masked%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20REPEAT('*'%2C%20LENGTH(v_clean_number)%20-%20p_show_last)%2C%0A%20%20%20%20%20%20%20%20RIGHT(v_clean_number%2C%20p_show_last)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Restore%20original%20formatting%0A%20%20%20%20IF%20p_card_number%20LIKE%20'%25-%25-%25-%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_masked%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%201%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%205%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%209%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%2013)%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_masked%3B%0AEND%20%2F%2F%0A%0A--%20Name%20shuffling%20function%20(simplified%20version)%0ACREATE%20FUNCTION%20shuffle_name(p_name%20VARCHAR(255))%0ARETURNS%20VARCHAR(255)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_hash%20INT%3B%0A%20%20%20%20DECLARE%20v_fake_names%20JSON%20DEFAULT%20'%5B%22John%20Smith%22%2C%20%22Jane%20Doe%22%2C%20%22Mike%20Johnson%22%2C%20%22Sarah%20Wilson%22%2C%20%22David%20Brown%22%2C%20%22Lisa%20Davis%22%2C%20%22Robert%20Miller%22%2C%20%22Jennifer%20Garcia%22%5D'%3B%0A%20%20%20%20DECLARE%20v_name_count%20INT%3B%0A%20%20%20%20DECLARE%20v_selected_index%20INT%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_name%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_name_count%20%3D%20JSON_LENGTH(v_fake_names)%3B%0A%20%20%20%20SET%20v_hash%20%3D%20CRC32(p_name)%3B%0A%20%20%20%20SET%20v_selected_index%20%3D%20ABS(v_hash)%20%25%20v_name_count%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20JSON_UNQUOTE(JSON_EXTRACT(v_fake_names%2C%20CONCAT('%24%5B'%2C%20v_selected_index%2C%20'%5D')))%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking utility functions
DELIMITER //

-- Email masking function
CREATE FUNCTION mask_email(p_email VARCHAR(255), p_preserve_domain BOOLEAN)
RETURNS VARCHAR(255)
DETERMINISTIC
BEGIN
    DECLARE v_local_part VARCHAR(255);
    DECLARE v_domain_part VARCHAR(255);
    DECLARE v_masked_local VARCHAR(255);
    DECLARE v_at_position INT;
    
    IF p_email IS NULL OR p_email = '' THEN
        RETURN p_email;
    END IF;
    
    SET v_at_position = LOCATE('@', p_email);
    
    IF v_at_position = 0 THEN
        RETURN 'invalid@email.com';
    END IF;
    
    SET v_local_part = LEFT(p_email, v_at_position - 1);
    SET v_domain_part = SUBSTRING(p_email, v_at_position + 1);
    
    -- Mask local part
    SET v_masked_local = CASE
        WHEN LENGTH(v_local_part) &lt;= 2 THEN REPEAT('*', LENGTH(v_local_part))
        ELSE CONCAT(LEFT(v_local_part, 1), REPEAT('*', LENGTH(v_local_part) - 2), RIGHT(v_local_part, 1))
    END;
    
    -- Handle domain masking
    IF NOT p_preserve_domain THEN
        SET v_domain_part = 'example.com';
    END IF;
    
    RETURN CONCAT(v_masked_local, '@', v_domain_part);
END //

-- Credit card masking function
CREATE FUNCTION mask_credit_card(p_card_number VARCHAR(20), p_show_last INT)
RETURNS VARCHAR(20)
DETERMINISTIC
BEGIN
    DECLARE v_clean_number VARCHAR(20);
    DECLARE v_masked VARCHAR(20);
    
    IF p_card_number IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Remove non-numeric characters
    SET v_clean_number = REGEXP_REPLACE(p_card_number, '[^0-9]', '');
    
    IF LENGTH(v_clean_number) &lt; 8 THEN
        RETURN REPEAT('*', LENGTH(v_clean_number));
    END IF;
    
    SET v_masked = CONCAT(
        REPEAT('*', LENGTH(v_clean_number) - p_show_last),
        RIGHT(v_clean_number, p_show_last)
    );
    
    -- Restore original formatting
    IF p_card_number LIKE '%-%-%-%' THEN
        SET v_masked = CONCAT(
            SUBSTRING(v_masked, 1, 4), '-',
            SUBSTRING(v_masked, 5, 4), '-',
            SUBSTRING(v_masked, 9, 4), '-',
            SUBSTRING(v_masked, 13)
        );
    END IF;
    
    RETURN v_masked;
END //

-- Name shuffling function (simplified version)
CREATE FUNCTION shuffle_name(p_name VARCHAR(255))
RETURNS VARCHAR(255)
DETERMINISTIC
BEGIN
    DECLARE v_hash INT;
    DECLARE v_fake_names JSON DEFAULT '["John Smith", "Jane Doe", "Mike Johnson", "Sarah Wilson", "David Brown", "Lisa Davis", "Robert Miller", "Jennifer Garcia"]';
    DECLARE v_name_count INT;
    DECLARE v_selected_index INT;
    
    IF p_name IS NULL THEN
        RETURN NULL;
    END IF;
    
    SET v_name_count = JSON_LENGTH(v_fake_names);
    SET v_hash = CRC32(p_name);
    SET v_selected_index = ABS(v_hash) % v_name_count;
    
    RETURN JSON_UNQUOTE(JSON_EXTRACT(v_fake_names, CONCAT('$[', v_selected_index, ']')));
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Comprehensive Masking Execution:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20execution%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_data_masking(IN%20p_environment%20VARCHAR(10))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_masking_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_masking_function%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_masking_parameters%20JSON%3B%0A%20%20%20%20DECLARE%20v_masking_condition%20TEXT%3B%0A%20%20%20%20DECLARE%20v_update_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_records_masked%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20masking_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20column_name%2C%20masking_type%2C%20masking_function%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20masking_parameters%2C%20masking_condition%0A%20%20%20%20%20%20%20%20FROM%20masking_rules%0A%20%20%20%20%20%20%20%20WHERE%20environment%20%3D%20p_environment%0A%20%20%20%20%20%20%20%20ORDER%20BY%20table_name%2C%20column_name%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20masking%20execution%20log%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20masking_log%20(%0A%20%20%20%20%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20masking_type%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20records_masked%20BIGINT%2C%0A%20%20%20%20%20%20%20%20execution_time%20DECIMAL(10%2C3)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20masking_cursor%3B%0A%20%20%20%20%0A%20%20%20%20masking_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20masking_cursor%20INTO%20v_table_name%2C%20v_column_name%2C%20v_masking_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_masking_function%2C%20v_masking_parameters%2C%20v_masking_condition%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20masking_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40start_time%20%3D%20NOW(3)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20update%20SQL%20based%20on%20masking%20type%0A%20%20%20%20%20%20%20%20CASE%20v_masking_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'PARTIAL_MASKING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IF%20v_masking_function%20%3D%20'mask_email'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20mask_email('%2C%20v_column_name%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_masking_parameters%2C%20'%24.preserve_domain')%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSEIF%20v_masking_function%20%3D%20'mask_credit_card'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20mask_credit_card('%2C%20v_column_name%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_masking_parameters%2C%20'%24.show_last')%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'SHUFFLING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20shuffle_name('%2C%20v_column_name%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'NULLING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20NULL'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'SUBSTITUTION'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20''MASKED_DATA'''%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Add%20condition%20if%20specified%0A%20%20%20%20%20%20%20%20IF%20v_masking_condition%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(v_update_sql%2C%20'%20WHERE%20'%2C%20v_masking_condition)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20masking%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_update_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20v_records_masked%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20execution%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20masking_log%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_name%2C%20v_column_name%2C%20v_masking_type%2C%20v_records_masked%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(MICROSECOND%2C%20%40start_time%2C%20NOW(3))%20%2F%201000%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20masking_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20execution%20summary%0A%20%20%20%20SELECT%20*%20FROM%20masking_log%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20to%20permanent%20table%0A%20%20%20%20INSERT%20INTO%20masking_execution_log%20(%0A%20%20%20%20%20%20%20%20environment%2C%20execution_date%2C%20tables_processed%2C%20total_records_masked%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_environment%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(DISTINCT%20table_name)%20FROM%20masking_log)%2C%0A%20%20%20%20%20%20%20%20(SELECT%20SUM(records_masked)%20FROM%20masking_log)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20masking_log%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking execution procedure
DELIMITER //
CREATE PROCEDURE execute_data_masking(IN p_environment VARCHAR(10))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_masking_type VARCHAR(50);
    DECLARE v_masking_function VARCHAR(200);
    DECLARE v_masking_parameters JSON;
    DECLARE v_masking_condition TEXT;
    DECLARE v_update_sql TEXT;
    DECLARE v_records_masked BIGINT DEFAULT 0;
    
    DECLARE masking_cursor CURSOR FOR
        SELECT table_name, column_name, masking_type, masking_function, 
               masking_parameters, masking_condition
        FROM masking_rules
        WHERE environment = p_environment
        ORDER BY table_name, column_name;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create masking execution log
    CREATE TEMPORARY TABLE masking_log (
        table_name VARCHAR(100),
        column_name VARCHAR(100),
        masking_type VARCHAR(50),
        records_masked BIGINT,
        execution_time DECIMAL(10,3)
    );
    
    OPEN masking_cursor;
    
    masking_loop: LOOP
        FETCH masking_cursor INTO v_table_name, v_column_name, v_masking_type,
                                 v_masking_function, v_masking_parameters, v_masking_condition;
        
        IF done THEN
            LEAVE masking_loop;
        END IF;
        
        SET @start_time = NOW(3);
        
        -- Build update SQL based on masking type
        CASE v_masking_type
            WHEN 'PARTIAL_MASKING' THEN
                IF v_masking_function = 'mask_email' THEN
                    SET v_update_sql = CONCAT(
                        'UPDATE ', v_table_name, ' SET ', v_column_name, ' = mask_email(', v_column_name, ', ',
                        JSON_EXTRACT(v_masking_parameters, '$.preserve_domain'), ')'
                    );
                ELSEIF v_masking_function = 'mask_credit_card' THEN
                    SET v_update_sql = CONCAT(
                        'UPDATE ', v_table_name, ' SET ', v_column_name, ' = mask_credit_card(', v_column_name, ', ',
                        JSON_EXTRACT(v_masking_parameters, '$.show_last'), ')'
                    );
                END IF;
            
            WHEN 'SHUFFLING' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = shuffle_name(', v_column_name, ')'
                );
            
            WHEN 'NULLING' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = NULL'
                );
            
            WHEN 'SUBSTITUTION' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = ''MASKED_DATA'''
                );
        END CASE;
        
        -- Add condition if specified
        IF v_masking_condition IS NOT NULL THEN
            SET v_update_sql = CONCAT(v_update_sql, ' WHERE ', v_masking_condition);
        END IF;
        
        -- Execute masking
        SET @sql = v_update_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        SET v_records_masked = ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        -- Log execution
        INSERT INTO masking_log VALUES (
            v_table_name, v_column_name, v_masking_type, v_records_masked,
            TIMESTAMPDIFF(MICROSECOND, @start_time, NOW(3)) / 1000
        );
        
    END LOOP;
    
    CLOSE masking_cursor;
    
    -- Return execution summary
    SELECT * FROM masking_log;
    
    -- Log to permanent table
    INSERT INTO masking_execution_log (
        environment, execution_date, tables_processed, total_records_masked
    ) VALUES (
        p_environment, NOW(),
        (SELECT COUNT(DISTINCT table_name) FROM masking_log),
        (SELECT SUM(records_masked) FROM masking_log)
    );
    
    DROP TEMPORARY TABLE masking_log;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Tokenization and Encryption:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Tokenization%20system%0ACREATE%20TABLE%20tokenization_vault%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20token%20VARCHAR(255)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20encrypted_value%20VARBINARY(500)%20NOT%20NULL%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20last_accessed%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_token%20(token)%2C%0A%20%20%20%20INDEX%20idx_created_at%20(created_at)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0A%0A--%20Tokenization%20function%0ACREATE%20FUNCTION%20tokenize_value(p_original_value%20VARCHAR(500)%2C%20p_data_type%20VARCHAR(50))%0ARETURNS%20VARCHAR(255)%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20v_token%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_encrypted_value%20VARBINARY(500)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_original_value%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20unique%20token%0A%20%20%20%20SET%20v_token%20%3D%20CONCAT('TKN_'%2C%20UPPER(SHA2(CONCAT(p_original_value%2C%20UNIX_TIMESTAMP()%2C%20RAND())%2C%20256)))%3B%0A%20%20%20%20SET%20v_token%20%3D%20LEFT(v_token%2C%2032)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Encrypt%20original%20value%20(simplified%20-%20use%20proper%20encryption%20in%20production)%0A%20%20%20%20SET%20v_encrypted_value%20%3D%20AES_ENCRYPT(p_original_value%2C%20'encryption_key_here')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Store%20in%20vault%0A%20%20%20%20INSERT%20INTO%20tokenization_vault%20(token%2C%20encrypted_value%2C%20data_type)%0A%20%20%20%20VALUES%20(v_token%2C%20v_encrypted_value%2C%20p_data_type)%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_token%3B%0AEND%20%2F%2F%0A%0A--%20Detokenization%20function%0ACREATE%20FUNCTION%20detokenize_value(p_token%20VARCHAR(255))%0ARETURNS%20VARCHAR(500)%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20v_encrypted_value%20VARBINARY(500)%3B%0A%20%20%20%20DECLARE%20v_original_value%20VARCHAR(500)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_token%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Retrieve%20from%20vault%0A%20%20%20%20SELECT%20encrypted_value%20INTO%20v_encrypted_value%0A%20%20%20%20FROM%20tokenization_vault%0A%20%20%20%20WHERE%20token%20%3D%20p_token%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_encrypted_value%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20'TOKEN_NOT_FOUND'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Decrypt%20value%0A%20%20%20%20SET%20v_original_value%20%3D%20AES_DECRYPT(v_encrypted_value%2C%20'encryption_key_here')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20access%20timestamp%0A%20%20%20%20UPDATE%20tokenization_vault%20%0A%20%20%20%20SET%20last_accessed%20%3D%20NOW()%0A%20%20%20%20WHERE%20token%20%3D%20p_token%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_original_value%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Tokenization system
CREATE TABLE tokenization_vault (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    token VARCHAR(255) UNIQUE NOT NULL,
    encrypted_value VARBINARY(500) NOT NULL,
    data_type VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_token (token),
    INDEX idx_created_at (created_at)
);

DELIMITER //

-- Tokenization function
CREATE FUNCTION tokenize_value(p_original_value VARCHAR(500), p_data_type VARCHAR(50))
RETURNS VARCHAR(255)
MODIFIES SQL DATA
BEGIN
    DECLARE v_token VARCHAR(255);
    DECLARE v_encrypted_value VARBINARY(500);
    
    IF p_original_value IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Generate unique token
    SET v_token = CONCAT('TKN_', UPPER(SHA2(CONCAT(p_original_value, UNIX_TIMESTAMP(), RAND()), 256)));
    SET v_token = LEFT(v_token, 32);
    
    -- Encrypt original value (simplified - use proper encryption in production)
    SET v_encrypted_value = AES_ENCRYPT(p_original_value, 'encryption_key_here');
    
    -- Store in vault
    INSERT INTO tokenization_vault (token, encrypted_value, data_type)
    VALUES (v_token, v_encrypted_value, p_data_type);
    
    RETURN v_token;
END //

-- Detokenization function
CREATE FUNCTION detokenize_value(p_token VARCHAR(255))
RETURNS VARCHAR(500)
READS SQL DATA
BEGIN
    DECLARE v_encrypted_value VARBINARY(500);
    DECLARE v_original_value VARCHAR(500);
    
    IF p_token IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Retrieve from vault
    SELECT encrypted_value INTO v_encrypted_value
    FROM tokenization_vault
    WHERE token = p_token;
    
    IF v_encrypted_value IS NULL THEN
        RETURN 'TOKEN_NOT_FOUND';
    END IF;
    
    -- Decrypt value
    SET v_original_value = AES_DECRYPT(v_encrypted_value, 'encryption_key_here');
    
    -- Update access timestamp
    UPDATE tokenization_vault 
    SET last_accessed = NOW()
    WHERE token = p_token;
    
    RETURN v_original_value;
END //

DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-383-what-are-data-lake-and-data-warehouse-differences-">**383. What are data lake and data warehouse differences?**</h2>

<p><strong>Answer:</strong> Data lakes store raw, unstructured data in native format for flexible analysis, while data warehouses contain structured, processed data optimized for specific business intelligence and reporting needs.</p>

<p><strong>Architecture Comparison:</strong></p>

<p><strong>1. Data Warehouse Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Traditional%20data%20warehouse%20schema%20(star%20schema)%0A--%20Fact%20table%20(central%20metrics)%0ACREATE%20TABLE%20sales_fact%20(%0A%20%20%20%20sale_id%20BIGINT%20PRIMARY%20KEY%2C%0A%20%20%20%20date_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20store_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Measures%2FMetrics%0A%20%20%20%20quantity_sold%20INT%20NOT%20NULL%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%20NOT%20NULL%2C%0A%20%20%20%20discount_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20profit_margin%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Pre-calculated%20aggregations%0A%20%20%20%20monthly_total%20DECIMAL(12%2C2)%2C%0A%20%20%20%20quarterly_total%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Foreign%20keys%20to%20dimension%20tables%0A%20%20%20%20FOREIGN%20KEY%20(date_key)%20REFERENCES%20date_dimension(date_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_key)%20REFERENCES%20customer_dimension(customer_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_key)%20REFERENCES%20product_dimension(product_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(store_key)%20REFERENCES%20store_dimension(store_key)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Optimized%20indexes%20for%20OLAP%20queries%0A%20%20%20%20INDEX%20idx_date_customer%20(date_key%2C%20customer_key)%2C%0A%20%20%20%20INDEX%20idx_product_store%20(product_key%2C%20store_key)%2C%0A%20%20%20%20INDEX%20idx_time_series%20(date_key%2C%20total_amount)%0A)%3B%0A%0A--%20Dimension%20table%20(descriptive%20attributes)%0ACREATE%20TABLE%20customer_dimension%20(%0A%20%20%20%20customer_key%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20VARCHAR(50)%20NOT%20NULL%2C%20--%20Business%20key%0A%20%20%20%20%0A%20%20%20%20--%20Current%20attributes%20(SCD%20Type%201)%0A%20%20%20%20customer_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Historical%20attributes%20(SCD%20Type%202)%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20credit_rating%20VARCHAR(10)%2C%0A%20%20%20%20city%20VARCHAR(100)%2C%0A%20%20%20%20state%20VARCHAR(50)%2C%0A%20%20%20%20country%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SCD%20metadata%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20is_current%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20version_number%20INT%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20--%20Hierarchy%20support%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20sales_territory%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_current%20(is_current)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%2C%0A%20%20%20%20INDEX%20idx_segment%20(customer_segment)%0A)%3B%0A%0A--%20Data%20mart%20for%20specific%20business%20area%0ACREATE%20TABLE%20marketing_datamart%20AS%0ASELECT%20%0A%20%20%20%20dd.year%2C%0A%20%20%20%20dd.quarter%2C%0A%20%20%20%20dd.month_name%2C%0A%20%20%20%20cd.customer_segment%2C%0A%20%20%20%20cd.region%2C%0A%20%20%20%20pd.product_category%2C%0A%20%20%20%20%0A%20%20%20%20--%20Pre-aggregated%20metrics%0A%20%20%20%20COUNT(DISTINCT%20sf.customer_key)%20as%20unique_customers%2C%0A%20%20%20%20SUM(sf.total_amount)%20as%20total_revenue%2C%0A%20%20%20%20AVG(sf.total_amount)%20as%20avg_order_value%2C%0A%20%20%20%20SUM(sf.quantity_sold)%20as%20total_units%2C%0A%20%20%20%20%0A%20%20%20%20--%20Calculated%20KPIs%0A%20%20%20%20SUM(sf.total_amount)%20%2F%20COUNT(DISTINCT%20sf.customer_key)%20as%20revenue_per_customer%2C%0A%20%20%20%20COUNT(sf.sale_id)%20%2F%20COUNT(DISTINCT%20sf.customer_key)%20as%20orders_per_customer%0A%20%20%20%20%0AFROM%20sales_fact%20sf%0AJOIN%20date_dimension%20dd%20ON%20sf.date_key%20%3D%20dd.date_key%0AJOIN%20customer_dimension%20cd%20ON%20sf.customer_key%20%3D%20cd.customer_key%0AJOIN%20product_dimension%20pd%20ON%20sf.product_key%20%3D%20pd.product_key%0AWHERE%20dd.year%20%3E%3D%20YEAR(CURDATE())%20-%202%0AGROUP%20BY%20dd.year%2C%20dd.quarter%2C%20dd.month_name%2C%20cd.customer_segment%2C%20%0A%20%20%20%20%20%20%20%20%20cd.region%2C%20pd.product_category%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Traditional data warehouse schema (star schema)
-- Fact table (central metrics)
CREATE TABLE sales_fact (
    sale_id BIGINT PRIMARY KEY,
    date_key INT NOT NULL,
    customer_key INT NOT NULL,
    product_key INT NOT NULL,
    store_key INT NOT NULL,
    
    -- Measures/Metrics
    quantity_sold INT NOT NULL,
    unit_price DECIMAL(10,2) NOT NULL,
    total_amount DECIMAL(12,2) NOT NULL,
    discount_amount DECIMAL(10,2) DEFAULT 0,
    profit_margin DECIMAL(10,2),
    
    -- Pre-calculated aggregations
    monthly_total DECIMAL(12,2),
    quarterly_total DECIMAL(12,2),
    
    -- Foreign keys to dimension tables
    FOREIGN KEY (date_key) REFERENCES date_dimension(date_key),
    FOREIGN KEY (customer_key) REFERENCES customer_dimension(customer_key),
    FOREIGN KEY (product_key) REFERENCES product_dimension(product_key),
    FOREIGN KEY (store_key) REFERENCES store_dimension(store_key),
    
    -- Optimized indexes for OLAP queries
    INDEX idx_date_customer (date_key, customer_key),
    INDEX idx_product_store (product_key, store_key),
    INDEX idx_time_series (date_key, total_amount)
);

-- Dimension table (descriptive attributes)
CREATE TABLE customer_dimension (
    customer_key INT AUTO_INCREMENT PRIMARY KEY,
    customer_id VARCHAR(50) NOT NULL, -- Business key
    
    -- Current attributes (SCD Type 1)
    customer_name VARCHAR(255) NOT NULL,
    email VARCHAR(255),
    phone VARCHAR(20),
    
    -- Historical attributes (SCD Type 2)
    customer_segment VARCHAR(50),
    credit_rating VARCHAR(10),
    city VARCHAR(100),
    state VARCHAR(50),
    country VARCHAR(50),
    
    -- SCD metadata
    effective_date DATE NOT NULL,
    expiry_date DATE DEFAULT '9999-12-31',
    is_current BOOLEAN DEFAULT TRUE,
    version_number INT DEFAULT 1,
    
    -- Hierarchy support
    region VARCHAR(50),
    sales_territory VARCHAR(50),
    
    INDEX idx_customer_id (customer_id),
    INDEX idx_current (is_current),
    INDEX idx_effective_date (effective_date),
    INDEX idx_segment (customer_segment)
);

-- Data mart for specific business area
CREATE TABLE marketing_datamart AS
SELECT 
    dd.year,
    dd.quarter,
    dd.month_name,
    cd.customer_segment,
    cd.region,
    pd.product_category,
    
    -- Pre-aggregated metrics
    COUNT(DISTINCT sf.customer_key) as unique_customers,
    SUM(sf.total_amount) as total_revenue,
    AVG(sf.total_amount) as avg_order_value,
    SUM(sf.quantity_sold) as total_units,
    
    -- Calculated KPIs
    SUM(sf.total_amount) / COUNT(DISTINCT sf.customer_key) as revenue_per_customer,
    COUNT(sf.sale_id) / COUNT(DISTINCT sf.customer_key) as orders_per_customer
    
FROM sales_fact sf
JOIN date_dimension dd ON sf.date_key = dd.date_key
JOIN customer_dimension cd ON sf.customer_key = cd.customer_key
JOIN product_dimension pd ON sf.product_key = pd.product_key
WHERE dd.year &gt;= YEAR(CURDATE()) - 2
GROUP BY dd.year, dd.quarter, dd.month_name, cd.customer_segment, 
         cd.region, pd.product_category;
</code></pre>
</div>

<p><strong>2. Data Lake Structure (Schema-on-Read):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Raw%20data%20landing%20tables%20(minimal%20structure)%0ACREATE%20TABLE%20raw_customer_data%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20raw_data%20JSON%20NOT%20NULL%2C%0A%20%20%20%20file_path%20VARCHAR(500)%2C%0A%20%20%20%20file_format%20ENUM('JSON'%2C%20'CSV'%2C%20'XML'%2C%20'PARQUET'%2C%20'AVRO')%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source_system%20(source_system)%2C%0A%20%20%20%20INDEX%20idx_ingestion_timestamp%20(ingestion_timestamp)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Schema%20registry%20for%20data%20lake%0ACREATE%20TABLE%20data_lake_schemas%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20schema_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20schema_version%20VARCHAR(20)%20NOT%20NULL%2C%0A%20%20%20%20data_source%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20schema_definition%20JSON%20NOT%20NULL%2C%0A%20%20%20%20schema_evolution%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_schema_version%20(schema_name%2C%20schema_version)%2C%0A%20%20%20%20INDEX%20idx_data_source%20(data_source)%0A)%3B%0A%0A--%20Data%20lake%20catalog%0ACREATE%20TABLE%20data_lake_catalog%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20dataset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20dataset_path%20VARCHAR(1000)%20NOT%20NULL%2C%0A%20%20%20%20dataset_type%20ENUM('RAW'%2C%20'CLEANSED'%2C%20'CURATED'%2C%20'SANDBOX')%2C%0A%20%20%20%20data_format%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Schema%20information%0A%20%20%20%20schema_id%20INT%2C%0A%20%20%20%20inferred_schema%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Partitioning%20information%0A%20%20%20%20partition_columns%20JSON%2C%0A%20%20%20%20partition_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Statistics%0A%20%20%20%20record_count%20BIGINT%2C%0A%20%20%20%20file_count%20INT%2C%0A%20%20%20%20total_size_bytes%20BIGINT%2C%0A%20%20%20%20last_updated%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20data_owner%20VARCHAR(100)%2C%0A%20%20%20%20access_level%20ENUM('PUBLIC'%2C%20'RESTRICTED'%2C%20'CONFIDENTIAL')%2C%0A%20%20%20%20retention_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(schema_id)%20REFERENCES%20data_lake_schemas(id)%2C%0A%20%20%20%20INDEX%20idx_dataset_type%20(dataset_type)%2C%0A%20%20%20%20INDEX%20idx_data_owner%20(data_owner)%2C%0A%20%20%20%20INDEX%20idx_last_updated%20(last_updated)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Raw data landing tables (minimal structure)
CREATE TABLE raw_customer_data (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_system VARCHAR(100),
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    raw_data JSON NOT NULL,
    file_path VARCHAR(500),
    file_format ENUM('JSON', 'CSV', 'XML', 'PARQUET', 'AVRO'),
    data_quality_score DECIMAL(3,2),
    
    INDEX idx_source_system (source_system),
    INDEX idx_ingestion_timestamp (ingestion_timestamp),
    INDEX idx_data_quality (data_quality_score)
);

-- Schema registry for data lake
CREATE TABLE data_lake_schemas (
    id INT AUTO_INCREMENT PRIMARY KEY,
    schema_name VARCHAR(200) NOT NULL,
    schema_version VARCHAR(20) NOT NULL,
    data_source VARCHAR(100) NOT NULL,
    schema_definition JSON NOT NULL,
    schema_evolution JSON,
    
    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    is_active BOOLEAN DEFAULT TRUE,
    
    UNIQUE KEY uk_schema_version (schema_name, schema_version),
    INDEX idx_data_source (data_source)
);

-- Data lake catalog
CREATE TABLE data_lake_catalog (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    dataset_name VARCHAR(200) NOT NULL,
    dataset_path VARCHAR(1000) NOT NULL,
    dataset_type ENUM('RAW', 'CLEANSED', 'CURATED', 'SANDBOX'),
    data_format VARCHAR(50),
    
    -- Schema information
    schema_id INT,
    inferred_schema JSON,
    
    -- Partitioning information
    partition_columns JSON,
    partition_count INT,
    
    -- Statistics
    record_count BIGINT,
    file_count INT,
    total_size_bytes BIGINT,
    last_updated TIMESTAMP,
    
    -- Governance
    data_owner VARCHAR(100),
    access_level ENUM('PUBLIC', 'RESTRICTED', 'CONFIDENTIAL'),
    retention_days INT,
    
    FOREIGN KEY (schema_id) REFERENCES data_lake_schemas(id),
    INDEX idx_dataset_type (dataset_type),
    INDEX idx_data_owner (data_owner),
    INDEX idx_last_updated (last_updated)
);
</code></pre>
</div>

<p><strong>3. Hybrid Architecture (Data Lakehouse):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Delta%20tables%20combining%20lake%20flexibility%20with%20warehouse%20performance%0ACREATE%20TABLE%20delta_customer_events%20(%0A%20%20%20%20event_id%20VARCHAR(100)%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20VARCHAR(50)%20NOT%20NULL%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Flexible%20schema%20using%20JSON%0A%20%20%20%20event_properties%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Structured%20columns%20for%20common%20queries%0A%20%20%20%20session_id%20VARCHAR(100)%2C%0A%20%20%20%20page_url%20VARCHAR(500)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Partitioning%20columns%0A%20%20%20%20event_date%20DATE%20GENERATED%20ALWAYS%20AS%20(DATE(event_timestamp))%20STORED%2C%0A%20%20%20%20event_hour%20INT%20GENERATED%20ALWAYS%20AS%20(HOUR(event_timestamp))%20STORED%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%20metadata%0A%20%20%20%20data_version%20INT%20DEFAULT%201%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20source_file%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_date%20(customer_id%2C%20event_date)%2C%0A%20%20%20%20INDEX%20idx_event_type_timestamp%20(event_type%2C%20event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_session%20(session_id)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(event_date))%20(%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A%0A--%20Materialized%20views%20for%20performance%20(warehouse-like)%0ACREATE%20VIEW%20customer_behavior_summary%20AS%0ASELECT%20%0A%20%20%20%20customer_id%2C%0A%20%20%20%20event_date%2C%0A%20%20%20%20COUNT(*)%20as%20total_events%2C%0A%20%20%20%20COUNT(DISTINCT%20session_id)%20as%20sessions%2C%0A%20%20%20%20COUNT(DISTINCT%20event_type)%20as%20unique_event_types%2C%0A%20%20%20%20%0A%20%20%20%20--%20JSON%20aggregations%0A%20%20%20%20JSON_ARRAYAGG(DISTINCT%20event_type)%20as%20event_types%2C%0A%20%20%20%20JSON_OBJECTAGG(event_type%2C%20COUNT(*))%20as%20event_counts%2C%0A%20%20%20%20%0A%20%20%20%20--%20Time-based%20metrics%0A%20%20%20%20MIN(event_timestamp)%20as%20first_event%2C%0A%20%20%20%20MAX(event_timestamp)%20as%20last_event%2C%0A%20%20%20%20TIMESTAMPDIFF(MINUTE%2C%20MIN(event_timestamp)%2C%20MAX(event_timestamp))%20as%20session_duration_minutes%0A%20%20%20%20%0AFROM%20delta_customer_events%0AWHERE%20event_date%20%3E%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20customer_id%2C%20event_date%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Delta tables combining lake flexibility with warehouse performance
CREATE TABLE delta_customer_events (
    event_id VARCHAR(100) PRIMARY KEY,
    customer_id VARCHAR(50) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_timestamp TIMESTAMP NOT NULL,
    
    -- Flexible schema using JSON
    event_properties JSON,
    
    -- Structured columns for common queries
    session_id VARCHAR(100),
    page_url VARCHAR(500),
    user_agent TEXT,
    ip_address VARCHAR(45),
    
    -- Partitioning columns
    event_date DATE GENERATED ALWAYS AS (DATE(event_timestamp)) STORED,
    event_hour INT GENERATED ALWAYS AS (HOUR(event_timestamp)) STORED,
    
    -- Data quality metadata
    data_version INT DEFAULT 1,
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source_file VARCHAR(500),
    
    INDEX idx_customer_date (customer_id, event_date),
    INDEX idx_event_type_timestamp (event_type, event_timestamp),
    INDEX idx_session (session_id)
) PARTITION BY RANGE (YEAR(event_date)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- Materialized views for performance (warehouse-like)
CREATE VIEW customer_behavior_summary AS
SELECT 
    customer_id,
    event_date,
    COUNT(*) as total_events,
    COUNT(DISTINCT session_id) as sessions,
    COUNT(DISTINCT event_type) as unique_event_types,
    
    -- JSON aggregations
    JSON_ARRAYAGG(DISTINCT event_type) as event_types,
    JSON_OBJECTAGG(event_type, COUNT(*)) as event_counts,
    
    -- Time-based metrics
    MIN(event_timestamp) as first_event,
    MAX(event_timestamp) as last_event,
    TIMESTAMPDIFF(MINUTE, MIN(event_timestamp), MAX(event_timestamp)) as session_duration_minutes
    
FROM delta_customer_events
WHERE event_date &gt;= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
GROUP BY customer_id, event_date;
</code></pre>
</div>

<p><strong>4. Data Processing Patterns:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20for%20Data%20Warehouse%20(Transform%20then%20Load)%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20etl_process_sales_data()%0ABEGIN%0A%20%20%20%20DECLARE%20batch_date%20DATE%20DEFAULT%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20and%20transform%20in%20staging%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20staging_sales%20AS%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20--%20Standardize%20and%20clean%20data%0A%20%20%20%20%20%20%20%20UPPER(TRIM(customer_name))%20as%20customer_name%2C%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%2B%5D'%2C%20'')%20as%20clean_phone%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Business%20rule%20transformations%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20total_amount%20%3E%2010000%20THEN%20'HIGH_VALUE'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20total_amount%20%3E%201000%20THEN%20'MEDIUM_VALUE'%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'LOW_VALUE'%0A%20%20%20%20%20%20%20%20END%20as%20order_category%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Lookups%20and%20enrichment%0A%20%20%20%20%20%20%20%20(SELECT%20customer_key%20FROM%20customer_dimension%20%0A%20%20%20%20%20%20%20%20%20WHERE%20customer_id%20%3D%20raw_sales.customer_id%20AND%20is_current%20%3D%20TRUE)%20as%20customer_key%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Date%20dimension%20lookup%0A%20%20%20%20%20%20%20%20(SELECT%20date_key%20FROM%20date_dimension%20%0A%20%20%20%20%20%20%20%20%20WHERE%20full_date%20%3D%20DATE(raw_sales.order_timestamp))%20as%20date_key%2C%0A%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20*%0A%20%20%20%20FROM%20raw_sales_data%0A%20%20%20%20WHERE%20DATE(created_at)%20%3D%20batch_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Load%20into%20fact%20table%0A%20%20%20%20INSERT%20INTO%20sales_fact%20(%0A%20%20%20%20%20%20%20%20customer_key%2C%20date_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20quantity_sold%2C%20unit_price%2C%20total_amount%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20customer_key%2C%20date_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20quantity%2C%20price%2C%20total%0A%20%20%20%20FROM%20staging_sales%0A%20%20%20%20WHERE%20customer_key%20IS%20NOT%20NULL%20AND%20date_key%20IS%20NOT%20NULL%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20staging_sales%3B%0AEND%20%2F%2F%0A%0A--%20ELT%20for%20Data%20Lake%20(Load%20then%20Transform)%0ACREATE%20PROCEDURE%20elt_process_raw_events()%0ABEGIN%0A%20%20%20%20--%20Load%20raw%20data%20first%0A%20%20%20%20INSERT%20INTO%20raw_customer_events%20(source_system%2C%20raw_data%2C%20file_format)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'web_analytics'%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'timestamp'%2C%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'user_id'%2C%20user_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'event'%2C%20event_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'properties'%2C%20properties%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'metadata'%2C%20metadata%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20'JSON'%0A%20%20%20%20FROM%20external_event_stream%3B%0A%20%20%20%20%0A%20%20%20%20--%20Transform%20on-demand%20using%20views%0A%20%20%20%20CREATE%20OR%20REPLACE%20VIEW%20processed_events%20AS%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20id%2C%0A%20%20%20%20%20%20%20%20source_system%2C%0A%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.user_id'))%20as%20user_id%2C%0A%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.event'))%20as%20event_type%2C%0A%20%20%20%20%20%20%20%20STR_TO_DATE(JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.timestamp'))%2C%20'%25Y-%25m-%25d%20%25H%3A%25i%3A%25s')%20as%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(raw_data%2C%20'%24.properties')%20as%20event_properties%2C%0A%20%20%20%20%20%20%20%20ingestion_timestamp%0A%20%20%20%20FROM%20raw_customer_events%0A%20%20%20%20WHERE%20source_system%20%3D%20'web_analytics'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL for Data Warehouse (Transform then Load)
DELIMITER //
CREATE PROCEDURE etl_process_sales_data()
BEGIN
    DECLARE batch_date DATE DEFAULT CURDATE();
    
    -- Extract and transform in staging
    CREATE TEMPORARY TABLE staging_sales AS
    SELECT 
        -- Standardize and clean data
        UPPER(TRIM(customer_name)) as customer_name,
        REGEXP_REPLACE(phone, '[^0-9+]', '') as clean_phone,
        
        -- Business rule transformations
        CASE 
            WHEN total_amount &gt; 10000 THEN 'HIGH_VALUE'
            WHEN total_amount &gt; 1000 THEN 'MEDIUM_VALUE'
            ELSE 'LOW_VALUE'
        END as order_category,
        
        -- Lookups and enrichment
        (SELECT customer_key FROM customer_dimension 
         WHERE customer_id = raw_sales.customer_id AND is_current = TRUE) as customer_key,
        
        -- Date dimension lookup
        (SELECT date_key FROM date_dimension 
         WHERE full_date = DATE(raw_sales.order_timestamp)) as date_key,
         
        *
    FROM raw_sales_data
    WHERE DATE(created_at) = batch_date;
    
    -- Load into fact table
    INSERT INTO sales_fact (
        customer_key, date_key, product_key, store_key,
        quantity_sold, unit_price, total_amount
    )
    SELECT 
        customer_key, date_key, product_key, store_key,
        quantity, price, total
    FROM staging_sales
    WHERE customer_key IS NOT NULL AND date_key IS NOT NULL;
    
    DROP TEMPORARY TABLE staging_sales;
END //

-- ELT for Data Lake (Load then Transform)
CREATE PROCEDURE elt_process_raw_events()
BEGIN
    -- Load raw data first
    INSERT INTO raw_customer_events (source_system, raw_data, file_format)
    SELECT 
        'web_analytics',
        JSON_OBJECT(
            'timestamp', event_timestamp,
            'user_id', user_id,
            'event', event_name,
            'properties', properties,
            'metadata', metadata
        ),
        'JSON'
    FROM external_event_stream;
    
    -- Transform on-demand using views
    CREATE OR REPLACE VIEW processed_events AS
    SELECT 
        id,
        source_system,
        JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.user_id')) as user_id,
        JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.event')) as event_type,
        STR_TO_DATE(JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.timestamp')), '%Y-%m-%d %H:%i:%s') as event_timestamp,
        JSON_EXTRACT(raw_data, '$.properties') as event_properties,
        ingestion_timestamp
    FROM raw_customer_events
    WHERE source_system = 'web_analytics';
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Key Differences Summary:</strong></p>

<p>- <strong>Data Warehouse</strong>: Structured, schema-on-write, optimized for known queries, expensive storage</p>
<p>- <strong>Data Lake</strong>: Flexible, schema-on-read, supports all data types, cost-effective storage</p>
<p>- <strong>Data Lakehouse</strong>: Combines benefits of both, ACID transactions on data lake storage</p>


<p>---</p>

<h2 id="-384-how-do-you-handle-real-time-data-processing-">**384. How do you handle real-time data processing?**</h2>

<p><strong>Answer:</strong> Real-time data processing involves capturing, processing, and analyzing data as it arrives, using streaming architectures, change data capture, and event-driven systems for immediate insights and actions.</p>

<p><strong>Real-Time Architecture Components:</strong></p>

<p><strong>1. Change Data Capture (CDC) Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20CDC%20configuration%20table%0ACREATE%20TABLE%20cdc_configuration%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20cdc_enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_inserts%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_updates%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_deletes%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Streaming%20configuration%0A%20%20%20%20stream_destination%20VARCHAR(200)%2C%0A%20%20%20%20batch_size%20INT%20DEFAULT%201000%2C%0A%20%20%20%20flush_interval_seconds%20INT%20DEFAULT%205%2C%0A%20%20%20%20%0A%20%20%20%20--%20Filtering%0A%20%20%20%20column_filter%20JSON%2C%0A%20%20%20%20row_filter%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_name%20(table_name)%0A)%3B%0A%0A--%20CDC%20log%20table%0ACREATE%20TABLE%20cdc_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20operation_type%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20primary_key_value%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20data%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_columns%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20change_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20binlog_file%20VARCHAR(255)%2C%0A%20%20%20%20binlog_position%20BIGINT%2C%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processed%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20stream_offset%20BIGINT%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_operation%20(table_name%2C%20operation_type)%2C%0A%20%20%20%20INDEX%20idx_change_timestamp%20(change_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processed%20(processed)%2C%0A%20%20%20%20INDEX%20idx_primary_key%20(table_name%2C%20primary_key_value)%0A)%3B%0A%0A--%20CDC%20trigger%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_cdc_triggers(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_trigger_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20INSERT%20trigger%0A%20%20%20%20SET%20v_trigger_sql%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_cdc_insert%0A%20%20%20%20%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20cdc_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20operation_type%2C%20primary_key_value%2C%20new_values%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20''INSERT''%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_trigger_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20UPDATE%20trigger%0A%20%20%20%20SET%20v_trigger_sql%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_cdc_update%0A%20%20%20%20%20%20%20%20AFTER%20UPDATE%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20cdc_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20operation_type%2C%20primary_key_value%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20old_values%2C%20new_values%2C%20changed_columns%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20''UPDATE''%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20OLD.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAY('%2C%20--%20This%20would%20contain%20logic%20to%20detect%20changed%20columns%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_trigger_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- CDC configuration table
CREATE TABLE cdc_configuration (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    cdc_enabled BOOLEAN DEFAULT TRUE,
    capture_inserts BOOLEAN DEFAULT TRUE,
    capture_updates BOOLEAN DEFAULT TRUE,
    capture_deletes BOOLEAN DEFAULT TRUE,
    
    -- Streaming configuration
    stream_destination VARCHAR(200),
    batch_size INT DEFAULT 1000,
    flush_interval_seconds INT DEFAULT 5,
    
    -- Filtering
    column_filter JSON,
    row_filter TEXT,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_name (table_name)
);

-- CDC log table
CREATE TABLE cdc_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    operation_type ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    primary_key_value VARCHAR(255) NOT NULL,
    
    -- Change data
    old_values JSON,
    new_values JSON,
    changed_columns JSON,
    
    -- Metadata
    change_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    binlog_file VARCHAR(255),
    binlog_position BIGINT,
    transaction_id VARCHAR(100),
    
    -- Processing status
    processed BOOLEAN DEFAULT FALSE,
    processed_at TIMESTAMP NULL,
    stream_offset BIGINT,
    
    INDEX idx_table_operation (table_name, operation_type),
    INDEX idx_change_timestamp (change_timestamp),
    INDEX idx_processed (processed),
    INDEX idx_primary_key (table_name, primary_key_value)
);

-- CDC trigger implementation
DELIMITER //
CREATE PROCEDURE create_cdc_triggers(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE v_trigger_sql TEXT;
    
    -- INSERT trigger
    SET v_trigger_sql = CONCAT('
        CREATE TRIGGER ', p_table_name, '_cdc_insert
        AFTER INSERT ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO cdc_log (
                table_name, operation_type, primary_key_value, new_values
            ) VALUES (
                ''', p_table_name, ''', ''INSERT'', NEW.id,
                JSON_OBJECT(', 
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', NEW.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                ')
            );
        END'
    );
    
    SET @sql = v_trigger_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- UPDATE trigger
    SET v_trigger_sql = CONCAT('
        CREATE TRIGGER ', p_table_name, '_cdc_update
        AFTER UPDATE ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO cdc_log (
                table_name, operation_type, primary_key_value, 
                old_values, new_values, changed_columns
            ) VALUES (
                ''', p_table_name, ''', ''UPDATE'', NEW.id,
                JSON_OBJECT(', 
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', OLD.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                '),
                JSON_OBJECT(',
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', NEW.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                '),
                JSON_ARRAY(', -- This would contain logic to detect changed columns
                ')
            );
        END'
    );
    
    SET @sql = v_trigger_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Event Streaming Infrastructure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Event%20stream%20configuration%0ACREATE%20TABLE%20event_streams%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20stream_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20stream_type%20ENUM('CDC'%2C%20'APPLICATION'%2C%20'SENSOR'%2C%20'LOG')%20NOT%20NULL%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stream%20properties%0A%20%20%20%20partition_key%20VARCHAR(100)%2C%0A%20%20%20%20retention_hours%20INT%20DEFAULT%20168%2C%20--%207%20days%0A%20%20%20%20compression_type%20ENUM('NONE'%2C%20'GZIP'%2C%20'SNAPPY')%20DEFAULT%20'SNAPPY'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20configuration%0A%20%20%20%20consumer_groups%20JSON%2C%0A%20%20%20%20processing_lag_threshold_seconds%20INT%20DEFAULT%2060%2C%0A%20%20%20%20%0A%20%20%20%20--%20Monitoring%0A%20%20%20%20events_per_second%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_event_timestamp%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_stream_name%20(stream_name)%2C%0A%20%20%20%20INDEX%20idx_stream_type%20(stream_type)%0A)%3B%0A%0A--%20Real-time%20event%20processing%0ACREATE%20TABLE%20real_time_events%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20stream_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP(6)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Event%20payload%0A%20%20%20%20event_data%20JSON%20NOT%20NULL%2C%0A%20%20%20%20event_schema_version%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20metadata%0A%20%20%20%20partition_key%20VARCHAR(255)%2C%0A%20%20%20%20offset_position%20BIGINT%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processing_status%20ENUM('PENDING'%2C%20'PROCESSING'%2C%20'COMPLETED'%2C%20'FAILED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_stream_timestamp%20(stream_name%2C%20event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_partition_offset%20(partition_key%2C%20offset_position)%0A)%3B%0A%0A--%20Real-time%20aggregations%0ACREATE%20TABLE%20real_time_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20time_window%20ENUM('1MIN'%2C%20'5MIN'%2C%20'15MIN'%2C%20'1HOUR')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metric%20values%0A%20%20%20%20metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_count%20BIGINT%2C%0A%20%20%20%20metric_sum%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_avg%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_min%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_max%20DECIMAL(15%2C4)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Dimensions%0A%20%20%20%20dimensions%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20calculated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20data_points_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_metric_time_window%20(metric_name%2C%20metric_timestamp%2C%20time_window%2C%20dimensions(255))%2C%0A%20%20%20%20INDEX%20idx_metric_timestamp%20(metric_name%2C%20metric_timestamp)%2C%0A%20%20%20%20INDEX%20idx_time_window%20(time_window)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Event stream configuration
CREATE TABLE event_streams (
    id INT AUTO_INCREMENT PRIMARY KEY,
    stream_name VARCHAR(100) NOT NULL,
    stream_type ENUM('CDC', 'APPLICATION', 'SENSOR', 'LOG') NOT NULL,
    source_table VARCHAR(100),
    
    -- Stream properties
    partition_key VARCHAR(100),
    retention_hours INT DEFAULT 168, -- 7 days
    compression_type ENUM('NONE', 'GZIP', 'SNAPPY') DEFAULT 'SNAPPY',
    
    -- Processing configuration
    consumer_groups JSON,
    processing_lag_threshold_seconds INT DEFAULT 60,
    
    -- Monitoring
    events_per_second DECIMAL(10,2),
    last_event_timestamp TIMESTAMP,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_stream_name (stream_name),
    INDEX idx_stream_type (stream_type)
);

-- Real-time event processing
CREATE TABLE real_time_events (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    stream_name VARCHAR(100) NOT NULL,
    event_id VARCHAR(255) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_timestamp TIMESTAMP(6) NOT NULL,
    
    -- Event payload
    event_data JSON NOT NULL,
    event_schema_version VARCHAR(20),
    
    -- Processing metadata
    partition_key VARCHAR(255),
    offset_position BIGINT,
    ingestion_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    
    -- Processing status
    processing_status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING',
    processed_at TIMESTAMP NULL,
    error_message TEXT,
    retry_count INT DEFAULT 0,
    
    INDEX idx_stream_timestamp (stream_name, event_timestamp),
    INDEX idx_processing_status (processing_status),
    INDEX idx_event_type (event_type),
    INDEX idx_partition_offset (partition_key, offset_position)
);

-- Real-time aggregations
CREATE TABLE real_time_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_timestamp TIMESTAMP NOT NULL,
    time_window ENUM('1MIN', '5MIN', '15MIN', '1HOUR') NOT NULL,
    
    -- Metric values
    metric_value DECIMAL(15,4),
    metric_count BIGINT,
    metric_sum DECIMAL(15,4),
    metric_avg DECIMAL(15,4),
    metric_min DECIMAL(15,4),
    metric_max DECIMAL(15,4),
    
    -- Dimensions
    dimensions JSON,
    
    -- Metadata
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    data_points_count INT,
    
    UNIQUE KEY uk_metric_time_window (metric_name, metric_timestamp, time_window, dimensions(255)),
    INDEX idx_metric_timestamp (metric_name, metric_timestamp),
    INDEX idx_time_window (time_window)
);
</code></pre>
</div>

<p><strong>3. Stream Processing Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Stream%20processor%20for%20real-time%20analytics%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20process_real_time_events()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_event_id%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_stream_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_event_type%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_event_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_event_timestamp%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20event_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20stream_name%2C%20event_type%2C%20event_data%2C%20event_timestamp%0A%20%20%20%20%20%20%20%20FROM%20real_time_events%0A%20%20%20%20%20%20%20%20WHERE%20processing_status%20%3D%20'PENDING'%0A%20%20%20%20%20%20%20%20ORDER%20BY%20event_timestamp%0A%20%20%20%20%20%20%20%20LIMIT%201000%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20event_cursor%3B%0A%20%20%20%20%0A%20%20%20%20processing_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20event_cursor%20INTO%20v_event_id%2C%20v_stream_name%2C%20v_event_type%2C%20v_event_data%2C%20v_event_timestamp%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20processing_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20processing%20status%0A%20%20%20%20%20%20%20%20UPDATE%20real_time_events%20%0A%20%20%20%20%20%20%20%20SET%20processing_status%20%3D%20'PROCESSING'%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_event_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Process%20based%20on%20event%20type%0A%20%20%20%20%20%20%20%20CASE%20v_event_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'user_action'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_user_action_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'transaction'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_transaction_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'system_metric'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_system_metric_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_generic_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20completed%0A%20%20%20%20%20%20%20%20UPDATE%20real_time_events%20%0A%20%20%20%20%20%20%20%20SET%20processing_status%20%3D%20'COMPLETED'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_event_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20event_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Process%20user%20action%20events%0ACREATE%20PROCEDURE%20process_user_action_event(%0A%20%20%20%20IN%20p_event_id%20BIGINT%2C%0A%20%20%20%20IN%20p_event_data%20JSON%2C%0A%20%20%20%20IN%20p_event_timestamp%20TIMESTAMP%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_user_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_action_type%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_session_id%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20event%20data%0A%20%20%20%20SET%20v_user_id%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.user_id'))%3B%0A%20%20%20%20SET%20v_action_type%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.action'))%3B%0A%20%20%20%20SET%20v_session_id%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.session_id'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20real-time%20user%20session%0A%20%20%20%20INSERT%20INTO%20user_sessions%20(%0A%20%20%20%20%20%20%20%20user_id%2C%20session_id%2C%20last_activity%2C%20action_count%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_user_id%2C%20v_session_id%2C%20p_event_timestamp%2C%201%0A%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20last_activity%20%3D%20p_event_timestamp%2C%0A%20%20%20%20%20%20%20%20action_count%20%3D%20action_count%20%2B%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20real-time%20metrics%0A%20%20%20%20CALL%20update_real_time_metric('user_actions_per_minute'%2C%201%2C%20p_event_timestamp%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('action_type'%2C%20v_action_type))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Trigger%20alerts%20if%20needed%0A%20%20%20%20IF%20v_action_type%20%3D%20'purchase'%20THEN%0A%20%20%20%20%20%20%20%20CALL%20check_purchase_alerts(v_user_id%2C%20p_event_data)%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Update%20real-time%20metrics%20with%20windowing%0ACREATE%20PROCEDURE%20update_real_time_metric(%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20IN%20p_timestamp%20TIMESTAMP%2C%0A%20%20%20%20IN%20p_dimensions%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_1min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_5min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_15min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_1hour_window%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Calculate%20time%20windows%0A%20%20%20%20SET%20v_1min_window%20%3D%20DATE_FORMAT(p_timestamp%2C%20'%25Y-%25m-%25d%20%25H%3A%25i%3A00')%3B%0A%20%20%20%20SET%20v_5min_window%20%3D%20FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp)%20%2F%20300)%20*%20300)%3B%0A%20%20%20%20SET%20v_15min_window%20%3D%20FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp)%20%2F%20900)%20*%20900)%3B%0A%20%20%20%20SET%20v_1hour_window%20%3D%20DATE_FORMAT(p_timestamp%2C%20'%25Y-%25m-%25d%20%25H%3A00%3A00')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%201-minute%20window%0A%20%20%20%20INSERT%20INTO%20real_time_metrics%20(%0A%20%20%20%20%20%20%20%20metric_name%2C%20metric_timestamp%2C%20time_window%2C%20metric_value%2C%20%0A%20%20%20%20%20%20%20%20metric_count%2C%20metric_sum%2C%20dimensions%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_metric_name%2C%20v_1min_window%2C%20'1MIN'%2C%20p_metric_value%2C%201%2C%20p_metric_value%2C%20p_dimensions%0A%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20metric_count%20%3D%20metric_count%20%2B%201%2C%0A%20%20%20%20%20%20%20%20metric_sum%20%3D%20metric_sum%20%2B%20p_metric_value%2C%0A%20%20%20%20%20%20%20%20metric_avg%20%3D%20metric_sum%20%2F%20metric_count%2C%0A%20%20%20%20%20%20%20%20metric_min%20%3D%20LEAST(metric_min%2C%20p_metric_value)%2C%0A%20%20%20%20%20%20%20%20metric_max%20%3D%20GREATEST(metric_max%2C%20p_metric_value)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20other%20windows%20similarly...%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Stream processor for real-time analytics
DELIMITER //
CREATE PROCEDURE process_real_time_events()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_event_id BIGINT;
    DECLARE v_stream_name VARCHAR(100);
    DECLARE v_event_type VARCHAR(100);
    DECLARE v_event_data JSON;
    DECLARE v_event_timestamp TIMESTAMP;
    
    DECLARE event_cursor CURSOR FOR
        SELECT id, stream_name, event_type, event_data, event_timestamp
        FROM real_time_events
        WHERE processing_status = 'PENDING'
        ORDER BY event_timestamp
        LIMIT 1000;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN event_cursor;
    
    processing_loop: LOOP
        FETCH event_cursor INTO v_event_id, v_stream_name, v_event_type, v_event_data, v_event_timestamp;
        
        IF done THEN
            LEAVE processing_loop;
        END IF;
        
        -- Update processing status
        UPDATE real_time_events 
        SET processing_status = 'PROCESSING'
        WHERE id = v_event_id;
        
        -- Process based on event type
        CASE v_event_type
            WHEN 'user_action' THEN
                CALL process_user_action_event(v_event_id, v_event_data, v_event_timestamp);
            
            WHEN 'transaction' THEN
                CALL process_transaction_event(v_event_id, v_event_data, v_event_timestamp);
            
            WHEN 'system_metric' THEN
                CALL process_system_metric_event(v_event_id, v_event_data, v_event_timestamp);
            
            ELSE
                CALL process_generic_event(v_event_id, v_event_data, v_event_timestamp);
        END CASE;
        
        -- Mark as completed
        UPDATE real_time_events 
        SET processing_status = 'COMPLETED',
            processed_at = NOW()
        WHERE id = v_event_id;
        
    END LOOP;
    
    CLOSE event_cursor;
END //

-- Process user action events
CREATE PROCEDURE process_user_action_event(
    IN p_event_id BIGINT,
    IN p_event_data JSON,
    IN p_event_timestamp TIMESTAMP
)
BEGIN
    DECLARE v_user_id VARCHAR(100);
    DECLARE v_action_type VARCHAR(100);
    DECLARE v_session_id VARCHAR(100);
    
    -- Extract event data
    SET v_user_id = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.user_id'));
    SET v_action_type = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.action'));
    SET v_session_id = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.session_id'));
    
    -- Update real-time user session
    INSERT INTO user_sessions (
        user_id, session_id, last_activity, action_count
    ) VALUES (
        v_user_id, v_session_id, p_event_timestamp, 1
    ) ON DUPLICATE KEY UPDATE
        last_activity = p_event_timestamp,
        action_count = action_count + 1;
    
    -- Update real-time metrics
    CALL update_real_time_metric('user_actions_per_minute', 1, p_event_timestamp, 
                                JSON_OBJECT('action_type', v_action_type));
    
    -- Trigger alerts if needed
    IF v_action_type = 'purchase' THEN
        CALL check_purchase_alerts(v_user_id, p_event_data);
    END IF;
    
END //

-- Update real-time metrics with windowing
CREATE PROCEDURE update_real_time_metric(
    IN p_metric_name VARCHAR(100),
    IN p_metric_value DECIMAL(15,4),
    IN p_timestamp TIMESTAMP,
    IN p_dimensions JSON
)
BEGIN
    DECLARE v_1min_window TIMESTAMP;
    DECLARE v_5min_window TIMESTAMP;
    DECLARE v_15min_window TIMESTAMP;
    DECLARE v_1hour_window TIMESTAMP;
    
    -- Calculate time windows
    SET v_1min_window = DATE_FORMAT(p_timestamp, '%Y-%m-%d %H:%i:00');
    SET v_5min_window = FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp) / 300) * 300);
    SET v_15min_window = FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp) / 900) * 900);
    SET v_1hour_window = DATE_FORMAT(p_timestamp, '%Y-%m-%d %H:00:00');
    
    -- Update 1-minute window
    INSERT INTO real_time_metrics (
        metric_name, metric_timestamp, time_window, metric_value, 
        metric_count, metric_sum, dimensions
    ) VALUES (
        p_metric_name, v_1min_window, '1MIN', p_metric_value, 1, p_metric_value, p_dimensions
    ) ON DUPLICATE KEY UPDATE
        metric_count = metric_count + 1,
        metric_sum = metric_sum + p_metric_value,
        metric_avg = metric_sum / metric_count,
        metric_min = LEAST(metric_min, p_metric_value),
        metric_max = GREATEST(metric_max, p_metric_value);
    
    -- Update other windows similarly...
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Real-Time Alerting System:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Real-time%20alert%20rules%0ACREATE%20TABLE%20alert_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20condition_type%20ENUM('THRESHOLD'%2C%20'ANOMALY'%2C%20'TREND'%2C%20'PATTERN')%20NOT%20NULL%2C%0A%20%20%20%20condition_config%20JSON%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Alert%20configuration%0A%20%20%20%20severity%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20DEFAULT%20'WARNING'%2C%0A%20%20%20%20notification_channels%20JSON%2C%0A%20%20%20%20cooldown_minutes%20INT%20DEFAULT%2015%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20last_triggered%20TIMESTAMP%20NULL%2C%0A%20%20%20%20trigger_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_name%20(metric_name)%2C%0A%20%20%20%20INDEX%20idx_is_active%20(is_active)%0A)%3B%0A%0A--%20Real-time%20alert%20processing%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20check_real_time_alerts()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_id%20INT%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_metric_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_condition_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_condition_config%20JSON%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_cooldown_minutes%20INT%3B%0A%20%20%20%20DECLARE%20v_last_triggered%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20alert_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20rule_name%2C%20metric_name%2C%20condition_type%2C%20condition_config%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20severity%2C%20cooldown_minutes%2C%20last_triggered%0A%20%20%20%20%20%20%20%20FROM%20alert_rules%0A%20%20%20%20%20%20%20%20WHERE%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20alert_cursor%3B%0A%20%20%20%20%0A%20%20%20%20alert_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20alert_cursor%20INTO%20v_rule_id%2C%20v_rule_name%2C%20v_metric_name%2C%20v_condition_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_condition_config%2C%20v_severity%2C%20v_cooldown_minutes%2C%20v_last_triggered%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20alert_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Check%20cooldown%20period%0A%20%20%20%20%20%20%20%20IF%20v_last_triggered%20IS%20NOT%20NULL%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(MINUTE%2C%20v_last_triggered%2C%20NOW())%20%3C%20v_cooldown_minutes%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20ITERATE%20alert_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Evaluate%20alert%20condition%0A%20%20%20%20%20%20%20%20CASE%20v_condition_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'THRESHOLD'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_threshold_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ANOMALY'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_anomaly_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'TREND'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_trend_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20alert_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Threshold-based%20alerting%0ACREATE%20PROCEDURE%20check_threshold_alert(%0A%20%20%20%20IN%20p_rule_id%20INT%2C%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_condition_config%20JSON%2C%0A%20%20%20%20IN%20p_severity%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20v_operator%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_time_window%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_current_value%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20v_alert_triggered%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20configuration%0A%20%20%20%20SET%20v_threshold%20%3D%20JSON_EXTRACT(p_condition_config%2C%20'%24.threshold')%3B%0A%20%20%20%20SET%20v_operator%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_condition_config%2C%20'%24.operator'))%3B%0A%20%20%20%20SET%20v_time_window%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_condition_config%2C%20'%24.time_window'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20metric%20value%0A%20%20%20%20SELECT%20metric_avg%20INTO%20v_current_value%0A%20%20%20%20FROM%20real_time_metrics%0A%20%20%20%20WHERE%20metric_name%20%3D%20p_metric_name%0A%20%20%20%20AND%20time_window%20%3D%20v_time_window%0A%20%20%20%20AND%20metric_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%205%20MINUTE)%0A%20%20%20%20ORDER%20BY%20metric_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Evaluate%20condition%0A%20%20%20%20CASE%20v_operator%0A%20%20%20%20%20%20%20%20WHEN%20'%3E'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3E%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3C'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3C%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3E%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3E%3D%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3C%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3C%3D%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3D%20v_threshold)%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Trigger%20alert%20if%20condition%20met%0A%20%20%20%20IF%20v_alert_triggered%20THEN%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20alert_instances%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20metric_name%2C%20alert_value%2C%20threshold_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20severity%2C%20triggered_at%2C%20status%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_rule_id%2C%20p_metric_name%2C%20v_current_value%2C%20v_threshold%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_severity%2C%20NOW()%2C%20'ACTIVE'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20rule%20trigger%20info%0A%20%20%20%20%20%20%20%20UPDATE%20alert_rules%0A%20%20%20%20%20%20%20%20SET%20last_triggered%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20trigger_count%20%3D%20trigger_count%20%2B%201%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20p_rule_id%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Real-time alert rules
CREATE TABLE alert_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(200) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    condition_type ENUM('THRESHOLD', 'ANOMALY', 'TREND', 'PATTERN') NOT NULL,
    condition_config JSON NOT NULL,
    
    -- Alert configuration
    severity ENUM('INFO', 'WARNING', 'CRITICAL') DEFAULT 'WARNING',
    notification_channels JSON,
    cooldown_minutes INT DEFAULT 15,
    
    -- Status
    is_active BOOLEAN DEFAULT TRUE,
    last_triggered TIMESTAMP NULL,
    trigger_count INT DEFAULT 0,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_name (metric_name),
    INDEX idx_is_active (is_active)
);

-- Real-time alert processing
DELIMITER //
CREATE PROCEDURE check_real_time_alerts()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_id INT;
    DECLARE v_rule_name VARCHAR(200);
    DECLARE v_metric_name VARCHAR(100);
    DECLARE v_condition_type VARCHAR(20);
    DECLARE v_condition_config JSON;
    DECLARE v_severity VARCHAR(20);
    DECLARE v_cooldown_minutes INT;
    DECLARE v_last_triggered TIMESTAMP;
    
    DECLARE alert_cursor CURSOR FOR
        SELECT id, rule_name, metric_name, condition_type, condition_config,
               severity, cooldown_minutes, last_triggered
        FROM alert_rules
        WHERE is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN alert_cursor;
    
    alert_loop: LOOP
        FETCH alert_cursor INTO v_rule_id, v_rule_name, v_metric_name, v_condition_type,
                               v_condition_config, v_severity, v_cooldown_minutes, v_last_triggered;
        
        IF done THEN
            LEAVE alert_loop;
        END IF;
        
        -- Check cooldown period
        IF v_last_triggered IS NOT NULL AND 
           TIMESTAMPDIFF(MINUTE, v_last_triggered, NOW()) &lt; v_cooldown_minutes THEN
            ITERATE alert_loop;
        END IF;
        
        -- Evaluate alert condition
        CASE v_condition_type
            WHEN 'THRESHOLD' THEN
                CALL check_threshold_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
            
            WHEN 'ANOMALY' THEN
                CALL check_anomaly_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
            
            WHEN 'TREND' THEN
                CALL check_trend_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
        END CASE;
        
    END LOOP;
    
    CLOSE alert_cursor;
END //

-- Threshold-based alerting
CREATE PROCEDURE check_threshold_alert(
    IN p_rule_id INT,
    IN p_metric_name VARCHAR(100),
    IN p_condition_config JSON,
    IN p_severity VARCHAR(20)
)
BEGIN
    DECLARE v_threshold DECIMAL(15,4);
    DECLARE v_operator VARCHAR(10);
    DECLARE v_time_window VARCHAR(10);
    DECLARE v_current_value DECIMAL(15,4);
    DECLARE v_alert_triggered BOOLEAN DEFAULT FALSE;
    
    -- Extract configuration
    SET v_threshold = JSON_EXTRACT(p_condition_config, '$.threshold');
    SET v_operator = JSON_UNQUOTE(JSON_EXTRACT(p_condition_config, '$.operator'));
    SET v_time_window = JSON_UNQUOTE(JSON_EXTRACT(p_condition_config, '$.time_window'));
    
    -- Get current metric value
    SELECT metric_avg INTO v_current_value
    FROM real_time_metrics
    WHERE metric_name = p_metric_name
    AND time_window = v_time_window
    AND metric_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 5 MINUTE)
    ORDER BY metric_timestamp DESC
    LIMIT 1;
    
    -- Evaluate condition
    CASE v_operator
        WHEN '&gt;' THEN SET v_alert_triggered = (v_current_value &gt; v_threshold);
        WHEN '&lt;' THEN SET v_alert_triggered = (v_current_value &lt; v_threshold);
        WHEN '&gt;=' THEN SET v_alert_triggered = (v_current_value &gt;= v_threshold);
        WHEN '&lt;=' THEN SET v_alert_triggered = (v_current_value &lt;= v_threshold);
        WHEN '=' THEN SET v_alert_triggered = (v_current_value = v_threshold);
    END CASE;
    
    -- Trigger alert if condition met
    IF v_alert_triggered THEN
        INSERT INTO alert_instances (
            rule_id, metric_name, alert_value, threshold_value,
            severity, triggered_at, status
        ) VALUES (
            p_rule_id, p_metric_name, v_current_value, v_threshold,
            p_severity, NOW(), 'ACTIVE'
        );
        
        -- Update rule trigger info
        UPDATE alert_rules
        SET last_triggered = NOW(),
            trigger_count = trigger_count + 1
        WHERE id = p_rule_id;
    END IF;
    
END //

DELIMITER ;
</code></pre>
</div>

<p>This completes the real-time data processing implementation with CDC, streaming, and alerting capabilities.</p>

<p>---</p>

<h2 id="-385-what-are-data-integration-patterns-and-etl-vs-elt-">**385. What are data integration patterns and ETL vs ELT?**</h2>

<p><strong>Answer:</strong> Data integration patterns define how data flows between systems, with ETL (Extract-Transform-Load) processing data before storage and ELT (Extract-Load-Transform) storing raw data first then transforming as needed.</p>

<p><strong>ETL Pattern Implementation:</strong></p>

<p><strong>1. Traditional ETL Pipeline:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20staging%20and%20control%20tables%0ACREATE%20TABLE%20etl_job_control%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20job_type%20ENUM('EXTRACT'%2C%20'TRANSFORM'%2C%20'LOAD'%2C%20'FULL_ETL')%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20target_system%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Execution%20control%0A%20%20%20%20schedule_expression%20VARCHAR(100)%2C%20--%20Cron%20expression%0A%20%20%20%20max_runtime_minutes%20INT%20DEFAULT%2060%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%203%2C%0A%20%20%20%20dependency_jobs%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%20tracking%0A%20%20%20%20last_run_start%20TIMESTAMP%20NULL%2C%0A%20%20%20%20last_run_end%20TIMESTAMP%20NULL%2C%0A%20%20%20%20last_run_status%20ENUM('SUCCESS'%2C%20'FAILED'%2C%20'RUNNING'%2C%20'CANCELLED')%2C%0A%20%20%20%20last_run_records_processed%20BIGINT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Configuration%0A%20%20%20%20job_parameters%20JSON%2C%0A%20%20%20%20notification_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_job_name%20(job_name)%2C%0A%20%20%20%20INDEX%20idx_job_type%20(job_type)%2C%0A%20%20%20%20INDEX%20idx_last_run_status%20(last_run_status)%0A)%3B%0A%0A--%20ETL%20execution%20log%0ACREATE%20TABLE%20etl_execution_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20execution_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Execution%20details%0A%20%20%20%20started_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20completed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20status%20ENUM('RUNNING'%2C%20'SUCCESS'%2C%20'FAILED'%2C%20'CANCELLED')%20DEFAULT%20'RUNNING'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metrics%0A%20%20%20%20records_extracted%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_transformed%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_loaded%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_rejected%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Error%20handling%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20error_details%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Performance%0A%20%20%20%20extraction_duration_seconds%20INT%2C%0A%20%20%20%20transformation_duration_seconds%20INT%2C%0A%20%20%20%20loading_duration_seconds%20INT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(job_id)%20REFERENCES%20etl_job_control(id)%2C%0A%20%20%20%20INDEX%20idx_execution_id%20(execution_id)%2C%0A%20%20%20%20INDEX%20idx_started_at%20(started_at)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A%0A--%20ETL%20transformation%20rules%0ACREATE%20TABLE%20etl_transformation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20rule_order%20INT%20NOT%20NULL%2C%0A%20%20%20%20rule_type%20ENUM('VALIDATION'%2C%20'CLEANSING'%2C%20'ENRICHMENT'%2C%20'AGGREGATION'%2C%20'BUSINESS_RULE')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rule%20definition%0A%20%20%20%20source_columns%20JSON%2C%0A%20%20%20%20target_columns%20JSON%2C%0A%20%20%20%20transformation_logic%20TEXT%2C%0A%20%20%20%20validation_criteria%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Error%20handling%0A%20%20%20%20on_error_action%20ENUM('REJECT'%2C%20'DEFAULT'%2C%20'SKIP'%2C%20'FAIL_JOB')%20DEFAULT%20'REJECT'%2C%0A%20%20%20%20default_value%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(job_id)%20REFERENCES%20etl_job_control(id)%2C%0A%20%20%20%20INDEX%20idx_job_order%20(job_id%2C%20rule_order)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL staging and control tables
CREATE TABLE etl_job_control (
    id INT AUTO_INCREMENT PRIMARY KEY,
    job_name VARCHAR(100) NOT NULL,
    job_type ENUM('EXTRACT', 'TRANSFORM', 'LOAD', 'FULL_ETL') NOT NULL,
    source_system VARCHAR(100),
    target_system VARCHAR(100),
    
    -- Execution control
    schedule_expression VARCHAR(100), -- Cron expression
    max_runtime_minutes INT DEFAULT 60,
    retry_count INT DEFAULT 3,
    dependency_jobs JSON,
    
    -- Status tracking
    last_run_start TIMESTAMP NULL,
    last_run_end TIMESTAMP NULL,
    last_run_status ENUM('SUCCESS', 'FAILED', 'RUNNING', 'CANCELLED'),
    last_run_records_processed BIGINT,
    
    -- Configuration
    job_parameters JSON,
    notification_config JSON,
    
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_job_name (job_name),
    INDEX idx_job_type (job_type),
    INDEX idx_last_run_status (last_run_status)
);

-- ETL execution log
CREATE TABLE etl_execution_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    job_id INT NOT NULL,
    execution_id VARCHAR(100) NOT NULL,
    
    -- Execution details
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP NULL,
    status ENUM('RUNNING', 'SUCCESS', 'FAILED', 'CANCELLED') DEFAULT 'RUNNING',
    
    -- Metrics
    records_extracted BIGINT DEFAULT 0,
    records_transformed BIGINT DEFAULT 0,
    records_loaded BIGINT DEFAULT 0,
    records_rejected BIGINT DEFAULT 0,
    
    -- Error handling
    error_message TEXT,
    error_details JSON,
    
    -- Performance
    extraction_duration_seconds INT,
    transformation_duration_seconds INT,
    loading_duration_seconds INT,
    
    FOREIGN KEY (job_id) REFERENCES etl_job_control(id),
    INDEX idx_execution_id (execution_id),
    INDEX idx_started_at (started_at),
    INDEX idx_status (status)
);

-- ETL transformation rules
CREATE TABLE etl_transformation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    job_id INT NOT NULL,
    rule_name VARCHAR(200) NOT NULL,
    rule_order INT NOT NULL,
    rule_type ENUM('VALIDATION', 'CLEANSING', 'ENRICHMENT', 'AGGREGATION', 'BUSINESS_RULE'),
    
    -- Rule definition
    source_columns JSON,
    target_columns JSON,
    transformation_logic TEXT,
    validation_criteria TEXT,
    
    -- Error handling
    on_error_action ENUM('REJECT', 'DEFAULT', 'SKIP', 'FAIL_JOB') DEFAULT 'REJECT',
    default_value VARCHAR(500),
    
    is_active BOOLEAN DEFAULT TRUE,
    
    FOREIGN KEY (job_id) REFERENCES etl_job_control(id),
    INDEX idx_job_order (job_id, rule_order)
);
</code></pre>
</div>

<p><strong>2. ETL Processing Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20ETL%20orchestrator%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_etl_job(IN%20p_job_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_job_id%20INT%3B%0A%20%20%20%20DECLARE%20v_execution_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_source_system%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_target_system%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_job_parameters%20JSON%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20UPDATE%20etl_execution_log%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'FAILED'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20completed_at%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20error_message%20%3D%20'ETL%20job%20failed%20with%20SQL%20exception'%0A%20%20%20%20%20%20%20%20WHERE%20execution_id%20%3D%20v_execution_id%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20job%20configuration%0A%20%20%20%20SELECT%20id%2C%20source_system%2C%20target_system%2C%20job_parameters%0A%20%20%20%20INTO%20v_job_id%2C%20v_source_system%2C%20v_target_system%2C%20v_job_parameters%0A%20%20%20%20FROM%20etl_job_control%0A%20%20%20%20WHERE%20job_name%20%3D%20p_job_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_job_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'ETL%20job%20not%20found%20or%20inactive'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20execution%20ID%0A%20%20%20%20SET%20v_execution_id%20%3D%20CONCAT(p_job_name%2C%20'_'%2C%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20execution%20start%0A%20%20%20%20INSERT%20INTO%20etl_execution_log%20(job_id%2C%20execution_id%2C%20started_at)%0A%20%20%20%20VALUES%20(v_job_id%2C%20v_execution_id%2C%20v_start_time)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20ETL%20phases%0A%20%20%20%20CALL%20etl_extract_phase(v_job_id%2C%20v_execution_id%2C%20v_source_system%2C%20v_job_parameters)%3B%0A%20%20%20%20CALL%20etl_transform_phase(v_job_id%2C%20v_execution_id%2C%20v_job_parameters)%3B%0A%20%20%20%20CALL%20etl_load_phase(v_job_id%2C%20v_execution_id%2C%20v_target_system%2C%20v_job_parameters)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20completion%20status%0A%20%20%20%20UPDATE%20etl_execution_log%20%0A%20%20%20%20SET%20status%20%3D%20'SUCCESS'%2C%0A%20%20%20%20%20%20%20%20completed_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20execution_id%20%3D%20v_execution_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20job%20control%0A%20%20%20%20UPDATE%20etl_job_control%0A%20%20%20%20SET%20last_run_start%20%3D%20v_start_time%2C%0A%20%20%20%20%20%20%20%20last_run_end%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20last_run_status%20%3D%20'SUCCESS'%2C%0A%20%20%20%20%20%20%20%20last_run_records_processed%20%3D%20v_records_processed%0A%20%20%20%20WHERE%20id%20%3D%20v_job_id%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20ETL%20Transform%20Phase%0ACREATE%20PROCEDURE%20etl_transform_phase(%0A%20%20%20%20IN%20p_job_id%20INT%2C%0A%20%20%20%20IN%20p_execution_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_job_parameters%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_id%20INT%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_rule_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_transformation_logic%20TEXT%3B%0A%20%20%20%20DECLARE%20v_validation_criteria%20TEXT%3B%0A%20%20%20%20DECLARE%20v_on_error_action%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20transform_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20rule_name%2C%20rule_type%2C%20transformation_logic%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20validation_criteria%2C%20on_error_action%0A%20%20%20%20%20%20%20%20FROM%20etl_transformation_rules%0A%20%20%20%20%20%20%20%20WHERE%20job_id%20%3D%20p_job_id%20AND%20is_active%20%3D%20TRUE%0A%20%20%20%20%20%20%20%20ORDER%20BY%20rule_order%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20transform_cursor%3B%0A%20%20%20%20%0A%20%20%20%20transform_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20transform_cursor%20INTO%20v_rule_id%2C%20v_rule_name%2C%20v_rule_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_transformation_logic%2C%20v_validation_criteria%2C%20v_on_error_action%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20transform_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20transformation%20based%20on%20type%0A%20%20%20%20%20%20%20%20CASE%20v_rule_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'VALIDATION'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_validation_rule(v_rule_id%2C%20v_validation_criteria%2C%20v_on_error_action)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'CLEANSING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_cleansing_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ENRICHMENT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_enrichment_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'BUSINESS_RULE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_business_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20transform_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20transformation%20metrics%0A%20%20%20%20UPDATE%20etl_execution_log%0A%20%20%20%20SET%20records_transformed%20%3D%20v_records_processed%2C%0A%20%20%20%20%20%20%20%20transformation_duration_seconds%20%3D%20TIMESTAMPDIFF(SECOND%2C%20started_at%2C%20NOW())%0A%20%20%20%20WHERE%20execution_id%20%3D%20p_execution_id%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Data%20validation%20rule%0ACREATE%20PROCEDURE%20apply_validation_rule(%0A%20%20%20%20IN%20p_rule_id%20INT%2C%0A%20%20%20%20IN%20p_validation_criteria%20TEXT%2C%0A%20%20%20%20IN%20p_on_error_action%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_invalid_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Build%20validation%20query%0A%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20%0A%20%20%20%20%20%20%20%20p_validation_criteria%2C%20')'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20validation%0A%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Get%20result%20into%20v_invalid_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20validation%20failures%0A%20%20%20%20IF%20v_invalid_count%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20CASE%20p_on_error_action%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'REJECT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Move%20invalid%20records%20to%20reject%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40reject_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20etl_rejected_records%20SELECT%20*%2C%20'''%2C%20p_rule_id%2C%20'''%20as%20rule_id%2C%20NOW()%20as%20rejected_at%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20p_validation_criteria%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40reject_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Remove%20invalid%20records%20from%20staging%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'DELETE%20FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20p_validation_criteria%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40delete_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'FAIL_JOB'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Validation%20rule%20failed%20-%20job%20terminated'%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main ETL orchestrator
DELIMITER //
CREATE PROCEDURE execute_etl_job(IN p_job_name VARCHAR(100))
BEGIN
    DECLARE v_job_id INT;
    DECLARE v_execution_id VARCHAR(100);
    DECLARE v_source_system VARCHAR(100);
    DECLARE v_target_system VARCHAR(100);
    DECLARE v_job_parameters JSON;
    DECLARE v_records_processed BIGINT DEFAULT 0;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        UPDATE etl_execution_log 
        SET status = 'FAILED',
            completed_at = NOW(),
            error_message = 'ETL job failed with SQL exception'
        WHERE execution_id = v_execution_id;
        RESIGNAL;
    END;
    
    -- Get job configuration
    SELECT id, source_system, target_system, job_parameters
    INTO v_job_id, v_source_system, v_target_system, v_job_parameters
    FROM etl_job_control
    WHERE job_name = p_job_name AND is_active = TRUE;
    
    IF v_job_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'ETL job not found or inactive';
    END IF;
    
    -- Generate execution ID
    SET v_execution_id = CONCAT(p_job_name, '_', DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'));
    
    -- Log execution start
    INSERT INTO etl_execution_log (job_id, execution_id, started_at)
    VALUES (v_job_id, v_execution_id, v_start_time);
    
    -- Execute ETL phases
    CALL etl_extract_phase(v_job_id, v_execution_id, v_source_system, v_job_parameters);
    CALL etl_transform_phase(v_job_id, v_execution_id, v_job_parameters);
    CALL etl_load_phase(v_job_id, v_execution_id, v_target_system, v_job_parameters);
    
    -- Update completion status
    UPDATE etl_execution_log 
    SET status = 'SUCCESS',
        completed_at = NOW()
    WHERE execution_id = v_execution_id;
    
    -- Update job control
    UPDATE etl_job_control
    SET last_run_start = v_start_time,
        last_run_end = NOW(),
        last_run_status = 'SUCCESS',
        last_run_records_processed = v_records_processed
    WHERE id = v_job_id;
    
END //

-- ETL Transform Phase
CREATE PROCEDURE etl_transform_phase(
    IN p_job_id INT,
    IN p_execution_id VARCHAR(100),
    IN p_job_parameters JSON
)
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_id INT;
    DECLARE v_rule_name VARCHAR(200);
    DECLARE v_rule_type VARCHAR(50);
    DECLARE v_transformation_logic TEXT;
    DECLARE v_validation_criteria TEXT;
    DECLARE v_on_error_action VARCHAR(20);
    DECLARE v_records_processed BIGINT DEFAULT 0;
    
    DECLARE transform_cursor CURSOR FOR
        SELECT id, rule_name, rule_type, transformation_logic, 
               validation_criteria, on_error_action
        FROM etl_transformation_rules
        WHERE job_id = p_job_id AND is_active = TRUE
        ORDER BY rule_order;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN transform_cursor;
    
    transform_loop: LOOP
        FETCH transform_cursor INTO v_rule_id, v_rule_name, v_rule_type,
                                   v_transformation_logic, v_validation_criteria, v_on_error_action;
        
        IF done THEN
            LEAVE transform_loop;
        END IF;
        
        -- Execute transformation based on type
        CASE v_rule_type
            WHEN 'VALIDATION' THEN
                CALL apply_validation_rule(v_rule_id, v_validation_criteria, v_on_error_action);
            
            WHEN 'CLEANSING' THEN
                CALL apply_cleansing_rule(v_rule_id, v_transformation_logic);
            
            WHEN 'ENRICHMENT' THEN
                CALL apply_enrichment_rule(v_rule_id, v_transformation_logic);
            
            WHEN 'BUSINESS_RULE' THEN
                CALL apply_business_rule(v_rule_id, v_transformation_logic);
        END CASE;
        
    END LOOP;
    
    CLOSE transform_cursor;
    
    -- Update transformation metrics
    UPDATE etl_execution_log
    SET records_transformed = v_records_processed,
        transformation_duration_seconds = TIMESTAMPDIFF(SECOND, started_at, NOW())
    WHERE execution_id = p_execution_id;
    
END //

-- Data validation rule
CREATE PROCEDURE apply_validation_rule(
    IN p_rule_id INT,
    IN p_validation_criteria TEXT,
    IN p_on_error_action VARCHAR(20)
)
BEGIN
    DECLARE v_invalid_count INT DEFAULT 0;
    DECLARE v_validation_sql TEXT;
    
    -- Build validation query
    SET v_validation_sql = CONCAT(
        'SELECT COUNT(*) FROM etl_staging_data WHERE NOT (', 
        p_validation_criteria, ')'
    );
    
    -- Execute validation
    SET @sql = v_validation_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Get result into v_invalid_count
    DEALLOCATE PREPARE stmt;
    
    -- Handle validation failures
    IF v_invalid_count &gt; 0 THEN
        CASE p_on_error_action
            WHEN 'REJECT' THEN
                -- Move invalid records to reject table
                SET @reject_sql = CONCAT(
                    'INSERT INTO etl_rejected_records SELECT *, ''', p_rule_id, ''' as rule_id, NOW() as rejected_at ',
                    'FROM etl_staging_data WHERE NOT (', p_validation_criteria, ')'
                );
                PREPARE stmt FROM @reject_sql;
                EXECUTE stmt;
                DEALLOCATE PREPARE stmt;
                
                -- Remove invalid records from staging
                SET @delete_sql = CONCAT(
                    'DELETE FROM etl_staging_data WHERE NOT (', p_validation_criteria, ')'
                );
                PREPARE stmt FROM @delete_sql;
                EXECUTE stmt;
                DEALLOCATE PREPARE stmt;
            
            WHEN 'FAIL_JOB' THEN
                SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Validation rule failed - job terminated';
        END CASE;
    END IF;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>ELT Pattern Implementation:</strong></p>

<p><strong>1. ELT Architecture:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Raw%20data%20landing%20zone%0ACREATE%20TABLE%20raw_data_landing%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_system%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20data_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Raw%20data%20storage%0A%20%20%20%20raw_payload%20JSON%20NOT%20NULL%2C%0A%20%20%20%20file_metadata%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processing_status%20ENUM('LANDED'%2C%20'VALIDATED'%2C%20'PROCESSED'%2C%20'FAILED')%20DEFAULT%20'LANDED'%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20lineage%0A%20%20%20%20batch_id%20VARCHAR(100)%2C%0A%20%20%20%20source_file_path%20VARCHAR(500)%2C%0A%20%20%20%20record_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source_type%20(source_system%2C%20data_type)%2C%0A%20%20%20%20INDEX%20idx_ingestion_timestamp%20(ingestion_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_batch_id%20(batch_id)%0A)%3B%0A%0A--%20ELT%20transformation%20catalog%0ACREATE%20TABLE%20elt_transformations%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20transformation_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20transformation_type%20ENUM('VIEW'%2C%20'MATERIALIZED_VIEW'%2C%20'STORED_PROCEDURE'%2C%20'FUNCTION')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Source%20and%20target%0A%20%20%20%20source_tables%20JSON%20NOT%20NULL%2C%0A%20%20%20%20target_table%20VARCHAR(200)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transformation%20logic%0A%20%20%20%20transformation_sql%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20transformation_schedule%20VARCHAR(100)%2C%20--%20Cron%20expression%0A%20%20%20%20%0A%20%20%20%20--%20Dependencies%0A%20%20%20%20depends_on%20JSON%2C%0A%20%20%20%20refresh_strategy%20ENUM('FULL'%2C%20'INCREMENTAL'%2C%20'MERGE')%20DEFAULT%20'FULL'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20technical_notes%20TEXT%2C%0A%20%20%20%20data_owner%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_transformation_name%20(transformation_name)%2C%0A%20%20%20%20INDEX%20idx_transformation_type%20(transformation_type)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Raw data landing zone
CREATE TABLE raw_data_landing (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_system VARCHAR(100) NOT NULL,
    data_type VARCHAR(100) NOT NULL,
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Raw data storage
    raw_payload JSON NOT NULL,
    file_metadata JSON,
    
    -- Processing status
    processing_status ENUM('LANDED', 'VALIDATED', 'PROCESSED', 'FAILED') DEFAULT 'LANDED',
    processed_at TIMESTAMP NULL,
    
    -- Data lineage
    batch_id VARCHAR(100),
    source_file_path VARCHAR(500),
    record_count INT,
    
    INDEX idx_source_type (source_system, data_type),
    INDEX idx_ingestion_timestamp (ingestion_timestamp),
    INDEX idx_processing_status (processing_status),
    INDEX idx_batch_id (batch_id)
);

-- ELT transformation catalog
CREATE TABLE elt_transformations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    transformation_name VARCHAR(200) NOT NULL,
    transformation_type ENUM('VIEW', 'MATERIALIZED_VIEW', 'STORED_PROCEDURE', 'FUNCTION'),
    
    -- Source and target
    source_tables JSON NOT NULL,
    target_table VARCHAR(200),
    
    -- Transformation logic
    transformation_sql TEXT NOT NULL,
    transformation_schedule VARCHAR(100), -- Cron expression
    
    -- Dependencies
    depends_on JSON,
    refresh_strategy ENUM('FULL', 'INCREMENTAL', 'MERGE') DEFAULT 'FULL',
    
    -- Metadata
    business_description TEXT,
    technical_notes TEXT,
    data_owner VARCHAR(100),
    
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_transformation_name (transformation_name),
    INDEX idx_transformation_type (transformation_type)
);
</code></pre>
</div>

<p><strong>2. ELT Processing Engine:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ELT%20transformation%20executor%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_elt_transformation(IN%20p_transformation_name%20VARCHAR(200))%0ABEGIN%0A%20%20%20%20DECLARE%20v_transformation_id%20INT%3B%0A%20%20%20%20DECLARE%20v_transformation_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_transformation_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_target_table%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_refresh_strategy%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_source_tables%20JSON%3B%0A%20%20%20%20DECLARE%20v_execution_start%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20transformation%20definition%0A%20%20%20%20SELECT%20id%2C%20transformation_type%2C%20transformation_sql%2C%20target_table%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20refresh_strategy%2C%20source_tables%0A%20%20%20%20INTO%20v_transformation_id%2C%20v_transformation_type%2C%20v_transformation_sql%2C%0A%20%20%20%20%20%20%20%20%20v_target_table%2C%20v_refresh_strategy%2C%20v_source_tables%0A%20%20%20%20FROM%20elt_transformations%0A%20%20%20%20WHERE%20transformation_name%20%3D%20p_transformation_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_transformation_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'ELT%20transformation%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20based%20on%20transformation%20type%0A%20%20%20%20CASE%20v_transformation_type%0A%20%20%20%20%20%20%20%20WHEN%20'VIEW'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20create_or_replace_view(p_transformation_name%2C%20v_transformation_sql)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'MATERIALIZED_VIEW'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20refresh_materialized_view(v_target_table%2C%20v_transformation_sql%2C%20v_refresh_strategy)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'STORED_PROCEDURE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_transformation_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20execution%0A%20%20%20%20INSERT%20INTO%20elt_execution_log%20(%0A%20%20%20%20%20%20%20%20transformation_id%2C%20transformation_name%2C%20execution_start%2C%20execution_end%2C%0A%20%20%20%20%20%20%20%20status%2C%20duration_seconds%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_transformation_id%2C%20p_transformation_name%2C%20v_execution_start%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20'SUCCESS'%2C%20TIMESTAMPDIFF(SECOND%2C%20v_execution_start%2C%20NOW())%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Dynamic%20view%20creation%0ACREATE%20PROCEDURE%20create_or_replace_view(%0A%20%20%20%20IN%20p_view_name%20VARCHAR(200)%2C%0A%20%20%20%20IN%20p_view_sql%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_create_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Drop%20existing%20view%20if%20exists%0A%20%20%20%20SET%20%40drop_sql%20%3D%20CONCAT('DROP%20VIEW%20IF%20EXISTS%20'%2C%20p_view_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20new%20view%0A%20%20%20%20SET%20v_create_sql%20%3D%20CONCAT('CREATE%20VIEW%20'%2C%20p_view_name%2C%20'%20AS%20'%2C%20p_view_sql)%3B%0A%20%20%20%20SET%20%40sql%20%3D%20v_create_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Materialized%20view%20refresh%0ACREATE%20PROCEDURE%20refresh_materialized_view(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(200)%2C%0A%20%20%20%20IN%20p_source_sql%20TEXT%2C%0A%20%20%20%20IN%20p_refresh_strategy%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_temp_table%20VARCHAR(220)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_temp_table%20%3D%20CONCAT(p_table_name%2C%20'_temp_'%2C%20UNIX_TIMESTAMP())%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20table%20with%20new%20data%0A%20%20%20%20SET%20%40create_temp_sql%20%3D%20CONCAT('CREATE%20TABLE%20'%2C%20v_temp_table%2C%20'%20AS%20'%2C%20p_source_sql)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40create_temp_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20refresh%20strategy%0A%20%20%20%20CASE%20p_refresh_strategy%0A%20%20%20%20%20%20%20%20WHEN%20'FULL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Replace%20entire%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40drop_sql%20%3D%20CONCAT('DROP%20TABLE%20IF%20EXISTS%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40rename_sql%20%3D%20CONCAT('RENAME%20TABLE%20'%2C%20v_temp_table%2C%20'%20TO%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40rename_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'INCREMENTAL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20only%20new%20records%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40insert_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_table_name%2C%20'%20SELECT%20*%20FROM%20'%2C%20v_temp_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20NOT%20EXISTS%20(SELECT%201%20FROM%20'%2C%20p_table_name%2C%20'%20t2%20WHERE%20t2.id%20%3D%20'%2C%20v_temp_table%2C%20'.id)'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40insert_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Clean%20up%20temp%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40drop_temp_sql%20%3D%20CONCAT('DROP%20TABLE%20'%2C%20v_temp_table)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_temp_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ELT transformation executor
DELIMITER //
CREATE PROCEDURE execute_elt_transformation(IN p_transformation_name VARCHAR(200))
BEGIN
    DECLARE v_transformation_id INT;
    DECLARE v_transformation_type VARCHAR(50);
    DECLARE v_transformation_sql TEXT;
    DECLARE v_target_table VARCHAR(200);
    DECLARE v_refresh_strategy VARCHAR(20);
    DECLARE v_source_tables JSON;
    DECLARE v_execution_start TIMESTAMP DEFAULT NOW();
    
    -- Get transformation definition
    SELECT id, transformation_type, transformation_sql, target_table, 
           refresh_strategy, source_tables
    INTO v_transformation_id, v_transformation_type, v_transformation_sql,
         v_target_table, v_refresh_strategy, v_source_tables
    FROM elt_transformations
    WHERE transformation_name = p_transformation_name AND is_active = TRUE;
    
    IF v_transformation_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'ELT transformation not found';
    END IF;
    
    -- Execute based on transformation type
    CASE v_transformation_type
        WHEN 'VIEW' THEN
            CALL create_or_replace_view(p_transformation_name, v_transformation_sql);
        
        WHEN 'MATERIALIZED_VIEW' THEN
            CALL refresh_materialized_view(v_target_table, v_transformation_sql, v_refresh_strategy);
        
        WHEN 'STORED_PROCEDURE' THEN
            SET @sql = v_transformation_sql;
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
    END CASE;
    
    -- Log execution
    INSERT INTO elt_execution_log (
        transformation_id, transformation_name, execution_start, execution_end,
        status, duration_seconds
    ) VALUES (
        v_transformation_id, p_transformation_name, v_execution_start, NOW(),
        'SUCCESS', TIMESTAMPDIFF(SECOND, v_execution_start, NOW())
    );
    
END //

-- Dynamic view creation
CREATE PROCEDURE create_or_replace_view(
    IN p_view_name VARCHAR(200),
    IN p_view_sql TEXT
)
BEGIN
    DECLARE v_create_sql TEXT;
    
    -- Drop existing view if exists
    SET @drop_sql = CONCAT('DROP VIEW IF EXISTS ', p_view_name);
    PREPARE stmt FROM @drop_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Create new view
    SET v_create_sql = CONCAT('CREATE VIEW ', p_view_name, ' AS ', p_view_sql);
    SET @sql = v_create_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //

-- Materialized view refresh
CREATE PROCEDURE refresh_materialized_view(
    IN p_table_name VARCHAR(200),
    IN p_source_sql TEXT,
    IN p_refresh_strategy VARCHAR(20)
)
BEGIN
    DECLARE v_temp_table VARCHAR(220);
    
    SET v_temp_table = CONCAT(p_table_name, '_temp_', UNIX_TIMESTAMP());
    
    -- Create temporary table with new data
    SET @create_temp_sql = CONCAT('CREATE TABLE ', v_temp_table, ' AS ', p_source_sql);
    PREPARE stmt FROM @create_temp_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Handle refresh strategy
    CASE p_refresh_strategy
        WHEN 'FULL' THEN
            -- Replace entire table
            SET @drop_sql = CONCAT('DROP TABLE IF EXISTS ', p_table_name);
            PREPARE stmt FROM @drop_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            SET @rename_sql = CONCAT('RENAME TABLE ', v_temp_table, ' TO ', p_table_name);
            PREPARE stmt FROM @rename_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
        
        WHEN 'INCREMENTAL' THEN
            -- Insert only new records
            SET @insert_sql = CONCAT(
                'INSERT INTO ', p_table_name, ' SELECT * FROM ', v_temp_table,
                ' WHERE NOT EXISTS (SELECT 1 FROM ', p_table_name, ' t2 WHERE t2.id = ', v_temp_table, '.id)'
            );
            PREPARE stmt FROM @insert_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            -- Clean up temp table
            SET @drop_temp_sql = CONCAT('DROP TABLE ', v_temp_table);
            PREPARE stmt FROM @drop_temp_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
    END CASE;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Integration Patterns:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Hub%20and%20Spoke%20Pattern%0ACREATE%20TABLE%20integration_hub%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20entity_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20business_key%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Master%20data%0A%20%20%20%20master_record%20JSON%20NOT%20NULL%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Source%20system%20mappings%0A%20%20%20%20source_systems%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20last_synchronized%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_entity_business_key%20(entity_type%2C%20business_key)%2C%0A%20%20%20%20INDEX%20idx_entity_type%20(entity_type)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Event-Driven%20Integration%0ACREATE%20TABLE%20integration_events%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20target_systems%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Event%20data%0A%20%20%20%20event_payload%20JSON%20NOT%20NULL%2C%0A%20%20%20%20correlation_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%0A%20%20%20%20processing_status%20ENUM('PENDING'%2C%20'PROCESSING'%2C%20'COMPLETED'%2C%20'FAILED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20max_retries%20INT%20DEFAULT%203%2C%0A%20%20%20%20%0A%20%20%20%20--%20Timestamps%0A%20%20%20%20event_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_source_system%20(source_system)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_correlation_id%20(correlation_id)%0A)%3B%0A%0A--%20API-Based%20Integration%0ACREATE%20TABLE%20api_integration_config%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20integration_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20api_endpoint%20VARCHAR(500)%20NOT%20NULL%2C%0A%20%20%20%20authentication_type%20ENUM('NONE'%2C%20'BASIC'%2C%20'BEARER'%2C%20'OAUTH2'%2C%20'API_KEY')%2C%0A%20%20%20%20authentication_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Request%20configuration%0A%20%20%20%20http_method%20ENUM('GET'%2C%20'POST'%2C%20'PUT'%2C%20'DELETE'%2C%20'PATCH')%20DEFAULT%20'GET'%2C%0A%20%20%20%20request_headers%20JSON%2C%0A%20%20%20%20request_body_template%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Response%20handling%0A%20%20%20%20response_format%20ENUM('JSON'%2C%20'XML'%2C%20'CSV'%2C%20'TEXT')%2C%0A%20%20%20%20response_mapping%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Scheduling%0A%20%20%20%20sync_frequency_minutes%20INT%20DEFAULT%2060%2C%0A%20%20%20%20last_sync_timestamp%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_integration_name%20(integration_name)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Hub and Spoke Pattern
CREATE TABLE integration_hub (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    entity_type VARCHAR(100) NOT NULL,
    business_key VARCHAR(255) NOT NULL,
    
    -- Master data
    master_record JSON NOT NULL,
    data_quality_score DECIMAL(3,2),
    
    -- Source system mappings
    source_systems JSON,
    
    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    last_synchronized TIMESTAMP,
    
    UNIQUE KEY uk_entity_business_key (entity_type, business_key),
    INDEX idx_entity_type (entity_type),
    INDEX idx_data_quality (data_quality_score)
);

-- Event-Driven Integration
CREATE TABLE integration_events (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,
    source_system VARCHAR(100) NOT NULL,
    target_systems JSON,
    
    -- Event data
    event_payload JSON NOT NULL,
    correlation_id VARCHAR(100),
    
    -- Processing
    processing_status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING',
    retry_count INT DEFAULT 0,
    max_retries INT DEFAULT 3,
    
    -- Timestamps
    event_timestamp TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP NULL,
    
    INDEX idx_event_type (event_type),
    INDEX idx_source_system (source_system),
    INDEX idx_processing_status (processing_status),
    INDEX idx_correlation_id (correlation_id)
);

-- API-Based Integration
CREATE TABLE api_integration_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    integration_name VARCHAR(200) NOT NULL,
    api_endpoint VARCHAR(500) NOT NULL,
    authentication_type ENUM('NONE', 'BASIC', 'BEARER', 'OAUTH2', 'API_KEY'),
    authentication_config JSON,
    
    -- Request configuration
    http_method ENUM('GET', 'POST', 'PUT', 'DELETE', 'PATCH') DEFAULT 'GET',
    request_headers JSON,
    request_body_template TEXT,
    
    -- Response handling
    response_format ENUM('JSON', 'XML', 'CSV', 'TEXT'),
    response_mapping JSON,
    
    -- Scheduling
    sync_frequency_minutes INT DEFAULT 60,
    last_sync_timestamp TIMESTAMP,
    
    is_active BOOLEAN DEFAULT TRUE,
    
    UNIQUE KEY uk_integration_name (integration_name)
);
</code></pre>
</div>

<p><strong>Key Differences Summary:</strong></p>

<p>- <strong>ETL</strong>: Transform data before loading, suitable for structured data, predictable queries</p>
<p>- <strong>ELT</strong>: Load raw data first, transform on-demand, suitable for big data, flexible analysis</p>
<p>- <strong>Modern Trend</strong>: ELT gaining popularity with cloud data warehouses and data lakes</p>


<p>---</p>

<h2 id="-386-how-do-you-implement-data-versioning-and-change-tracking-">**386. How do you implement data versioning and change tracking?**</h2>

<p><strong>Answer:</strong> Data versioning and change tracking maintain historical records of data changes, enabling audit trails, rollback capabilities, and temporal analysis through systematic version control mechanisms.</p>

<p><strong>Temporal Data Management:</strong></p>

<p><strong>1. System-Versioned Temporal Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20table%20with%20system%20versioning%0ACREATE%20TABLE%20customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20address%20TEXT%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'suspended')%20DEFAULT%20'active'%2C%0A%20%20%20%20%0A%20%20%20%20--%20System%20versioning%20columns%0A%20%20%20%20row_start%20TIMESTAMP(6)%20GENERATED%20ALWAYS%20AS%20ROW%20START%2C%0A%20%20%20%20row_end%20TIMESTAMP(6)%20GENERATED%20ALWAYS%20AS%20ROW%20END%2C%0A%20%20%20%20%0A%20%20%20%20PERIOD%20FOR%20SYSTEM_TIME%20(row_start%2C%20row_end)%0A)%20WITH%20SYSTEM%20VERSIONING%3B%0A%0A--%20History%20table%20(automatically%20managed)%0ACREATE%20TABLE%20customers_history%20(%0A%20%20%20%20id%20INT%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20address%20TEXT%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'suspended')%2C%0A%20%20%20%20row_start%20TIMESTAMP(6)%2C%0A%20%20%20%20row_end%20TIMESTAMP(6)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_id_period%20(id%2C%20row_start%2C%20row_end)%2C%0A%20%20%20%20INDEX%20idx_row_start%20(row_start)%2C%0A%20%20%20%20INDEX%20idx_row_end%20(row_end)%0A)%3B%0A%0A--%20Application-versioned%20temporal%20table%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20category_id%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Application%20versioning%0A%20%20%20%20valid_from%20DATE%20NOT%20NULL%2C%0A%20%20%20%20valid_to%20DATE%20NOT%20NULL%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20version_number%20INT%20NOT%20NULL%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20tracking%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20modified_by%20VARCHAR(100)%2C%0A%20%20%20%20modified_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ensure%20no%20overlapping%20periods%20for%20same%20product%0A%20%20%20%20UNIQUE%20KEY%20uk_product_period%20(id%2C%20valid_from%2C%20valid_to)%2C%0A%20%20%20%20INDEX%20idx_valid_period%20(valid_from%2C%20valid_to)%2C%0A%20%20%20%20INDEX%20idx_version%20(id%2C%20version_number)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main table with system versioning
CREATE TABLE customers (
    id INT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    email VARCHAR(255) NOT NULL,
    phone VARCHAR(20),
    address TEXT,
    status ENUM('active', 'inactive', 'suspended') DEFAULT 'active',
    
    -- System versioning columns
    row_start TIMESTAMP(6) GENERATED ALWAYS AS ROW START,
    row_end TIMESTAMP(6) GENERATED ALWAYS AS ROW END,
    
    PERIOD FOR SYSTEM_TIME (row_start, row_end)
) WITH SYSTEM VERSIONING;

-- History table (automatically managed)
CREATE TABLE customers_history (
    id INT,
    name VARCHAR(255),
    email VARCHAR(255),
    phone VARCHAR(20),
    address TEXT,
    status ENUM('active', 'inactive', 'suspended'),
    row_start TIMESTAMP(6),
    row_end TIMESTAMP(6),
    
    INDEX idx_id_period (id, row_start, row_end),
    INDEX idx_row_start (row_start),
    INDEX idx_row_end (row_end)
);

-- Application-versioned temporal table
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    category_id INT,
    
    -- Application versioning
    valid_from DATE NOT NULL,
    valid_to DATE NOT NULL DEFAULT '9999-12-31',
    version_number INT NOT NULL DEFAULT 1,
    
    -- Change tracking
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    modified_by VARCHAR(100),
    modified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    -- Ensure no overlapping periods for same product
    UNIQUE KEY uk_product_period (id, valid_from, valid_to),
    INDEX idx_valid_period (valid_from, valid_to),
    INDEX idx_version (id, version_number)
);
</code></pre>
</div>

<p><strong>2. Change Data Capture (CDC) Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Change%20tracking%20configuration%0ACREATE%20TABLE%20change_tracking_config%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20tracking_enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_columns%20JSON%2C%20--%20Specific%20columns%20to%20track%0A%20%20%20%20retention_days%20INT%20DEFAULT%20365%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20types%20to%20track%0A%20%20%20%20track_inserts%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_updates%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_deletes%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Notification%20settings%0A%20%20%20%20notify_on_change%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20notification_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_name%20(table_name)%0A)%3B%0A%0A--%20Universal%20change%20log%0ACREATE%20TABLE%20change_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20operation_type%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20data%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_columns%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20metadata%0A%20%20%20%20change_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20change_user%20VARCHAR(100)%2C%0A%20%20%20%20change_session%20VARCHAR(100)%2C%0A%20%20%20%20change_application%20VARCHAR(100)%2C%0A%20%20%20%20change_reason%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transaction%20context%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20batch_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20lineage%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20correlation_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_record%20(table_name%2C%20record_id)%2C%0A%20%20%20%20INDEX%20idx_change_timestamp%20(change_timestamp)%2C%0A%20%20%20%20INDEX%20idx_operation_type%20(operation_type)%2C%0A%20%20%20%20INDEX%20idx_change_user%20(change_user)%2C%0A%20%20%20%20INDEX%20idx_transaction_id%20(transaction_id)%0A)%3B%0A%0A--%20Change%20tracking%20triggers%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_change_tracking_triggers(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_columns%20TEXT%3B%0A%20%20%20%20DECLARE%20v_insert_trigger%20TEXT%3B%0A%20%20%20%20DECLARE%20v_update_trigger%20TEXT%3B%0A%20%20%20%20DECLARE%20v_delete_trigger%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20table%20columns%20for%20JSON%20construction%0A%20%20%20%20SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20)%20INTO%20v_columns%0A%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%0A%20%20%20%20AND%20table_schema%20%3D%20DATABASE()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20INSERT%20trigger%0A%20%20%20%20SET%20v_insert_trigger%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_change_insert%0A%20%20%20%20%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20change_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20operation_type%2C%20new_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20change_user%2C%20change_session%2C%20change_application%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20NEW.id%2C%20''INSERT''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20v_columns%2C%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_session%2C%20CONNECTION_ID())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_application%2C%20''UNKNOWN'')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_insert_trigger%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20UPDATE%20trigger%20(similar%20pattern)%0A%20%20%20%20--%20Create%20DELETE%20trigger%20(similar%20pattern)%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Version%20management%20procedures%0ACREATE%20PROCEDURE%20create_new_version(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20INT%2C%0A%20%20%20%20IN%20p_new_data%20JSON%2C%0A%20%20%20%20IN%20p_valid_from%20DATE%2C%0A%20%20%20%20IN%20p_change_reason%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_current_version%20INT%3B%0A%20%20%20%20DECLARE%20v_update_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20version%0A%20%20%20%20SET%20%40version_sql%20%3D%20CONCAT('SELECT%20MAX(version_number)%20FROM%20'%2C%20p_table_name%2C%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40version_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20v_current_version%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Close%20current%20version%0A%20%20%20%20SET%20%40close_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20p_table_name%2C%20'%20SET%20valid_to%20%3D%20'''%2C%20DATE_SUB(p_valid_from%2C%20INTERVAL%201%20DAY)%2C%20''''%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id%2C%20'%20AND%20valid_to%20%3D%20''9999-12-31'''%0A%20%20%20%20)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40close_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Insert%20new%20version%0A%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_table_name%2C%20'%20(id%2C%20name%2C%20price%2C%20category_id%2C%20valid_from%2C%20version_number%2C%20created_by)%20'%2C%0A%20%20%20%20%20%20%20%20'VALUES%20('%2C%20p_record_id%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20JSON_UNQUOTE(JSON_EXTRACT(p_new_data%2C%20'%24.name'))%2C%20'''%2C%20'%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(p_new_data%2C%20'%24.price')%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(p_new_data%2C%20'%24.category_id')%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20p_valid_from%2C%20'''%2C%20'%2C%20v_current_version%20%2B%201%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20COALESCE(%40change_user%2C%20USER())%2C%20''')'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_update_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20version%20creation%0A%20%20%20%20INSERT%20INTO%20version_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20old_version%2C%20new_version%2C%0A%20%20%20%20%20%20%20%20change_reason%2C%20created_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20v_current_version%2C%20v_current_version%20%2B%201%2C%0A%20%20%20%20%20%20%20%20p_change_reason%2C%20COALESCE(%40change_user%2C%20USER())%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Change tracking configuration
CREATE TABLE change_tracking_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    tracking_enabled BOOLEAN DEFAULT TRUE,
    track_columns JSON, -- Specific columns to track
    retention_days INT DEFAULT 365,
    
    -- Change types to track
    track_inserts BOOLEAN DEFAULT TRUE,
    track_updates BOOLEAN DEFAULT TRUE,
    track_deletes BOOLEAN DEFAULT TRUE,
    
    -- Notification settings
    notify_on_change BOOLEAN DEFAULT FALSE,
    notification_config JSON,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_name (table_name)
);

-- Universal change log
CREATE TABLE change_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    operation_type ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    
    -- Change data
    old_values JSON,
    new_values JSON,
    changed_columns JSON,
    
    -- Change metadata
    change_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    change_user VARCHAR(100),
    change_session VARCHAR(100),
    change_application VARCHAR(100),
    change_reason VARCHAR(500),
    
    -- Transaction context
    transaction_id VARCHAR(100),
    batch_id VARCHAR(100),
    
    -- Data lineage
    source_system VARCHAR(100),
    correlation_id VARCHAR(100),
    
    INDEX idx_table_record (table_name, record_id),
    INDEX idx_change_timestamp (change_timestamp),
    INDEX idx_operation_type (operation_type),
    INDEX idx_change_user (change_user),
    INDEX idx_transaction_id (transaction_id)
);

-- Change tracking triggers
DELIMITER //
CREATE PROCEDURE create_change_tracking_triggers(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE v_columns TEXT;
    DECLARE v_insert_trigger TEXT;
    DECLARE v_update_trigger TEXT;
    DECLARE v_delete_trigger TEXT;
    
    -- Get table columns for JSON construction
    SELECT GROUP_CONCAT(
        CONCAT('''', column_name, ''', NEW.', column_name)
        SEPARATOR ', '
    ) INTO v_columns
    FROM information_schema.columns
    WHERE table_name = p_table_name
    AND table_schema = DATABASE();
    
    -- Create INSERT trigger
    SET v_insert_trigger = CONCAT('
        CREATE TRIGGER ', p_table_name, '_change_insert
        AFTER INSERT ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO change_log (
                table_name, record_id, operation_type, new_values,
                change_user, change_session, change_application
            ) VALUES (
                ''', p_table_name, ''', NEW.id, ''INSERT'',
                JSON_OBJECT(', v_columns, '),
                COALESCE(@change_user, USER()),
                COALESCE(@change_session, CONNECTION_ID()),
                COALESCE(@change_application, ''UNKNOWN'')
            );
        END'
    );
    
    SET @sql = v_insert_trigger;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Create UPDATE trigger (similar pattern)
    -- Create DELETE trigger (similar pattern)
    
END //

-- Version management procedures
CREATE PROCEDURE create_new_version(
    IN p_table_name VARCHAR(100),
    IN p_record_id INT,
    IN p_new_data JSON,
    IN p_valid_from DATE,
    IN p_change_reason VARCHAR(500)
)
BEGIN
    DECLARE v_current_version INT;
    DECLARE v_update_sql TEXT;
    
    -- Get current version
    SET @version_sql = CONCAT('SELECT MAX(version_number) FROM ', p_table_name, ' WHERE id = ', p_record_id);
    PREPARE stmt FROM @version_sql;
    EXECUTE stmt;
    -- Store result in v_current_version
    DEALLOCATE PREPARE stmt;
    
    -- Close current version
    SET @close_sql = CONCAT(
        'UPDATE ', p_table_name, ' SET valid_to = ''', DATE_SUB(p_valid_from, INTERVAL 1 DAY), '''',
        ' WHERE id = ', p_record_id, ' AND valid_to = ''9999-12-31'''
    );
    PREPARE stmt FROM @close_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Insert new version
    SET v_update_sql = CONCAT(
        'INSERT INTO ', p_table_name, ' (id, name, price, category_id, valid_from, version_number, created_by) ',
        'VALUES (', p_record_id, ', ',
        '''', JSON_UNQUOTE(JSON_EXTRACT(p_new_data, '$.name')), ''', ',
        JSON_EXTRACT(p_new_data, '$.price'), ', ',
        JSON_EXTRACT(p_new_data, '$.category_id'), ', ',
        '''', p_valid_from, ''', ', v_current_version + 1, ', ',
        '''', COALESCE(@change_user, USER()), ''')'
    );
    
    SET @sql = v_update_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log version creation
    INSERT INTO version_log (
        table_name, record_id, old_version, new_version,
        change_reason, created_by
    ) VALUES (
        p_table_name, p_record_id, v_current_version, v_current_version + 1,
        p_change_reason, COALESCE(@change_user, USER())
    );
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Lineage and Provenance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20lineage%20tracking%0ACREATE%20TABLE%20data_lineage%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_table%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20target_table%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20target_record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transformation%20details%0A%20%20%20%20transformation_type%20ENUM('COPY'%2C%20'AGGREGATE'%2C%20'JOIN'%2C%20'CALCULATE'%2C%20'ENRICH')%2C%0A%20%20%20%20transformation_rule%20TEXT%2C%0A%20%20%20%20transformation_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20context%0A%20%20%20%20job_name%20VARCHAR(200)%2C%0A%20%20%20%20job_execution_id%20VARCHAR(100)%2C%0A%20%20%20%20processing_user%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%0A%20%20%20%20confidence_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20quality_flags%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source%20(source_table%2C%20source_record_id)%2C%0A%20%20%20%20INDEX%20idx_target%20(target_table%2C%20target_record_id)%2C%0A%20%20%20%20INDEX%20idx_transformation_timestamp%20(transformation_timestamp)%0A)%3B%0A%0A--%20Data%20provenance%20queries%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20trace_data_lineage(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_direction%20ENUM('UPSTREAM'%2C%20'DOWNSTREAM'%2C%20'BOTH')%0A)%0ABEGIN%0A%20%20%20%20--%20Recursive%20CTE%20to%20trace%20lineage%0A%20%20%20%20WITH%20RECURSIVE%20lineage_trace%20AS%20(%0A%20%20%20%20%20%20%20%20--%20Base%20case%3A%20starting%20record%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%200%20as%20level%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_table_name%20as%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_record_id%20as%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'ORIGIN'%20as%20relationship_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NULL%20as%20transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NULL%20as%20transformation_rule%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20upstream%20lineage%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20lt.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.source_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.source_record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SOURCE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_rule%0A%20%20%20%20%20%20%20%20FROM%20lineage_trace%20lt%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20lt.table_name%20%3D%20dl.target_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20lt.record_id%20%3D%20dl.target_record_id%0A%20%20%20%20%20%20%20%20WHERE%20p_direction%20IN%20('UPSTREAM'%2C%20'BOTH')%0A%20%20%20%20%20%20%20%20AND%20lt.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20downstream%20lineage%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20lt.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.target_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.target_record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'TARGET'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_rule%0A%20%20%20%20%20%20%20%20FROM%20lineage_trace%20lt%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20lt.table_name%20%3D%20dl.source_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20lt.record_id%20%3D%20dl.source_record_id%0A%20%20%20%20%20%20%20%20WHERE%20p_direction%20IN%20('DOWNSTREAM'%2C%20'BOTH')%0A%20%20%20%20%20%20%20%20AND%20lt.level%20%3C%2010%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20level%2C%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20relationship_type%2C%0A%20%20%20%20%20%20%20%20transformation_type%2C%0A%20%20%20%20%20%20%20%20transformation_rule%2C%0A%20%20%20%20%20%20%20%20REPEAT('%20%20'%2C%20level)%20as%20indentation%0A%20%20%20%20FROM%20lineage_trace%0A%20%20%20%20ORDER%20BY%20level%2C%20table_name%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data lineage tracking
CREATE TABLE data_lineage (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_table VARCHAR(100) NOT NULL,
    source_record_id VARCHAR(255) NOT NULL,
    target_table VARCHAR(100) NOT NULL,
    target_record_id VARCHAR(255) NOT NULL,
    
    -- Transformation details
    transformation_type ENUM('COPY', 'AGGREGATE', 'JOIN', 'CALCULATE', 'ENRICH'),
    transformation_rule TEXT,
    transformation_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Processing context
    job_name VARCHAR(200),
    job_execution_id VARCHAR(100),
    processing_user VARCHAR(100),
    
    -- Data quality
    confidence_score DECIMAL(3,2),
    quality_flags JSON,
    
    INDEX idx_source (source_table, source_record_id),
    INDEX idx_target (target_table, target_record_id),
    INDEX idx_transformation_timestamp (transformation_timestamp)
);

-- Data provenance queries
DELIMITER //
CREATE PROCEDURE trace_data_lineage(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_direction ENUM('UPSTREAM', 'DOWNSTREAM', 'BOTH')
)
BEGIN
    -- Recursive CTE to trace lineage
    WITH RECURSIVE lineage_trace AS (
        -- Base case: starting record
        SELECT 
            0 as level,
            p_table_name as table_name,
            p_record_id as record_id,
            'ORIGIN' as relationship_type,
            NULL as transformation_type,
            NULL as transformation_rule
        
        UNION ALL
        
        -- Recursive case: upstream lineage
        SELECT 
            lt.level + 1,
            dl.source_table,
            dl.source_record_id,
            'SOURCE',
            dl.transformation_type,
            dl.transformation_rule
        FROM lineage_trace lt
        JOIN data_lineage dl ON lt.table_name = dl.target_table 
                             AND lt.record_id = dl.target_record_id
        WHERE p_direction IN ('UPSTREAM', 'BOTH')
        AND lt.level &lt; 10  -- Prevent infinite recursion
        
        UNION ALL
        
        -- Recursive case: downstream lineage
        SELECT 
            lt.level + 1,
            dl.target_table,
            dl.target_record_id,
            'TARGET',
            dl.transformation_type,
            dl.transformation_rule
        FROM lineage_trace lt
        JOIN data_lineage dl ON lt.table_name = dl.source_table 
                             AND lt.record_id = dl.source_record_id
        WHERE p_direction IN ('DOWNSTREAM', 'BOTH')
        AND lt.level &lt; 10
    )
    SELECT 
        level,
        table_name,
        record_id,
        relationship_type,
        transformation_type,
        transformation_rule,
        REPEAT('  ', level) as indentation
    FROM lineage_trace
    ORDER BY level, table_name;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Version Comparison and Rollback:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Version%20comparison%0ACREATE%20TABLE%20version_comparisons%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20version_from%20INT%20NOT%20NULL%2C%0A%20%20%20%20version_to%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Comparison%20results%0A%20%20%20%20differences%20JSON%20NOT%20NULL%2C%0A%20%20%20%20comparison_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20compared_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_record%20(table_name%2C%20record_id)%2C%0A%20%20%20%20INDEX%20idx_versions%20(version_from%2C%20version_to)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0A--%20Compare%20versions%0ACREATE%20PROCEDURE%20compare_versions(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_version_from%20INT%2C%0A%20%20%20%20IN%20p_version_to%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_from_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_to_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_differences%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20version%20data%20(simplified%20-%20would%20need%20dynamic%20SQL%20for%20real%20implementation)%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20'price'%2C%20price%2C%0A%20%20%20%20%20%20%20%20'category_id'%2C%20category_id%2C%0A%20%20%20%20%20%20%20%20'status'%2C%20status%0A%20%20%20%20)%20INTO%20v_from_data%0A%20%20%20%20FROM%20products%0A%20%20%20%20WHERE%20id%20%3D%20p_record_id%20AND%20version_number%20%3D%20p_version_from%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20'price'%2C%20price%2C%0A%20%20%20%20%20%20%20%20'category_id'%2C%20category_id%2C%0A%20%20%20%20%20%20%20%20'status'%2C%20status%0A%20%20%20%20)%20INTO%20v_to_data%0A%20%20%20%20FROM%20products%0A%20%20%20%20WHERE%20id%20%3D%20p_record_id%20AND%20version_number%20%3D%20p_version_to%3B%0A%20%20%20%20%0A%20%20%20%20--%20Calculate%20differences%20(simplified)%0A%20%20%20%20SET%20v_differences%20%3D%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'from_version'%2C%20p_version_from%2C%0A%20%20%20%20%20%20%20%20'to_version'%2C%20p_version_to%2C%0A%20%20%20%20%20%20%20%20'from_data'%2C%20v_from_data%2C%0A%20%20%20%20%20%20%20%20'to_data'%2C%20v_to_data%2C%0A%20%20%20%20%20%20%20%20'changed_fields'%2C%20JSON_ARRAY()%20--%20Would%20contain%20actual%20field%20differences%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Store%20comparison%0A%20%20%20%20INSERT%20INTO%20version_comparisons%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20version_from%2C%20version_to%2C%20%0A%20%20%20%20%20%20%20%20differences%2C%20compared_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20p_version_from%2C%20p_version_to%2C%0A%20%20%20%20%20%20%20%20v_differences%2C%20USER()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20comparison%20results%0A%20%20%20%20SELECT%20v_differences%20as%20comparison_result%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Rollback%20to%20previous%20version%0ACREATE%20PROCEDURE%20rollback_to_version(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_target_version%20INT%2C%0A%20%20%20%20IN%20p_rollback_reason%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_version_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_current_version%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20target%20version%20data%0A%20%20%20%20SET%20%40get_version_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20JSON_OBJECT('%2C%0A%20%20%20%20%20%20%20%20'''name''%2C%20name%2C%20''price''%2C%20price%2C%20''category_id''%2C%20category_id'%2C%0A%20%20%20%20%20%20%20%20')%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id%2C%20'%20AND%20version_number%20%3D%20'%2C%20p_target_version%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40get_version_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_version_data%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_version_data%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Target%20version%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20new%20version%20with%20old%20data%0A%20%20%20%20CALL%20create_new_version(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20v_version_data%2C%20CURDATE()%2C%0A%20%20%20%20%20%20%20%20CONCAT('Rollback%20to%20version%20'%2C%20p_target_version%2C%20'%3A%20'%2C%20p_rollback_reason)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20rollback%0A%20%20%20%20INSERT%20INTO%20rollback_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20target_version%2C%20rollback_reason%2C%0A%20%20%20%20%20%20%20%20rollback_timestamp%2C%20rollback_user%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20p_target_version%2C%20p_rollback_reason%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%20USER()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Version comparison
CREATE TABLE version_comparisons (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    version_from INT NOT NULL,
    version_to INT NOT NULL,
    
    -- Comparison results
    differences JSON NOT NULL,
    comparison_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    compared_by VARCHAR(100),
    
    INDEX idx_table_record (table_name, record_id),
    INDEX idx_versions (version_from, version_to)
);

DELIMITER //
-- Compare versions
CREATE PROCEDURE compare_versions(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_version_from INT,
    IN p_version_to INT
)
BEGIN
    DECLARE v_from_data JSON;
    DECLARE v_to_data JSON;
    DECLARE v_differences JSON;
    
    -- Get version data (simplified - would need dynamic SQL for real implementation)
    SELECT JSON_OBJECT(
        'name', name,
        'price', price,
        'category_id', category_id,
        'status', status
    ) INTO v_from_data
    FROM products
    WHERE id = p_record_id AND version_number = p_version_from;
    
    SELECT JSON_OBJECT(
        'name', name,
        'price', price,
        'category_id', category_id,
        'status', status
    ) INTO v_to_data
    FROM products
    WHERE id = p_record_id AND version_number = p_version_to;
    
    -- Calculate differences (simplified)
    SET v_differences = JSON_OBJECT(
        'from_version', p_version_from,
        'to_version', p_version_to,
        'from_data', v_from_data,
        'to_data', v_to_data,
        'changed_fields', JSON_ARRAY() -- Would contain actual field differences
    );
    
    -- Store comparison
    INSERT INTO version_comparisons (
        table_name, record_id, version_from, version_to, 
        differences, compared_by
    ) VALUES (
        p_table_name, p_record_id, p_version_from, p_version_to,
        v_differences, USER()
    );
    
    -- Return comparison results
    SELECT v_differences as comparison_result;
    
END //

-- Rollback to previous version
CREATE PROCEDURE rollback_to_version(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_target_version INT,
    IN p_rollback_reason VARCHAR(500)
)
BEGIN
    DECLARE v_version_data JSON;
    DECLARE v_current_version INT;
    
    -- Get target version data
    SET @get_version_sql = CONCAT(
        'SELECT JSON_OBJECT(',
        '''name'', name, ''price'', price, ''category_id'', category_id',
        ') FROM ', p_table_name,
        ' WHERE id = ', p_record_id, ' AND version_number = ', p_target_version
    );
    
    PREPARE stmt FROM @get_version_sql;
    EXECUTE stmt;
    -- Store in v_version_data
    DEALLOCATE PREPARE stmt;
    
    IF v_version_data IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Target version not found';
    END IF;
    
    -- Create new version with old data
    CALL create_new_version(
        p_table_name, p_record_id, v_version_data, CURDATE(),
        CONCAT('Rollback to version ', p_target_version, ': ', p_rollback_reason)
    );
    
    -- Log rollback
    INSERT INTO rollback_log (
        table_name, record_id, target_version, rollback_reason,
        rollback_timestamp, rollback_user
    ) VALUES (
        p_table_name, p_record_id, p_target_version, p_rollback_reason,
        NOW(), USER()
    );
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>5. Temporal Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Temporal%20query%20examples%0A--%20Point-in-time%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20AS%20OF%20'2024-01-01%2012%3A00%3A00'%3B%0A%0A--%20Range%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20FROM%20'2024-01-01'%20TO%20'2024-01-31'%3B%0A%0A--%20All%20versions%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20ALL%0AWHERE%20id%20%3D%20123%0AORDER%20BY%20row_start%3B%0A%0A--%20Application%20versioning%20queries%0A--%20Current%20version%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20AND%20valid_to%20%3D%20'9999-12-31'%3B%0A%0A--%20Version%20at%20specific%20date%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20%0AAND%20valid_from%20%3C%3D%20'2024-01-15'%20%0AAND%20valid_to%20%3E%20'2024-01-15'%3B%0A%0A--%20All%20versions%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20%0AORDER%20BY%20version_number%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Temporal query examples
-- Point-in-time query
SELECT * FROM customers 
FOR SYSTEM_TIME AS OF '2024-01-01 12:00:00';

-- Range query
SELECT * FROM customers 
FOR SYSTEM_TIME FROM '2024-01-01' TO '2024-01-31';

-- All versions query
SELECT * FROM customers 
FOR SYSTEM_TIME ALL
WHERE id = 123
ORDER BY row_start;

-- Application versioning queries
-- Current version
SELECT * FROM products 
WHERE id = 123 AND valid_to = '9999-12-31';

-- Version at specific date
SELECT * FROM products 
WHERE id = 123 
AND valid_from &lt;= '2024-01-15' 
AND valid_to &gt; '2024-01-15';

-- All versions
SELECT * FROM products 
WHERE id = 123 
ORDER BY version_number;
</code></pre>
</div>

<p>This completes the data versioning and change tracking implementation with comprehensive temporal data management, lineage tracking, and version control capabilities.</p>

<p>---</p>

<h2 id="-387-what-are-data-mesh-and-decentralized-data-architectures-">**387. What are data mesh and decentralized data architectures?**</h2>

<p><strong>Answer:</strong> Data mesh is a decentralized data architecture that treats data as products owned by domain teams, promoting distributed ownership while maintaining governance, discoverability, and interoperability across the organization.</p>

<p><strong>Data Mesh Architecture Implementation:</strong></p>

<p><strong>1. Domain Data Products:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20product%20registry%0ACREATE%20TABLE%20data_products%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20product_type%20ENUM('ANALYTICAL'%2C%20'OPERATIONAL'%2C%20'ML_FEATURE'%2C%20'REFERENCE')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Product%20metadata%0A%20%20%20%20description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20business_purpose%20TEXT%2C%0A%20%20%20%20use_cases%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20product_owner%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_team%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20technical_contact%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20characteristics%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20update_frequency%20ENUM('REAL_TIME'%2C%20'HOURLY'%2C%20'DAILY'%2C%20'WEEKLY'%2C%20'MONTHLY')%2C%0A%20%20%20%20data_retention_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20metrics%0A%20%20%20%20sla_availability%20DECIMAL(5%2C2)%2C%20--%2099.9%25%0A%20%20%20%20sla_freshness_hours%20INT%2C%0A%20%20%20%20quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Access%20information%0A%20%20%20%20access_patterns%20JSON%2C%0A%20%20%20%20api_endpoints%20JSON%2C%0A%20%20%20%20schema_registry_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%0A%20%20%20%20status%20ENUM('DEVELOPMENT'%2C%20'ACTIVE'%2C%20'DEPRECATED'%2C%20'RETIRED')%20DEFAULT%20'DEVELOPMENT'%2C%0A%20%20%20%20version%20VARCHAR(20)%20DEFAULT%20'1.0.0'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_product_name%20(product_name)%2C%0A%20%20%20%20INDEX%20idx_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_product_owner%20(product_owner)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A%0A--%20Domain%20boundaries%20and%20responsibilities%0ACREATE%20TABLE%20data_domains%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_description%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20domain_owner%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_team_lead%20VARCHAR(100)%2C%0A%20%20%20%20team_members%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20context%0A%20%20%20%20business_capability%20VARCHAR(200)%2C%0A%20%20%20%20bounded_context%20TEXT%2C%0A%20%20%20%20key_entities%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20infrastructure%0A%20%20%20%20infrastructure_platform%20VARCHAR(100)%2C%0A%20%20%20%20data_storage_config%20JSON%2C%0A%20%20%20%20compute_resources%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20data_governance_policies%20JSON%2C%0A%20%20%20%20compliance_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_domain_owner%20(domain_owner)%0A)%3B%0A%0A--%20Data%20product%20contracts%20(API%20specifications)%0ACREATE%20TABLE%20data_product_contracts%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20contract_version%20VARCHAR(20)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Schema%20definition%0A%20%20%20%20input_schema%20JSON%2C%0A%20%20%20%20output_schema%20JSON%2C%0A%20%20%20%20schema_evolution_strategy%20ENUM('BACKWARD_COMPATIBLE'%2C%20'FORWARD_COMPATIBLE'%2C%20'BREAKING')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Service%20level%20agreements%0A%20%20%20%20sla_definition%20JSON%20NOT%20NULL%2C%0A%20%20%20%20quality_guarantees%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Access%20patterns%0A%20%20%20%20supported_access_patterns%20JSON%2C%20--%20batch%2C%20streaming%2C%20query%2C%20etc.%0A%20%20%20%20rate_limits%20JSON%2C%0A%20%20%20%20authentication_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Documentation%0A%20%20%20%20api_documentation%20TEXT%2C%0A%20%20%20%20usage_examples%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20deprecation_date%20DATE%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_product_version%20(product_id%2C%20contract_version)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data product registry
CREATE TABLE data_products (
    id INT AUTO_INCREMENT PRIMARY KEY,
    product_name VARCHAR(200) NOT NULL,
    domain_name VARCHAR(100) NOT NULL,
    product_type ENUM('ANALYTICAL', 'OPERATIONAL', 'ML_FEATURE', 'REFERENCE') NOT NULL,
    
    -- Product metadata
    description TEXT NOT NULL,
    business_purpose TEXT,
    use_cases JSON,
    
    -- Ownership
    product_owner VARCHAR(100) NOT NULL,
    domain_team VARCHAR(100) NOT NULL,
    technical_contact VARCHAR(100),
    
    -- Data characteristics
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    update_frequency ENUM('REAL_TIME', 'HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY'),
    data_retention_days INT,
    
    -- Quality metrics
    sla_availability DECIMAL(5,2), -- 99.9%
    sla_freshness_hours INT,
    quality_score DECIMAL(3,2),
    
    -- Access information
    access_patterns JSON,
    api_endpoints JSON,
    schema_registry_id VARCHAR(100),
    
    -- Lifecycle
    status ENUM('DEVELOPMENT', 'ACTIVE', 'DEPRECATED', 'RETIRED') DEFAULT 'DEVELOPMENT',
    version VARCHAR(20) DEFAULT '1.0.0',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_product_name (product_name),
    INDEX idx_domain_name (domain_name),
    INDEX idx_product_owner (product_owner),
    INDEX idx_status (status)
);

-- Domain boundaries and responsibilities
CREATE TABLE data_domains (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_name VARCHAR(100) NOT NULL,
    domain_description TEXT,
    
    -- Ownership
    domain_owner VARCHAR(100) NOT NULL,
    domain_team_lead VARCHAR(100),
    team_members JSON,
    
    -- Business context
    business_capability VARCHAR(200),
    bounded_context TEXT,
    key_entities JSON,
    
    -- Technical infrastructure
    infrastructure_platform VARCHAR(100),
    data_storage_config JSON,
    compute_resources JSON,
    
    -- Governance
    data_governance_policies JSON,
    compliance_requirements JSON,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_domain_name (domain_name),
    INDEX idx_domain_owner (domain_owner)
);

-- Data product contracts (API specifications)
CREATE TABLE data_product_contracts (
    id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    contract_version VARCHAR(20) NOT NULL,
    
    -- Schema definition
    input_schema JSON,
    output_schema JSON,
    schema_evolution_strategy ENUM('BACKWARD_COMPATIBLE', 'FORWARD_COMPATIBLE', 'BREAKING'),
    
    -- Service level agreements
    sla_definition JSON NOT NULL,
    quality_guarantees JSON,
    
    -- Access patterns
    supported_access_patterns JSON, -- batch, streaming, query, etc.
    rate_limits JSON,
    authentication_requirements JSON,
    
    -- Documentation
    api_documentation TEXT,
    usage_examples JSON,
    
    -- Lifecycle
    effective_date DATE NOT NULL,
    deprecation_date DATE,
    is_active BOOLEAN DEFAULT TRUE,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    UNIQUE KEY uk_product_version (product_id, contract_version),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. Federated Governance Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Global%20governance%20policies%0ACREATE%20TABLE%20global_governance_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20policy_category%20ENUM('DATA_QUALITY'%2C%20'SECURITY'%2C%20'PRIVACY'%2C%20'INTEROPERABILITY'%2C%20'DISCOVERABILITY')%2C%0A%20%20%20%20policy_level%20ENUM('MANDATORY'%2C%20'RECOMMENDED'%2C%20'OPTIONAL')%20DEFAULT%20'MANDATORY'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Policy%20definition%0A%20%20%20%20policy_description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20policy_rules%20JSON%20NOT%20NULL%2C%0A%20%20%20%20implementation_guidelines%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%0A%20%20%20%20compliance_check_automated%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20compliance_check_procedure%20VARCHAR(200)%2C%0A%20%20%20%20violation_consequences%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20policy_owner%20VARCHAR(100)%2C%0A%20%20%20%20approval_authority%20VARCHAR(100)%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_frequency_months%20INT%20DEFAULT%2012%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_policy_name%20(policy_name)%2C%0A%20%20%20%20INDEX%20idx_policy_category%20(policy_category)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A%0A--%20Domain-specific%20governance%20implementations%0ACREATE%20TABLE%20domain_governance_implementations%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20global_policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Implementation%20details%0A%20%20%20%20implementation_approach%20TEXT%2C%0A%20%20%20%20domain_specific_rules%20JSON%2C%0A%20%20%20%20monitoring_procedures%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%20status%0A%20%20%20%20compliance_status%20ENUM('COMPLIANT'%2C%20'PARTIAL'%2C%20'NON_COMPLIANT'%2C%20'NOT_ASSESSED')%2C%0A%20%20%20%20last_assessment_date%20DATE%2C%0A%20%20%20%20assessment_notes%20TEXT%2C%0A%20%20%20%20remediation_plan%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20implementation_owner%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(global_policy_id)%20REFERENCES%20global_governance_policies(id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_policy%20(domain_id%2C%20global_policy_id)%2C%0A%20%20%20%20INDEX%20idx_compliance_status%20(compliance_status)%0A)%3B%0A%0A--%20Self-serve%20data%20platform%20capabilities%0ACREATE%20TABLE%20platform_capabilities%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20capability_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20capability_type%20ENUM('INFRASTRUCTURE'%2C%20'TOOLING'%2C%20'GOVERNANCE'%2C%20'MONITORING')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Capability%20description%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20technical_specifications%20JSON%2C%0A%20%20%20%20usage_documentation%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Service%20details%0A%20%20%20%20service_endpoints%20JSON%2C%0A%20%20%20%20api_documentation_url%20VARCHAR(500)%2C%0A%20%20%20%20support_contact%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SLA%0A%20%20%20%20availability_sla%20DECIMAL(5%2C2)%2C%0A%20%20%20%20performance_sla%20JSON%2C%0A%20%20%20%20support_sla%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20tracking%0A%20%20%20%20active_users_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20usage_metrics%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20status%20ENUM('AVAILABLE'%2C%20'BETA'%2C%20'DEPRECATED'%2C%20'MAINTENANCE')%20DEFAULT%20'AVAILABLE'%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_capability_name%20(capability_name)%2C%0A%20%20%20%20INDEX%20idx_capability_type%20(capability_type)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Global governance policies
CREATE TABLE global_governance_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    policy_category ENUM('DATA_QUALITY', 'SECURITY', 'PRIVACY', 'INTEROPERABILITY', 'DISCOVERABILITY'),
    policy_level ENUM('MANDATORY', 'RECOMMENDED', 'OPTIONAL') DEFAULT 'MANDATORY',
    
    -- Policy definition
    policy_description TEXT NOT NULL,
    policy_rules JSON NOT NULL,
    implementation_guidelines TEXT,
    
    -- Compliance
    compliance_check_automated BOOLEAN DEFAULT FALSE,
    compliance_check_procedure VARCHAR(200),
    violation_consequences TEXT,
    
    -- Governance
    policy_owner VARCHAR(100),
    approval_authority VARCHAR(100),
    effective_date DATE NOT NULL,
    review_frequency_months INT DEFAULT 12,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_policy_name (policy_name),
    INDEX idx_policy_category (policy_category),
    INDEX idx_effective_date (effective_date)
);

-- Domain-specific governance implementations
CREATE TABLE domain_governance_implementations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_id INT NOT NULL,
    global_policy_id INT NOT NULL,
    
    -- Implementation details
    implementation_approach TEXT,
    domain_specific_rules JSON,
    monitoring_procedures TEXT,
    
    -- Compliance status
    compliance_status ENUM('COMPLIANT', 'PARTIAL', 'NON_COMPLIANT', 'NOT_ASSESSED'),
    last_assessment_date DATE,
    assessment_notes TEXT,
    remediation_plan TEXT,
    
    -- Ownership
    implementation_owner VARCHAR(100),
    
    FOREIGN KEY (domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (global_policy_id) REFERENCES global_governance_policies(id),
    UNIQUE KEY uk_domain_policy (domain_id, global_policy_id),
    INDEX idx_compliance_status (compliance_status)
);

-- Self-serve data platform capabilities
CREATE TABLE platform_capabilities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    capability_name VARCHAR(200) NOT NULL,
    capability_type ENUM('INFRASTRUCTURE', 'TOOLING', 'GOVERNANCE', 'MONITORING'),
    
    -- Capability description
    description TEXT,
    technical_specifications JSON,
    usage_documentation TEXT,
    
    -- Service details
    service_endpoints JSON,
    api_documentation_url VARCHAR(500),
    support_contact VARCHAR(100),
    
    -- SLA
    availability_sla DECIMAL(5,2),
    performance_sla JSON,
    support_sla TEXT,
    
    -- Usage tracking
    active_users_count INT DEFAULT 0,
    usage_metrics JSON,
    
    status ENUM('AVAILABLE', 'BETA', 'DEPRECATED', 'MAINTENANCE') DEFAULT 'AVAILABLE',
    
    UNIQUE KEY uk_capability_name (capability_name),
    INDEX idx_capability_type (capability_type),
    INDEX idx_status (status)
);
</code></pre>
</div>

<p><strong>3. Data Product Discovery and Catalog:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Federated%20data%20catalog%0ACREATE%20TABLE%20federated_data_catalog%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Discoverability%20metadata%0A%20%20%20%20searchable_tags%20JSON%2C%0A%20%20%20%20business_glossary_terms%20JSON%2C%0A%20%20%20%20semantic_annotations%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20information%0A%20%20%20%20consumer_applications%20JSON%2C%0A%20%20%20%20usage_patterns%20JSON%2C%0A%20%20%20%20access_frequency_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20indicators%0A%20%20%20%20data_quality_metrics%20JSON%2C%0A%20%20%20%20freshness_indicators%20JSON%2C%0A%20%20%20%20completeness_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20accuracy_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lineage%20information%0A%20%20%20%20upstream_dependencies%20JSON%2C%0A%20%20%20%20downstream_consumers%20JSON%2C%0A%20%20%20%20transformation_lineage%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Social%20features%0A%20%20%20%20user_ratings%20DECIMAL(3%2C2)%2C%0A%20%20%20%20user_reviews%20JSON%2C%0A%20%20%20%20bookmark_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Search%20optimization%0A%20%20%20%20search_vector%20TEXT%2C%20--%20For%20full-text%20search%0A%20%20%20%20popularity_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20last_updated%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_id%20(product_id)%2C%0A%20%20%20%20INDEX%20idx_popularity_score%20(popularity_score)%2C%0A%20%20%20%20FULLTEXT%20idx_search_vector%20(search_vector)%0A)%3B%0A%0A--%20Data%20product%20discovery%20procedures%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20discover_data_products(%0A%20%20%20%20IN%20p_search_term%20VARCHAR(500)%2C%0A%20%20%20%20IN%20p_domain_filter%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_type_filter%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_quality_threshold%20DECIMAL(3%2C2)%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20dp.id%2C%0A%20%20%20%20%20%20%20%20dp.product_name%2C%0A%20%20%20%20%20%20%20%20dp.domain_name%2C%0A%20%20%20%20%20%20%20%20dp.description%2C%0A%20%20%20%20%20%20%20%20dp.product_owner%2C%0A%20%20%20%20%20%20%20%20dp.quality_score%2C%0A%20%20%20%20%20%20%20%20dp.update_frequency%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Catalog%20enrichment%0A%20%20%20%20%20%20%20%20fdc.popularity_score%2C%0A%20%20%20%20%20%20%20%20fdc.user_ratings%2C%0A%20%20%20%20%20%20%20%20fdc.access_frequency_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Relevance%20scoring%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dp.product_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%2010%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dp.description%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%205%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20MATCH(fdc.search_vector)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20THEN%203%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20fdc.popularity_score%0A%20%20%20%20%20%20%20%20)%20as%20relevance_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Usage%20indicators%0A%20%20%20%20%20%20%20%20JSON_LENGTH(fdc.consumer_applications)%20as%20consumer_count%2C%0A%20%20%20%20%20%20%20%20fdc.bookmark_count%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20FROM%20data_products%20dp%0A%20%20%20%20JOIN%20federated_data_catalog%20fdc%20ON%20dp.id%20%3D%20fdc.product_id%0A%20%20%20%20WHERE%20dp.status%20%3D%20'ACTIVE'%0A%20%20%20%20AND%20(p_domain_filter%20IS%20NULL%20OR%20dp.domain_name%20%3D%20p_domain_filter)%0A%20%20%20%20AND%20(p_data_type_filter%20IS%20NULL%20OR%20dp.product_type%20%3D%20p_data_type_filter)%0A%20%20%20%20AND%20(p_quality_threshold%20IS%20NULL%20OR%20dp.quality_score%20%3E%3D%20p_quality_threshold)%0A%20%20%20%20AND%20(%0A%20%20%20%20%20%20%20%20p_search_term%20IS%20NULL%20OR%0A%20%20%20%20%20%20%20%20dp.product_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20dp.description%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20MATCH(fdc.search_vector)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%0A%20%20%20%20)%0A%20%20%20%20%0A%20%20%20%20HAVING%20relevance_score%20%3E%200%0A%20%20%20%20ORDER%20BY%20relevance_score%20DESC%2C%20fdc.popularity_score%20DESC%0A%20%20%20%20LIMIT%2050%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Federated data catalog
CREATE TABLE federated_data_catalog (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    
    -- Discoverability metadata
    searchable_tags JSON,
    business_glossary_terms JSON,
    semantic_annotations JSON,
    
    -- Usage information
    consumer_applications JSON,
    usage_patterns JSON,
    access_frequency_score DECIMAL(5,2),
    
    -- Quality indicators
    data_quality_metrics JSON,
    freshness_indicators JSON,
    completeness_score DECIMAL(3,2),
    accuracy_score DECIMAL(3,2),
    
    -- Lineage information
    upstream_dependencies JSON,
    downstream_consumers JSON,
    transformation_lineage JSON,
    
    -- Social features
    user_ratings DECIMAL(3,2),
    user_reviews JSON,
    bookmark_count INT DEFAULT 0,
    
    -- Search optimization
    search_vector TEXT, -- For full-text search
    popularity_score DECIMAL(5,2),
    
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_id (product_id),
    INDEX idx_popularity_score (popularity_score),
    FULLTEXT idx_search_vector (search_vector)
);

-- Data product discovery procedures
DELIMITER //
CREATE PROCEDURE discover_data_products(
    IN p_search_term VARCHAR(500),
    IN p_domain_filter VARCHAR(100),
    IN p_data_type_filter VARCHAR(50),
    IN p_quality_threshold DECIMAL(3,2)
)
BEGIN
    SELECT 
        dp.id,
        dp.product_name,
        dp.domain_name,
        dp.description,
        dp.product_owner,
        dp.quality_score,
        dp.update_frequency,
        
        -- Catalog enrichment
        fdc.popularity_score,
        fdc.user_ratings,
        fdc.access_frequency_score,
        
        -- Relevance scoring
        (
            CASE WHEN dp.product_name LIKE CONCAT('%', p_search_term, '%') THEN 10 ELSE 0 END +
            CASE WHEN dp.description LIKE CONCAT('%', p_search_term, '%') THEN 5 ELSE 0 END +
            CASE WHEN MATCH(fdc.search_vector) AGAINST(p_search_term IN NATURAL LANGUAGE MODE) THEN 3 ELSE 0 END +
            fdc.popularity_score
        ) as relevance_score,
        
        -- Usage indicators
        JSON_LENGTH(fdc.consumer_applications) as consumer_count,
        fdc.bookmark_count
        
    FROM data_products dp
    JOIN federated_data_catalog fdc ON dp.id = fdc.product_id
    WHERE dp.status = 'ACTIVE'
    AND (p_domain_filter IS NULL OR dp.domain_name = p_domain_filter)
    AND (p_data_type_filter IS NULL OR dp.product_type = p_data_type_filter)
    AND (p_quality_threshold IS NULL OR dp.quality_score &gt;= p_quality_threshold)
    AND (
        p_search_term IS NULL OR
        dp.product_name LIKE CONCAT('%', p_search_term, '%') OR
        dp.description LIKE CONCAT('%', p_search_term, '%') OR
        MATCH(fdc.search_vector) AGAINST(p_search_term IN NATURAL LANGUAGE MODE)
    )
    
    HAVING relevance_score &gt; 0
    ORDER BY relevance_score DESC, fdc.popularity_score DESC
    LIMIT 50;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Data Product Lifecycle Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20product%20lifecycle%20tracking%0ACREATE%20TABLE%20data_product_lifecycle%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20lifecycle_stage%20ENUM('IDEATION'%2C%20'DEVELOPMENT'%2C%20'TESTING'%2C%20'PRODUCTION'%2C%20'MAINTENANCE'%2C%20'DEPRECATION'%2C%20'RETIREMENT')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stage%20details%0A%20%20%20%20stage_entry_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20stage_exit_date%20TIMESTAMP%20NULL%2C%0A%20%20%20%20stage_duration_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stage-specific%20metadata%0A%20%20%20%20stage_artifacts%20JSON%2C%0A%20%20%20%20quality_gates_passed%20JSON%2C%0A%20%20%20%20approval_checkpoints%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stakeholder%20involvement%0A%20%20%20%20stage_owner%20VARCHAR(100)%2C%0A%20%20%20%20reviewers%20JSON%2C%0A%20%20%20%20approvers%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Notes%20and%20documentation%0A%20%20%20%20stage_notes%20TEXT%2C%0A%20%20%20%20lessons_learned%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_stage%20(product_id%2C%20lifecycle_stage)%2C%0A%20%20%20%20INDEX%20idx_stage_entry_date%20(stage_entry_date)%0A)%3B%0A%0A--%20Data%20product%20metrics%20and%20monitoring%0ACREATE%20TABLE%20data_product_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20metric_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20metrics%0A%20%20%20%20daily_active_consumers%20INT%2C%0A%20%20%20%20api_request_count%20BIGINT%2C%0A%20%20%20%20data_volume_gb%20DECIMAL(12%2C2)%2C%0A%20%20%20%20query_response_time_ms%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20metrics%0A%20%20%20%20data_freshness_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20completeness_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20accuracy_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20consistency_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metrics%0A%20%20%20%20business_value_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20cost_per_query%20DECIMAL(10%2C4)%2C%0A%20%20%20%20revenue_attribution%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20metrics%0A%20%20%20%20availability_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20error_rate_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20infrastructure_cost%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_timestamp%20(product_id%2C%20metric_timestamp)%2C%0A%20%20%20%20INDEX%20idx_metric_timestamp%20(metric_timestamp)%0A)%3B%0A%0A--%20Cross-domain%20data%20sharing%20agreements%0ACREATE%20TABLE%20data_sharing_agreements%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20provider_domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20consumer_domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Agreement%20details%0A%20%20%20%20agreement_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20sharing_purpose%20TEXT%2C%0A%20%20%20%20data_usage_restrictions%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Terms%20and%20conditions%0A%20%20%20%20sla_terms%20JSON%2C%0A%20%20%20%20data_retention_terms%20TEXT%2C%0A%20%20%20%20privacy_requirements%20JSON%2C%0A%20%20%20%20security_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Commercial%20terms%0A%20%20%20%20cost_model%20ENUM('FREE'%2C%20'USAGE_BASED'%2C%20'SUBSCRIPTION'%2C%20'CUSTOM')%2C%0A%20%20%20%20pricing_details%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20agreement_owner%20VARCHAR(100)%2C%0A%20%20%20%20legal_review_status%20ENUM('PENDING'%2C%20'APPROVED'%2C%20'REJECTED')%2C%0A%20%20%20%20effective_date%20DATE%2C%0A%20%20%20%20expiry_date%20DATE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20status%20ENUM('DRAFT'%2C%20'ACTIVE'%2C%20'SUSPENDED'%2C%20'TERMINATED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(provider_domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(consumer_domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_provider_consumer%20(provider_domain_id%2C%20consumer_domain_id)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data product lifecycle tracking
CREATE TABLE data_product_lifecycle (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    lifecycle_stage ENUM('IDEATION', 'DEVELOPMENT', 'TESTING', 'PRODUCTION', 'MAINTENANCE', 'DEPRECATION', 'RETIREMENT'),
    
    -- Stage details
    stage_entry_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    stage_exit_date TIMESTAMP NULL,
    stage_duration_days INT,
    
    -- Stage-specific metadata
    stage_artifacts JSON,
    quality_gates_passed JSON,
    approval_checkpoints JSON,
    
    -- Stakeholder involvement
    stage_owner VARCHAR(100),
    reviewers JSON,
    approvers JSON,
    
    -- Notes and documentation
    stage_notes TEXT,
    lessons_learned TEXT,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_stage (product_id, lifecycle_stage),
    INDEX idx_stage_entry_date (stage_entry_date)
);

-- Data product metrics and monitoring
CREATE TABLE data_product_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    metric_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Usage metrics
    daily_active_consumers INT,
    api_request_count BIGINT,
    data_volume_gb DECIMAL(12,2),
    query_response_time_ms DECIMAL(10,2),
    
    -- Quality metrics
    data_freshness_score DECIMAL(3,2),
    completeness_percentage DECIMAL(5,2),
    accuracy_percentage DECIMAL(5,2),
    consistency_score DECIMAL(3,2),
    
    -- Business metrics
    business_value_score DECIMAL(5,2),
    cost_per_query DECIMAL(10,4),
    revenue_attribution DECIMAL(12,2),
    
    -- Technical metrics
    availability_percentage DECIMAL(5,2),
    error_rate_percentage DECIMAL(5,2),
    infrastructure_cost DECIMAL(10,2),
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_timestamp (product_id, metric_timestamp),
    INDEX idx_metric_timestamp (metric_timestamp)
);

-- Cross-domain data sharing agreements
CREATE TABLE data_sharing_agreements (
    id INT AUTO_INCREMENT PRIMARY KEY,
    provider_domain_id INT NOT NULL,
    consumer_domain_id INT NOT NULL,
    product_id INT NOT NULL,
    
    -- Agreement details
    agreement_name VARCHAR(200) NOT NULL,
    sharing_purpose TEXT,
    data_usage_restrictions JSON,
    
    -- Terms and conditions
    sla_terms JSON,
    data_retention_terms TEXT,
    privacy_requirements JSON,
    security_requirements JSON,
    
    -- Commercial terms
    cost_model ENUM('FREE', 'USAGE_BASED', 'SUBSCRIPTION', 'CUSTOM'),
    pricing_details JSON,
    
    -- Governance
    agreement_owner VARCHAR(100),
    legal_review_status ENUM('PENDING', 'APPROVED', 'REJECTED'),
    effective_date DATE,
    expiry_date DATE,
    
    -- Status
    status ENUM('DRAFT', 'ACTIVE', 'SUSPENDED', 'TERMINATED') DEFAULT 'DRAFT',
    
    FOREIGN KEY (provider_domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (consumer_domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_provider_consumer (provider_domain_id, consumer_domain_id),
    INDEX idx_status (status)
);
</code></pre>
</div>

<p><strong>5. Decentralized Data Quality Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Domain-specific%20data%20quality%20rules%0ACREATE%20TABLE%20domain_quality_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20rule_category%20ENUM('COMPLETENESS'%2C%20'ACCURACY'%2C%20'CONSISTENCY'%2C%20'TIMELINESS'%2C%20'VALIDITY')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rule%20definition%0A%20%20%20%20rule_expression%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20rule_parameters%20JSON%2C%0A%20%20%20%20expected_threshold%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Implementation%0A%20%20%20%20check_frequency%20ENUM('REAL_TIME'%2C%20'HOURLY'%2C%20'DAILY'%2C%20'WEEKLY')%2C%0A%20%20%20%20automated_remediation%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20remediation_procedure%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20rule_owner%20VARCHAR(100)%2C%0A%20%20%20%20business_justification%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20last_execution%20TIMESTAMP%2C%0A%20%20%20%20last_result%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_domain_product%20(domain_id%2C%20product_id)%2C%0A%20%20%20%20INDEX%20idx_rule_category%20(rule_category)%0A)%3B%0A%0A--%20Federated%20data%20quality%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_federated_data_quality()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_domain_id%20INT%3B%0A%20%20%20%20DECLARE%20v_domain_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_quality_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20domain_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20domain_name%20FROM%20data_domains%20WHERE%20status%20%3D%20'ACTIVE'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20quality_summary%20(%0A%20%20%20%20%20%20%20%20domain_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20total_products%20INT%2C%0A%20%20%20%20%20%20%20%20avg_quality_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%20%20%20%20products_below_threshold%20INT%2C%0A%20%20%20%20%20%20%20%20critical_issues%20INT%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20domain_cursor%3B%0A%20%20%20%20%0A%20%20%20%20quality_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20domain_cursor%20INTO%20v_domain_id%2C%20v_domain_name%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20quality_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20domain%20quality%20metrics%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20COUNT(*)%20as%20total_products%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20AVG(quality_score)%20as%20avg_quality%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20quality_score%20%3C%200.8%20THEN%201%20ELSE%200%20END)%20as%20below_threshold%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20quality_score%20%3C%200.6%20THEN%201%20ELSE%200%20END)%20as%20critical_issues%0A%20%20%20%20%20%20%20%20INTO%20%40total%2C%20%40avg_quality%2C%20%40below_threshold%2C%20%40critical%0A%20%20%20%20%20%20%20%20FROM%20data_products%0A%20%20%20%20%20%20%20%20WHERE%20domain_name%20%3D%20v_domain_name%20AND%20status%20%3D%20'ACTIVE'%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20quality_summary%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_domain_name%2C%20%40total%2C%20%40avg_quality%2C%20%40below_threshold%2C%20%40critical%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20domain_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20federated%20quality%20summary%0A%20%20%20%20SELECT%20*%20FROM%20quality_summary%20ORDER%20BY%20avg_quality_score%20DESC%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20quality_summary%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Domain-specific data quality rules
CREATE TABLE domain_quality_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_id INT NOT NULL,
    product_id INT,
    rule_name VARCHAR(200) NOT NULL,
    rule_category ENUM('COMPLETENESS', 'ACCURACY', 'CONSISTENCY', 'TIMELINESS', 'VALIDITY'),
    
    -- Rule definition
    rule_expression TEXT NOT NULL,
    rule_parameters JSON,
    expected_threshold DECIMAL(5,2),
    
    -- Implementation
    check_frequency ENUM('REAL_TIME', 'HOURLY', 'DAILY', 'WEEKLY'),
    automated_remediation BOOLEAN DEFAULT FALSE,
    remediation_procedure TEXT,
    
    -- Ownership
    rule_owner VARCHAR(100),
    business_justification TEXT,
    
    -- Status
    is_active BOOLEAN DEFAULT TRUE,
    last_execution TIMESTAMP,
    last_result DECIMAL(5,2),
    
    FOREIGN KEY (domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_domain_product (domain_id, product_id),
    INDEX idx_rule_category (rule_category)
);

-- Federated data quality monitoring
DELIMITER //
CREATE PROCEDURE monitor_federated_data_quality()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_domain_id INT;
    DECLARE v_domain_name VARCHAR(100);
    DECLARE v_quality_score DECIMAL(5,2);
    
    DECLARE domain_cursor CURSOR FOR
        SELECT id, domain_name FROM data_domains WHERE status = 'ACTIVE';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create temporary results table
    CREATE TEMPORARY TABLE quality_summary (
        domain_name VARCHAR(100),
        total_products INT,
        avg_quality_score DECIMAL(5,2),
        products_below_threshold INT,
        critical_issues INT
    );
    
    OPEN domain_cursor;
    
    quality_loop: LOOP
        FETCH domain_cursor INTO v_domain_id, v_domain_name;
        
        IF done THEN
            LEAVE quality_loop;
        END IF;
        
        -- Calculate domain quality metrics
        SELECT 
            COUNT(*) as total_products,
            AVG(quality_score) as avg_quality,
            SUM(CASE WHEN quality_score &lt; 0.8 THEN 1 ELSE 0 END) as below_threshold,
            SUM(CASE WHEN quality_score &lt; 0.6 THEN 1 ELSE 0 END) as critical_issues
        INTO @total, @avg_quality, @below_threshold, @critical
        FROM data_products
        WHERE domain_name = v_domain_name AND status = 'ACTIVE';
        
        INSERT INTO quality_summary VALUES (
            v_domain_name, @total, @avg_quality, @below_threshold, @critical
        );
        
    END LOOP;
    
    CLOSE domain_cursor;
    
    -- Return federated quality summary
    SELECT * FROM quality_summary ORDER BY avg_quality_score DESC;
    
    DROP TEMPORARY TABLE quality_summary;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Key Data Mesh Principles:</strong></p>

<p>- <strong>Domain Ownership</strong>: Each domain owns and operates their data products</p>
<p>- <strong>Data as a Product</strong>: Treat data with product thinking - quality, usability, discoverability</p>
<p>- <strong>Self-Serve Data Platform</strong>: Provide infrastructure and tools for domain autonomy</p>
<p>- <strong>Federated Computational Governance</strong>: Balance autonomy with global standards</p>


            </div>
        </main>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        
        // Initialize TOC
        document.getElementById('toc-list').innerHTML = `<li><a href="#-321-what-are-indexes-and-how-do-they-work-" class="h2-link">**321. What are indexes and how do they work?**</a></li><li><a href="#-322-what-are-the-different-types-of-indexes-in-mysql-" class="h2-link">**322. What are the different types of indexes in MySQL?**</a></li><li><a href="#-323-how-do-you-create-and-optimize-composite-indexes-" class="h2-link">**323. How do you create and optimize composite indexes?**</a></li><li><a href="#-324-what-is-the-difference-between-clustered-and-non-clustered-indexes-" class="h2-link">**324. What is the difference between clustered and non-clustered indexes?**</a></li><li><a href="#-325-how-do-you-analyze-index-usage-and-effectiveness-" class="h2-link">**325. How do you analyze index usage and effectiveness?**</a></li><li><a href="#-326-what-is-index-cardinality-and-why-is-it-important-" class="h2-link">**326. What is index cardinality and why is it important?**</a></li><li><a href="#-327-how-do-you-handle-index-maintenance-and-rebuilding-" class="h2-link">**327. How do you handle index maintenance and rebuilding?**</a></li><li><a href="#-328-what-are-covering-indexes-and-when-do-you-use-them-" class="h2-link">**328. What are covering indexes and when do you use them?**</a></li><li><a href="#-329-how-do-you-implement-full-text-search-indexes-" class="h2-link">**329. How do you implement full-text search indexes?**</a></li><li><a href="#-330-what-is-the-impact-of-indexes-on-insert-update-delete-operations-" class="h2-link">**330. What is the impact of indexes on INSERT/UPDATE/DELETE operations?**</a></li><li><a href="#-331-how-do-you-optimize-queries-using-explain-" class="h2-link">**331. How do you optimize queries using EXPLAIN?**</a></li><li><a href="#-332-what-are-query-execution-plans-and-how-do-you-read-them-" class="h2-link">**332. What are query execution plans and how do you read them?**</a></li><li><a href="#-333-how-do-you-handle-index-hints-and-force-index-usage-" class="h2-link">**333. How do you handle index hints and force index usage?**</a></li><li><a href="#-334-what-is-index-selectivity-and-how-do-you-calculate-it-" class="h2-link">**334. What is index selectivity and how do you calculate it?**</a></li><li><a href="#-335-how-do-you-optimize-order-by-and-group-by-clauses-" class="h2-link">**335. How do you optimize ORDER BY and GROUP BY clauses?**</a></li><li><a href="#-336-what-are-partial-indexes-and-when-do-you-use-them-" class="h2-link">**336. What are partial indexes and when do you use them?**</a></li><li><a href="#-337-how-do-you-handle-index-fragmentation-" class="h2-link">**337. How do you handle index fragmentation?**</a></li><li><a href="#-338-what-is-the-difference-between-b-tree-and-hash-indexes-" class="h2-link">**338. What is the difference between B-tree and Hash indexes?**</a></li><li><a href="#-339-how-do-you-optimize-joins-using-indexes-" class="h2-link">**339. How do you optimize joins using indexes?**</a></li><li><a href="#-340-what-are-invisible-indexes-and-their-use-cases-" class="h2-link">**340. What are invisible indexes and their use cases?**</a></li><li><a href="#-341-how-do-you-monitor-index-performance-and-usage-" class="h2-link">**341. How do you monitor index performance and usage?**</a></li><li><a href="#-342-what-are-functional-indexes-and-how-do-you-implement-them-" class="h2-link">**342. What are functional indexes and how do you implement them?**</a></li><li><a href="#-343-how-do-you-handle-index-bloat-and-maintenance-" class="h2-link">**343. How do you handle index bloat and maintenance?**</a></li><li><a href="#-344-what-is-index-intersection-and-how-does-it-work-" class="h2-link">**344. What is index intersection and how does it work?**</a></li><li><a href="#-345-how-do-you-optimize-database-schema-for-better-index-performance-" class="h2-link">**345. How do you optimize database schema for better index performance?**</a></li><li><a href="#-346-what-are-stored-procedures-and-their-advantages-disadvantages-" class="h2-link">**346. What are stored procedures and their advantages/disadvantages?**</a></li><li><a href="#-347-how-do-you-implement-and-use-triggers-" class="h2-link">**347. How do you implement and use triggers?**</a></li><li><a href="#-348-what-are-views-and-materialized-views-" class="h2-link">**348. What are views and materialized views?**</a></li><li><a href="#-349-how-do-you-work-with-json-data-in-mysql-" class="h2-link">**349. How do you work with JSON data in MySQL?**</a></li><li><a href="#-350-what-are-window-functions-and-how-do-you-use-them-" class="h2-link">**350. What are window functions and how do you use them?**</a></li><li><a href="#-351-how-do-you-implement-recursive-queries-with-ctes-" class="h2-link">**351. How do you implement recursive queries with CTEs?**</a></li><li><a href="#-352-what-are-user-defined-functions-udfs-" class="h2-link">**352. What are user-defined functions (UDFs)?**</a></li><li><a href="#-353-how-do-you-work-with-temporary-tables-" class="h2-link">**353. How do you work with temporary tables?**</a></li><li><a href="#-354-what-are-database-events-and-how-do-you-schedule-them-" class="h2-link">**354. What are database events and how do you schedule them?**</a></li><li><a href="#-355-how-do-you-implement-database-partitioning-" class="h2-link">**355. How do you implement database partitioning?**</a></li><li><a href="#-356-what-are-database-constraints-and-their-types-" class="h2-link">**356. What are database constraints and their types?**</a></li><li><a href="#-357-how-do-you-work-with-database-transactions-and-isolation-levels-" class="h2-link">**357. How do you work with database transactions and isolation levels?**</a></li><li><a href="#-358-what-are-database-triggers-for-auditing-and-logging-" class="h2-link">**358. What are database triggers for auditing and logging?**</a></li><li><a href="#-359-how-do-you-implement-database-replication-" class="h2-link">**359. How do you implement database replication?**</a></li><li><a href="#-360-what-are-database-locks-and-deadlock-handling-" class="h2-link">**360. What are database locks and deadlock handling?**</a></li><li><a href="#-361-what-are-database-synonyms-and-aliases-" class="h2-link">**361. What are database synonyms and aliases?**</a></li><li><a href="#-362-how-do-you-work-with-database-sequences-and-auto-increment-" class="h2-link">**362. How do you work with database sequences and auto-increment?**</a></li><li><a href="#-363-what-are-database-collations-and-character-sets-" class="h2-link">**363. What are database collations and character sets?**</a></li><li><a href="#-364-how-do-you-implement-database-connection-pooling-" class="h2-link">**364. How do you implement database connection pooling?**</a></li><li><a href="#-365-what-are-database-hints-and-optimizer-directives-" class="h2-link">**365. What are database hints and optimizer directives?**</a></li><li><a href="#-366-what-are-database-cursors-and-how-do-you-use-them-" class="h2-link">**366. What are database cursors and how do you use them?**</a></li><li><a href="#-367-what-are-database-packages-and-modules-" class="h2-link">**367. What are database packages and modules?**</a></li><li><a href="#-368-how-do-you-implement-database-auditing-and-compliance-" class="h2-link">**368. How do you implement database auditing and compliance?**</a></li><li><a href="#-369-what-are-database-federation-and-distributed-queries-" class="h2-link">**369. What are database federation and distributed queries?**</a></li><li><a href="#-370-how-do-you-implement-database-monitoring-and-alerting-" class="h2-link">**370. How do you implement database monitoring and alerting?**</a></li><li><a href="#-371-what-are-data-warehousing-concepts-in-mysql-" class="h2-link">**371. What are data warehousing concepts in MySQL?**</a></li><li><a href="#-372-how-do-you-implement-data-archiving-strategies-" class="h2-link">**372. How do you implement data archiving strategies?**</a></li><li><a href="#-373-what-are-data-migration-best-practices-" class="h2-link">**373. What are data migration best practices?**</a></li><li><a href="#-374-how-do-you-implement-data-backup-and-recovery-strategies-" class="h2-link">**374. How do you implement data backup and recovery strategies?**</a></li><li><a href="#-375-what-are-data-quality-management-techniques-" class="h2-link">**375. What are data quality management techniques?**</a></li><li><a href="#-376-how-do-you-implement-data-lineage-tracking-" class="h2-link">**376. How do you implement data lineage tracking?**</a></li><li><a href="#-377-what-are-master-data-management-mdm-principles-" class="h2-link">**377. What are master data management (MDM) principles?**</a></li><li><a href="#-378-how-do-you-implement-data-cataloging-and-metadata-management-" class="h2-link">**378. How do you implement data cataloging and metadata management?**</a></li><li><a href="#-379-what-are-data-governance-frameworks-and-policies-" class="h2-link">**379. What are data governance frameworks and policies?**</a></li><li><a href="#-380-how-do-you-implement-data-privacy-and-gdpr-compliance-" class="h2-link">**380. How do you implement data privacy and GDPR compliance?**</a></li><li><a href="#-381-what-are-data-retention-and-purging-strategies-" class="h2-link">**381. What are data retention and purging strategies?**</a></li><li><a href="#-382-how-do-you-implement-data-masking-and-anonymization-" class="h2-link">**382. How do you implement data masking and anonymization?**</a></li><li><a href="#-383-what-are-data-lake-and-data-warehouse-differences-" class="h2-link">**383. What are data lake and data warehouse differences?**</a></li><li><a href="#-384-how-do-you-handle-real-time-data-processing-" class="h2-link">**384. How do you handle real-time data processing?**</a></li><li><a href="#-385-what-are-data-integration-patterns-and-etl-vs-elt-" class="h2-link">**385. What are data integration patterns and ETL vs ELT?**</a></li><li><a href="#-386-how-do-you-implement-data-versioning-and-change-tracking-" class="h2-link">**386. How do you implement data versioning and change tracking?**</a></li><li><a href="#-387-what-are-data-mesh-and-decentralized-data-architectures-" class="h2-link">**387. What are data mesh and decentralized data architectures?**</a></li>`;
        
        // Initialize theme from localStorage
        const savedTheme = localStorage.getItem('theme') || 'light';
        document.body.setAttribute('data-theme', savedTheme);
        const themeButton = document.getElementById('theme-toggle');
        themeButton.textContent = savedTheme === 'dark' ? 'â˜€ï¸ Light Mode' : 'ðŸŒ™ Dark Mode';
        
        // Set initial theme stylesheets
        const lightTheme = document.getElementById('light-theme');
        const darkTheme = document.getElementById('dark-theme');
        if (savedTheme === 'dark') {
            lightTheme.disabled = true;
            darkTheme.disabled = false;
        } else {
            lightTheme.disabled = false;
            darkTheme.disabled = true;
        }
        
        // Mobile menu functionality
        function toggleMobileMenu() {
            const sidebar = document.getElementById('sidebar');
            const overlay = document.getElementById('mobile-overlay');
            const isOpen = sidebar.classList.contains('mobile-open');
            
            if (isOpen) {
                sidebar.classList.remove('mobile-open');
                overlay.classList.remove('active');
            } else {
                sidebar.classList.add('mobile-open');
                overlay.classList.add('active');
            }
        }
        
        // Theme toggle functionality
        function toggleTheme() {
            const body = document.body;
            const button = document.getElementById('theme-toggle');
            const currentTheme = body.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            body.setAttribute('data-theme', newTheme);
            button.textContent = newTheme === 'dark' ? 'â˜€ï¸ Light Mode' : 'ðŸŒ™ Dark Mode';
            localStorage.setItem('theme', newTheme);
            
            const lightTheme = document.getElementById('light-theme');
            const darkTheme = document.getElementById('dark-theme');
            if (newTheme === 'dark') {
                lightTheme.disabled = true;
                darkTheme.disabled = false;
            } else {
                lightTheme.disabled = false;
                darkTheme.disabled = true;
            }
            
            // Re-highlight code after theme change
            setTimeout(() => {
                if (typeof Prism !== 'undefined') {
                    Prism.highlightAll();
                }
            }, 100);
        }
        
        // Copy code functionality
        function copyCode(text, button) {
            // Modern clipboard API
            if (navigator.clipboard && navigator.clipboard.writeText) {
                navigator.clipboard.writeText(text).then(() => {
                    button.textContent = 'Copied!';
                    button.style.background = '#10b981';
                    setTimeout(() => {
                        button.textContent = 'Copy';
                        button.style.background = 'var(--accent-color)';
                    }, 2000);
                }).catch(() => {
                    fallbackCopyTextToClipboard(text, button);
                });
            } else {
                fallbackCopyTextToClipboard(text, button);
            }
        }
        
        // Fallback copy function for older browsers
        function fallbackCopyTextToClipboard(text, button) {
            const textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-999999px";
            textArea.style.top = "-999999px";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            try {
                const successful = document.execCommand('copy');
                if (successful) {
                    button.textContent = 'Copied!';
                    button.style.background = '#10b981';
                    setTimeout(() => {
                        button.textContent = 'Copy';
                        button.style.background = 'var(--accent-color)';
                    }, 2000);
                } else {
                    throw new Error('Copy command failed');
                }
            } catch (err) {
                console.error('Copy failed:', err);
                button.textContent = 'Copy failed';
                button.style.background = '#ef4444';
                setTimeout(() => {
                    button.textContent = 'Copy';
                    button.style.background = 'var(--accent-color)';
                }, 2000);
            } finally {
                document.body.removeChild(textArea);
            }
        }
        
        // Event listeners
        document.addEventListener('DOMContentLoaded', function() {
            // Mobile menu button
            const mobileMenuBtn = document.getElementById('mobile-menu-btn');
            if (mobileMenuBtn) {
                mobileMenuBtn.addEventListener('click', toggleMobileMenu);
            }
            
            // Theme toggle button
            const themeToggleBtn = document.getElementById('theme-toggle');
            if (themeToggleBtn) {
                themeToggleBtn.addEventListener('click', toggleTheme);
            }
            
            // Copy buttons
            document.addEventListener('click', function(e) {
                if (e.target.classList.contains('copy-btn')) {
                    const encodedCode = e.target.getAttribute('data-code');
                    if (encodedCode) {
                        const code = decodeURIComponent(encodedCode);
                        copyCode(code, e.target);
                    }
                }
            });
            
            // Overlay and TOC link clicks
            const overlay = document.getElementById('mobile-overlay');
            if (overlay) {
                overlay.addEventListener('click', function() {
                    const sidebar = document.getElementById('sidebar');
                    sidebar.classList.remove('mobile-open');
                    overlay.classList.remove('active');
                });
            }
            
            // TOC links
            document.addEventListener('click', function(e) {
                if (e.target.matches('.toc a')) {
                    const sidebar = document.getElementById('sidebar');
                    const overlay = document.getElementById('mobile-overlay');
                    sidebar.classList.remove('mobile-open');
                    overlay.classList.remove('active');
                }
            });
            
            // Highlight code after page load
            setTimeout(() => {
                if (typeof Prism !== 'undefined') {
                    Prism.highlightAll();
                }
            }, 500);
        });

        

    </script>
    <script src="../sidebar-fix.js"></script>
</body>
</html>