<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" id="dark-theme">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" id="light-theme">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --bg-primary: #ffffff; --bg-secondary: #f8f9fa; --text-primary: #333333;
            --text-secondary: #666666; --border-color: #e1e5e9; --accent-color: #6366f1;
            --code-bg: #f8f9fa; --sidebar-bg: #ffffff; --shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        [data-theme="dark"] {
            --bg-primary: #0d1117; --bg-secondary: #161b22; --text-primary: #e6edf3;
            --text-secondary: #7d8590; --border-color: #30363d; --accent-color: #58a6ff;
            --code-bg: #161b22; --sidebar-bg: #0d1117; --shadow: 0 2px 10px rgba(0,0,0,0.3);
        }
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
            line-height: 1.6; 
            background-color: var(--bg-primary); 
            color: var(--text-primary); 
            transition: all 0.3s ease;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .container { 
            display: flex; 
            min-height: 100vh;
            width: 100%;
            max-width: 100vw;
            overflow-x: hidden;
        }
        
        .sidebar { 
            width: 280px; 
            background-color: var(--sidebar-bg); 
            border-right: 1px solid var(--border-color); 
            position: fixed; 
            height: 100vh; 
            overflow-y: auto; 
            box-shadow: var(--shadow); 
            transition: transform 0.3s ease; 
            z-index: 200;
        }
        
        .main-content { 
            flex: 1; 
            margin-left: 280px; 
            transition: margin-left 0.3s ease;
            width: calc(100% - 280px);
            max-width: calc(100vw - 280px);
            overflow-x: hidden;
        }
        
        .header { 
            background-color: var(--sidebar-bg); 
            border-bottom: 1px solid var(--border-color); 
            padding: 1rem 2rem; 
            display: flex; 
            justify-content: space-between; 
            align-items: center; 
            position: sticky; 
            top: 0; 
            z-index: 100; 
            box-shadow: var(--shadow);
        }
        
        .theme-toggle { 
            background: none; 
            border: 2px solid var(--border-color); 
            padding: 0.5rem 1rem; 
            border-radius: 6px; 
            cursor: pointer; 
            color: var(--text-primary); 
            font-size: 0.9rem; 
            transition: all 0.2s ease;
            white-space: nowrap;
        }
        .theme-toggle:hover { background-color: var(--bg-secondary); }
        
        .mobile-menu-btn { 
            display: none; 
            background: none; 
            border: 2px solid var(--border-color); 
            padding: 0.5rem; 
            border-radius: 6px; 
            cursor: pointer; 
            color: var(--text-primary); 
            font-size: 1.2rem; 
            transition: all 0.2s ease;
        }
        .mobile-menu-btn:hover { background-color: var(--bg-secondary); }
        
        .mobile-overlay { 
            display: none; 
            position: fixed; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            background-color: rgba(0, 0, 0, 0.5); 
            z-index: 150; 
            opacity: 0; 
            transition: opacity 0.3s ease;
            pointer-events: none;
        }
        .mobile-overlay.active { 
            opacity: 1; 
            pointer-events: auto;
        }
        
        .content { 
            padding: 2rem; 
            max-width: 1200px; 
            margin: 0 auto;
            width: 100%;
            overflow-x: auto;
            -webkit-overflow-scrolling: touch;
        }
        
        h1 { 
            font-size: clamp(1.8rem, 4vw, 2.5rem); 
            margin-bottom: 1rem; 
            color: var(--text-primary); 
            border-bottom: 3px solid var(--accent-color); 
            padding-bottom: 0.5rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        h2 { 
            font-size: clamp(1.4rem, 3vw, 2rem); 
            margin: 2rem 0 1rem 0; 
            color: var(--text-primary); 
            border-bottom: 2px solid var(--border-color); 
            padding-bottom: 0.5rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .h2-link{
            font-weight:700;
        }
        
        h3 { 
            font-size: clamp(1.2rem, 2.5vw, 1.5rem); 
            margin: 1.5rem 0 1rem 0; 
            color: var(--accent-color);
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        p { 
            margin-bottom: 1rem; 
            color: var(--text-secondary);
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
            max-width: 100%;
        }
        
        .code-container { 
            position: relative; 
            margin: 1.5rem 0; 
            border-radius: 8px; 
            overflow: hidden; 
            box-shadow: var(--shadow);
            max-width: 100%;
        }
        
        .code-header { 
            background-color: var(--bg-secondary); 
            padding: 0.75rem 1rem; 
            border-bottom: 1px solid var(--border-color); 
            display: flex; 
            justify-content: space-between; 
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }
        
        .copy-btn { 
            background: var(--accent-color); 
            color: white; 
            border: none; 
            padding: 0.4rem 0.8rem; 
            border-radius: 4px; 
            cursor: pointer; 
            font-size: 0.8rem;
            white-space: nowrap;
            transition: all 0.2s ease;
        }
        .copy-btn:hover { opacity: 0.9; }
        
        pre[class*="language-"] { 
            margin: 0 !important; 
            padding: 1rem !important;
            background: var(--code-bg) !important;
            border: none !important;
            border-radius: 0 !important;
            font-size: clamp(0.75rem, 2vw, 0.9rem) !important;
            line-height: 1.5 !important;
            overflow-x: auto !important;
            overflow-y: hidden !important;
            white-space: pre !important;
            word-wrap: normal !important;
            max-width: 100% !important;
            -webkit-overflow-scrolling: touch !important;
            scrollbar-width: thin !important;
            scrollbar-color: var(--accent-color) transparent !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar {
            height: 12px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-track {
            background: var(--bg-secondary) !important;
            border-radius: 6px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-thumb {
            background: var(--accent-color) !important;
            border-radius: 6px !important;
        }
        
        pre[class*="language-"]::-webkit-scrollbar-thumb:hover {
            background: var(--text-secondary) !important;
        }
        
        code[class*="language-"] { 
            background: transparent !important;
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace !important;
            font-size: inherit !important;
            color: inherit !important;
            white-space: pre !important;
            word-wrap: normal !important;
            display: inline-block !important;
            min-width: max-content !important;
            width: auto !important;
        }
        
        [data-theme="dark"] .token.comment, [data-theme="dark"] .token.prolog, [data-theme="dark"] .token.doctype, [data-theme="dark"] .token.cdata { color: #7d8590 !important; font-style: italic !important; }
        [data-theme="dark"] .token.punctuation { color: #e6edf3 !important; }
        [data-theme="dark"] .token.property, [data-theme="dark"] .token.tag, [data-theme="dark"] .token.boolean, [data-theme="dark"] .token.number, [data-theme="dark"] .token.constant, .token.symbol, .token.deleted { color: #ff7b72 !important; }
        [data-theme="dark"] .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted { color: #a5d6ff !important; }
        [data-theme="dark"] .token.operator, [data-theme="dark"] .token.entity, [data-theme="dark"] .token.url, .language-css .token.string, .style .token.string { color: #79c0ff !important; }
        [data-theme="dark"] .token.atrule, [data-theme="dark"] .token.attr-value, [data-theme="dark"] .token.keyword { color: #ff7b72 !important; }
        [data-theme="dark"] .token.function, [data-theme="dark"] .token.class-name { color: #d2a8ff !important; }
        [data-theme="dark"] .token.regex, [data-theme="dark"] .token.important, [data-theme="dark"] .token.variable { color: #ffa657 !important; }
        
        [data-theme="light"] .token.comment, [data-theme="light"] .token.prolog, [data-theme="light"] .token.doctype, [data-theme="light"] .token.cdata { color: #6a737d !important; }
        [data-theme="light"] .token.punctuation { color: #24292e !important; }
        [data-theme="light"] .token.property, .token.tag, .token.boolean, .token.number, .token.constant, .token.symbol, .token.deleted { color: #d73a49 !important; }
        [data-theme="light"] .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted { color: #032f62 !important; }
        [data-theme="light"] .token.operator, .token.entity, .token.url, .language-css .token.string, .style .token.string { color: #24292e !important; }
        [data-theme="light"] .token.atrule, .token.attr-value, .token.keyword { color: #d73a49 !important; }
        [data-theme="light"] .token.function, .token.class-name { color: #6f42c1 !important; }
        [data-theme="light"] .token.regex, [data-theme="light"] .token.important, [data-theme="light"] .token.variable { color: #e36209 !important; }
        
        .toc { padding: 1rem; }
        .toc ul { list-style: none; }
        .toc li { margin: 0.5rem 0; }
        .toc a { 
            color: var(--text-secondary); 
            text-decoration: none; 
            display: block; 
            padding: 0.5rem; 
            border-radius: 6px; 
            transition: all 0.2s ease; 
            font-size: 0.9rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }

        .toc a.active {
            color: blue !important;
             background-color: #5ec7ff2a;
}


        .toc a:hover { background-color: #0077ff16}
        
        @media (max-width: 767px) { 
            .sidebar { 
                transform: translateX(-100%);
                width: 85vw;
                max-width: 320px;
            }
            .sidebar.mobile-open { transform: translateX(0); }
            .main-content { 
                margin-left: 0;
                width: 100%;
                max-width: 100vw;
                overflow-x: auto;
            }
            .mobile-menu-btn { display: block; }
            .mobile-overlay { display: block; }
            .header { 
                padding: 0.75rem 1rem;
                flex-wrap: wrap;
                gap: 0.5rem;
            }
            .content { 
                padding: 1rem;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
            }
            .theme-toggle {
                font-size: 0.8rem;
                padding: 0.4rem 0.8rem;
            }
            .code-header {
                padding: 0.5rem;
                font-size: 0.8rem;
            }
            .copy-btn {
                padding: 0.3rem 0.6rem;
                font-size: 0.7rem;
            }
            pre[class*="language-"] {
                padding: 0.75rem !important;
                font-size: 0.75rem !important;
            }
            pre[class*="language-"]::-webkit-scrollbar {
                height: 10px !important;
            }
            .toc {
                padding: 0.75rem;
            }
            .toc a {
                font-size: 0.8rem;
                padding: 0.4rem;
            }
        }
        
        @media (max-width: 480px) {
            h1 { font-size: 1.5rem; }
            h2 { font-size: 1.3rem; }
            h3 { font-size: 1.1rem; }
            .content { padding: 0.75rem; }
            .header { padding: 0.5rem; }
            .sidebar { width: 90vw; }
            pre[class*="language-"] {
                font-size: 0.7rem !important;
                padding: 0.5rem !important;
            }
        }
    </style>
</head>
<body data-theme="light">
    <div class="mobile-overlay" id="mobile-overlay"></div>
    
    <div class="container">
        <nav class="sidebar" id="sidebar">
            <div class="toc">
                <h3 style="padding: 0.5rem; color: var(--text-primary);">Table of Contents</h3>
                <ul id="toc-list"></ul>
            </div>
        </nav>
        <main class="main-content">
            <header class="header">
                <div style="display: flex; align-items: center; gap: 1rem;">
                    <button class="mobile-menu-btn" id="mobile-menu-btn">☰</button>
                    <h2 style="margin: 0; color: var(--text-primary);">Documentation</h2>
                </div>
                <button class="theme-toggle" id="theme-toggle">🌙 Dark Mode</button>
            </header>
            <div class="content" id="content">
<p>section (Questions 346-370) next?</p>

<h2 id="-321-what-are-indexes-and-how-do-they-work-">**321. What are indexes and how do they work?**</h2>

<p><strong>Answer:</strong> Indexes are database objects that improve the speed of data retrieval operations on a table. They work like an index in a book - instead of scanning every page to find information, you can jump directly to the relevant section.</p>

<p><strong>How they work:</strong></p>

<p>- Indexes create a separate data structure that contains sorted references to the actual table rows</p>
<p>- When a query is executed, MySQL uses the index to quickly locate the relevant rows</p>
<p>- Indexes store key values and pointers to the corresponding rows in the table</p>


<p><strong>Example:</strong> If you have a `users` table with 1 million records and frequently search by `email`, creating an index on the `email` column allows MySQL to find a specific email in milliseconds instead of scanning all 1 million rows.</p>

<p>---</p>

<h2 id="-322-what-are-the-different-types-of-indexes-in-mysql-">**322. What are the different types of indexes in MySQL?**</h2>

<p><strong>Answer:</strong> MySQL supports several types of indexes:</p>

<p><strong>1. Primary Index (Clustered):</strong></p>

<p>- Automatically created for PRIMARY KEY</p>
<p>- Data is physically stored in the order of the primary key</p>


<p><strong>2. Secondary Index (Non-clustered):</strong></p>

<p>- Created on non-primary key columns</p>
<p>- Contains pointers to the actual data rows</p>


<p><strong>3. Unique Index:</strong></p>

<p>- Ensures uniqueness of values</p>
<p>- Automatically created for UNIQUE constraints</p>


<p><strong>4. Composite Index:</strong></p>

<p>- Covers multiple columns</p>
<p>- Example: INDEX(last_name, first_name)</p>


<p><strong>5. Partial Index:</strong></p>

<p>- Index on a subset of data based on conditions</p>


<p><strong>6. Full-text Index:</strong></p>

<p>- Used for text searching in VARCHAR, TEXT columns</p>


<p><strong>7. Spatial Index:</strong></p>

<p>- Used for geometric data types</p>


<p>---</p>

<h2 id="-323-how-do-you-create-and-optimize-composite-indexes-">**323. How do you create and optimize composite indexes?**</h2>

<p><strong>Answer:</strong> Composite indexes cover multiple columns and are crucial for multi-column queries.</p>

<p><strong>Creation Strategy:</strong></p>

<p>- Order columns by selectivity (most selective first)</p>
<p>- Consider query patterns and WHERE clause usage</p>
<p>- Follow the "leftmost prefix" rule</p>


<p><strong>Example Scenario:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20orders%0ACommon%20queries%3A%0A-%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%0A-%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%20AND%20created_date%20%3E%20'2024-01-01'%0A%0AOptimal%20composite%20index%3A%20(customer_id%2C%20status%2C%20created_date)%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: orders
Common queries:
- WHERE customer_id = 123 AND status = 'pending'
- WHERE customer_id = 123 AND status = 'pending' AND created_date &gt; '2024-01-01'

Optimal composite index: (customer_id, status, created_date)
</code></pre>
</div>

<p><strong>Optimization Tips:</strong></p>

<p>- Most selective column first</p>
<p>- Consider column cardinality</p>
<p>- Avoid too many columns (usually max 3-4)</p>
<p>- Monitor index usage with EXPLAIN</p>


<p>---</p>

<h2 id="-324-what-is-the-difference-between-clustered-and-non-clustered-indexes-">**324. What is the difference between clustered and non-clustered indexes?**</h2>

<p><strong>Answer:</strong></p>

<p><strong>Clustered Index:</strong></p>

<p>- Physical storage order matches index order</p>
<p>- Only one per table (usually PRIMARY KEY)</p>
<p>- Data pages are stored in order of the clustered index key</p>
<p>- Faster for range queries and sorting</p>


<p><strong>Non-clustered Index:</strong></p>

<p>- Separate structure from table data</p>
<p>- Multiple non-clustered indexes per table</p>
<p>- Contains pointers to actual data rows</p>
<p>- Additional lookup required to fetch data</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20employees%20(clustered%20on%20employee_id)%0APhysical%20storage%3A%20%5B1%2C%202%2C%203%2C%204%2C%205...%5D%20(sorted%20by%20employee_id)%0A%0ANon-clustered%20index%20on%20last_name%3A%0AIndex%3A%20%5BAdams-%3Erow_ptr%2C%20Brown-%3Erow_ptr%2C%20Clark-%3Erow_ptr%5D%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: employees (clustered on employee_id)
Physical storage: [1, 2, 3, 4, 5...] (sorted by employee_id)

Non-clustered index on last_name:
Index: [Adams-&gt;row_ptr, Brown-&gt;row_ptr, Clark-&gt;row_ptr]
</code></pre>
</div>

<p>---</p>

<h2 id="-325-how-do-you-analyze-index-usage-and-effectiveness-">**325. How do you analyze index usage and effectiveness?**</h2>

<p><strong>Answer:</strong> Several methods to analyze index performance:</p>

<p><strong>1. EXPLAIN Statement:</strong></p>

<p>- Shows query execution plan</p>
<p>- Indicates which indexes are used</p>
<p>- Shows estimated rows examined</p>


<p><strong>2. Performance Schema:</strong></p>

<p>- `performance_schema.table_io_waits_summary_by_index_usage`</p>
<p>- Shows index usage statistics</p>


<p><strong>3. SHOW INDEX:</strong></p>

<p>- Displays index information and cardinality</p>


<p><strong>4. Slow Query Log:</strong></p>

<p>- Identifies queries not using indexes effectively</p>


<p><strong>Example Analysis:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'john%40example.com'%3B%0A%0AKey%20indicators%3A%0A-%20type%3A%20'ref'%20(good)%20vs%20'ALL'%20(bad%20-%20full%20table%20scan)%0A-%20key%3A%20shows%20which%20index%20is%20used%0A-%20rows%3A%20estimated%20rows%20examined%0A-%20Extra%3A%20'Using%20index'%20means%20covering%20index%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">EXPLAIN SELECT * FROM users WHERE email = 'john@example.com';

Key indicators:
- type: 'ref' (good) vs 'ALL' (bad - full table scan)
- key: shows which index is used
- rows: estimated rows examined
- Extra: 'Using index' means covering index
</code></pre>
</div>

<p>---</p>

<h2 id="-326-what-is-index-cardinality-and-why-is-it-important-">**326. What is index cardinality and why is it important?**</h2>

<p><strong>Answer:</strong> Index cardinality refers to the number of unique values in an indexed column relative to the total number of rows.</p>

<p><strong>Types:</strong></p>

<p>- <strong>High Cardinality:</strong> Many unique values (e.g., email addresses, IDs)</p>
<p>- <strong>Low Cardinality:</strong> Few unique values (e.g., gender, status)</p>


<p><strong>Importance:</strong></p>

<p>- High cardinality indexes are more selective and efficient</p>
<p>- Low cardinality indexes may not provide significant performance benefits</p>
<p>- MySQL optimizer uses cardinality to choose optimal execution plans</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%3A%20users%20(1%2C000%2C000%20rows)%0A-%20email%20column%3A%20999%2C000%20unique%20values%20(high%20cardinality%20-%20good%20for%20indexing)%0A-%20gender%20column%3A%203%20unique%20values%20(low%20cardinality%20-%20poor%20for%20indexing)%0A-%20status%20column%3A%205%20unique%20values%20(low%20cardinality)%0A%0AIndex%20on%20email%3A%20Very%20effective%0AIndex%20on%20gender%3A%20Ineffective%20for%20single-value%20queries%0AComposite%20index%20(status%2C%20email)%3A%20Can%20be%20effective%20for%20combined%20queries%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table: users (1,000,000 rows)
- email column: 999,000 unique values (high cardinality - good for indexing)
- gender column: 3 unique values (low cardinality - poor for indexing)
- status column: 5 unique values (low cardinality)

Index on email: Very effective
Index on gender: Ineffective for single-value queries
Composite index (status, email): Can be effective for combined queries
</code></pre>
</div>

<p>---</p>

<h2 id="-327-how-do-you-handle-index-maintenance-and-rebuilding-">**327. How do you handle index maintenance and rebuilding?**</h2>

<p><strong>Answer:</strong> Index maintenance ensures optimal performance over time.</p>

<p><strong>Maintenance Tasks:</strong></p>

<p><strong>1. Monitor Index Fragmentation:</strong></p>

<p>- Fragmentation occurs with frequent INSERT/UPDATE/DELETE operations</p>
<p>- Check using `INFORMATION_SCHEMA.INNODB_SYS_INDEXES`</p>


<p><strong>2. Rebuild Indexes:</strong></p>

<p>- `ALTER TABLE table_name ENGINE=InnoDB` (rebuilds all indexes)</p>
<p>- `OPTIMIZE TABLE table_name` (defragments and rebuilds)</p>


<p><strong>3. Update Statistics:</strong></p>

<p>- `ANALYZE TABLE table_name` (updates index statistics)</p>
<p>- Helps optimizer make better decisions</p>


<p><strong>4. Regular Monitoring:</strong></p>

<p>- Check index usage patterns</p>
<p>- Remove unused indexes</p>
<p>- Add missing indexes based on query patterns</p>


<p><strong>Best Practices:</strong></p>

<p>- Schedule maintenance during low-traffic periods</p>
<p>- Monitor performance before and after maintenance</p>
<p>- Keep statistics updated regularly</p>


<p>---</p>

<h2 id="-328-what-are-covering-indexes-and-when-do-you-use-them-">**328. What are covering indexes and when do you use them?**</h2>

<p><strong>Answer:</strong> A covering index contains all columns needed to satisfy a query, eliminating the need to access the actual table data.</p>

<p><strong>Benefits:</strong></p>

<p>- Faster query execution (no additional data page reads)</p>
<p>- Reduced I/O operations</p>
<p>- Better performance for SELECT queries</p>


<p><strong>When to Use:</strong></p>

<p>- Frequently executed queries with specific column sets</p>
<p>- Queries that only need indexed columns</p>
<p>- Read-heavy applications</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Query%3A%20SELECT%20customer_id%2C%20order_date%2C%20total%20FROM%20orders%20WHERE%20status%20%3D%20'completed'%0A%0ACovering%20Index%3A%20(status%2C%20customer_id%2C%20order_date%2C%20total)%0A%0AThis%20index%20contains%20all%20needed%20columns%2C%20so%20MySQL%20doesn't%20need%20to%20access%20the%20orders%20table%20data%20pages.%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Query: SELECT customer_id, order_date, total FROM orders WHERE status = 'completed'

Covering Index: (status, customer_id, order_date, total)

This index contains all needed columns, so MySQL doesn't need to access the orders table data pages.
</code></pre>
</div>

<p><strong>Considerations:</strong></p>

<p>- Larger index size (more storage)</p>
<p>- Slower INSERT/UPDATE operations</p>
<p>- Maintenance overhead</p>


<p>---</p>

<h2 id="-329-how-do-you-implement-full-text-search-indexes-">**329. How do you implement full-text search indexes?**</h2>

<p><strong>Answer:</strong> Full-text indexes enable efficient text searching in VARCHAR, TEXT, and JSON columns.</p>

<p><strong>Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20full-text%20index%0AALTER%20TABLE%20articles%20ADD%20FULLTEXT(title%2C%20content)%3B%0A%0A--%20Or%20during%20table%20creation%0ACREATE%20TABLE%20articles%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20title%20VARCHAR(255)%2C%0A%20%20%20%20content%20TEXT%2C%0A%20%20%20%20FULLTEXT(title%2C%20content)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create full-text index
ALTER TABLE articles ADD FULLTEXT(title, content);

-- Or during table creation
CREATE TABLE articles (
    id INT PRIMARY KEY,
    title VARCHAR(255),
    content TEXT,
    FULLTEXT(title, content)
);
</code></pre>
</div>

<p><strong>Search Modes:</strong></p>

<p><strong>1. Natural Language Mode (default):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('database%20optimization')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('database optimization');
</code></pre>
</div>

<p><strong>2. Boolean Mode:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('%2Bdatabase%20-mysql'%20IN%20BOOLEAN%20MODE)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('+database -mysql' IN BOOLEAN MODE);
</code></pre>
</div>

<p><strong>3. Query Expansion:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20articles%20%0AWHERE%20MATCH(title%2C%20content)%20AGAINST('database'%20WITH%20QUERY%20EXPANSION)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('database' WITH QUERY EXPANSION);
</code></pre>
</div>

<p><strong>Configuration:</strong></p>

<p>- Minimum word length: `ft_min_word_len` (default 4)</p>
<p>- Stop words: Common words ignored in searches</p>
<p>- Relevance scoring: Automatic ranking of results</p>


<p>---</p>

<h2 id="-330-what-is-the-impact-of-indexes-on-insert-update-delete-operations-">**330. What is the impact of indexes on INSERT/UPDATE/DELETE operations?**</h2>

<p><strong>Answer:</strong> Indexes improve SELECT performance but can slow down data modification operations.</p>

<p><strong>Impact on INSERT:</strong></p>

<p>- Each index must be updated with new entry</p>
<p>- More indexes = slower INSERTs</p>
<p>- Index maintenance overhead</p>


<p><strong>Impact on UPDATE:</strong></p>

<p>- If indexed columns are updated, index entries must be modified</p>
<p>- May require index reorganization</p>
<p>- Non-indexed column updates have minimal impact</p>


<p><strong>Impact on DELETE:</strong></p>

<p>- Index entries must be removed</p>
<p>- May cause index fragmentation</p>
<p>- Cleanup overhead</p>


<p><strong>Example Performance Impact:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">plaintext</span>
        <button class="copy-btn" data-code="Table%20with%205%20indexes%3A%0A-%20INSERT%3A%205x%20index%20updates%20per%20row%0A-%20UPDATE%20(indexed%20column)%3A%20Potential%20index%20reorganization%0A-%20DELETE%3A%205x%20index%20cleanup%20operations%0A%0AMitigation%20strategies%3A%0A-%20Bulk%20operations%20during%20low-traffic%20periods%0A-%20Disable%20indexes%20during%20large%20data%20loads%0A-%20Use%20appropriate%20batch%20sizes%0A">Copy</button>
    </div>
    <pre><code class="language-plaintext">Table with 5 indexes:
- INSERT: 5x index updates per row
- UPDATE (indexed column): Potential index reorganization
- DELETE: 5x index cleanup operations

Mitigation strategies:
- Bulk operations during low-traffic periods
- Disable indexes during large data loads
- Use appropriate batch sizes
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Balance read vs. write performance needs</p>
<p>- Consider dropping indexes during bulk operations</p>
<p>- Monitor write operation performance</p>
<p>- Use covering indexes to reduce index count</p>


<p>---</p>

<h2 id="-331-how-do-you-optimize-queries-using-explain-">**331. How do you optimize queries using EXPLAIN?**</h2>

<p><strong>Answer:</strong> EXPLAIN shows MySQL's execution plan, helping identify performance bottlenecks.</p>

<p><strong>Key EXPLAIN Columns:</strong></p>
<p>- <strong>select_type:</strong> Query type (SIMPLE, SUBQUERY, UNION)</p>
<p>- <strong>table:</strong> Table being accessed</p>
<p>- <strong>type:</strong> Join type (const, eq_ref, ref, range, index, ALL)</p>
<p>- <strong>key:</strong> Index used (NULL means no index)</p>
<p>- <strong>rows:</strong> Estimated rows examined</p>
<p>- <strong>Extra:</strong> Additional information</p>

<p><strong>Optimization Process:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20orders%20o%20%0AJOIN%20customers%20c%20ON%20o.customer_id%20%3D%20c.id%20%0AWHERE%20o.status%20%3D%20'pending'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">EXPLAIN SELECT * FROM orders o 
JOIN customers c ON o.customer_id = c.id 
WHERE o.status = 'pending';
</code></pre>
</div>

<p><strong>Red Flags to Look For:</strong></p>
<p>- <strong>type: ALL</strong> (full table scan)</p>
<p>- <strong>Extra: Using filesort</strong> (expensive sorting)</p>
<p>- <strong>Extra: Using temporary</strong> (temporary table creation)</p>
<p>- <strong>High rows count</strong> with small result set</p>

<p><strong>Optimization Actions:</strong></p>
<p>1. Add missing indexes for WHERE/JOIN conditions</p>
<p>2. Rewrite queries to avoid filesort</p>
<p>3. Use covering indexes</p>
<p>4. Consider query restructuring</p>

<p>---</p>

<h2 id="-332-what-are-query-execution-plans-and-how-do-you-read-them-">**332. What are query execution plans and how do you read them?**</h2>

<p><strong>Answer:</strong> Query execution plans show the step-by-step process MySQL uses to execute a query.</p>

<p><strong>Reading Execution Plans:</strong></p>

<p><strong>1. Join Types (Best to Worst):</strong></p>
<p>- <strong>const:</strong> Single row match (PRIMARY KEY lookup)</p>
<p>- <strong>eq_ref:</strong> One row per join (UNIQUE index)</p>
<p>- <strong>ref:</strong> Multiple rows with same key value</p>
<p>- <strong>range:</strong> Index range scan (BETWEEN, >, <)</p>
<p>- <strong>index:</strong> Full index scan</p>
<p>- <strong>ALL:</strong> Full table scan (worst)</p>

<p><strong>2. Extra Information:</strong></p>
<p>- <strong>Using index:</strong> Covering index used</p>
<p>- <strong>Using where:</strong> WHERE clause filtering</p>
<p>- <strong>Using filesort:</strong> External sorting required</p>
<p>- <strong>Using temporary:</strong> Temporary table created</p>

<p><strong>Example Analysis:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Good%20plan%3A%0Atype%3A%20const%2C%20key%3A%20PRIMARY%2C%20rows%3A%201%2C%20Extra%3A%20Using%20index%0A%0A--%20Bad%20plan%3A%0Atype%3A%20ALL%2C%20key%3A%20NULL%2C%20rows%3A%20100000%2C%20Extra%3A%20Using%20filesort%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Good plan:
type: const, key: PRIMARY, rows: 1, Extra: Using index

-- Bad plan:
type: ALL, key: NULL, rows: 100000, Extra: Using filesort
</code></pre>
</div>

<p><strong>Optimization Priority:</strong></p>
<p>1. Eliminate full table scans (type: ALL)</p>
<p>2. Add indexes for JOIN conditions</p>
<p>3. Optimize ORDER BY clauses</p>
<p>4. Reduce rows examined</p>

<p>---</p>

<h2 id="-333-how-do-you-handle-index-hints-and-force-index-usage-">**333. How do you handle index hints and force index usage?**</h2>

<p><strong>Answer:</strong> Index hints guide MySQL's optimizer to use specific indexes when automatic selection is suboptimal.</p>

<p><strong>Types of Index Hints:</strong></p>

<p><strong>1. USE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20USE%20INDEX%20(idx_email)%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A--%20Suggests%20using%20idx_email%2C%20but%20optimizer%20can%20ignore%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users USE INDEX (idx_email) 
WHERE email = 'john@example.com';
-- Suggests using idx_email, but optimizer can ignore
</code></pre>
</div>

<p><strong>2. FORCE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20FORCE%20INDEX%20(idx_email)%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A--%20Forces%20use%20of%20idx_email%2C%20optimizer%20must%20comply%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users FORCE INDEX (idx_email) 
WHERE email = 'john@example.com';
-- Forces use of idx_email, optimizer must comply
</code></pre>
</div>

<p><strong>3. IGNORE INDEX:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20*%20FROM%20users%20IGNORE%20INDEX%20(idx_name)%20%0AWHERE%20name%20%3D%20'John'%3B%0A--%20Prevents%20use%20of%20idx_name%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT * FROM users IGNORE INDEX (idx_name) 
WHERE name = 'John';
-- Prevents use of idx_name
</code></pre>
</div>

<p><strong>When to Use:</strong></p>
<p>- Optimizer chooses wrong index</p>
<p>- Testing different index strategies</p>
<p>- Temporary performance fixes</p>
<p>- Complex queries with multiple possible indexes</p>

<p><strong>Best Practices:</strong></p>
<p>- Use sparingly - optimizer is usually correct</p>
<p>- Document why hints are needed</p>
<p>- Review hints after MySQL upgrades</p>
<p>- Prefer query rewriting over hints</p>

<p>---</p>

<h2 id="-334-what-is-index-selectivity-and-how-do-you-calculate-it-">**334. What is index selectivity and how do you calculate it?**</h2>

<p><strong>Answer:</strong> Index selectivity measures how unique the values in an indexed column are.</p>

<p><strong>Formula:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">text</span>
        <button class="copy-btn" data-code="Selectivity%20%3D%20Number%20of%20Distinct%20Values%20%2F%20Total%20Number%20of%20Rows%0A">Copy</button>
    </div>
    <pre><code class="language-text">Selectivity = Number of Distinct Values / Total Number of Rows
</code></pre>
</div>

<p><strong>Selectivity Ranges:</strong></p>
<p>- <strong>1.0:</strong> Perfect selectivity (all unique values)</p>
<p>- <strong>0.5:</strong> Moderate selectivity</p>
<p>- <strong>0.01:</strong> Poor selectivity (many duplicates)</p>

<p><strong>Calculation Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Calculate%20selectivity%20for%20email%20column%0ASELECT%20%0A%20%20%20%20COUNT(DISTINCT%20email)%20%2F%20COUNT(*)%20as%20email_selectivity%2C%0A%20%20%20%20COUNT(DISTINCT%20status)%20%2F%20COUNT(*)%20as%20status_selectivity%0AFROM%20users%3B%0A%0A--%20Results%3A%0A--%20email_selectivity%3A%200.98%20(excellent)%0A--%20status_selectivity%3A%200.003%20(poor)%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Calculate selectivity for email column
SELECT 
    COUNT(DISTINCT email) / COUNT(*) as email_selectivity,
    COUNT(DISTINCT status) / COUNT(*) as status_selectivity
FROM users;

-- Results:
-- email_selectivity: 0.98 (excellent)
-- status_selectivity: 0.003 (poor)
</code></pre>
</div>

<p><strong>Impact on Performance:</strong></p>
<p>- <strong>High Selectivity (>0.1):</strong> Good index candidates</p>
<p>- <strong>Low Selectivity (<0.01):</strong> Poor index candidates</p>
<p>- <strong>Composite Indexes:</strong> Combine low-selectivity columns</p>

<p><strong>Optimization Strategy:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20indexing%20low-selectivity%20'status'%20alone%3A%0ACREATE%20INDEX%20idx_status%20ON%20orders%20(status)%3B%20%20--%20Poor%0A%0A--%20Combine%20with%20high-selectivity%20column%3A%0ACREATE%20INDEX%20idx_status_date%20ON%20orders%20(status%2C%20created_date)%3B%20%20--%20Better%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of indexing low-selectivity 'status' alone:
CREATE INDEX idx_status ON orders (status);  -- Poor

-- Combine with high-selectivity column:
CREATE INDEX idx_status_date ON orders (status, created_date);  -- Better
</code></pre>
</div>

<p>---</p>

<h2 id="-335-how-do-you-optimize-order-by-and-group-by-clauses-">**335. How do you optimize ORDER BY and GROUP BY clauses?**</h2>

<p><strong>Answer:</strong> ORDER BY and GROUP BY optimization focuses on index usage and avoiding filesort operations.</p>

<p><strong>ORDER BY Optimization:</strong></p>

<p><strong>1. Index Column Order:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20last_name%2C%20first_name%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_name%20ON%20users%20(last_name%2C%20first_name)%3B%0A--%20Index%20order%20must%20match%20ORDER%20BY%20order%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users ORDER BY last_name, first_name;

-- Optimal index:
CREATE INDEX idx_name ON users (last_name, first_name);
-- Index order must match ORDER BY order
</code></pre>
</div>

<p><strong>2. Covering Indexes:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20id%2C%20email%20FROM%20users%20ORDER%20BY%20created_date%3B%0A%0A--%20Covering%20index%3A%0ACREATE%20INDEX%20idx_covering%20ON%20users%20(created_date%2C%20id%2C%20email)%3B%0A--%20Avoids%20table%20access%20entirely%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT id, email FROM users ORDER BY created_date;

-- Covering index:
CREATE INDEX idx_covering ON users (created_date, id, email);
-- Avoids table access entirely
</code></pre>
</div>

<p><strong>GROUP BY Optimization:</strong></p>

<p><strong>1. Index on GROUP BY Columns:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20status%2C%20COUNT(*)%20FROM%20orders%20GROUP%20BY%20status%3B%0A%0A--%20Index%3A%0ACREATE%20INDEX%20idx_status%20ON%20orders%20(status)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT status, COUNT(*) FROM orders GROUP BY status;

-- Index:
CREATE INDEX idx_status ON orders (status);
</code></pre>
</div>

<p><strong>2. Composite Index for GROUP BY + WHERE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20category%2C%20COUNT(*)%20FROM%20products%20%0AWHERE%20active%20%3D%201%20GROUP%20BY%20category%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_active_category%20ON%20products%20(active%2C%20category)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT category, COUNT(*) FROM products 
WHERE active = 1 GROUP BY category;

-- Optimal index:
CREATE INDEX idx_active_category ON products (active, category);
</code></pre>
</div>

<p><strong>Avoiding Filesort:</strong></p>
<p>- Match index column order exactly</p>
<p>- Use LIMIT with ORDER BY when possible</p>
<p>- Consider partial indexes for large datasets</p>

<p>---</p>

<h2 id="-336-what-are-partial-indexes-and-when-do-you-use-them-">**336. What are partial indexes and when do you use them?**</h2>

<p><strong>Answer:</strong> Partial indexes index only a subset of rows or column data, reducing index size and maintenance overhead.</p>

<p><strong>Types of Partial Indexes:</strong></p>

<p><strong>1. Conditional Partial Index (PostgreSQL concept, MySQL workaround):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20doesn't%20support%20WHERE%20clauses%20in%20indexes%20directly%0A--%20Workaround%3A%20Use%20functional%20indexes%20or%20filtered%20views%0A%0A--%20Simulate%20with%20functional%20index%3A%0ACREATE%20INDEX%20idx_active_users%20ON%20users%20(email%2C%20(CASE%20WHEN%20status%20%3D%20'active'%20THEN%201%20END))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL doesn't support WHERE clauses in indexes directly
-- Workaround: Use functional indexes or filtered views

-- Simulate with functional index:
CREATE INDEX idx_active_users ON users (email, (CASE WHEN status = 'active' THEN 1 END));
</code></pre>
</div>

<p><strong>2. Prefix Indexes (MySQL Native):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20only%20first%2010%20characters%20of%20email%0ACREATE%20INDEX%20idx_email_prefix%20ON%20users%20(email(10))%3B%0A%0A--%20Useful%20for%3A%0A--%20-%20Large%20VARCHAR%2FTEXT%20columns%0A--%20-%20Reducing%20index%20size%0A--%20-%20When%20full%20column%20indexing%20is%20unnecessary%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index only first 10 characters of email
CREATE INDEX idx_email_prefix ON users (email(10));

-- Useful for:
-- - Large VARCHAR/TEXT columns
-- - Reducing index size
-- - When full column indexing is unnecessary
</code></pre>
</div>

<p><strong>When to Use:</strong></p>
<p>1. <strong>Large Text Columns:</strong> Index prefixes instead of full content</p>
<p>2. <strong>Sparse Data:</strong> When most rows don't need indexing</p>
<p>3. <strong>Storage Optimization:</strong> Reduce index storage requirements</p>
<p>4. <strong>Selective Queries:</strong> When queries filter on specific conditions</p>

<p><strong>Example Use Case:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20with%20mostly%20inactive%20users%0A--%20Only%20index%20active%20users'%20emails%0ACREATE%20INDEX%20idx_active_email%20ON%20users%20(email)%20%0AWHERE%20status%20%3D%20'active'%3B%20%20--%20PostgreSQL%20syntax%0A%0A--%20MySQL%20alternative%3A%0ACREATE%20INDEX%20idx_status_email%20ON%20users%20(status%2C%20email)%3B%0A--%20Query%3A%20WHERE%20status%20%3D%20'active'%20AND%20email%20%3D%20'x'%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table with mostly inactive users
-- Only index active users' emails
CREATE INDEX idx_active_email ON users (email) 
WHERE status = 'active';  -- PostgreSQL syntax

-- MySQL alternative:
CREATE INDEX idx_status_email ON users (status, email);
-- Query: WHERE status = 'active' AND email = 'x'
</code></pre>
</div>

<p>---</p>

<h2 id="-337-how-do-you-handle-index-fragmentation-">**337. How do you handle index fragmentation?**</h2>

<p><strong>Answer:</strong> Index fragmentation occurs when index pages are not stored contiguously, leading to performance degradation.</p>

<p><strong>Types of Fragmentation:</strong></p>

<p><strong>1. Internal Fragmentation:</strong></p>
<p>- Partially filled index pages</p>
<p>- Caused by random INSERTs/DELETEs</p>
<p>- Wastes storage space</p>

<p><strong>2. External Fragmentation:</strong></p>
<p>- Index pages scattered across disk</p>
<p>- Causes additional I/O operations</p>
<p>- Slows range scans</p>

<p><strong>Detection Methods:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20table%20fragmentation%0ASHOW%20TABLE%20STATUS%20LIKE%20'users'%3B%0A--%20Look%20at%20'Data_free'%20column%20for%20fragmented%20space%0A%0A--%20InnoDB%20specific%3A%0ASELECT%20table_name%2C%20%0A%20%20%20%20%20%20%20ROUND(data_length%2F1024%2F1024%2C%202)%20AS%20data_mb%2C%0A%20%20%20%20%20%20%20ROUND(index_length%2F1024%2F1024%2C%202)%20AS%20index_mb%2C%0A%20%20%20%20%20%20%20ROUND(data_free%2F1024%2F1024%2C%202)%20AS%20fragmented_mb%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check table fragmentation
SHOW TABLE STATUS LIKE 'users';
-- Look at 'Data_free' column for fragmented space

-- InnoDB specific:
SELECT table_name, 
       ROUND(data_length/1024/1024, 2) AS data_mb,
       ROUND(index_length/1024/1024, 2) AS index_mb,
       ROUND(data_free/1024/1024, 2) AS fragmented_mb
FROM information_schema.tables 
WHERE table_schema = 'your_database';
</code></pre>
</div>

<p><strong>Defragmentation Solutions:</strong></p>

<p><strong>1. OPTIMIZE TABLE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="OPTIMIZE%20TABLE%20users%3B%0A--%20Rebuilds%20table%20and%20all%20indexes%0A--%20Reclaims%20fragmented%20space%0A">Copy</button>
    </div>
    <pre><code class="language-sql">OPTIMIZE TABLE users;
-- Rebuilds table and all indexes
-- Reclaims fragmented space
</code></pre>
</div>

<p><strong>2. ALTER TABLE:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="ALTER%20TABLE%20users%20ENGINE%3DInnoDB%3B%0A--%20Forces%20table%20rebuild%0A--%20More%20control%20over%20process%0A">Copy</button>
    </div>
    <pre><code class="language-sql">ALTER TABLE users ENGINE=InnoDB;
-- Forces table rebuild
-- More control over process
</code></pre>
</div>

<p><strong>3. Scheduled Maintenance:</strong></p>
<p>- Run during low-traffic periods</p>
<p>- Monitor fragmentation levels</p>
<p>- Automate based on fragmentation percentage</p>

<p><strong>Prevention:</strong></p>
<p>- Use appropriate PRIMARY KEY design</p>
<p>- Avoid random UUID keys</p>
<p>- Regular maintenance schedules</p>

<p>---</p>

<h2 id="-338-what-is-the-difference-between-b-tree-and-hash-indexes-">**338. What is the difference between B-tree and Hash indexes?**</h2>

<p><strong>Answer:</strong> B-tree and Hash indexes use different data structures and are optimized for different query patterns.</p>

<p><strong>B-tree Indexes:</strong></p>

<p><strong>Structure:</strong></p>
<p>- Balanced tree structure</p>
<p>- Sorted data organization</p>
<p>- Multiple levels (root, internal, leaf)</p>

<p><strong>Best For:</strong></p>
<p>- Range queries (BETWEEN, >, <)</p>
<p>- ORDER BY operations</p>
<p>- Pattern matching (LIKE 'prefix%')</p>
<p>- Equality searches</p>

<p><strong>Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20B-tree%20excels%20at%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20BETWEEN%2025%20AND%2035%3B%0ASELECT%20*%20FROM%20users%20WHERE%20name%20LIKE%20'John%25'%3B%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20created_date%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- B-tree excels at:
SELECT * FROM users WHERE age BETWEEN 25 AND 35;
SELECT * FROM users WHERE name LIKE 'John%';
SELECT * FROM users ORDER BY created_date;
</code></pre>
</div>

<p><strong>Hash Indexes:</strong></p>

<p><strong>Structure:</strong></p>
<p>- Hash table implementation</p>
<p>- Direct key-to-location mapping</p>
<p>- Single-level lookup</p>

<p><strong>Best For:</strong></p>
<p>- Exact equality matches only</p>
<p>- Very fast single-row lookups</p>
<p>- Memory-based storage engines</p>

<p><strong>Example:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Hash%20excels%20at%3A%0ASELECT%20*%20FROM%20users%20WHERE%20id%20%3D%2012345%3B%0ASELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'exact%40match.com'%3B%0A%0A--%20Hash%20cannot%20handle%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3E%2025%3B%20%20--%20No%20range%20support%0ASELECT%20*%20FROM%20users%20ORDER%20BY%20name%3B%20%20%20--%20No%20sorting%20support%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Hash excels at:
SELECT * FROM users WHERE id = 12345;
SELECT * FROM users WHERE email = 'exact@match.com';

-- Hash cannot handle:
SELECT * FROM users WHERE age &gt; 25;  -- No range support
SELECT * FROM users ORDER BY name;   -- No sorting support
</code></pre>
</div>

<p><strong>Comparison:</strong></p>
<p>| Feature | B-tree | Hash |</p>
<p>|---------|--------|------|</p>
<p>| Equality | Good | Excellent |</p>
<p>| Range | Excellent | Not supported |</p>
<p>| Sorting | Excellent | Not supported |</p>
<p>| Memory usage | Higher | Lower |</p>
<p>| Maintenance | Moderate | Low |</p>

<p>---</p>

<h2 id="-339-how-do-you-optimize-joins-using-indexes-">**339. How do you optimize joins using indexes?**</h2>

<p><strong>Answer:</strong> Join optimization relies heavily on proper indexing of join columns and understanding join algorithms.</p>

<p><strong>Join Index Strategy:</strong></p>

<p><strong>1. Index Join Columns:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20u.name%2C%20o.total%20%0AFROM%20users%20u%20%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%3B%0A%0A--%20Required%20indexes%3A%0ACREATE%20INDEX%20idx_user_id%20ON%20orders%20(user_id)%3B%20%20--%20Foreign%20key%0A--%20users.id%20already%20has%20PRIMARY%20KEY%20index%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT u.name, o.total 
FROM users u 
JOIN orders o ON u.id = o.user_id;

-- Required indexes:
CREATE INDEX idx_user_id ON orders (user_id);  -- Foreign key
-- users.id already has PRIMARY KEY index
</code></pre>
</div>

<p><strong>2. Composite Indexes for Filtered Joins:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20with%20WHERE%20clause%3A%0ASELECT%20u.name%2C%20o.total%20%0AFROM%20users%20u%20%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%20%0AWHERE%20o.status%20%3D%20'completed'%3B%0A%0A--%20Optimal%20index%3A%0ACREATE%20INDEX%20idx_status_user_id%20ON%20orders%20(status%2C%20user_id)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query with WHERE clause:
SELECT u.name, o.total 
FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE o.status = 'completed';

-- Optimal index:
CREATE INDEX idx_status_user_id ON orders (status, user_id);
</code></pre>
</div>

<p><strong>Join Algorithm Optimization:</strong></p>

<p><strong>1. Nested Loop Join:</strong></p>
<p>- Best for small result sets</p>
<p>- Requires index on inner table join column</p>
<p>- O(n*m) complexity without index</p>

<p><strong>2. Hash Join:</strong></p>
<p>- Good for larger datasets</p>
<p>- Builds hash table from smaller table</p>
<p>- Requires sufficient memory</p>

<p><strong>3. Sort-Merge Join:</strong></p>
<p>- When both tables are large</p>
<p>- Benefits from sorted data/indexes</p>
<p>- Used when hash join memory insufficient</p>

<p><strong>Best Practices:</strong></p>
<p>- Always index foreign key columns</p>
<p>- Consider covering indexes for join queries</p>
<p>- Use STRAIGHT_JOIN to force join order when needed</p>
<p>- Monitor join buffer size settings</p>

<p>---</p>

<h2 id="-340-what-are-invisible-indexes-and-their-use-cases-">**340. What are invisible indexes and their use cases?**</h2>

<p><strong>Answer:</strong> Invisible indexes exist in the database but are ignored by the query optimizer, allowing safe testing of index removal.</p>

<p><strong>Purpose:</strong></p>
<p>- Test index removal impact without dropping</p>
<p>- Gradual index deprecation</p>
<p>- Performance testing scenarios</p>
<p>- Maintenance planning</p>

<p><strong>MySQL Implementation:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20invisible%20index%3A%0ACREATE%20INDEX%20idx_email%20ON%20users%20(email)%20INVISIBLE%3B%0A%0A--%20Make%20existing%20index%20invisible%3A%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_email%20INVISIBLE%3B%0A%0A--%20Make%20invisible%20index%20visible%3A%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_email%20VISIBLE%3B%0A%0A--%20Force%20use%20of%20invisible%20index%20(for%20testing)%3A%0ASELECT%20%2F*%2B%20USE_INDEX(users%2C%20idx_email)%20*%2F%20*%20FROM%20users%20WHERE%20email%20%3D%20'test%40example.com'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create invisible index:
CREATE INDEX idx_email ON users (email) INVISIBLE;

-- Make existing index invisible:
ALTER TABLE users ALTER INDEX idx_email INVISIBLE;

-- Make invisible index visible:
ALTER TABLE users ALTER INDEX idx_email VISIBLE;

-- Force use of invisible index (for testing):
SELECT /*+ USE_INDEX(users, idx_email) */ * FROM users WHERE email = 'test@example.com';
</code></pre>
</div>

<p><strong>Use Cases:</strong></p>

<p><strong>1. Safe Index Removal:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Step%201%3A%20Make%20index%20invisible%0AALTER%20TABLE%20users%20ALTER%20INDEX%20idx_old_column%20INVISIBLE%3B%0A%0A--%20Step%202%3A%20Monitor%20performance%20for%20days%2Fweeks%0A--%20Step%203%3A%20If%20no%20issues%2C%20drop%20the%20index%0ADROP%20INDEX%20idx_old_column%20ON%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Step 1: Make index invisible
ALTER TABLE users ALTER INDEX idx_old_column INVISIBLE;

-- Step 2: Monitor performance for days/weeks
-- Step 3: If no issues, drop the index
DROP INDEX idx_old_column ON users;
</code></pre>
</div>

<p><strong>2. A/B Testing:</strong></p>
<p>- Compare query performance with/without specific indexes</p>
<p>- Test different index strategies</p>
<p>- Validate optimizer decisions</p>

<p><strong>3. Maintenance Windows:</strong></p>
<p>- Prepare indexes before maintenance</p>
<p>- Quick activation/deactivation</p>
<p>- Rollback capability</p>

<p><strong>Limitations:</strong></p>
<p>- PRIMARY KEY cannot be invisible</p>
<p>- UNIQUE indexes enforce constraints even when invisible</p>
<p>- Available in MySQL 8.0+</p>

<p>---</p>

<h2 id="-341-how-do-you-monitor-index-performance-and-usage-">**341. How do you monitor index performance and usage?**</h2>

<p><strong>Answer:</strong> Index monitoring involves tracking usage patterns, performance metrics, and identifying optimization opportunities.</p>

<p><strong>Monitoring Tools:</strong></p>

<p><strong>1. Performance Schema:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20usage%20statistics%3A%0ASELECT%20object_schema%2C%20object_name%2C%20index_name%2C%0A%20%20%20%20%20%20%20count_read%2C%20count_write%2C%20count_fetch%2C%0A%20%20%20%20%20%20%20sum_timer_read%2C%20sum_timer_write%0AFROM%20performance_schema.table_io_waits_summary_by_index_usage%0AWHERE%20object_schema%20%3D%20'your_database'%0AORDER%20BY%20count_read%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index usage statistics:
SELECT object_schema, object_name, index_name,
       count_read, count_write, count_fetch,
       sum_timer_read, sum_timer_write
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
ORDER BY count_read DESC;
</code></pre>
</div>

<p><strong>2. Information Schema:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20information%3A%0ASELECT%20table_name%2C%20index_name%2C%20column_name%2C%20cardinality%0AFROM%20information_schema.statistics%0AWHERE%20table_schema%20%3D%20'your_database'%0AORDER%20BY%20table_name%2C%20seq_in_index%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index information:
SELECT table_name, index_name, column_name, cardinality
FROM information_schema.statistics
WHERE table_schema = 'your_database'
ORDER BY table_name, seq_in_index;
</code></pre>
</div>

<p><strong>3. Slow Query Log:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20slow%20query%20log%3A%0ASET%20GLOBAL%20slow_query_log%20%3D%20'ON'%3B%0ASET%20GLOBAL%20long_query_time%20%3D%201%3B%0ASET%20GLOBAL%20log_queries_not_using_indexes%20%3D%20'ON'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable slow query log:
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 1;
SET GLOBAL log_queries_not_using_indexes = 'ON';
</code></pre>
</div>

<p><strong>Key Metrics to Monitor:</strong></p>

<p><strong>1. Index Usage Frequency:</strong></p>
<p>- Reads vs. writes ratio</p>
<p>- Unused indexes identification</p>
<p>- Most accessed indexes</p>

<p><strong>2. Performance Metrics:</strong></p>
<p>- Query execution time</p>
<p>- Rows examined vs. rows returned</p>
<p>- Index seek vs. scan operations</p>

<p><strong>3. Storage Metrics:</strong></p>
<p>- Index size growth</p>
<p>- Fragmentation levels</p>
<p>- Memory usage</p>

<p><strong>Automated Monitoring:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20monitoring%20view%3A%0ACREATE%20VIEW%20index_usage_summary%20AS%0ASELECT%20%0A%20%20%20%20t.table_name%2C%0A%20%20%20%20t.index_name%2C%0A%20%20%20%20t.count_read%2C%0A%20%20%20%20t.count_write%2C%0A%20%20%20%20ROUND(t.sum_timer_read%2F1000000000%2C%202)%20as%20read_time_sec%2C%0A%20%20%20%20s.cardinality%0AFROM%20performance_schema.table_io_waits_summary_by_index_usage%20t%0AJOIN%20information_schema.statistics%20s%20ON%20%0A%20%20%20%20t.object_name%20%3D%20s.table_name%20AND%20t.index_name%20%3D%20s.index_name%0AWHERE%20t.object_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create monitoring view:
CREATE VIEW index_usage_summary AS
SELECT 
    t.table_name,
    t.index_name,
    t.count_read,
    t.count_write,
    ROUND(t.sum_timer_read/1000000000, 2) as read_time_sec,
    s.cardinality
FROM performance_schema.table_io_waits_summary_by_index_usage t
JOIN information_schema.statistics s ON 
    t.object_name = s.table_name AND t.index_name = s.index_name
WHERE t.object_schema = 'your_database';
</code></pre>
</div>

<p>---</p>

<h2 id="-342-what-are-functional-indexes-and-how-do-you-implement-them-">**342. What are functional indexes and how do you implement them?**</h2>

<p><strong>Answer:</strong> Functional indexes are built on expressions or functions rather than direct column values, enabling optimization of computed queries.</p>

<p><strong>MySQL Implementation (8.0+):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20on%20expression%3A%0ACREATE%20INDEX%20idx_upper_email%20ON%20users%20((UPPER(email)))%3B%0A%0A--%20Index%20on%20JSON%20extraction%3A%0ACREATE%20INDEX%20idx_json_field%20ON%20products%20((JSON_EXTRACT(attributes%2C%20'%24.category')))%3B%0A%0A--%20Index%20on%20calculated%20field%3A%0ACREATE%20INDEX%20idx_full_name%20ON%20users%20((CONCAT(first_name%2C%20'%20'%2C%20last_name)))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index on expression:
CREATE INDEX idx_upper_email ON users ((UPPER(email)));

-- Index on JSON extraction:
CREATE INDEX idx_json_field ON products ((JSON_EXTRACT(attributes, '$.category')));

-- Index on calculated field:
CREATE INDEX idx_full_name ON users ((CONCAT(first_name, ' ', last_name)));
</code></pre>
</div>

<p><strong>Use Cases:</strong></p>

<p><strong>1. Case-Insensitive Searches:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Without%20functional%20index%3A%0ASELECT%20*%20FROM%20users%20WHERE%20UPPER(email)%20%3D%20'JOHN%40EXAMPLE.COM'%3B%0A--%20Requires%20full%20table%20scan%0A%0A--%20With%20functional%20index%3A%0ACREATE%20INDEX%20idx_upper_email%20ON%20users%20((UPPER(email)))%3B%0A--%20Now%20the%20query%20uses%20the%20index%20efficiently%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Without functional index:
SELECT * FROM users WHERE UPPER(email) = 'JOHN@EXAMPLE.COM';
-- Requires full table scan

-- With functional index:
CREATE INDEX idx_upper_email ON users ((UPPER(email)));
-- Now the query uses the index efficiently
</code></pre>
</div>

<p><strong>2. JSON Data Indexing:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20JSON%20field%3A%0ACREATE%20INDEX%20idx_product_category%20ON%20products%20((JSON_EXTRACT(data%2C%20'%24.category')))%3B%0A%0A--%20Optimized%20query%3A%0ASELECT%20*%20FROM%20products%20WHERE%20JSON_EXTRACT(data%2C%20'%24.category')%20%3D%20'electronics'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index JSON field:
CREATE INDEX idx_product_category ON products ((JSON_EXTRACT(data, '$.category')));

-- Optimized query:
SELECT * FROM products WHERE JSON_EXTRACT(data, '$.category') = 'electronics';
</code></pre>
</div>

<p><strong>3. Date Calculations:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Index%20on%20year%20extraction%3A%0ACREATE%20INDEX%20idx_birth_year%20ON%20users%20((YEAR(birth_date)))%3B%0A%0A--%20Optimized%20query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20YEAR(birth_date)%20%3D%201990%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Index on year extraction:
CREATE INDEX idx_birth_year ON users ((YEAR(birth_date)));

-- Optimized query:
SELECT * FROM users WHERE YEAR(birth_date) = 1990;
</code></pre>
</div>

<p><strong>Benefits:</strong></p>
<p>- Optimize function-based WHERE clauses</p>
<p>- Avoid full table scans on computed values</p>
<p>- Support complex data types (JSON, spatial)</p>

<p><strong>Limitations:</strong></p>
<p>- Increased storage requirements</p>
<p>- Slower INSERT/UPDATE operations</p>
<p>- Expression must be deterministic</p>

<p>---</p>

<h2 id="-343-how-do-you-handle-index-bloat-and-maintenance-">**343. How do you handle index bloat and maintenance?**</h2>

<p><strong>Answer:</strong> Index bloat occurs when indexes grow larger than necessary due to fragmentation, deleted records, or inefficient design.</p>

<p><strong>Causes of Index Bloat:</strong></p>
<p>1. <strong>Frequent DELETE operations</strong> leaving empty pages</p>
<p>2. <strong>Random INSERT patterns</strong> causing page splits</p>
<p>3. <strong>UPDATE operations</strong> on indexed columns</p>
<p>4. <strong>Poor fill factor</strong> settings</p>

<p><strong>Detection Methods:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20index%20sizes%3A%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20index_name%2C%0A%20%20%20%20ROUND(stat_value%20*%20%40%40innodb_page_size%20%2F%201024%20%2F%201024%2C%202)%20AS%20size_mb%0AFROM%20mysql.innodb_index_stats%20%0AWHERE%20stat_name%20%3D%20'size'%20AND%20database_name%20%3D%20'your_db'%0AORDER%20BY%20stat_value%20DESC%3B%0A%0A--%20Compare%20logical%20vs%20physical%20size%3A%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20ROUND(data_length%2F1024%2F1024%2C%202)%20AS%20data_mb%2C%0A%20%20%20%20ROUND(index_length%2F1024%2F1024%2C%202)%20AS%20index_mb%2C%0A%20%20%20%20ROUND(data_free%2F1024%2F1024%2C%202)%20AS%20free_mb%0AFROM%20information_schema.tables%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check index sizes:
SELECT 
    table_name,
    index_name,
    ROUND(stat_value * @@innodb_page_size / 1024 / 1024, 2) AS size_mb
FROM mysql.innodb_index_stats 
WHERE stat_name = 'size' AND database_name = 'your_db'
ORDER BY stat_value DESC;

-- Compare logical vs physical size:
SELECT 
    table_name,
    ROUND(data_length/1024/1024, 2) AS data_mb,
    ROUND(index_length/1024/1024, 2) AS index_mb,
    ROUND(data_free/1024/1024, 2) AS free_mb
FROM information_schema.tables
WHERE table_schema = 'your_database';
</code></pre>
</div>

<p><strong>Maintenance Strategies:</strong></p>

<p><strong>1. Regular Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Rebuild%20indexes%20and%20reclaim%20space%3A%0AOPTIMIZE%20TABLE%20users%3B%0A%0A--%20Alternative%20approach%3A%0AALTER%20TABLE%20users%20ENGINE%3DInnoDB%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Rebuild indexes and reclaim space:
OPTIMIZE TABLE users;

-- Alternative approach:
ALTER TABLE users ENGINE=InnoDB;
</code></pre>
</div>

<p><strong>2. Proactive Maintenance:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Schedule%20regular%20maintenance%3A%0A--%20Daily%20for%20high-write%20tables%0A--%20Weekly%20for%20moderate-write%20tables%0A--%20Monthly%20for%20read-heavy%20tables%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Schedule regular maintenance:
-- Daily for high-write tables
-- Weekly for moderate-write tables
-- Monthly for read-heavy tables
</code></pre>
</div>

<p><strong>3. Fill Factor Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Leave%20space%20for%20future%20inserts%20(InnoDB%20automatic)%0A--%20Reduces%20page%20splits%20and%20fragmentation%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Leave space for future inserts (InnoDB automatic)
-- Reduces page splits and fragmentation
</code></pre>
</div>

<p><strong>Prevention Strategies:</strong></p>
<p>- Use sequential PRIMARY KEYs when possible</p>
<p>- Batch DELETE operations</p>
<p>- Monitor fragmentation levels</p>
<p>- Regular statistics updates</p>

<p>---</p>

<h2 id="-344-what-is-index-intersection-and-how-does-it-work-">**344. What is index intersection and how does it work?**</h2>

<p><strong>Answer:</strong> Index intersection (Index Merge) allows MySQL to use multiple indexes simultaneously for a single query, combining their results.</p>

<p><strong>How It Works:</strong></p>
<p>1. <strong>Multiple Index Scans:</strong> Query uses several single-column indexes</p>
<p>2. <strong>Result Intersection:</strong> Combines results using AND/OR logic</p>
<p>3. <strong>Row ID Merging:</strong> Merges row identifiers from different indexes</p>
<p>4. <strong>Final Row Retrieval:</strong> Fetches actual rows using merged IDs</p>

<p><strong>Types of Index Merge:</strong></p>

<p><strong>1. Intersection (AND conditions):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20AND%20city%20%3D%20'New%20York'%3B%0A%0A--%20Indexes%3A%0ACREATE%20INDEX%20idx_age%20ON%20users%20(age)%3B%0ACREATE%20INDEX%20idx_city%20ON%20users%20(city)%3B%0A%0A--%20Execution%3A%0A--%201.%20Scan%20idx_age%20for%20age%20%3D%2025%0A--%202.%20Scan%20idx_city%20for%20city%20%3D%20'New%20York'%20%20%0A--%203.%20Intersect%20results%20(AND%20operation)%0A--%204.%20Fetch%20matching%20rows%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users WHERE age = 25 AND city = 'New York';

-- Indexes:
CREATE INDEX idx_age ON users (age);
CREATE INDEX idx_city ON users (city);

-- Execution:
-- 1. Scan idx_age for age = 25
-- 2. Scan idx_city for city = 'New York'  
-- 3. Intersect results (AND operation)
-- 4. Fetch matching rows
</code></pre>
</div>

<p><strong>2. Union (OR conditions):</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%3A%0ASELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20OR%20city%20%3D%20'New%20York'%3B%0A%0A--%20Uses%20same%20indexes%20but%20unions%20results%20instead%20of%20intersecting%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query:
SELECT * FROM users WHERE age = 25 OR city = 'New York';

-- Uses same indexes but unions results instead of intersecting
</code></pre>
</div>

<p><strong>When MySQL Uses Index Merge:</strong></p>
<p>- Multiple single-column indexes available</p>
<p>- No suitable composite index exists</p>
<p>- Cost-based optimizer determines it's efficient</p>
<p>- Conditions use AND/OR operators</p>

<p><strong>EXPLAIN Output:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="EXPLAIN%20SELECT%20*%20FROM%20users%20WHERE%20age%20%3D%2025%20AND%20city%20%3D%20'New%20York'%3B%0A--%20type%3A%20index_merge%0A--%20key%3A%20idx_age%2Cidx_city%0A--%20Extra%3A%20Using%20intersect(idx_age%2Cidx_city)%3B%20Using%20where%0A">Copy</button>
    </div>
    <pre><code class="language-sql">EXPLAIN SELECT * FROM users WHERE age = 25 AND city = 'New York';
-- type: index_merge
-- key: idx_age,idx_city
-- Extra: Using intersect(idx_age,idx_city); Using where
</code></pre>
</div>

<p><strong>Optimization Considerations:</strong></p>
<p>- <strong>Composite Index Usually Better:</strong> Single index often outperforms merge</p>
<p>- <strong>Cost Overhead:</strong> Merging operation has CPU cost</p>
<p>- <strong>Memory Usage:</strong> Requires sort buffers for merging</p>

<p><strong>Best Practice:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20relying%20on%20index%20merge%3A%0ACREATE%20INDEX%20idx_age_city%20ON%20users%20(age%2C%20city)%3B%0A--%20Single%20composite%20index%20is%20typically%20more%20efficient%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of relying on index merge:
CREATE INDEX idx_age_city ON users (age, city);
-- Single composite index is typically more efficient
</code></pre>
</div>

<p>---</p>

<h2 id="-345-how-do-you-optimize-database-schema-for-better-index-performance-">**345. How do you optimize database schema for better index performance?**</h2>

<p><strong>Answer:</strong> Schema optimization for indexing involves strategic design decisions that maximize index effectiveness.</p>

<p><strong>Schema Design Principles:</strong></p>

<p><strong>1. Primary Key Design:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Good%3A%20Sequential%2C%20compact%20primary%20key%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%20%20--%20Sequential%2C%208%20bytes%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20created_at%20TIMESTAMP%0A)%3B%0A%0A--%20Avoid%3A%20Random%20UUIDs%20as%20primary%20key%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20CHAR(36)%20PRIMARY%20KEY%2C%20%20--%20Random%2C%2036%20bytes%2C%20causes%20fragmentation%0A%20%20%20%20email%20VARCHAR(255)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Good: Sequential, compact primary key
CREATE TABLE users (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,  -- Sequential, 8 bytes
    email VARCHAR(255),
    created_at TIMESTAMP
);

-- Avoid: Random UUIDs as primary key
CREATE TABLE users (
    id CHAR(36) PRIMARY KEY,  -- Random, 36 bytes, causes fragmentation
    email VARCHAR(255)
);
</code></pre>
</div>

<p><strong>2. Data Type Optimization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Efficient%20data%20types%20for%20indexing%3A%0Auser_id%20INT%20NOT%20NULL%2C%20%20%20%20%20%20%20%20%20%20%20--%204%20bytes%20vs%20BIGINT%208%20bytes%0Astatus%20ENUM('active'%2C'inactive')%2C%20--%201%20byte%20vs%20VARCHAR%0Acreated_date%20DATE%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%203%20bytes%20vs%20DATETIME%208%20bytes%0Ais_verified%20BOOLEAN%20%20%20%20%20%20%20%20%20%20%20%20%20--%201%20bit%20vs%20TINYINT%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Efficient data types for indexing:
user_id INT NOT NULL,           -- 4 bytes vs BIGINT 8 bytes
status ENUM('active','inactive'), -- 1 byte vs VARCHAR
created_date DATE,              -- 3 bytes vs DATETIME 8 bytes
is_verified BOOLEAN             -- 1 bit vs TINYINT
</code></pre>
</div>

<p><strong>3. Column Order in Composite Indexes:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Optimal%20order%3A%20Most%20selective%20first%0ACREATE%20INDEX%20idx_user_search%20ON%20users%20(%0A%20%20%20%20status%2C%20%20%20%20%20%20%20%20--%20High%20selectivity%20(many%20statuses)%0A%20%20%20%20created_date%2C%20%20--%20Medium%20selectivity%20%20%0A%20%20%20%20user_type%20%20%20%20%20%20--%20Low%20selectivity%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Optimal order: Most selective first
CREATE INDEX idx_user_search ON users (
    status,        -- High selectivity (many statuses)
    created_date,  -- Medium selectivity  
    user_type      -- Low selectivity
);
</code></pre>
</div>

<p><strong>4. Normalization vs. Denormalization:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Normalized%20(better%20for%20writes)%3A%0ACREATE%20TABLE%20orders%20(id%2C%20customer_id%2C%20total)%3B%0ACREATE%20TABLE%20customers%20(id%2C%20name%2C%20email)%3B%0A%0A--%20Denormalized%20(better%20for%20reads)%3A%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%2C%20%0A%20%20%20%20customer_id%2C%20%0A%20%20%20%20customer_name%2C%20%20--%20Denormalized%20for%20faster%20joins%0A%20%20%20%20customer_email%2C%20--%20Denormalized%20for%20faster%20joins%0A%20%20%20%20total%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Normalized (better for writes):
CREATE TABLE orders (id, customer_id, total);
CREATE TABLE customers (id, name, email);

-- Denormalized (better for reads):
CREATE TABLE orders (
    id, 
    customer_id, 
    customer_name,  -- Denormalized for faster joins
    customer_email, -- Denormalized for faster joins
    total
);
</code></pre>
</div>

<p><strong>Schema Optimization Strategies:</strong></p>

<p><strong>1. Vertical Partitioning:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Split%20wide%20tables%3A%0A--%20Hot%20columns%20(frequently%20accessed)%3A%0ACREATE%20TABLE%20users_core%20(id%2C%20email%2C%20status%2C%20last_login)%3B%0A%0A--%20Cold%20columns%20(rarely%20accessed)%3A%0ACREATE%20TABLE%20users_profile%20(id%2C%20bio%2C%20preferences%2C%20settings)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Split wide tables:
-- Hot columns (frequently accessed):
CREATE TABLE users_core (id, email, status, last_login);

-- Cold columns (rarely accessed):
CREATE TABLE users_profile (id, bio, preferences, settings);
</code></pre>
</div>

<p><strong>2. Horizontal Partitioning:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20date%20for%20time-series%20data%3A%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(order_date))%20(%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by date for time-series data:
CREATE TABLE orders (
    id INT,
    customer_id INT,
    order_date DATE,
    total DECIMAL(10,2)
) PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025)
);
</code></pre>
</div>

<p><strong>3. Index-Only Table Design:</strong></p>

<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Design%20tables%20to%20support%20covering%20indexes%3A%0ACREATE%20TABLE%20user_activity%20(%0A%20%20%20%20user_id%20INT%2C%0A%20%20%20%20activity_date%20DATE%2C%0A%20%20%20%20activity_type%20VARCHAR(50)%2C%0A%20%20%20%20activity_count%20INT%2C%0A%20%20%20%20INDEX%20idx_covering%20(user_id%2C%20activity_date%2C%20activity_type%2C%20activity_count)%0A)%3B%0A--%20Queries%20can%20be%20satisfied%20entirely%20from%20index%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Design tables to support covering indexes:
CREATE TABLE user_activity (
    user_id INT,
    activity_date DATE,
    activity_type VARCHAR(50),
    activity_count INT,
    INDEX idx_covering (user_id, activity_date, activity_type, activity_count)
);
-- Queries can be satisfied entirely from index
</code></pre>
</div>

<h2 id="-346-what-are-stored-procedures-and-their-advantages-disadvantages-">**346. What are stored procedures and their advantages/disadvantages?**</h2>

<p><strong>Answer:</strong> Stored procedures are precompiled SQL code blocks stored in the database that can be executed with parameters.</p>

<p><strong>Advantages:</strong></p>

<p>1. <strong>Performance:</strong> Precompiled and cached execution plans</p>
<p>2. <strong>Security:</strong> Prevent SQL injection, controlled data access</p>
<p>3. <strong>Reusability:</strong> Centralized business logic</p>
<p>4. <strong>Network Traffic:</strong> Reduced data transfer</p>
<p>5. <strong>Consistency:</strong> Standardized operations across applications</p>


<p><strong>Disadvantages:</strong></p>

<p>1. <strong>Database Lock-in:</strong> Vendor-specific syntax</p>
<p>2. <strong>Version Control:</strong> Difficult to track changes</p>
<p>3. <strong>Debugging:</strong> Limited debugging tools</p>
<p>4. <strong>Scalability:</strong> Database server resource consumption</p>
<p>5. <strong>Maintenance:</strong> Complex deployment processes</p>


<p><strong>Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20GetUserOrders(IN%20user_id%20INT%2C%20IN%20status%20VARCHAR(20))%0ABEGIN%0A%20%20%20%20SELECT%20o.id%2C%20o.total%2C%20o.created_date%0A%20%20%20%20FROM%20orders%20o%0A%20%20%20%20WHERE%20o.user_id%20%3D%20user_id%20%0A%20%20%20%20AND%20(status%20IS%20NULL%20OR%20o.status%20%3D%20status)%0A%20%20%20%20ORDER%20BY%20o.created_date%20DESC%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%3A%0ACALL%20GetUserOrders(123%2C%20'completed')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE GetUserOrders(IN user_id INT, IN status VARCHAR(20))
BEGIN
    SELECT o.id, o.total, o.created_date
    FROM orders o
    WHERE o.user_id = user_id 
    AND (status IS NULL OR o.status = status)
    ORDER BY o.created_date DESC;
END //
DELIMITER ;

-- Usage:
CALL GetUserOrders(123, 'completed');
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use for complex business logic</p>
<p>- Implement proper error handling</p>
<p>- Document parameters and return values</p>
<p>- Keep procedures focused and small</p>


<p>---</p>

<h2 id="-347-how-do-you-implement-and-use-triggers-">**347. How do you implement and use triggers?**</h2>

<p><strong>Answer:</strong> Triggers are special stored procedures that automatically execute in response to database events (INSERT, UPDATE, DELETE).</p>

<p><strong>Types of Triggers:</strong></p>

<p><strong>1. BEFORE Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Validate%20data%20before%20insertion%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20before_user_insert%0ABEFORE%20INSERT%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Validate%20email%20format%0A%20%20%20%20IF%20NEW.email%20NOT%20REGEXP%20'%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C.%5BA-Za-z%5D%7B2%2C%7D%24'%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Invalid%20email%20format'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Set%20default%20values%0A%20%20%20%20IF%20NEW.created_at%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20NEW.created_at%20%3D%20NOW()%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Validate data before insertion
DELIMITER //
CREATE TRIGGER before_user_insert
BEFORE INSERT ON users
FOR EACH ROW
BEGIN
    -- Validate email format
    IF NEW.email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Invalid email format';
    END IF;
    
    -- Set default values
    IF NEW.created_at IS NULL THEN
        SET NEW.created_at = NOW();
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. AFTER Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Audit%20trail%20after%20updates%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20after_user_update%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20user_audit%20(%0A%20%20%20%20%20%20%20%20user_id%2C%20%0A%20%20%20%20%20%20%20%20old_email%2C%20%0A%20%20%20%20%20%20%20%20new_email%2C%20%0A%20%20%20%20%20%20%20%20changed_by%2C%20%0A%20%20%20%20%20%20%20%20changed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20OLD.email%2C%0A%20%20%20%20%20%20%20%20NEW.email%2C%0A%20%20%20%20%20%20%20%20USER()%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Audit trail after updates
DELIMITER //
CREATE TRIGGER after_user_update
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    INSERT INTO user_audit (
        user_id, 
        old_email, 
        new_email, 
        changed_by, 
        changed_at
    ) VALUES (
        NEW.id,
        OLD.email,
        NEW.email,
        USER(),
        NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. INSTEAD OF Triggers (Views):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Make%20views%20updatable%0ACREATE%20VIEW%20active_users%20AS%0ASELECT%20id%2C%20name%2C%20email%20FROM%20users%20WHERE%20status%20%3D%20'active'%3B%0A%0ADELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20instead_of_active_users_update%0AINSTEAD%20OF%20UPDATE%20ON%20active_users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20NEW.name%2C%20email%20%3D%20NEW.email%0A%20%20%20%20WHERE%20id%20%3D%20NEW.id%20AND%20status%20%3D%20'active'%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Make views updatable
CREATE VIEW active_users AS
SELECT id, name, email FROM users WHERE status = 'active';

DELIMITER //
CREATE TRIGGER instead_of_active_users_update
INSTEAD OF UPDATE ON active_users
FOR EACH ROW
BEGIN
    UPDATE users 
    SET name = NEW.name, email = NEW.email
    WHERE id = NEW.id AND status = 'active';
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Common Use Cases:</strong></p>

<p>- <strong>Auditing:</strong> Track data changes</p>
<p>- <strong>Validation:</strong> Complex business rules</p>
<p>- <strong>Logging:</strong> Activity tracking</p>
<p>- <strong>Denormalization:</strong> Maintain calculated fields</p>
<p>- <strong>Security:</strong> Access control</p>


<p><strong>Best Practices:</strong></p>

<p>- Keep triggers simple and fast</p>
<p>- Avoid recursive triggers</p>
<p>- Handle errors gracefully</p>
<p>- Document trigger logic thoroughly</p>


<p>---</p>

<h2 id="-348-what-are-views-and-materialized-views-">**348. What are views and materialized views?**</h2>

<p><strong>Answer:</strong> Views are virtual tables based on queries, while materialized views store query results physically.</p>

<p><strong>Regular Views:</strong></p>

<p><strong>Definition:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20VIEW%20user_summary%20AS%0ASELECT%20%0A%20%20%20%20u.id%2C%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20SUM(o.total)%20as%20total_spent%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE VIEW user_summary AS
SELECT 
    u.id,
    u.name,
    u.email,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_spent
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name, u.email;
</code></pre>
</div>

<p><strong>Characteristics:</strong></p>

<p>- Virtual table (no data storage)</p>
<p>- Query executed each time view is accessed</p>
<p>- Always shows current data</p>
<p>- Can be updatable under certain conditions</p>


<p><strong>Materialized Views (MySQL doesn't support natively):</strong></p>

<p><strong>Workaround Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20table%20to%20store%20materialized%20data%0ACREATE%20TABLE%20mv_user_summary%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20order_count%20INT%2C%0A%20%20%20%20total_spent%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_updated%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Populate%20materialized%20view%0AINSERT%20INTO%20mv_user_summary%20%0ASELECT%20%0A%20%20%20%20u.id%2C%20u.name%2C%20u.email%2C%0A%20%20%20%20COUNT(o.id)%2C%20SUM(o.total)%2C%0A%20%20%20%20NOW()%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A%0A--%20Refresh%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20RefreshUserSummary()%0ABEGIN%0A%20%20%20%20TRUNCATE%20TABLE%20mv_user_summary%3B%0A%20%20%20%20INSERT%20INTO%20mv_user_summary%20%0A%20%20%20%20SELECT%20u.id%2C%20u.name%2C%20u.email%2C%20COUNT(o.id)%2C%20SUM(o.total)%2C%20NOW()%0A%20%20%20%20FROM%20users%20u%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0A%20%20%20%20GROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create table to store materialized data
CREATE TABLE mv_user_summary (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    order_count INT,
    total_spent DECIMAL(10,2),
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Populate materialized view
INSERT INTO mv_user_summary 
SELECT 
    u.id, u.name, u.email,
    COUNT(o.id), SUM(o.total),
    NOW()
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name, u.email;

-- Refresh procedure
DELIMITER //
CREATE PROCEDURE RefreshUserSummary()
BEGIN
    TRUNCATE TABLE mv_user_summary;
    INSERT INTO mv_user_summary 
    SELECT u.id, u.name, u.email, COUNT(o.id), SUM(o.total), NOW()
    FROM users u
    LEFT JOIN orders o ON u.id = o.user_id
    GROUP BY u.id, u.name, u.email;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>When to Use:</strong></p>

<p>- <strong>Views:</strong> Simple queries, always current data needed</p>
<p>- <strong>Materialized Views:</strong> Complex aggregations, acceptable data lag</p>


<p>---</p>

<h2 id="-349-how-do-you-work-with-json-data-in-mysql-">**349. How do you work with JSON data in MySQL?**</h2>

<p><strong>Answer:</strong> MySQL provides extensive JSON support with native data type and specialized functions.</p>

<p><strong>JSON Data Type:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20attributes%20JSON%2C%0A%20%20%20%20metadata%20JSON%0A)%3B%0A%0A--%20Insert%20JSON%20data%0AINSERT%20INTO%20products%20(id%2C%20name%2C%20attributes)%20VALUES%0A(1%2C%20'Laptop'%2C%20'%7B%22brand%22%3A%20%22Dell%22%2C%20%22ram%22%3A%20%2216GB%22%2C%20%22storage%22%3A%20%22512GB%20SSD%22%7D')%2C%0A(2%2C%20'Phone'%2C%20'%7B%22brand%22%3A%20%22Apple%22%2C%20%22model%22%3A%20%22iPhone%2014%22%2C%20%22color%22%3A%20%22blue%22%7D')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255),
    attributes JSON,
    metadata JSON
);

-- Insert JSON data
INSERT INTO products (id, name, attributes) VALUES
(1, 'Laptop', '{"brand": "Dell", "ram": "16GB", "storage": "512GB SSD"}'),
(2, 'Phone', '{"brand": "Apple", "model": "iPhone 14", "color": "blue"}');
</code></pre>
</div>

<p><strong>JSON Functions:</strong></p>

<p><strong>1. Extraction Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Extract%20specific%20values%0ASELECT%20%0A%20%20%20%20name%2C%0A%20%20%20%20JSON_EXTRACT(attributes%2C%20'%24.brand')%20as%20brand%2C%0A%20%20%20%20attributes-%3E%3E'%24.ram'%20as%20ram%2C%20%20--%20Shorthand%20syntax%0A%20%20%20%20attributes-%3E'%24.storage'%20as%20storage%0AFROM%20products%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Extract specific values
SELECT 
    name,
    JSON_EXTRACT(attributes, '$.brand') as brand,
    attributes-&gt;&gt;'$.ram' as ram,  -- Shorthand syntax
    attributes-&gt;'$.storage' as storage
FROM products;
</code></pre>
</div>

<p><strong>2. Modification Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Update%20JSON%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_SET(attributes%2C%20'%24.warranty'%2C%20'2%20years')%0AWHERE%20id%20%3D%201%3B%0A%0A--%20Add%20new%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_INSERT(attributes%2C%20'%24.price'%2C%20999.99)%0AWHERE%20id%20%3D%201%3B%0A%0A--%20Remove%20fields%0AUPDATE%20products%20%0ASET%20attributes%20%3D%20JSON_REMOVE(attributes%2C%20'%24.color')%0AWHERE%20id%20%3D%202%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Update JSON fields
UPDATE products 
SET attributes = JSON_SET(attributes, '$.warranty', '2 years')
WHERE id = 1;

-- Add new fields
UPDATE products 
SET attributes = JSON_INSERT(attributes, '$.price', 999.99)
WHERE id = 1;

-- Remove fields
UPDATE products 
SET attributes = JSON_REMOVE(attributes, '$.color')
WHERE id = 2;
</code></pre>
</div>

<p><strong>3. Search Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Search%20within%20JSON%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_EXTRACT(attributes%2C%20'%24.brand')%20%3D%20'Dell'%3B%0A%0A--%20Search%20for%20key%20existence%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_CONTAINS_PATH(attributes%2C%20'one'%2C%20'%24.warranty')%3B%0A%0A--%20Search%20array%20values%0ASELECT%20*%20FROM%20products%20%0AWHERE%20JSON_CONTAINS(attributes%2C%20'%22blue%22'%2C%20'%24.colors')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Search within JSON
SELECT * FROM products 
WHERE JSON_EXTRACT(attributes, '$.brand') = 'Dell';

-- Search for key existence
SELECT * FROM products 
WHERE JSON_CONTAINS_PATH(attributes, 'one', '$.warranty');

-- Search array values
SELECT * FROM products 
WHERE JSON_CONTAINS(attributes, '"blue"', '$.colors');
</code></pre>
</div>

<p><strong>JSON Indexing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20functional%20index%20on%20JSON%20field%0ACREATE%20INDEX%20idx_brand%20ON%20products%20((JSON_EXTRACT(attributes%2C%20'%24.brand')))%3B%0A%0A--%20Create%20generated%20column%20for%20better%20performance%0AALTER%20TABLE%20products%20%0AADD%20COLUMN%20brand%20VARCHAR(50)%20AS%20(JSON_EXTRACT(attributes%2C%20'%24.brand'))%3B%0ACREATE%20INDEX%20idx_generated_brand%20ON%20products%20(brand)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create functional index on JSON field
CREATE INDEX idx_brand ON products ((JSON_EXTRACT(attributes, '$.brand')));

-- Create generated column for better performance
ALTER TABLE products 
ADD COLUMN brand VARCHAR(50) AS (JSON_EXTRACT(attributes, '$.brand'));
CREATE INDEX idx_generated_brand ON products (brand);
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use generated columns for frequently queried JSON fields</p>
<p>- Index JSON paths that are commonly searched</p>
<p>- Validate JSON structure in application layer</p>
<p>- Consider normalization for highly structured data</p>


<p>---</p>

<h2 id="-350-what-are-window-functions-and-how-do-you-use-them-">**350. What are window functions and how do you use them?**</h2>

<p><strong>Answer:</strong> Window functions perform calculations across related rows without grouping them, providing analytical capabilities.</p>

<p><strong>Basic Syntax:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20column1%2C%0A%20%20%20%20window_function()%20OVER%20(%0A%20%20%20%20%20%20%20%20%5BPARTITION%20BY%20column2%5D%0A%20%20%20%20%20%20%20%20%5BORDER%20BY%20column3%5D%0A%20%20%20%20%20%20%20%20%5BROWS%2FRANGE%20frame_specification%5D%0A%20%20%20%20)%0AFROM%20table%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    column1,
    window_function() OVER (
        [PARTITION BY column2]
        [ORDER BY column3]
        [ROWS/RANGE frame_specification]
    )
FROM table;
</code></pre>
</div>

<p><strong>Common Window Functions:</strong></p>

<p><strong>1. Ranking Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20employee_id%2C%0A%20%20%20%20department%2C%0A%20%20%20%20salary%2C%0A%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20row_num%2C%0A%20%20%20%20RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20rank_pos%2C%0A%20%20%20%20DENSE_RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20dense_rank%2C%0A%20%20%20%20PERCENT_RANK()%20OVER%20(PARTITION%20BY%20department%20ORDER%20BY%20salary%20DESC)%20as%20percent_rank%0AFROM%20employees%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    employee_id,
    department,
    salary,
    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as row_num,
    RANK() OVER (PARTITION BY department ORDER BY salary DESC) as rank_pos,
    DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dense_rank,
    PERCENT_RANK() OVER (PARTITION BY department ORDER BY salary DESC) as percent_rank
FROM employees;
</code></pre>
</div>

<p><strong>2. Aggregate Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20order_date%2C%0A%20%20%20%20daily_sales%2C%0A%20%20%20%20SUM(daily_sales)%20OVER%20(ORDER%20BY%20order_date)%20as%20running_total%2C%0A%20%20%20%20AVG(daily_sales)%20OVER%20(ORDER%20BY%20order_date%20ROWS%206%20PRECEDING)%20as%20moving_avg_7days%2C%0A%20%20%20%20COUNT(*)%20OVER%20(PARTITION%20BY%20MONTH(order_date))%20as%20monthly_count%0AFROM%20daily_sales%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    order_date,
    daily_sales,
    SUM(daily_sales) OVER (ORDER BY order_date) as running_total,
    AVG(daily_sales) OVER (ORDER BY order_date ROWS 6 PRECEDING) as moving_avg_7days,
    COUNT(*) OVER (PARTITION BY MONTH(order_date)) as monthly_count
FROM daily_sales;
</code></pre>
</div>

<p><strong>3. Value Functions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SELECT%20%0A%20%20%20%20employee_id%2C%0A%20%20%20%20salary%2C%0A%20%20%20%20LAG(salary%2C%201)%20OVER%20(ORDER%20BY%20hire_date)%20as%20prev_salary%2C%0A%20%20%20%20LEAD(salary%2C%201)%20OVER%20(ORDER%20BY%20hire_date)%20as%20next_salary%2C%0A%20%20%20%20FIRST_VALUE(salary)%20OVER%20(ORDER%20BY%20hire_date)%20as%20first_salary%2C%0A%20%20%20%20LAST_VALUE(salary)%20OVER%20(ORDER%20BY%20hire_date%20ROWS%20UNBOUNDED%20FOLLOWING)%20as%20last_salary%0AFROM%20employees%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SELECT 
    employee_id,
    salary,
    LAG(salary, 1) OVER (ORDER BY hire_date) as prev_salary,
    LEAD(salary, 1) OVER (ORDER BY hire_date) as next_salary,
    FIRST_VALUE(salary) OVER (ORDER BY hire_date) as first_salary,
    LAST_VALUE(salary) OVER (ORDER BY hire_date ROWS UNBOUNDED FOLLOWING) as last_salary
FROM employees;
</code></pre>
</div>

<p><strong>Frame Specifications:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Different%20frame%20types%3A%0AROWS%20BETWEEN%20UNBOUNDED%20PRECEDING%20AND%20CURRENT%20ROW%20%20--%20From%20start%20to%20current%0AROWS%20BETWEEN%202%20PRECEDING%20AND%202%20FOLLOWING%20%20%20%20%20%20%20%20%20%20--%205-row%20window%0ARANGE%20BETWEEN%20INTERVAL%201%20MONTH%20PRECEDING%20AND%20CURRENT%20ROW%20%20--%20Date%20range%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Different frame types:
ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW  -- From start to current
ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING          -- 5-row window
RANGE BETWEEN INTERVAL 1 MONTH PRECEDING AND CURRENT ROW  -- Date range
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Top N per Group:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Top%203%20products%20per%20category%20by%20sales%0ASELECT%20category%2C%20product_name%2C%20sales%0AFROM%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20category%2C%20%0A%20%20%20%20%20%20%20%20product_name%2C%20%0A%20%20%20%20%20%20%20%20sales%2C%0A%20%20%20%20%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20category%20ORDER%20BY%20sales%20DESC)%20as%20rn%0A%20%20%20%20FROM%20products%0A)%20ranked%0AWHERE%20rn%20%3C%3D%203%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Top 3 products per category by sales
SELECT category, product_name, sales
FROM (
    SELECT 
        category, 
        product_name, 
        sales,
        ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as rn
    FROM products
) ranked
WHERE rn &lt;= 3;
</code></pre>
</div>

<p><strong>2. Running Calculations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Running%20total%20and%20percentage%20of%20total%0ASELECT%20%0A%20%20%20%20month%2C%0A%20%20%20%20revenue%2C%0A%20%20%20%20SUM(revenue)%20OVER%20(ORDER%20BY%20month)%20as%20running_total%2C%0A%20%20%20%20revenue%20%2F%20SUM(revenue)%20OVER%20()%20*%20100%20as%20pct_of_total%0AFROM%20monthly_revenue%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Running total and percentage of total
SELECT 
    month,
    revenue,
    SUM(revenue) OVER (ORDER BY month) as running_total,
    revenue / SUM(revenue) OVER () * 100 as pct_of_total
FROM monthly_revenue;
</code></pre>
</div>

<p>---</p>

<h2 id="-351-how-do-you-implement-recursive-queries-with-ctes-">**351. How do you implement recursive queries with CTEs?**</h2>

<p><strong>Answer:</strong> Common Table Expressions (CTEs) with recursion solve hierarchical and tree-structured data problems.</p>

<p><strong>Basic Recursive CTE Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="WITH%20RECURSIVE%20cte_name%20AS%20(%0A%20%20%20%20--%20Anchor%20member%20(base%20case)%0A%20%20%20%20SELECT%20initial_query%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%20member%0A%20%20%20%20SELECT%20recursive_query%0A%20%20%20%20FROM%20cte_name%0A%20%20%20%20WHERE%20termination_condition%0A)%0ASELECT%20*%20FROM%20cte_name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">WITH RECURSIVE cte_name AS (
    -- Anchor member (base case)
    SELECT initial_query
    
    UNION ALL
    
    -- Recursive member
    SELECT recursive_query
    FROM cte_name
    WHERE termination_condition
)
SELECT * FROM cte_name;
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Organizational Hierarchy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20structure%3A%0ACREATE%20TABLE%20employees%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20manager_id%20INT%2C%0A%20%20%20%20FOREIGN%20KEY%20(manager_id)%20REFERENCES%20employees(id)%0A)%3B%0A%0A--%20Find%20all%20subordinates%20of%20a%20manager%0AWITH%20RECURSIVE%20employee_hierarchy%20AS%20(%0A%20%20%20%20--%20Anchor%3A%20Start%20with%20the%20manager%0A%20%20%20%20SELECT%20id%2C%20name%2C%20manager_id%2C%200%20as%20level%0A%20%20%20%20FROM%20employees%20%0A%20%20%20%20WHERE%20id%20%3D%201%20%20--%20CEO%20or%20specific%20manager%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%3A%20Find%20direct%20reports%0A%20%20%20%20SELECT%20e.id%2C%20e.name%2C%20e.manager_id%2C%20eh.level%20%2B%201%0A%20%20%20%20FROM%20employees%20e%0A%20%20%20%20INNER%20JOIN%20employee_hierarchy%20eh%20ON%20e.manager_id%20%3D%20eh.id%0A%20%20%20%20WHERE%20eh.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A)%0ASELECT%20%0A%20%20%20%20CONCAT(REPEAT('%20%20'%2C%20level)%2C%20name)%20as%20hierarchy%2C%0A%20%20%20%20level%0AFROM%20employee_hierarchy%0AORDER%20BY%20level%2C%20name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table structure:
CREATE TABLE employees (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    manager_id INT,
    FOREIGN KEY (manager_id) REFERENCES employees(id)
);

-- Find all subordinates of a manager
WITH RECURSIVE employee_hierarchy AS (
    -- Anchor: Start with the manager
    SELECT id, name, manager_id, 0 as level
    FROM employees 
    WHERE id = 1  -- CEO or specific manager
    
    UNION ALL
    
    -- Recursive: Find direct reports
    SELECT e.id, e.name, e.manager_id, eh.level + 1
    FROM employees e
    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.id
    WHERE eh.level &lt; 10  -- Prevent infinite recursion
)
SELECT 
    CONCAT(REPEAT('  ', level), name) as hierarchy,
    level
FROM employee_hierarchy
ORDER BY level, name;
</code></pre>
</div>

<p><strong>2. Category Tree Navigation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Product%20categories%20with%20parent-child%20relationships%0AWITH%20RECURSIVE%20category_path%20AS%20(%0A%20%20%20%20--%20Anchor%3A%20Root%20categories%0A%20%20%20%20SELECT%20id%2C%20name%2C%20parent_id%2C%20name%20as%20path%2C%200%20as%20depth%0A%20%20%20%20FROM%20categories%20%0A%20%20%20%20WHERE%20parent_id%20IS%20NULL%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Recursive%3A%20Child%20categories%0A%20%20%20%20SELECT%20c.id%2C%20c.name%2C%20c.parent_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20CONCAT(cp.path%2C%20'%20%3E%20'%2C%20c.name)%20as%20path%2C%0A%20%20%20%20%20%20%20%20%20%20%20cp.depth%20%2B%201%0A%20%20%20%20FROM%20categories%20c%0A%20%20%20%20INNER%20JOIN%20category_path%20cp%20ON%20c.parent_id%20%3D%20cp.id%0A%20%20%20%20WHERE%20cp.depth%20%3C%205%20%20--%20Limit%20depth%0A)%0ASELECT%20id%2C%20name%2C%20path%2C%20depth%0AFROM%20category_path%0AORDER%20BY%20path%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Product categories with parent-child relationships
WITH RECURSIVE category_path AS (
    -- Anchor: Root categories
    SELECT id, name, parent_id, name as path, 0 as depth
    FROM categories 
    WHERE parent_id IS NULL
    
    UNION ALL
    
    -- Recursive: Child categories
    SELECT c.id, c.name, c.parent_id, 
           CONCAT(cp.path, ' &gt; ', c.name) as path,
           cp.depth + 1
    FROM categories c
    INNER JOIN category_path cp ON c.parent_id = cp.id
    WHERE cp.depth &lt; 5  -- Limit depth
)
SELECT id, name, path, depth
FROM category_path
ORDER BY path;
</code></pre>
</div>

<p><strong>3. Graph Traversal:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20all%20connected%20nodes%20in%20a%20network%0AWITH%20RECURSIVE%20connected_nodes%20AS%20(%0A%20%20%20%20--%20Start%20from%20specific%20node%0A%20%20%20%20SELECT%20node_id%2C%20connected_to%2C%201%20as%20distance%0A%20%20%20%20FROM%20connections%20%0A%20%20%20%20WHERE%20node_id%20%3D%20'A'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Follow%20connections%0A%20%20%20%20SELECT%20c.node_id%2C%20c.connected_to%2C%20cn.distance%20%2B%201%0A%20%20%20%20FROM%20connections%20c%0A%20%20%20%20INNER%20JOIN%20connected_nodes%20cn%20ON%20c.node_id%20%3D%20cn.connected_to%0A%20%20%20%20WHERE%20cn.distance%20%3C%206%20%20--%20Limit%20traversal%20depth%0A)%0ASELECT%20DISTINCT%20connected_to%20as%20reachable_nodes%2C%20MIN(distance)%20as%20min_distance%0AFROM%20connected_nodes%0AGROUP%20BY%20connected_to%0AORDER%20BY%20min_distance%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find all connected nodes in a network
WITH RECURSIVE connected_nodes AS (
    -- Start from specific node
    SELECT node_id, connected_to, 1 as distance
    FROM connections 
    WHERE node_id = 'A'
    
    UNION ALL
    
    -- Follow connections
    SELECT c.node_id, c.connected_to, cn.distance + 1
    FROM connections c
    INNER JOIN connected_nodes cn ON c.node_id = cn.connected_to
    WHERE cn.distance &lt; 6  -- Limit traversal depth
)
SELECT DISTINCT connected_to as reachable_nodes, MIN(distance) as min_distance
FROM connected_nodes
GROUP BY connected_to
ORDER BY min_distance;
</code></pre>
</div>

<p><strong>4. Time Series Generation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generate%20date%20series%0AWITH%20RECURSIVE%20date_series%20AS%20(%0A%20%20%20%20SELECT%20DATE('2024-01-01')%20as%20date_value%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20DATE_ADD(date_value%2C%20INTERVAL%201%20DAY)%0A%20%20%20%20FROM%20date_series%0A%20%20%20%20WHERE%20date_value%20%3C%20DATE('2024-12-31')%0A)%0ASELECT%20date_value%2C%20DAYNAME(date_value)%20as%20day_name%0AFROM%20date_series%0AWHERE%20DAYOFWEEK(date_value)%20IN%20(1%2C%207)%3B%20%20--%20Weekends%20only%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generate date series
WITH RECURSIVE date_series AS (
    SELECT DATE('2024-01-01') as date_value
    
    UNION ALL
    
    SELECT DATE_ADD(date_value, INTERVAL 1 DAY)
    FROM date_series
    WHERE date_value &lt; DATE('2024-12-31')
)
SELECT date_value, DAYNAME(date_value) as day_name
FROM date_series
WHERE DAYOFWEEK(date_value) IN (1, 7);  -- Weekends only
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Always include termination conditions</p>
<p>- Limit recursion depth to prevent infinite loops</p>
<p>- Index foreign key columns used in joins</p>
<p>- Consider iterative approaches for very deep hierarchies</p>


<p>---</p>

<h2 id="-352-what-are-user-defined-functions-udfs-">**352. What are user-defined functions (UDFs)?**</h2>

<p><strong>Answer:</strong> User-Defined Functions are custom functions that extend MySQL's built-in function library, allowing reusable logic encapsulation.</p>

<p><strong>Types of UDFs:</strong></p>

<p><strong>1. Scalar Functions (Return single value):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CalculateAge(birth_date%20DATE)%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20TIMESTAMPDIFF(YEAR%2C%20birth_date%2C%20CURDATE())%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%3A%0ASELECT%20name%2C%20birth_date%2C%20CalculateAge(birth_date)%20as%20age%0AFROM%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CalculateAge(birth_date DATE)
RETURNS INT
READS SQL DATA
DETERMINISTIC
BEGIN
    RETURN TIMESTAMPDIFF(YEAR, birth_date, CURDATE());
END //
DELIMITER ;

-- Usage:
SELECT name, birth_date, CalculateAge(birth_date) as age
FROM users;
</code></pre>
</div>

<p><strong>2. Table Functions (MySQL doesn't support, but can simulate):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Workaround%20using%20stored%20procedure%20with%20temporary%20table%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20GetUsersByAge(IN%20min_age%20INT%2C%20IN%20max_age%20INT)%0ABEGIN%0A%20%20%20%20SELECT%20*%20FROM%20users%20%0A%20%20%20%20WHERE%20CalculateAge(birth_date)%20BETWEEN%20min_age%20AND%20max_age%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Workaround using stored procedure with temporary table
DELIMITER //
CREATE PROCEDURE GetUsersByAge(IN min_age INT, IN max_age INT)
BEGIN
    SELECT * FROM users 
    WHERE CalculateAge(birth_date) BETWEEN min_age AND max_age;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Function Characteristics:</strong></p>

<p><strong>1. Deterministic vs Non-deterministic:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Deterministic%20(same%20input%20%3D%20same%20output)%0ACREATE%20FUNCTION%20FormatCurrency(amount%20DECIMAL(10%2C2))%0ARETURNS%20VARCHAR(20)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20CONCAT('%24'%2C%20FORMAT(amount%2C%202))%3B%0AEND%20%2F%2F%0A%0A--%20Non-deterministic%20(output%20can%20vary)%0ACREATE%20FUNCTION%20GetCurrentTimestamp()%0ARETURNS%20TIMESTAMP%0ANOT%20DETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20NOW()%3B%0AEND%20%2F%2F%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Deterministic (same input = same output)
CREATE FUNCTION FormatCurrency(amount DECIMAL(10,2))
RETURNS VARCHAR(20)
DETERMINISTIC
BEGIN
    RETURN CONCAT('$', FORMAT(amount, 2));
END //

-- Non-deterministic (output can vary)
CREATE FUNCTION GetCurrentTimestamp()
RETURNS TIMESTAMP
NOT DETERMINISTIC
BEGIN
    RETURN NOW();
END //
</code></pre>
</div>

<p><strong>2. Data Access Levels:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20NO%20SQL%3A%20No%20database%20access%0ACREATE%20FUNCTION%20SimpleCalculation(x%20INT%2C%20y%20INT)%0ARETURNS%20INT%0ANO%20SQL%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20RETURN%20x%20*%20y%20%2B%2010%3B%0AEND%20%2F%2F%0A%0A--%20READS%20SQL%20DATA%3A%20Read-only%20access%0ACREATE%20FUNCTION%20GetUserCount()%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20user_count%20INT%3B%0A%20%20%20%20SELECT%20COUNT(*)%20INTO%20user_count%20FROM%20users%3B%0A%20%20%20%20RETURN%20user_count%3B%0AEND%20%2F%2F%0A%0A--%20MODIFIES%20SQL%20DATA%3A%20Can%20modify%20data%0ACREATE%20FUNCTION%20LogAndReturn(message%20VARCHAR(255))%0ARETURNS%20VARCHAR(255)%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20function_log%20(message%2C%20called_at)%20VALUES%20(message%2C%20NOW())%3B%0A%20%20%20%20RETURN%20CONCAT('Logged%3A%20'%2C%20message)%3B%0AEND%20%2F%2F%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- NO SQL: No database access
CREATE FUNCTION SimpleCalculation(x INT, y INT)
RETURNS INT
NO SQL
DETERMINISTIC
BEGIN
    RETURN x * y + 10;
END //

-- READS SQL DATA: Read-only access
CREATE FUNCTION GetUserCount()
RETURNS INT
READS SQL DATA
BEGIN
    DECLARE user_count INT;
    SELECT COUNT(*) INTO user_count FROM users;
    RETURN user_count;
END //

-- MODIFIES SQL DATA: Can modify data
CREATE FUNCTION LogAndReturn(message VARCHAR(255))
RETURNS VARCHAR(255)
MODIFIES SQL DATA
BEGIN
    INSERT INTO function_log (message, called_at) VALUES (message, NOW());
    RETURN CONCAT('Logged: ', message);
END //
</code></pre>
</div>

<p><strong>Advanced Examples:</strong></p>

<p><strong>1. Business Logic Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CalculateDiscount(%0A%20%20%20%20customer_type%20VARCHAR(20)%2C%0A%20%20%20%20order_amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20is_member%20BOOLEAN%0A)%0ARETURNS%20DECIMAL(5%2C2)%0AREADS%20SQL%20DATA%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20discount%20DECIMAL(5%2C2)%20DEFAULT%200.00%3B%0A%20%20%20%20%0A%20%20%20%20--%20Base%20discount%20by%20customer%20type%0A%20%20%20%20CASE%20customer_type%0A%20%20%20%20%20%20%20%20WHEN%20'premium'%20THEN%20SET%20discount%20%3D%200.15%3B%0A%20%20%20%20%20%20%20%20WHEN%20'gold'%20THEN%20SET%20discount%20%3D%200.10%3B%0A%20%20%20%20%20%20%20%20WHEN%20'silver'%20THEN%20SET%20discount%20%3D%200.05%3B%0A%20%20%20%20%20%20%20%20ELSE%20SET%20discount%20%3D%200.00%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Additional%20discount%20for%20large%20orders%0A%20%20%20%20IF%20order_amount%20%3E%201000%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%20discount%20%2B%200.05%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Member%20bonus%0A%20%20%20%20IF%20is_member%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%20discount%20%2B%200.02%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Cap%20maximum%20discount%0A%20%20%20%20IF%20discount%20%3E%200.25%20THEN%0A%20%20%20%20%20%20%20%20SET%20discount%20%3D%200.25%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20discount%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CalculateDiscount(
    customer_type VARCHAR(20),
    order_amount DECIMAL(10,2),
    is_member BOOLEAN
)
RETURNS DECIMAL(5,2)
READS SQL DATA
DETERMINISTIC
BEGIN
    DECLARE discount DECIMAL(5,2) DEFAULT 0.00;
    
    -- Base discount by customer type
    CASE customer_type
        WHEN 'premium' THEN SET discount = 0.15;
        WHEN 'gold' THEN SET discount = 0.10;
        WHEN 'silver' THEN SET discount = 0.05;
        ELSE SET discount = 0.00;
    END CASE;
    
    -- Additional discount for large orders
    IF order_amount &gt; 1000 THEN
        SET discount = discount + 0.05;
    END IF;
    
    -- Member bonus
    IF is_member THEN
        SET discount = discount + 0.02;
    END IF;
    
    -- Cap maximum discount
    IF discount &gt; 0.25 THEN
        SET discount = 0.25;
    END IF;
    
    RETURN discount;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. String Processing Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20CleanPhoneNumber(phone%20VARCHAR(20))%0ARETURNS%20VARCHAR(15)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20cleaned%20VARCHAR(15)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20all%20non-numeric%20characters%0A%20%20%20%20SET%20cleaned%20%3D%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%5D'%2C%20'')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Format%20as%20(XXX)%20XXX-XXXX%20if%2010%20digits%0A%20%20%20%20IF%20LENGTH(cleaned)%20%3D%2010%20THEN%0A%20%20%20%20%20%20%20%20SET%20cleaned%20%3D%20CONCAT('('%2C%20SUBSTRING(cleaned%2C%201%2C%203)%2C%20')%20'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(cleaned%2C%204%2C%203)%2C%20'-'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(cleaned%2C%207%2C%204))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20cleaned%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION CleanPhoneNumber(phone VARCHAR(20))
RETURNS VARCHAR(15)
DETERMINISTIC
BEGIN
    DECLARE cleaned VARCHAR(15);
    
    -- Remove all non-numeric characters
    SET cleaned = REGEXP_REPLACE(phone, '[^0-9]', '');
    
    -- Format as (XXX) XXX-XXXX if 10 digits
    IF LENGTH(cleaned) = 10 THEN
        SET cleaned = CONCAT('(', SUBSTRING(cleaned, 1, 3), ') ', 
                           SUBSTRING(cleaned, 4, 3), '-', 
                           SUBSTRING(cleaned, 7, 4));
    END IF;
    
    RETURN cleaned;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Keep functions simple and focused</p>
<p>- Use appropriate data access levels</p>
<p>- Handle NULL inputs gracefully</p>
<p>- Document function purpose and parameters</p>
<p>- Consider performance impact on queries</p>


<p>---</p>

<h2 id="-353-how-do-you-work-with-temporary-tables-">**353. How do you work with temporary tables?**</h2>

<p><strong>Answer:</strong> Temporary tables are session-specific tables that exist only during the database connection, useful for complex data processing.</p>

<p><strong>Types of Temporary Tables:</strong></p>

<p><strong>1. Local Temporary Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20temporary%20table%0ACREATE%20TEMPORARY%20TABLE%20temp_user_stats%20(%0A%20%20%20%20user_id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20order_count%20INT%2C%0A%20%20%20%20total_spent%20DECIMAL(10%2C2)%2C%0A%20%20%20%20avg_order_value%20DECIMAL(10%2C2)%0A)%3B%0A%0A--%20Populate%20with%20complex%20logic%0AINSERT%20INTO%20temp_user_stats%0ASELECT%20%0A%20%20%20%20u.id%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20COALESCE(SUM(o.total)%2C%200)%20as%20total_spent%2C%0A%20%20%20%20COALESCE(AVG(o.total)%2C%200)%20as%20avg_order_value%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.user_id%0AWHERE%20u.created_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%0AGROUP%20BY%20u.id%3B%0A%0A--%20Use%20in%20subsequent%20queries%0ASELECT%20%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20ts.order_count%2C%0A%20%20%20%20ts.total_spent%0AFROM%20users%20u%0AJOIN%20temp_user_stats%20ts%20ON%20u.id%20%3D%20ts.user_id%0AWHERE%20ts.total_spent%20%3E%201000%0AORDER%20BY%20ts.total_spent%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create temporary table
CREATE TEMPORARY TABLE temp_user_stats (
    user_id INT PRIMARY KEY,
    order_count INT,
    total_spent DECIMAL(10,2),
    avg_order_value DECIMAL(10,2)
);

-- Populate with complex logic
INSERT INTO temp_user_stats
SELECT 
    u.id,
    COUNT(o.id) as order_count,
    COALESCE(SUM(o.total), 0) as total_spent,
    COALESCE(AVG(o.total), 0) as avg_order_value
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.created_at &gt;= DATE_SUB(NOW(), INTERVAL 1 YEAR)
GROUP BY u.id;

-- Use in subsequent queries
SELECT 
    u.name,
    u.email,
    ts.order_count,
    ts.total_spent
FROM users u
JOIN temp_user_stats ts ON u.id = ts.user_id
WHERE ts.total_spent &gt; 1000
ORDER BY ts.total_spent DESC;
</code></pre>
</div>

<p><strong>2. Memory-Based Temporary Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TEMPORARY%20TABLE%20temp_calculations%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20result%20DECIMAL(15%2C4)%0A)%20ENGINE%3DMEMORY%3B%0A%0A--%20Faster%20for%20small%20datasets%20that%20fit%20in%20memory%0A--%20Automatically%20uses%20MEMORY%20storage%20engine%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TEMPORARY TABLE temp_calculations (
    id INT PRIMARY KEY,
    result DECIMAL(15,4)
) ENGINE=MEMORY;

-- Faster for small datasets that fit in memory
-- Automatically uses MEMORY storage engine
</code></pre>
</div>

<p><strong>Common Use Cases:</strong></p>

<p><strong>1. Complex Data Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multi-step%20data%20transformation%0ACREATE%20TEMPORARY%20TABLE%20temp_sales_analysis%20(%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20category%20VARCHAR(50)%2C%0A%20%20%20%20monthly_sales%20DECIMAL(12%2C2)%2C%0A%20%20%20%20growth_rate%20DECIMAL(5%2C2)%2C%0A%20%20%20%20rank_in_category%20INT%0A)%3B%0A%0A--%20Step%201%3A%20Calculate%20monthly%20sales%0AINSERT%20INTO%20temp_sales_analysis%20(product_id%2C%20category%2C%20monthly_sales)%0ASELECT%20p.id%2C%20p.category%2C%20SUM(oi.quantity%20*%20oi.price)%0AFROM%20products%20p%0AJOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0AJOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0AWHERE%20o.order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20MONTH)%0AGROUP%20BY%20p.id%2C%20p.category%3B%0A%0A--%20Step%202%3A%20Calculate%20growth%20rates%0AUPDATE%20temp_sales_analysis%20tsa%0AJOIN%20(%0A%20%20%20%20SELECT%20product_id%2C%20SUM(oi.quantity%20*%20oi.price)%20as%20prev_sales%0A%20%20%20%20FROM%20products%20p%0A%20%20%20%20JOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0A%20%20%20%20JOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0A%20%20%20%20WHERE%20o.order_date%20BETWEEN%20DATE_SUB(NOW()%2C%20INTERVAL%202%20MONTH)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20DATE_SUB(NOW()%2C%20INTERVAL%201%20MONTH)%0A%20%20%20%20GROUP%20BY%20product_id%0A)%20prev%20ON%20tsa.product_id%20%3D%20prev.product_id%0ASET%20tsa.growth_rate%20%3D%20((tsa.monthly_sales%20-%20prev.prev_sales)%20%2F%20prev.prev_sales)%20*%20100%3B%0A%0A--%20Step%203%3A%20Add%20rankings%0AUPDATE%20temp_sales_analysis%20tsa%0AJOIN%20(%0A%20%20%20%20SELECT%20product_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20ROW_NUMBER()%20OVER%20(PARTITION%20BY%20category%20ORDER%20BY%20monthly_sales%20DESC)%20as%20rank_num%0A%20%20%20%20FROM%20temp_sales_analysis%0A)%20ranked%20ON%20tsa.product_id%20%3D%20ranked.product_id%0ASET%20tsa.rank_in_category%20%3D%20ranked.rank_num%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multi-step data transformation
CREATE TEMPORARY TABLE temp_sales_analysis (
    product_id INT,
    category VARCHAR(50),
    monthly_sales DECIMAL(12,2),
    growth_rate DECIMAL(5,2),
    rank_in_category INT
);

-- Step 1: Calculate monthly sales
INSERT INTO temp_sales_analysis (product_id, category, monthly_sales)
SELECT p.id, p.category, SUM(oi.quantity * oi.price)
FROM products p
JOIN order_items oi ON p.id = oi.product_id
JOIN orders o ON oi.order_id = o.id
WHERE o.order_date &gt;= DATE_SUB(NOW(), INTERVAL 1 MONTH)
GROUP BY p.id, p.category;

-- Step 2: Calculate growth rates
UPDATE temp_sales_analysis tsa
JOIN (
    SELECT product_id, SUM(oi.quantity * oi.price) as prev_sales
    FROM products p
    JOIN order_items oi ON p.id = oi.product_id
    JOIN orders o ON oi.order_id = o.id
    WHERE o.order_date BETWEEN DATE_SUB(NOW(), INTERVAL 2 MONTH) 
                           AND DATE_SUB(NOW(), INTERVAL 1 MONTH)
    GROUP BY product_id
) prev ON tsa.product_id = prev.product_id
SET tsa.growth_rate = ((tsa.monthly_sales - prev.prev_sales) / prev.prev_sales) * 100;

-- Step 3: Add rankings
UPDATE temp_sales_analysis tsa
JOIN (
    SELECT product_id, 
           ROW_NUMBER() OVER (PARTITION BY category ORDER BY monthly_sales DESC) as rank_num
    FROM temp_sales_analysis
) ranked ON tsa.product_id = ranked.product_id
SET tsa.rank_in_category = ranked.rank_num;
</code></pre>
</div>

<p><strong>2. Data Import/ETL Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Staging%20table%20for%20data%20validation%0ACREATE%20TEMPORARY%20TABLE%20temp_import_users%20(%0A%20%20%20%20external_id%20VARCHAR(50)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20validation_errors%20TEXT%0A)%3B%0A%0A--%20Load%20raw%20data%0ALOAD%20DATA%20INFILE%20'users.csv'%20INTO%20TABLE%20temp_import_users%0AFIELDS%20TERMINATED%20BY%20'%2C'%20ENCLOSED%20BY%20'%22'%0ALINES%20TERMINATED%20BY%20'%5Cn'%0AIGNORE%201%20ROWS%3B%0A%0A--%20Validate%20and%20clean%20data%0AUPDATE%20temp_import_users%20%0ASET%20validation_errors%20%3D%20CASE%0A%20%20%20%20WHEN%20email%20NOT%20REGEXP%20'%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C.%5BA-Za-z%5D%7B2%2C%7D%24'%20%0A%20%20%20%20%20%20%20%20THEN%20CONCAT(COALESCE(validation_errors%2C%20'')%2C%20'Invalid%20email%3B%20')%0A%20%20%20%20WHEN%20LENGTH(name)%20%3C%202%20%0A%20%20%20%20%20%20%20%20THEN%20CONCAT(COALESCE(validation_errors%2C%20'')%2C%20'Name%20too%20short%3B%20')%0A%20%20%20%20ELSE%20validation_errors%0AEND%3B%0A%0A--%20Insert%20only%20valid%20records%0AINSERT%20INTO%20users%20(external_id%2C%20email%2C%20name%2C%20phone%2C%20status)%0ASELECT%20external_id%2C%20email%2C%20name%2C%20phone%2C%20status%0AFROM%20temp_import_users%0AWHERE%20validation_errors%20IS%20NULL%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Staging table for data validation
CREATE TEMPORARY TABLE temp_import_users (
    external_id VARCHAR(50),
    email VARCHAR(255),
    name VARCHAR(100),
    phone VARCHAR(20),
    status VARCHAR(20),
    validation_errors TEXT
);

-- Load raw data
LOAD DATA INFILE 'users.csv' INTO TABLE temp_import_users
FIELDS TERMINATED BY ',' ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

-- Validate and clean data
UPDATE temp_import_users 
SET validation_errors = CASE
    WHEN email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' 
        THEN CONCAT(COALESCE(validation_errors, ''), 'Invalid email; ')
    WHEN LENGTH(name) &lt; 2 
        THEN CONCAT(COALESCE(validation_errors, ''), 'Name too short; ')
    ELSE validation_errors
END;

-- Insert only valid records
INSERT INTO users (external_id, email, name, phone, status)
SELECT external_id, email, name, phone, status
FROM temp_import_users
WHERE validation_errors IS NULL;
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Temporary tables are stored in tmpdir (usually RAM or fast storage)</p>
<p>- Automatically dropped when session ends</p>
<p>- Can be indexed like regular tables</p>
<p>- Use MEMORY engine for small, frequently accessed temp tables</p>
<p>- Monitor tmp_table_size and max_heap_table_size settings</p>


<p><strong>Best Practices:</strong></p>

<p>- Explicitly drop temporary tables when done: `DROP TEMPORARY TABLE temp_table_name;`</p>
<p>- Use meaningful names with temp_ prefix</p>
<p>- Index temporary tables for complex joins</p>
<p>- Consider CTEs as alternative for simpler cases</p>


<p>---</p>

<h2 id="-354-what-are-database-events-and-how-do-you-schedule-them-">**354. What are database events and how do you schedule them?**</h2>

<p><strong>Answer:</strong> Database events are scheduled tasks that run automatically at specified times, similar to cron jobs but managed within MySQL.</p>

<p><strong>Event Scheduler Setup:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20event%20scheduler%0ASET%20GLOBAL%20event_scheduler%20%3D%20ON%3B%0A%0A--%20Check%20if%20enabled%0ASHOW%20VARIABLES%20LIKE%20'event_scheduler'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable event scheduler
SET GLOBAL event_scheduler = ON;

-- Check if enabled
SHOW VARIABLES LIKE 'event_scheduler';
</code></pre>
</div>

<p><strong>Event Types:</strong></p>

<p><strong>1. One-Time Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Run%20once%20at%20specific%20time%0ACREATE%20EVENT%20cleanup_temp_data%0AON%20SCHEDULE%20AT%20'2024-12-31%2023%3A59%3A59'%0ADO%0A%20%20%20%20DELETE%20FROM%20temp_logs%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Run once at specific time
CREATE EVENT cleanup_temp_data
ON SCHEDULE AT '2024-12-31 23:59:59'
DO
    DELETE FROM temp_logs WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 30 DAY);
</code></pre>
</div>

<p><strong>2. Recurring Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Daily%20cleanup%20at%202%20AM%0ACREATE%20EVENT%20daily_cleanup%0AON%20SCHEDULE%20EVERY%201%20DAY%0ASTARTS%20'2024-01-01%2002%3A00%3A00'%0ADO%0ABEGIN%0A%20%20%20%20--%20Clean%20old%20logs%0A%20%20%20%20DELETE%20FROM%20application_logs%20%0A%20%20%20%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20statistics%0A%20%20%20%20CALL%20UpdateDailyStatistics()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Optimize%20tables%0A%20%20%20%20OPTIMIZE%20TABLE%20users%2C%20orders%2C%20products%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Daily cleanup at 2 AM
CREATE EVENT daily_cleanup
ON SCHEDULE EVERY 1 DAY
STARTS '2024-01-01 02:00:00'
DO
BEGIN
    -- Clean old logs
    DELETE FROM application_logs 
    WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 90 DAY);
    
    -- Update statistics
    CALL UpdateDailyStatistics();
    
    -- Optimize tables
    OPTIMIZE TABLE users, orders, products;
END;
</code></pre>
</div>

<p><strong>3. Complex Scheduling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Weekly%20report%20generation%20every%20Monday%20at%209%20AM%0ACREATE%20EVENT%20weekly_sales_report%0AON%20SCHEDULE%20EVERY%201%20WEEK%0ASTARTS%20'2024-01-01%2009%3A00%3A00'%20%20--%20First%20Monday%0AON%20COMPLETION%20PRESERVE%0AENABLE%0ACOMMENT%20'Generate%20weekly%20sales%20reports'%0ADO%0ABEGIN%0A%20%20%20%20DECLARE%20report_date%20DATE%20DEFAULT%20DATE_SUB(CURDATE()%2C%20INTERVAL%201%20WEEK)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20report%20data%0A%20%20%20%20INSERT%20INTO%20weekly_reports%20(report_date%2C%20total_sales%2C%20order_count%2C%20avg_order_value)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20report_date%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_sales%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20orders%20%0A%20%20%20%20WHERE%20DATE(created_at)%20BETWEEN%20report_date%20AND%20DATE_ADD(report_date%2C%20INTERVAL%206%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Send%20notification%20(would%20typically%20call%20external%20procedure)%0A%20%20%20%20INSERT%20INTO%20notifications%20(type%2C%20message%2C%20created_at)%0A%20%20%20%20VALUES%20('report_generated'%2C%20CONCAT('Weekly%20report%20for%20'%2C%20report_date%2C%20'%20completed')%2C%20NOW())%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Weekly report generation every Monday at 9 AM
CREATE EVENT weekly_sales_report
ON SCHEDULE EVERY 1 WEEK
STARTS '2024-01-01 09:00:00'  -- First Monday
ON COMPLETION PRESERVE
ENABLE
COMMENT 'Generate weekly sales reports'
DO
BEGIN
    DECLARE report_date DATE DEFAULT DATE_SUB(CURDATE(), INTERVAL 1 WEEK);
    
    -- Generate report data
    INSERT INTO weekly_reports (report_date, total_sales, order_count, avg_order_value)
    SELECT 
        report_date,
        SUM(total) as total_sales,
        COUNT(*) as order_count,
        AVG(total) as avg_order_value
    FROM orders 
    WHERE DATE(created_at) BETWEEN report_date AND DATE_ADD(report_date, INTERVAL 6 DAY);
    
    -- Send notification (would typically call external procedure)
    INSERT INTO notifications (type, message, created_at)
    VALUES ('report_generated', CONCAT('Weekly report for ', report_date, ' completed'), NOW());
END;
</code></pre>
</div>

<p><strong>Event Management:</strong></p>

<p><strong>1. View Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Show%20all%20events%0ASHOW%20EVENTS%3B%0A%0A--%20Detailed%20event%20information%0ASELECT%20%0A%20%20%20%20event_name%2C%0A%20%20%20%20event_definition%2C%0A%20%20%20%20interval_value%2C%0A%20%20%20%20interval_field%2C%0A%20%20%20%20status%2C%0A%20%20%20%20last_executed%2C%0A%20%20%20%20next_execution%0AFROM%20information_schema.events%0AWHERE%20event_schema%20%3D%20'your_database'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Show all events
SHOW EVENTS;

-- Detailed event information
SELECT 
    event_name,
    event_definition,
    interval_value,
    interval_field,
    status,
    last_executed,
    next_execution
FROM information_schema.events
WHERE event_schema = 'your_database';
</code></pre>
</div>

<p><strong>2. Modify Events:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Disable%20event%0AALTER%20EVENT%20daily_cleanup%20DISABLE%3B%0A%0A--%20Enable%20event%0AALTER%20EVENT%20daily_cleanup%20ENABLE%3B%0A%0A--%20Change%20schedule%0AALTER%20EVENT%20daily_cleanup%0AON%20SCHEDULE%20EVERY%202%20DAY%0ASTARTS%20'2024-01-01%2003%3A00%3A00'%3B%0A%0A--%20Drop%20event%0ADROP%20EVENT%20IF%20EXISTS%20old_cleanup_event%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Disable event
ALTER EVENT daily_cleanup DISABLE;

-- Enable event
ALTER EVENT daily_cleanup ENABLE;

-- Change schedule
ALTER EVENT daily_cleanup
ON SCHEDULE EVERY 2 DAY
STARTS '2024-01-01 03:00:00';

-- Drop event
DROP EVENT IF EXISTS old_cleanup_event;
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Database Maintenance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20EVENT%20monthly_maintenance%0AON%20SCHEDULE%20EVERY%201%20MONTH%0ASTARTS%20'2024-01-01%2001%3A00%3A00'%0ADO%0ABEGIN%0A%20%20%20%20--%20Update%20table%20statistics%0A%20%20%20%20ANALYZE%20TABLE%20users%2C%20orders%2C%20products%2C%20order_items%3B%0A%20%20%20%20%0A%20%20%20%20--%20Rebuild%20fragmented%20indexes%0A%20%20%20%20OPTIMIZE%20TABLE%20users%2C%20orders%2C%20products%2C%20order_items%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clean%20up%20old%20data%0A%20%20%20%20DELETE%20FROM%20audit_logs%20WHERE%20created_at%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%3B%0A%20%20%20%20DELETE%20FROM%20session_data%20WHERE%20expires_at%20%3C%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20maintenance%20completion%0A%20%20%20%20INSERT%20INTO%20maintenance_log%20(task%2C%20completed_at%2C%20status)%0A%20%20%20%20VALUES%20('monthly_maintenance'%2C%20NOW()%2C%20'completed')%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE EVENT monthly_maintenance
ON SCHEDULE EVERY 1 MONTH
STARTS '2024-01-01 01:00:00'
DO
BEGIN
    -- Update table statistics
    ANALYZE TABLE users, orders, products, order_items;
    
    -- Rebuild fragmented indexes
    OPTIMIZE TABLE users, orders, products, order_items;
    
    -- Clean up old data
    DELETE FROM audit_logs WHERE created_at &lt; DATE_SUB(NOW(), INTERVAL 1 YEAR);
    DELETE FROM session_data WHERE expires_at &lt; NOW();
    
    -- Log maintenance completion
    INSERT INTO maintenance_log (task, completed_at, status)
    VALUES ('monthly_maintenance', NOW(), 'completed');
END;
</code></pre>
</div>

<p><strong>2. Data Aggregation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20EVENT%20hourly_metrics_aggregation%0AON%20SCHEDULE%20EVERY%201%20HOUR%0ADO%0ABEGIN%0A%20%20%20%20DECLARE%20current_hour%20DATETIME%20DEFAULT%20DATE_FORMAT(NOW()%2C%20'%25Y-%25m-%25d%20%25H%3A00%3A00')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20hourly%20metrics%0A%20%20%20%20INSERT%20INTO%20hourly_metrics%20(hour%2C%20page_views%2C%20unique_visitors%2C%20orders%2C%20revenue)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20current_hour%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20page_views%2C%0A%20%20%20%20%20%20%20%20COUNT(DISTINCT%20user_id)%20as%20unique_visitors%2C%0A%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20event_type%20%3D%20'order'%20THEN%201%20ELSE%200%20END)%20as%20orders%2C%0A%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20event_type%20%3D%20'order'%20THEN%20event_value%20ELSE%200%20END)%20as%20revenue%0A%20%20%20%20FROM%20user_events%20%0A%20%20%20%20WHERE%20created_at%20%3E%3D%20DATE_SUB(current_hour%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20created_at%20%3C%20current_hour%0A%20%20%20%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20page_views%20%3D%20VALUES(page_views)%2C%0A%20%20%20%20%20%20%20%20unique_visitors%20%3D%20VALUES(unique_visitors)%2C%0A%20%20%20%20%20%20%20%20orders%20%3D%20VALUES(orders)%2C%0A%20%20%20%20%20%20%20%20revenue%20%3D%20VALUES(revenue)%3B%0AEND%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE EVENT hourly_metrics_aggregation
ON SCHEDULE EVERY 1 HOUR
DO
BEGIN
    DECLARE current_hour DATETIME DEFAULT DATE_FORMAT(NOW(), '%Y-%m-%d %H:00:00');
    
    -- Aggregate hourly metrics
    INSERT INTO hourly_metrics (hour, page_views, unique_visitors, orders, revenue)
    SELECT 
        current_hour,
        COUNT(*) as page_views,
        COUNT(DISTINCT user_id) as unique_visitors,
        SUM(CASE WHEN event_type = 'order' THEN 1 ELSE 0 END) as orders,
        SUM(CASE WHEN event_type = 'order' THEN event_value ELSE 0 END) as revenue
    FROM user_events 
    WHERE created_at &gt;= DATE_SUB(current_hour, INTERVAL 1 HOUR)
    AND created_at &lt; current_hour
    ON DUPLICATE KEY UPDATE
        page_views = VALUES(page_views),
        unique_visitors = VALUES(unique_visitors),
        orders = VALUES(orders),
        revenue = VALUES(revenue);
END;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use ON COMPLETION PRESERVE to keep event definition after execution</p>
<p>- Include error handling in event procedures</p>
<p>- Log event execution for monitoring</p>
<p>- Test events thoroughly before deployment</p>
<p>- Monitor event scheduler performance impact</p>
<p>- Use appropriate privileges for event creation</p>


<p>---</p>

<h2 id="-355-how-do-you-implement-database-partitioning-">**355. How do you implement database partitioning?**</h2>

<p><strong>Answer:</strong> Database partitioning divides large tables into smaller, more manageable pieces while maintaining logical unity.</p>

<p><strong>Types of Partitioning:</strong></p>

<p><strong>1. Range Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20date%20ranges%0ACREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20order_date)%20%20--%20Partition%20key%20must%20be%20in%20primary%20key%0A)%20PARTITION%20BY%20RANGE%20(YEAR(order_date))%20(%0A%20%20%20%20PARTITION%20p2021%20VALUES%20LESS%20THAN%20(2022)%2C%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by date ranges
CREATE TABLE orders (
    id INT NOT NULL,
    customer_id INT,
    order_date DATE NOT NULL,
    total DECIMAL(10,2),
    status VARCHAR(20),
    PRIMARY KEY (id, order_date)  -- Partition key must be in primary key
) PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>2. List Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Partition%20by%20specific%20values%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20region%20VARCHAR(20)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20region)%0A)%20PARTITION%20BY%20LIST%20COLUMNS(region)%20(%0A%20%20%20%20PARTITION%20p_north%20VALUES%20IN%20('north'%2C%20'northeast'%2C%20'northwest')%2C%0A%20%20%20%20PARTITION%20p_south%20VALUES%20IN%20('south'%2C%20'southeast'%2C%20'southwest')%2C%0A%20%20%20%20PARTITION%20p_east%20VALUES%20IN%20('east'%2C%20'central_east')%2C%0A%20%20%20%20PARTITION%20p_west%20VALUES%20IN%20('west'%2C%20'central_west')%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Partition by specific values
CREATE TABLE users (
    id INT NOT NULL,
    name VARCHAR(100),
    region VARCHAR(20),
    email VARCHAR(255),
    PRIMARY KEY (id, region)
) PARTITION BY LIST COLUMNS(region) (
    PARTITION p_north VALUES IN ('north', 'northeast', 'northwest'),
    PARTITION p_south VALUES IN ('south', 'southeast', 'southwest'),
    PARTITION p_east VALUES IN ('east', 'central_east'),
    PARTITION p_west VALUES IN ('west', 'central_west')
);
</code></pre>
</div>

<p><strong>3. Hash Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Distribute%20data%20evenly%20across%20partitions%0ACREATE%20TABLE%20user_sessions%20(%0A%20%20%20%20id%20BIGINT%20NOT%20NULL%2C%0A%20%20%20%20user_id%20INT%2C%0A%20%20%20%20session_data%20TEXT%2C%0A%20%20%20%20created_at%20TIMESTAMP%2C%0A%20%20%20%20PRIMARY%20KEY%20(id)%0A)%20PARTITION%20BY%20HASH(id)%20PARTITIONS%208%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Distribute data evenly across partitions
CREATE TABLE user_sessions (
    id BIGINT NOT NULL,
    user_id INT,
    session_data TEXT,
    created_at TIMESTAMP,
    PRIMARY KEY (id)
) PARTITION BY HASH(id) PARTITIONS 8;
</code></pre>
</div>

<p><strong>4. Key Partitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20chooses%20hash%20function%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20category%20VARCHAR(100)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id)%0A)%20PARTITION%20BY%20KEY()%20PARTITIONS%204%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL chooses hash function
CREATE TABLE products (
    id INT NOT NULL,
    name VARCHAR(255),
    category VARCHAR(100),
    price DECIMAL(10,2),
    PRIMARY KEY (id)
) PARTITION BY KEY() PARTITIONS 4;
</code></pre>
</div>

<p><strong>Subpartitioning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Combine%20partitioning%20methods%0ACREATE%20TABLE%20sales_data%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20sale_date%20DATE%2C%0A%20%20%20%20region%20VARCHAR(20)%2C%0A%20%20%20%20amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20sale_date%2C%20region)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(sale_date))%0ASUBPARTITION%20BY%20HASH(CRC32(region))%0ASUBPARTITIONS%204%20(%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Combine partitioning methods
CREATE TABLE sales_data (
    id INT NOT NULL,
    sale_date DATE,
    region VARCHAR(20),
    amount DECIMAL(10,2),
    PRIMARY KEY (id, sale_date, region)
) PARTITION BY RANGE (YEAR(sale_date))
SUBPARTITION BY HASH(CRC32(region))
SUBPARTITIONS 4 (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>Partition Management:</strong></p>

<p><strong>1. Add Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Add%20new%20partition%20for%202025%0AALTER%20TABLE%20orders%20%0AADD%20PARTITION%20(PARTITION%20p2025%20VALUES%20LESS%20THAN%20(2026))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Add new partition for 2025
ALTER TABLE orders 
ADD PARTITION (PARTITION p2025 VALUES LESS THAN (2026));
</code></pre>
</div>

<p><strong>2. Drop Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Remove%20old%20data%20by%20dropping%20partition%0AALTER%20TABLE%20orders%20DROP%20PARTITION%20p2021%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Remove old data by dropping partition
ALTER TABLE orders DROP PARTITION p2021;
</code></pre>
</div>

<p><strong>3. Reorganize Partitions:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Split%20partition%0AALTER%20TABLE%20orders%20%0AREORGANIZE%20PARTITION%20p_future%20INTO%20(%0A%20%20%20%20PARTITION%20p2025%20VALUES%20LESS%20THAN%20(2026)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Split partition
ALTER TABLE orders 
REORGANIZE PARTITION p_future INTO (
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
</code></pre>
</div>

<p><strong>4. Partition Information:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20partition%20information%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20partition_name%2C%0A%20%20%20%20partition_method%2C%0A%20%20%20%20partition_expression%2C%0A%20%20%20%20table_rows%2C%0A%20%20%20%20data_length%2C%0A%20%20%20%20index_length%0AFROM%20information_schema.partitions%0AWHERE%20table_schema%20%3D%20'your_database'%20%0AAND%20table_name%20%3D%20'orders'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View partition information
SELECT 
    table_name,
    partition_name,
    partition_method,
    partition_expression,
    table_rows,
    data_length,
    index_length
FROM information_schema.partitions
WHERE table_schema = 'your_database' 
AND table_name = 'orders';
</code></pre>
</div>

<p><strong>Query Optimization with Partitions:</strong></p>

<p><strong>1. Partition Pruning:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20hits%20only%20relevant%20partitions%0ASELECT%20*%20FROM%20orders%20%0AWHERE%20order_date%20BETWEEN%20'2024-01-01'%20AND%20'2024-12-31'%3B%0A--%20Only%20accesses%20p2024%20partition%0A%0AEXPLAIN%20PARTITIONS%20%0ASELECT%20*%20FROM%20orders%20WHERE%20order_date%20%3D%20'2024-06-15'%3B%0A--%20Shows%20which%20partitions%20are%20accessed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query hits only relevant partitions
SELECT * FROM orders 
WHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';
-- Only accesses p2024 partition

EXPLAIN PARTITIONS 
SELECT * FROM orders WHERE order_date = '2024-06-15';
-- Shows which partitions are accessed
</code></pre>
</div>

<p><strong>2. Partition-wise Joins:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Both%20tables%20partitioned%20the%20same%20way%0ASELECT%20o.*%2C%20od.product_id%2C%20od.quantity%0AFROM%20orders%20o%0AJOIN%20order_details%20od%20ON%20o.id%20%3D%20od.order_id%0AWHERE%20o.order_date%20%3D%20'2024-06-15'%3B%0A--%20Can%20join%20partition-to-partition%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Both tables partitioned the same way
SELECT o.*, od.product_id, od.quantity
FROM orders o
JOIN order_details od ON o.id = od.order_id
WHERE o.order_date = '2024-06-15';
-- Can join partition-to-partition
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Choose partition key based on query patterns</p>
<p>- Include partition key in WHERE clauses for pruning</p>
<p>- Partition key must be part of PRIMARY KEY or UNIQUE indexes</p>
<p>- Monitor partition sizes and balance</p>
<p>- Plan for partition maintenance (adding/dropping)</p>
<p>- Test query performance with EXPLAIN PARTITIONS</p>


<p><strong>When to Use Partitioning:</strong></p>

<p>- Tables larger than 2GB</p>
<p>- Clear partitioning strategy (date, region, etc.)</p>
<p>- Queries frequently filter on partition key</p>
<p>- Need to archive/purge old data efficiently</p>
<p>- Parallel processing benefits</p>


<h2 id="-356-what-are-database-constraints-and-their-types-">**356. What are database constraints and their types?**</h2>

<p><strong>Answer:</strong> Database constraints are rules that enforce data integrity and business logic at the database level.</p>

<p><strong>Types of Constraints:</strong></p>

<p><strong>1. PRIMARY KEY Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%20%20--%20Single%20column%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%0A)%3B%0A%0A--%20Composite%20primary%20key%0ACREATE%20TABLE%20order_items%20(%0A%20%20%20%20order_id%20INT%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20quantity%20INT%2C%0A%20%20%20%20PRIMARY%20KEY%20(order_id%2C%20product_id)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,  -- Single column
    email VARCHAR(255) NOT NULL
);

-- Composite primary key
CREATE TABLE order_items (
    order_id INT,
    product_id INT,
    quantity INT,
    PRIMARY KEY (order_id, product_id)
);
</code></pre>
</div>

<p><strong>2. FOREIGN KEY Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20orders%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_id)%20REFERENCES%20customers(id)%0A%20%20%20%20%20%20%20%20ON%20DELETE%20CASCADE%0A%20%20%20%20%20%20%20%20ON%20UPDATE%20RESTRICT%0A)%3B%0A%0A--%20Named%20foreign%20key%20with%20custom%20actions%0AALTER%20TABLE%20orders%20%0AADD%20CONSTRAINT%20fk_customer%20%0AFOREIGN%20KEY%20(customer_id)%20REFERENCES%20customers(id)%0AON%20DELETE%20SET%20NULL%0AON%20UPDATE%20CASCADE%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE orders (
    id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    FOREIGN KEY (customer_id) REFERENCES customers(id)
        ON DELETE CASCADE
        ON UPDATE RESTRICT
);

-- Named foreign key with custom actions
ALTER TABLE orders 
ADD CONSTRAINT fk_customer 
FOREIGN KEY (customer_id) REFERENCES customers(id)
ON DELETE SET NULL
ON UPDATE CASCADE;
</code></pre>
</div>

<p><strong>3. UNIQUE Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20email%20VARCHAR(255)%20UNIQUE%2C%20%20%20%20%20%20%20%20%20%20%20--%20Column-level%0A%20%20%20%20username%20VARCHAR(50)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_username%20(username)%2C%20%20%20--%20Table-level%0A%20%20%20%20UNIQUE%20KEY%20uk_phone_email%20(phone%2C%20email)%20%20--%20Composite%20unique%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT PRIMARY KEY,
    email VARCHAR(255) UNIQUE,           -- Column-level
    username VARCHAR(50),
    phone VARCHAR(20),
    UNIQUE KEY uk_username (username),   -- Table-level
    UNIQUE KEY uk_phone_email (phone, email)  -- Composite unique
);
</code></pre>
</div>

<p><strong>4. CHECK Constraint (MySQL 8.0+):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20discount_percent%20DECIMAL(5%2C2)%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'discontinued')%2C%0A%20%20%20%20CONSTRAINT%20chk_price%20CHECK%20(price%20%3E%200)%2C%0A%20%20%20%20CONSTRAINT%20chk_discount%20CHECK%20(discount_percent%20BETWEEN%200%20AND%20100)%2C%0A%20%20%20%20CONSTRAINT%20chk_discounted_price%20CHECK%20(price%20*%20(1%20-%20discount_percent%2F100)%20%3E%200)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10,2),
    discount_percent DECIMAL(5,2),
    status ENUM('active', 'inactive', 'discontinued'),
    CONSTRAINT chk_price CHECK (price &gt; 0),
    CONSTRAINT chk_discount CHECK (discount_percent BETWEEN 0 AND 100),
    CONSTRAINT chk_discounted_price CHECK (price * (1 - discount_percent/100) &gt; 0)
);
</code></pre>
</div>

<p><strong>5. NOT NULL Constraint:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Nullable%0A%20%20%20%20created_at%20TIMESTAMP%20NOT%20NULL%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE customers (
    id INT PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    phone VARCHAR(20),              -- Nullable
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);
</code></pre>
</div>

<p><strong>Constraint Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Add%20constraint%20to%20existing%20table%0AALTER%20TABLE%20products%20%0AADD%20CONSTRAINT%20chk_positive_price%20CHECK%20(price%20%3E%200)%3B%0A%0A--%20Drop%20constraint%0AALTER%20TABLE%20products%20DROP%20CHECK%20chk_positive_price%3B%0A%0A--%20Disable%2FEnable%20foreign%20key%20checks%20(temporarily)%0ASET%20FOREIGN_KEY_CHECKS%20%3D%200%3B%20%20--%20Disable%0ASET%20FOREIGN_KEY_CHECKS%20%3D%201%3B%20%20--%20Enable%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Add constraint to existing table
ALTER TABLE products 
ADD CONSTRAINT chk_positive_price CHECK (price &gt; 0);

-- Drop constraint
ALTER TABLE products DROP CHECK chk_positive_price;

-- Disable/Enable foreign key checks (temporarily)
SET FOREIGN_KEY_CHECKS = 0;  -- Disable
SET FOREIGN_KEY_CHECKS = 1;  -- Enable
</code></pre>
</div>

<p><strong>Benefits:</strong></p>

<p>- <strong>Data Integrity:</strong> Prevents invalid data entry</p>
<p>- <strong>Referential Integrity:</strong> Maintains relationships</p>
<p>- <strong>Business Rules:</strong> Enforces domain-specific logic</p>
<p>- <strong>Performance:</strong> Optimizer uses constraints for query planning</p>


<p>---</p>

<h2 id="-357-how-do-you-work-with-database-transactions-and-isolation-levels-">**357. How do you work with database transactions and isolation levels?**</h2>

<p><strong>Answer:</strong> Transactions ensure ACID properties, while isolation levels control how concurrent transactions interact.</p>

<p><strong>Transaction Basics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Explicit%20transaction%0ASTART%20TRANSACTION%3B%0A%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20100%20WHERE%20id%20%3D%202%3B%0A%0A--%20Check%20if%20everything%20is%20correct%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20IN%20(1%2C%202)%3B%0A%0ACOMMIT%3B%20%20--%20or%20ROLLBACK%20if%20there's%20an%20issue%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Explicit transaction
START TRANSACTION;

UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;

-- Check if everything is correct
SELECT balance FROM accounts WHERE id IN (1, 2);

COMMIT;  -- or ROLLBACK if there's an issue
</code></pre>
</div>

<p><strong>Transaction with Error Handling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20TransferMoney(%0A%20%20%20%20IN%20from_account%20INT%2C%0A%20%20%20%20IN%20to_account%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%20%20--%20Re-throw%20the%20error%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20sufficient%20balance%0A%20%20%20%20IF%20(SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20from_account)%20%3C%20amount%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Insufficient%20balance'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20transfer%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_account%3B%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_account%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE TransferMoney(
    IN from_account INT,
    IN to_account INT,
    IN amount DECIMAL(10,2)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;  -- Re-throw the error
    END;
    
    START TRANSACTION;
    
    -- Check sufficient balance
    IF (SELECT balance FROM accounts WHERE id = from_account) &lt; amount THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Insufficient balance';
    END IF;
    
    -- Perform transfer
    UPDATE accounts SET balance = balance - amount WHERE id = from_account;
    UPDATE accounts SET balance = balance + amount WHERE id = to_account;
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Isolation Levels:</strong></p>

<p><strong>1. READ UNCOMMITTED:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20READ%20UNCOMMITTED%3B%0A--%20Allows%20dirty%20reads%2C%20non-repeatable%20reads%2C%20phantom%20reads%0A--%20Fastest%20but%20least%20consistent%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20May%20see%20uncommitted%20changes%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
-- Allows dirty reads, non-repeatable reads, phantom reads
-- Fastest but least consistent

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- May see uncommitted changes
COMMIT;
</code></pre>
</div>

<p><strong>2. READ COMMITTED:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20READ%20COMMITTED%3B%0A--%20Prevents%20dirty%20reads%2C%20allows%20non-repeatable%20reads%20and%20phantom%20reads%0A--%20Default%20in%20many%20databases%20(not%20MySQL)%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20100%0A--%20Another%20transaction%20commits%20a%20change%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20150%20(non-repeatable%20read)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;
-- Prevents dirty reads, allows non-repeatable reads and phantom reads
-- Default in many databases (not MySQL)

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- 100
-- Another transaction commits a change
SELECT balance FROM accounts WHERE id = 1;  -- 150 (non-repeatable read)
COMMIT;
</code></pre>
</div>

<p><strong>3. REPEATABLE READ (MySQL Default):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20REPEATABLE%20READ%3B%0A--%20Prevents%20dirty%20reads%20and%20non-repeatable%20reads%2C%20allows%20phantom%20reads%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20100%0A--%20Another%20transaction%20commits%20a%20change%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Still%20100%20(repeatable)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
-- Prevents dirty reads and non-repeatable reads, allows phantom reads

START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- 100
-- Another transaction commits a change
SELECT balance FROM accounts WHERE id = 1;  -- Still 100 (repeatable)
COMMIT;
</code></pre>
</div>

<p><strong>4. SERIALIZABLE:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="SET%20SESSION%20TRANSACTION%20ISOLATION%20LEVEL%20SERIALIZABLE%3B%0A--%20Prevents%20all%20phenomena%2C%20highest%20consistency%2C%20lowest%20performance%0A%0ASTART%20TRANSACTION%3B%0ASELECT%20*%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%0A--%20Locks%20prevent%20other%20transactions%20from%20inserting%2Fupdating%20matching%20rows%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;
-- Prevents all phenomena, highest consistency, lowest performance

START TRANSACTION;
SELECT * FROM accounts WHERE balance &gt; 1000;
-- Locks prevent other transactions from inserting/updating matching rows
COMMIT;
</code></pre>
</div>

<p><strong>Concurrency Issues:</strong></p>

<p><strong>1. Dirty Read Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20500%20WHERE%20id%20%3D%201%3B%0A--%20Don't%20commit%20yet%0A%0A--%20Transaction%202%20(READ%20UNCOMMITTED)%3A%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Sees%20500%20(dirty%20read)%0A%0A--%20Transaction%201%3A%0AROLLBACK%3B%20%20--%20Transaction%202%20saw%20data%20that%20never%20existed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
UPDATE accounts SET balance = 500 WHERE id = 1;
-- Don't commit yet

-- Transaction 2 (READ UNCOMMITTED):
SELECT balance FROM accounts WHERE id = 1;  -- Sees 500 (dirty read)

-- Transaction 1:
ROLLBACK;  -- Transaction 2 saw data that never existed
</code></pre>
</div>

<p><strong>2. Phantom Read Example:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0ASELECT%20COUNT(*)%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%20%20--%20Returns%205%0A%0A--%20Transaction%202%3A%0AINSERT%20INTO%20accounts%20(id%2C%20balance)%20VALUES%20(100%2C%201500)%3B%0ACOMMIT%3B%0A%0A--%20Transaction%201%3A%0ASELECT%20COUNT(*)%20FROM%20accounts%20WHERE%20balance%20%3E%201000%3B%20%20--%20Returns%206%20(phantom)%0ACOMMIT%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
SELECT COUNT(*) FROM accounts WHERE balance &gt; 1000;  -- Returns 5

-- Transaction 2:
INSERT INTO accounts (id, balance) VALUES (100, 1500);
COMMIT;

-- Transaction 1:
SELECT COUNT(*) FROM accounts WHERE balance &gt; 1000;  -- Returns 6 (phantom)
COMMIT;
</code></pre>
</div>

<p><strong>Locking Mechanisms:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Shared%20lock%20(read%20lock)%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20LOCK%20IN%20SHARE%20MODE%3B%0A%0A--%20Exclusive%20lock%20(write%20lock)%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20FOR%20UPDATE%3B%0A%0A--%20Skip%20locked%20rows%20(MySQL%208.0%2B)%0ASELECT%20*%20FROM%20queue_items%20WHERE%20processed%20%3D%200%20%0AFOR%20UPDATE%20SKIP%20LOCKED%20LIMIT%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Shared lock (read lock)
SELECT * FROM accounts WHERE id = 1 LOCK IN SHARE MODE;

-- Exclusive lock (write lock)
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;

-- Skip locked rows (MySQL 8.0+)
SELECT * FROM queue_items WHERE processed = 0 
FOR UPDATE SKIP LOCKED LIMIT 10;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use appropriate isolation level for your use case</p>
<p>- Keep transactions short to reduce lock contention</p>
<p>- Handle deadlocks with retry logic</p>
<p>- Use explicit locking sparingly</p>
<p>- Monitor transaction performance and blocking</p>


<p>---</p>

<h2 id="-358-what-are-database-triggers-for-auditing-and-logging-">**358. What are database triggers for auditing and logging?**</h2>

<p><strong>Answer:</strong> Audit triggers automatically track data changes, providing comprehensive logging for compliance and debugging.</p>

<p><strong>Basic Audit Table Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20audit_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(64)%20NOT%20NULL%2C%0A%20%20%20%20operation%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_by%20VARCHAR(100)%2C%0A%20%20%20%20changed_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20INDEX%20idx_table_operation%20(table_name%2C%20operation)%2C%0A%20%20%20%20INDEX%20idx_record_id%20(record_id)%2C%0A%20%20%20%20INDEX%20idx_changed_at%20(changed_at)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE audit_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64) NOT NULL,
    operation ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    old_values JSON,
    new_values JSON,
    changed_by VARCHAR(100),
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address VARCHAR(45),
    user_agent TEXT,
    INDEX idx_table_operation (table_name, operation),
    INDEX idx_record_id (record_id),
    INDEX idx_changed_at (changed_at)
);
</code></pre>
</div>

<p><strong>Comprehensive Audit Triggers:</strong></p>

<p><strong>1. INSERT Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_insert%0AAFTER%20INSERT%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20new_values%2C%0A%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20'INSERT'%2C%0A%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'id'%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20NEW.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20NEW.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20NEW.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20NEW.created_at%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_insert
AFTER INSERT ON users
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        table_name,
        operation,
        record_id,
        new_values,
        changed_by,
        ip_address
    ) VALUES (
        'users',
        'INSERT',
        NEW.id,
        JSON_OBJECT(
            'id', NEW.id,
            'name', NEW.name,
            'email', NEW.email,
            'status', NEW.status,
            'created_at', NEW.created_at
        ),
        COALESCE(@audit_user, USER()),
        COALESCE(@audit_ip, CONNECTION_ID())
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. UPDATE Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_update%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Only%20log%20if%20data%20actually%20changed%0A%20%20%20%20IF%20NOT%20(OLD.name%20%3C%3D%3E%20NEW.name%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20%20OLD.email%20%3C%3D%3E%20NEW.email%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20%20OLD.status%20%3C%3D%3E%20NEW.status)%20THEN%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20old_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20new_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20OLD.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20OLD.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20OLD.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20OLD.updated_at%0A%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20NEW.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20NEW.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20NEW.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20NEW.updated_at%0A%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_update
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    -- Only log if data actually changed
    IF NOT (OLD.name &lt;=&gt; NEW.name AND 
            OLD.email &lt;=&gt; NEW.email AND 
            OLD.status &lt;=&gt; NEW.status) THEN
        
        INSERT INTO audit_log (
            table_name,
            operation,
            record_id,
            old_values,
            new_values,
            changed_by,
            ip_address
        ) VALUES (
            'users',
            'UPDATE',
            NEW.id,
            JSON_OBJECT(
                'name', OLD.name,
                'email', OLD.email,
                'status', OLD.status,
                'updated_at', OLD.updated_at
            ),
            JSON_OBJECT(
                'name', NEW.name,
                'email', NEW.email,
                'status', NEW.status,
                'updated_at', NEW.updated_at
            ),
            COALESCE(@audit_user, USER()),
            COALESCE(@audit_ip, CONNECTION_ID())
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. DELETE Audit Trigger:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20users_audit_delete%0ABEFORE%20DELETE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20audit_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20operation%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20old_values%2C%0A%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20ip_address%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20'DELETE'%2C%0A%20%20%20%20%20%20%20%20OLD.id%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'id'%2C%20OLD.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20OLD.name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20OLD.email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'status'%2C%20OLD.status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20OLD.created_at%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'updated_at'%2C%20OLD.updated_at%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20COALESCE(%40audit_ip%2C%20CONNECTION_ID())%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER users_audit_delete
BEFORE DELETE ON users
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        table_name,
        operation,
        record_id,
        old_values,
        changed_by,
        ip_address
    ) VALUES (
        'users',
        'DELETE',
        OLD.id,
        JSON_OBJECT(
            'id', OLD.id,
            'name', OLD.name,
            'email', OLD.email,
            'status', OLD.status,
            'created_at', OLD.created_at,
            'updated_at', OLD.updated_at
        ),
        COALESCE(@audit_user, USER()),
        COALESCE(@audit_ip, CONNECTION_ID())
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Advanced Audit Features:</strong></p>

<p><strong>1. Field-Level Change Tracking:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20detailed_user_audit%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20DECLARE%20changes%20JSON%20DEFAULT%20JSON_OBJECT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Track%20individual%20field%20changes%0A%20%20%20%20IF%20OLD.name%20!%3D%20NEW.name%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.name'%2C%20JSON_OBJECT('old'%2C%20OLD.name%2C%20'new'%2C%20NEW.name))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20OLD.email%20!%3D%20NEW.email%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.email'%2C%20JSON_OBJECT('old'%2C%20OLD.email%2C%20'new'%2C%20NEW.email))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20OLD.status%20!%3D%20NEW.status%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes%20%3D%20JSON_SET(changes%2C%20'%24.status'%2C%20JSON_OBJECT('old'%2C%20OLD.status%2C%20'new'%2C%20NEW.status))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Only%20insert%20if%20there%20are%20actual%20changes%0A%20%20%20%20IF%20JSON_LENGTH(changes)%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20detailed_audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20field_changes%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_at%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changes%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER detailed_user_audit
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    DECLARE changes JSON DEFAULT JSON_OBJECT();
    
    -- Track individual field changes
    IF OLD.name != NEW.name THEN
        SET changes = JSON_SET(changes, '$.name', JSON_OBJECT('old', OLD.name, 'new', NEW.name));
    END IF;
    
    IF OLD.email != NEW.email THEN
        SET changes = JSON_SET(changes, '$.email', JSON_OBJECT('old', OLD.email, 'new', NEW.email));
    END IF;
    
    IF OLD.status != NEW.status THEN
        SET changes = JSON_SET(changes, '$.status', JSON_OBJECT('old', OLD.status, 'new', NEW.status));
    END IF;
    
    -- Only insert if there are actual changes
    IF JSON_LENGTH(changes) &gt; 0 THEN
        INSERT INTO detailed_audit_log (
            table_name,
            record_id,
            field_changes,
            changed_by,
            changed_at
        ) VALUES (
            'users',
            NEW.id,
            changes,
            COALESCE(@audit_user, USER()),
            NOW()
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Conditional Auditing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20TRIGGER%20sensitive_data_audit%0AAFTER%20UPDATE%20ON%20users%0AFOR%20EACH%20ROW%0ABEGIN%0A%20%20%20%20--%20Only%20audit%20sensitive%20field%20changes%0A%20%20%20%20IF%20OLD.email%20!%3D%20NEW.email%20OR%20%0A%20%20%20%20%20%20%20OLD.phone%20!%3D%20NEW.phone%20OR%20%0A%20%20%20%20%20%20%20OLD.ssn%20!%3D%20NEW.ssn%20THEN%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20security_audit_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20sensitive_change%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20old_hash%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20new_hash%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20changed_by%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20requires_review%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20'users'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'PII_UPDATE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SHA2(CONCAT(OLD.email%2C%20OLD.phone%2C%20OLD.ssn)%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SHA2(CONCAT(NEW.email%2C%20NEW.phone%2C%20NEW.ssn)%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40audit_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TRUE%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE TRIGGER sensitive_data_audit
AFTER UPDATE ON users
FOR EACH ROW
BEGIN
    -- Only audit sensitive field changes
    IF OLD.email != NEW.email OR 
       OLD.phone != NEW.phone OR 
       OLD.ssn != NEW.ssn THEN
        
        INSERT INTO security_audit_log (
            table_name,
            record_id,
            sensitive_change,
            old_hash,
            new_hash,
            changed_by,
            requires_review
        ) VALUES (
            'users',
            NEW.id,
            'PII_UPDATE',
            SHA2(CONCAT(OLD.email, OLD.phone, OLD.ssn), 256),
            SHA2(CONCAT(NEW.email, NEW.phone, NEW.ssn), 256),
            COALESCE(@audit_user, USER()),
            TRUE
        );
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Setting Audit Context:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20audit%20context%20before%20operations%0ASET%20%40audit_user%20%3D%20'john.doe%40company.com'%3B%0ASET%20%40audit_ip%20%3D%20'192.168.1.100'%3B%0ASET%20%40audit_reason%20%3D%20'User%20profile%20update'%3B%0A%0A--%20Perform%20operations%0AUPDATE%20users%20SET%20email%20%3D%20'newemail%40example.com'%20WHERE%20id%20%3D%20123%3B%0A%0A--%20Clear%20context%0ASET%20%40audit_user%20%3D%20NULL%3B%0ASET%20%40audit_ip%20%3D%20NULL%3B%0ASET%20%40audit_reason%20%3D%20NULL%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set audit context before operations
SET @audit_user = 'john.doe@company.com';
SET @audit_ip = '192.168.1.100';
SET @audit_reason = 'User profile update';

-- Perform operations
UPDATE users SET email = 'newemail@example.com' WHERE id = 123;

-- Clear context
SET @audit_user = NULL;
SET @audit_ip = NULL;
SET @audit_reason = NULL;
</code></pre>
</div>

<p><strong>Audit Query Examples:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20all%20changes%20to%20a%20specific%20user%0ASELECT%20*%20FROM%20audit_log%20%0AWHERE%20table_name%20%3D%20'users'%20AND%20record_id%20%3D%20'123'%0AORDER%20BY%20changed_at%20DESC%3B%0A%0A--%20Find%20all%20changes%20by%20a%20specific%20user%0ASELECT%20table_name%2C%20operation%2C%20COUNT(*)%20as%20change_count%0AFROM%20audit_log%20%0AWHERE%20changed_by%20%3D%20'john.doe%40company.com'%0AAND%20changed_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20table_name%2C%20operation%3B%0A%0A--%20Find%20recent%20sensitive%20changes%0ASELECT%20al.*%2C%20u.name%2C%20u.email%0AFROM%20audit_log%20al%0AJOIN%20users%20u%20ON%20al.record_id%20%3D%20u.id%0AWHERE%20al.table_name%20%3D%20'users'%0AAND%20JSON_CONTAINS_PATH(al.new_values%2C%20'one'%2C%20'%24.email'%2C%20'%24.phone')%0AAND%20al.changed_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%207%20DAY)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find all changes to a specific user
SELECT * FROM audit_log 
WHERE table_name = 'users' AND record_id = '123'
ORDER BY changed_at DESC;

-- Find all changes by a specific user
SELECT table_name, operation, COUNT(*) as change_count
FROM audit_log 
WHERE changed_by = 'john.doe@company.com'
AND changed_at &gt;= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY table_name, operation;

-- Find recent sensitive changes
SELECT al.*, u.name, u.email
FROM audit_log al
JOIN users u ON al.record_id = u.id
WHERE al.table_name = 'users'
AND JSON_CONTAINS_PATH(al.new_values, 'one', '$.email', '$.phone')
AND al.changed_at &gt;= DATE_SUB(NOW(), INTERVAL 7 DAY);
</code></pre>
</div>

<p><strong>Performance Considerations:</strong></p>

<p>- Use separate audit database for high-volume systems</p>
<p>- Implement audit log rotation/archiving</p>
<p>- Index audit tables appropriately</p>
<p>- Consider async audit logging for performance-critical systems</p>
<p>- Monitor audit table growth and storage requirements</p>


<p>---</p>

<h2 id="-359-how-do-you-implement-database-replication-">**359. How do you implement database replication?**</h2>

<p><strong>Answer:</strong> Database replication creates copies of data across multiple servers for high availability, load distribution, and disaster recovery.</p>

<p><strong>Types of Replication:</strong></p>

<p><strong>1. Master-Slave Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Master%20Configuration%20(my.cnf)%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Alog-bin%20%3D%20mysql-bin%0Abinlog-format%20%3D%20ROW%0Abinlog-do-db%20%3D%20production_db%0Aexpire-logs-days%20%3D%207%0A%0A--%20Create%20replication%20user%20on%20master%0ACREATE%20USER%20'replication'%40'slave_ip'%20IDENTIFIED%20BY%20'strong_password'%3B%0AGRANT%20REPLICATION%20SLAVE%20ON%20*.*%20TO%20'replication'%40'slave_ip'%3B%0AFLUSH%20PRIVILEGES%3B%0A%0A--%20Get%20master%20status%0ASHOW%20MASTER%20STATUS%3B%0A--%20Note%3A%20File%20and%20Position%20values%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Master Configuration (my.cnf)
[mysqld]
server-id = 1
log-bin = mysql-bin
binlog-format = ROW
binlog-do-db = production_db
expire-logs-days = 7

-- Create replication user on master
CREATE USER 'replication'@'slave_ip' IDENTIFIED BY 'strong_password';
GRANT REPLICATION SLAVE ON *.* TO 'replication'@'slave_ip';
FLUSH PRIVILEGES;

-- Get master status
SHOW MASTER STATUS;
-- Note: File and Position values
</code></pre>
</div>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Slave%20Configuration%20(my.cnf)%0A%5Bmysqld%5D%0Aserver-id%20%3D%202%0Arelay-log%20%3D%20relay-bin%0Aread-only%20%3D%201%0Areplicate-do-db%20%3D%20production_db%0A%0A--%20Configure%20slave%0ACHANGE%20MASTER%20TO%0A%20%20%20%20MASTER_HOST%20%3D%20'master_ip'%2C%0A%20%20%20%20MASTER_USER%20%3D%20'replication'%2C%0A%20%20%20%20MASTER_PASSWORD%20%3D%20'strong_password'%2C%0A%20%20%20%20MASTER_LOG_FILE%20%3D%20'mysql-bin.000001'%2C%20%20--%20From%20SHOW%20MASTER%20STATUS%0A%20%20%20%20MASTER_LOG_POS%20%3D%20154%3B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20From%20SHOW%20MASTER%20STATUS%0A%0A--%20Start%20replication%0ASTART%20SLAVE%3B%0A%0A--%20Check%20slave%20status%0ASHOW%20SLAVE%20STATUS%5CG%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Slave Configuration (my.cnf)
[mysqld]
server-id = 2
relay-log = relay-bin
read-only = 1
replicate-do-db = production_db

-- Configure slave
CHANGE MASTER TO
    MASTER_HOST = 'master_ip',
    MASTER_USER = 'replication',
    MASTER_PASSWORD = 'strong_password',
    MASTER_LOG_FILE = 'mysql-bin.000001',  -- From SHOW MASTER STATUS
    MASTER_LOG_POS = 154;                  -- From SHOW MASTER STATUS

-- Start replication
START SLAVE;

-- Check slave status
SHOW SLAVE STATUS\G
</code></pre>
</div>

<p><strong>2. Master-Master Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Server%201%20Configuration%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Alog-bin%20%3D%20mysql-bin%0Aauto-increment-increment%20%3D%202%0Aauto-increment-offset%20%3D%201%0Abinlog-format%20%3D%20ROW%0A%0A--%20Server%202%20Configuration%0A%5Bmysqld%5D%0Aserver-id%20%3D%202%0Alog-bin%20%3D%20mysql-bin%0Aauto-increment-increment%20%3D%202%0Aauto-increment-offset%20%3D%202%0Abinlog-format%20%3D%20ROW%0A%0A--%20Each%20server%20acts%20as%20master%20and%20slave%20to%20the%20other%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Server 1 Configuration
[mysqld]
server-id = 1
log-bin = mysql-bin
auto-increment-increment = 2
auto-increment-offset = 1
binlog-format = ROW

-- Server 2 Configuration
[mysqld]
server-id = 2
log-bin = mysql-bin
auto-increment-increment = 2
auto-increment-offset = 2
binlog-format = ROW

-- Each server acts as master and slave to the other
</code></pre>
</div>

<p><strong>3. Group Replication (MySQL 5.7+):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Install%20Group%20Replication%20plugin%0AINSTALL%20PLUGIN%20group_replication%20SONAME%20'group_replication.so'%3B%0A%0A--%20Configuration%20for%20each%20node%0A%5Bmysqld%5D%0Aserver-id%20%3D%201%0Agtid-mode%20%3D%20ON%0Aenforce-gtid-consistency%20%3D%20ON%0Abinlog-format%20%3D%20ROW%0Alog-slave-updates%20%3D%20ON%0Abinlog-checksum%20%3D%20NONE%0Aslave-sql-verify-checksum%20%3D%200%0A%0A--%20Group%20Replication%20specific%0Aloose-group_replication_group_name%20%3D%20%22aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa%22%0Aloose-group_replication_start_on_boot%20%3D%20OFF%0Aloose-group_replication_local_address%20%3D%20%22node1%3A33061%22%0Aloose-group_replication_group_seeds%20%3D%20%22node1%3A33061%2Cnode2%3A33061%2Cnode3%3A33061%22%0Aloose-group_replication_bootstrap_group%20%3D%20OFF%0A%0A--%20Start%20Group%20Replication%20on%20first%20node%0ASET%20GLOBAL%20group_replication_bootstrap_group%3DON%3B%0ASTART%20GROUP_REPLICATION%3B%0ASET%20GLOBAL%20group_replication_bootstrap_group%3DOFF%3B%0A%0A--%20Join%20other%20nodes%0ASTART%20GROUP_REPLICATION%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Install Group Replication plugin
INSTALL PLUGIN group_replication SONAME 'group_replication.so';

-- Configuration for each node
[mysqld]
server-id = 1
gtid-mode = ON
enforce-gtid-consistency = ON
binlog-format = ROW
log-slave-updates = ON
binlog-checksum = NONE
slave-sql-verify-checksum = 0

-- Group Replication specific
loose-group_replication_group_name = "aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"
loose-group_replication_start_on_boot = OFF
loose-group_replication_local_address = "node1:33061"
loose-group_replication_group_seeds = "node1:33061,node2:33061,node3:33061"
loose-group_replication_bootstrap_group = OFF

-- Start Group Replication on first node
SET GLOBAL group_replication_bootstrap_group=ON;
START GROUP_REPLICATION;
SET GLOBAL group_replication_bootstrap_group=OFF;

-- Join other nodes
START GROUP_REPLICATION;
</code></pre>
</div>

<p><strong>Monitoring Replication:</strong></p>

<p><strong>1. Slave Status Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20replication%20health%0ASHOW%20SLAVE%20STATUS%5CG%0A%0A--%20Key%20metrics%20to%20monitor%3A%0A--%20Slave_IO_Running%3A%20Yes%0A--%20Slave_SQL_Running%3A%20Yes%0A--%20Seconds_Behind_Master%3A%20Should%20be%20low%0A--%20Last_Error%3A%20Should%20be%20empty%0A%0A--%20Detailed%20replication%20info%0ASELECT%20%0A%20%20%20%20CHANNEL_NAME%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20PORT%2C%0A%20%20%20%20USER%2C%0A%20%20%20%20SOURCE_LOG_FILE%2C%0A%20%20%20%20READ_MASTER_LOG_POS%2C%0A%20%20%20%20RELAY_LOG_FILE%2C%0A%20%20%20%20RELAY_LOG_POS%2C%0A%20%20%20%20SERVICE_STATE%0AFROM%20performance_schema.replication_connection_status%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check replication health
SHOW SLAVE STATUS\G

-- Key metrics to monitor:
-- Slave_IO_Running: Yes
-- Slave_SQL_Running: Yes
-- Seconds_Behind_Master: Should be low
-- Last_Error: Should be empty

-- Detailed replication info
SELECT 
    CHANNEL_NAME,
    HOST,
    PORT,
    USER,
    SOURCE_LOG_FILE,
    READ_MASTER_LOG_POS,
    RELAY_LOG_FILE,
    RELAY_LOG_POS,
    SERVICE_STATE
FROM performance_schema.replication_connection_status;
</code></pre>
</div>

<p><strong>2. Replication Lag Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20heartbeat%20table%20on%20master%0ACREATE%20TABLE%20heartbeat%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20ts%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Update%20heartbeat%20regularly%20(via%20cron%2Fevent)%0AINSERT%20INTO%20heartbeat%20(id%2C%20ts)%20VALUES%20(1%2C%20NOW())%20%0AON%20DUPLICATE%20KEY%20UPDATE%20ts%20%3D%20NOW()%3B%0A%0A--%20Check%20lag%20on%20slave%0ASELECT%20%0A%20%20%20%20TIMESTAMPDIFF(SECOND%2C%20ts%2C%20NOW())%20as%20lag_seconds%0AFROM%20heartbeat%20WHERE%20id%20%3D%201%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create heartbeat table on master
CREATE TABLE heartbeat (
    id INT PRIMARY KEY,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Update heartbeat regularly (via cron/event)
INSERT INTO heartbeat (id, ts) VALUES (1, NOW()) 
ON DUPLICATE KEY UPDATE ts = NOW();

-- Check lag on slave
SELECT 
    TIMESTAMPDIFF(SECOND, ts, NOW()) as lag_seconds
FROM heartbeat WHERE id = 1;
</code></pre>
</div>

<p><strong>Replication Troubleshooting:</strong></p>

<p><strong>1. Skip Replication Errors:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Skip%20single%20error%20(use%20carefully)%0ASTOP%20SLAVE%3B%0ASET%20GLOBAL%20sql_slave_skip_counter%20%3D%201%3B%0ASTART%20SLAVE%3B%0A%0A--%20Skip%20specific%20error%20types%0ASET%20GLOBAL%20slave_skip_errors%20%3D%20'1062%2C1053'%3B%20%20--%20Duplicate%20key%2C%20server%20shutdown%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Skip single error (use carefully)
STOP SLAVE;
SET GLOBAL sql_slave_skip_counter = 1;
START SLAVE;

-- Skip specific error types
SET GLOBAL slave_skip_errors = '1062,1053';  -- Duplicate key, server shutdown
</code></pre>
</div>

<p><strong>2. Reset Replication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20On%20slave%0ASTOP%20SLAVE%3B%0ARESET%20SLAVE%20ALL%3B%0A%0A--%20Reconfigure%20from%20current%20master%20position%0ASHOW%20MASTER%20STATUS%3B%20%20--%20On%20master%0ACHANGE%20MASTER%20TO%20...%3B%20%20--%20Use%20new%20position%0ASTART%20SLAVE%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- On slave
STOP SLAVE;
RESET SLAVE ALL;

-- Reconfigure from current master position
SHOW MASTER STATUS;  -- On master
CHANGE MASTER TO ...;  -- Use new position
START SLAVE;
</code></pre>
</div>

<p><strong>3. Point-in-Time Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20specific%20position%20in%20binlog%0ASHOW%20BINLOG%20EVENTS%20IN%20'mysql-bin.000001'%20FROM%20154%3B%0A%0A--%20Start%20slave%20from%20specific%20position%0ACHANGE%20MASTER%20TO%0A%20%20%20%20MASTER_LOG_FILE%20%3D%20'mysql-bin.000001'%2C%0A%20%20%20%20MASTER_LOG_POS%20%3D%201234%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find specific position in binlog
SHOW BINLOG EVENTS IN 'mysql-bin.000001' FROM 154;

-- Start slave from specific position
CHANGE MASTER TO
    MASTER_LOG_FILE = 'mysql-bin.000001',
    MASTER_LOG_POS = 1234;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use GTID (Global Transaction Identifiers) for easier failover</p>
<p>- Monitor replication lag continuously</p>
<p>- Implement automated failover procedures</p>
<p>- Regular backup of both master and slaves</p>
<p>- Test failover procedures regularly</p>
<p>- Use semi-synchronous replication for critical data</p>
<p>- Implement proper network security between servers</p>


<p>---</p>

<h2 id="-360-what-are-database-locks-and-deadlock-handling-">**360. What are database locks and deadlock handling?**</h2>

<p><strong>Answer:</strong> Database locks control concurrent access to data, while deadlock handling resolves circular waiting situations between transactions.</p>

<p><strong>Types of Locks:</strong></p>

<p><strong>1. Shared Locks (S-locks):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multiple%20transactions%20can%20hold%20shared%20locks%20simultaneously%0A--%20Prevents%20writes%2C%20allows%20reads%0A%0A--%20Explicit%20shared%20lock%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20LOCK%20IN%20SHARE%20MODE%3B%0A%0A--%20Implicit%20shared%20locks%20during%20SELECT%20(depending%20on%20isolation%20level)%0ASET%20TRANSACTION%20ISOLATION%20LEVEL%20REPEATABLE%20READ%3B%0ASTART%20TRANSACTION%3B%0ASELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%201%3B%20%20--%20Acquires%20shared%20lock%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multiple transactions can hold shared locks simultaneously
-- Prevents writes, allows reads

-- Explicit shared lock
SELECT * FROM accounts WHERE id = 1 LOCK IN SHARE MODE;

-- Implicit shared locks during SELECT (depending on isolation level)
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;  -- Acquires shared lock
</code></pre>
</div>

<p><strong>2. Exclusive Locks (X-locks):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Only%20one%20transaction%20can%20hold%20exclusive%20lock%0A--%20Prevents%20both%20reads%20and%20writes%20by%20other%20transactions%0A%0A--%20Explicit%20exclusive%20lock%0ASELECT%20*%20FROM%20accounts%20WHERE%20id%20%3D%201%20FOR%20UPDATE%3B%0A%0A--%20Implicit%20exclusive%20locks%20during%20modifications%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%20%20--%20X-lock%20on%20row%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Only one transaction can hold exclusive lock
-- Prevents both reads and writes by other transactions

-- Explicit exclusive lock
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;

-- Implicit exclusive locks during modifications
UPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- X-lock on row
</code></pre>
</div>

<p><strong>3. Intention Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20uses%20intention%20locks%20automatically%0A--%20IS%20(Intention%20Shared)%20-%20intends%20to%20acquire%20S-locks%20on%20rows%0A--%20IX%20(Intention%20Exclusive)%20-%20intends%20to%20acquire%20X-locks%20on%20rows%0A%0A--%20These%20are%20acquired%20automatically%20by%20InnoDB%0A--%20No%20explicit%20syntax%20needed%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB uses intention locks automatically
-- IS (Intention Shared) - intends to acquire S-locks on rows
-- IX (Intention Exclusive) - intends to acquire X-locks on rows

-- These are acquired automatically by InnoDB
-- No explicit syntax needed
</code></pre>
</div>

<p><strong>Lock Granularity:</strong></p>

<p><strong>1. Row-Level Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20default%20-%20locks%20individual%20rows%0AUPDATE%20users%20SET%20last_login%20%3D%20NOW()%20WHERE%20id%20%3D%20123%3B%0A--%20Only%20locks%20the%20specific%20row%20with%20id%20%3D%20123%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB default - locks individual rows
UPDATE users SET last_login = NOW() WHERE id = 123;
-- Only locks the specific row with id = 123
</code></pre>
</div>

<p><strong>2. Table-Level Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Explicit%20table%20locking%0ALOCK%20TABLES%20users%20READ%3B%20%20%20%20--%20Shared%20table%20lock%0ASELECT%20*%20FROM%20users%3B%0AUNLOCK%20TABLES%3B%0A%0ALOCK%20TABLES%20users%20WRITE%3B%20%20%20--%20Exclusive%20table%20lock%0AUPDATE%20users%20SET%20status%20%3D%20'inactive'%20WHERE%20last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%3B%0AUNLOCK%20TABLES%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Explicit table locking
LOCK TABLES users READ;    -- Shared table lock
SELECT * FROM users;
UNLOCK TABLES;

LOCK TABLES users WRITE;   -- Exclusive table lock
UPDATE users SET status = 'inactive' WHERE last_login &lt; DATE_SUB(NOW(), INTERVAL 1 YEAR);
UNLOCK TABLES;
</code></pre>
</div>

<p><strong>3. Gap Locks and Next-Key Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20InnoDB%20uses%20these%20to%20prevent%20phantom%20reads%0A--%20Gap%20lock%3A%20locks%20the%20gap%20between%20index%20records%0A--%20Next-key%20lock%3A%20combination%20of%20record%20lock%20and%20gap%20lock%0A%0A--%20Example%20with%20REPEATABLE%20READ%20isolation%0ASTART%20TRANSACTION%3B%0ASELECT%20*%20FROM%20users%20WHERE%20age%20BETWEEN%2025%20AND%2035%20FOR%20UPDATE%3B%0A--%20Locks%20existing%20rows%20AND%20gaps%20to%20prevent%20new%20rows%20in%20range%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- InnoDB uses these to prevent phantom reads
-- Gap lock: locks the gap between index records
-- Next-key lock: combination of record lock and gap lock

-- Example with REPEATABLE READ isolation
START TRANSACTION;
SELECT * FROM users WHERE age BETWEEN 25 AND 35 FOR UPDATE;
-- Locks existing rows AND gaps to prevent new rows in range
</code></pre>
</div>

<p><strong>Deadlock Examples and Resolution:</strong></p>

<p><strong>1. Classic Deadlock Scenario:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Transaction%201%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20100%20WHERE%20id%20%3D%201%3B%20%20--%20Locks%20account%201%0A--%20...%20some%20processing%20time%20...%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20100%20WHERE%20id%20%3D%202%3B%20%20--%20Waits%20for%20account%202%0A%0A--%20Transaction%202%20(simultaneously)%3A%0ASTART%20TRANSACTION%3B%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%2050%20WHERE%20id%20%3D%202%3B%20%20%20--%20Locks%20account%202%0A--%20...%20some%20processing%20time%20...%0AUPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%2050%20WHERE%20id%20%3D%201%3B%20%20%20--%20Waits%20for%20account%201%0A%0A--%20Result%3A%20Deadlock!%20Each%20transaction%20waits%20for%20the%20other's%20lock%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Transaction 1:
START TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- Locks account 1
-- ... some processing time ...
UPDATE accounts SET balance = balance + 100 WHERE id = 2;  -- Waits for account 2

-- Transaction 2 (simultaneously):
START TRANSACTION;
UPDATE accounts SET balance = balance - 50 WHERE id = 2;   -- Locks account 2
-- ... some processing time ...
UPDATE accounts SET balance = balance + 50 WHERE id = 1;   -- Waits for account 1

-- Result: Deadlock! Each transaction waits for the other's lock
</code></pre>
</div>

<p><strong>2. Deadlock Detection and Resolution:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20automatically%20detects%20deadlocks%20and%20rolls%20back%20one%20transaction%0A--%20The%20rolled-back%20transaction%20receives%20error%201213%0A%0A--%20Check%20deadlock%20information%0ASHOW%20ENGINE%20INNODB%20STATUS%3B%0A--%20Look%20for%20%22LATEST%20DETECTED%20DEADLOCK%22%20section%0A%0A--%20Deadlock%20history%20(MySQL%208.0%2B)%0ASELECT%20*%20FROM%20performance_schema.events_statements_history%0AWHERE%20sql_text%20LIKE%20'%25deadlock%25'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL automatically detects deadlocks and rolls back one transaction
-- The rolled-back transaction receives error 1213

-- Check deadlock information
SHOW ENGINE INNODB STATUS;
-- Look for "LATEST DETECTED DEADLOCK" section

-- Deadlock history (MySQL 8.0+)
SELECT * FROM performance_schema.events_statements_history
WHERE sql_text LIKE '%deadlock%';
</code></pre>
</div>

<p><strong>Deadlock Prevention Strategies:</strong></p>

<p><strong>1. Consistent Lock Ordering:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Always%20acquire%20locks%20in%20the%20same%20order%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20SafeTransfer(%0A%20%20%20%20IN%20from_id%20INT%2C%0A%20%20%20%20IN%20to_id%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20first_id%20INT%3B%0A%20%20%20%20DECLARE%20second_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Always%20lock%20lower%20ID%20first%0A%20%20%20%20IF%20from_id%20%3C%20to_id%20THEN%0A%20%20%20%20%20%20%20%20SET%20first_id%20%3D%20from_id%3B%0A%20%20%20%20%20%20%20%20SET%20second_id%20%3D%20to_id%3B%0A%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20SET%20first_id%20%3D%20to_id%3B%0A%20%20%20%20%20%20%20%20SET%20second_id%20%3D%20from_id%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Lock%20in%20consistent%20order%0A%20%20%20%20SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20first_id%20FOR%20UPDATE%3B%0A%20%20%20%20SELECT%20balance%20FROM%20accounts%20WHERE%20id%20%3D%20second_id%20FOR%20UPDATE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20transfer%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_id%3B%0A%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_id%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Always acquire locks in the same order
DELIMITER //
CREATE PROCEDURE SafeTransfer(
    IN from_id INT,
    IN to_id INT,
    IN amount DECIMAL(10,2)
)
BEGIN
    DECLARE first_id INT;
    DECLARE second_id INT;
    
    -- Always lock lower ID first
    IF from_id &lt; to_id THEN
        SET first_id = from_id;
        SET second_id = to_id;
    ELSE
        SET first_id = to_id;
        SET second_id = from_id;
    END IF;
    
    START TRANSACTION;
    
    -- Lock in consistent order
    SELECT balance FROM accounts WHERE id = first_id FOR UPDATE;
    SELECT balance FROM accounts WHERE id = second_id FOR UPDATE;
    
    -- Perform transfer
    UPDATE accounts SET balance = balance - amount WHERE id = from_id;
    UPDATE accounts SET balance = balance + amount WHERE id = to_id;
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Timeout-Based Approach:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20lock%20wait%20timeout%0ASET%20SESSION%20innodb_lock_wait_timeout%20%3D%205%3B%20%20--%205%20seconds%0A%0A--%20Application-level%20retry%20logic%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20TransferWithRetry(%0A%20%20%20%20IN%20from_id%20INT%2C%0A%20%20%20%20IN%20to_id%20INT%2C%0A%20%20%20%20IN%20amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20IN%20max_retries%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20retry_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%201213%2C%201205%20%20--%20Deadlock%2C%20lock%20timeout%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20SET%20retry_count%20%3D%20retry_count%20%2B%201%3B%0A%20%20%20%20%20%20%20%20IF%20retry_count%20%3E%3D%20max_retries%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20--%20Wait%20before%20retry%0A%20%20%20%20%20%20%20%20DO%20SLEEP(RAND()%20*%200.1)%3B%20%20--%20Random%20delay%200-100ms%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20NOT%20done%20AND%20retry_count%20%3C%20max_retries%20DO%0A%20%20%20%20%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Perform%20transfer%20logic%20here%0A%20%20%20%20%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20-%20amount%20WHERE%20id%20%3D%20from_id%3B%0A%20%20%20%20%20%20%20%20UPDATE%20accounts%20SET%20balance%20%3D%20balance%20%2B%20amount%20WHERE%20id%20%3D%20to_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20COMMIT%3B%0A%20%20%20%20%20%20%20%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20END%20WHILE%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set lock wait timeout
SET SESSION innodb_lock_wait_timeout = 5;  -- 5 seconds

-- Application-level retry logic
DELIMITER //
CREATE PROCEDURE TransferWithRetry(
    IN from_id INT,
    IN to_id INT,
    IN amount DECIMAL(10,2),
    IN max_retries INT
)
BEGIN
    DECLARE retry_count INT DEFAULT 0;
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE CONTINUE HANDLER FOR 1213, 1205  -- Deadlock, lock timeout
    BEGIN
        SET retry_count = retry_count + 1;
        IF retry_count &gt;= max_retries THEN
            SET done = TRUE;
            RESIGNAL;
        END IF;
        -- Wait before retry
        DO SLEEP(RAND() * 0.1);  -- Random delay 0-100ms
    END;
    
    WHILE NOT done AND retry_count &lt; max_retries DO
        START TRANSACTION;
        
        -- Perform transfer logic here
        UPDATE accounts SET balance = balance - amount WHERE id = from_id;
        UPDATE accounts SET balance = balance + amount WHERE id = to_id;
        
        COMMIT;
        SET done = TRUE;
    END WHILE;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Lock Monitoring:</strong></p>

<p><strong>1. Current Locks:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20current%20locks%20(MySQL%208.0%2B)%0ASELECT%20%0A%20%20%20%20r.trx_id%2C%0A%20%20%20%20r.trx_mysql_thread_id%2C%0A%20%20%20%20r.trx_query%2C%0A%20%20%20%20b.blocking_trx_id%2C%0A%20%20%20%20b.blocking_pid%2C%0A%20%20%20%20l.lock_table%2C%0A%20%20%20%20l.lock_type%2C%0A%20%20%20%20l.lock_mode%0AFROM%20information_schema.innodb_lock_waits%20w%0AJOIN%20information_schema.innodb_trx%20r%20ON%20r.trx_id%20%3D%20w.requesting_trx_id%0AJOIN%20information_schema.innodb_trx%20b%20ON%20b.trx_id%20%3D%20w.blocking_trx_id%0AJOIN%20information_schema.innodb_locks%20l%20ON%20l.lock_trx_id%20%3D%20w.blocking_trx_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View current locks (MySQL 8.0+)
SELECT 
    r.trx_id,
    r.trx_mysql_thread_id,
    r.trx_query,
    b.blocking_trx_id,
    b.blocking_pid,
    l.lock_table,
    l.lock_type,
    l.lock_mode
FROM information_schema.innodb_lock_waits w
JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id
JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
JOIN information_schema.innodb_locks l ON l.lock_trx_id = w.blocking_trx_id;
</code></pre>
</div>

<p><strong>2. Lock Wait Statistics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Performance%20schema%20lock%20statistics%0ASELECT%20%0A%20%20%20%20object_schema%2C%0A%20%20%20%20object_name%2C%0A%20%20%20%20count_read%2C%0A%20%20%20%20count_write%2C%0A%20%20%20%20sum_timer_wait%2F1000000000%20as%20total_wait_sec%0AFROM%20performance_schema.table_lock_waits_summary_by_table%0AWHERE%20object_schema%20%3D%20'your_database'%0AORDER%20BY%20sum_timer_wait%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Performance schema lock statistics
SELECT 
    object_schema,
    object_name,
    count_read,
    count_write,
    sum_timer_wait/1000000000 as total_wait_sec
FROM performance_schema.table_lock_waits_summary_by_table
WHERE object_schema = 'your_database'
ORDER BY sum_timer_wait DESC;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Keep transactions short and focused</p>
<p>- Access resources in consistent order</p>
<p>- Use appropriate isolation levels</p>
<p>- Implement retry logic for deadlock handling</p>
<p>- Monitor lock contention regularly</p>
<p>- Consider application-level locking for complex scenarios</p>
<p>- Use SELECT ... FOR UPDATE sparingly</p>

<h2 id="-361-what-are-database-synonyms-and-aliases-">**361. What are database synonyms and aliases?**</h2>

<p><strong>Answer:</strong> Database synonyms and aliases provide alternative names for database objects, improving code readability and abstraction.</p>

<p><strong>Table Aliases in Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Simple%20aliases%20for%20readability%0ASELECT%20u.name%2C%20u.email%2C%20o.total%2C%20o.order_date%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AWHERE%20u.status%20%3D%20'active'%3B%0A%0A--%20Complex%20query%20with%20multiple%20aliases%0ASELECT%20%0A%20%20%20%20c.company_name%2C%0A%20%20%20%20u.name%20as%20contact_name%2C%0A%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20SUM(o.total)%20as%20total_revenue%2C%0A%20%20%20%20AVG(o.total)%20as%20avg_order_value%0AFROM%20customers%20c%0AJOIN%20users%20u%20ON%20c.primary_contact_id%20%3D%20u.id%0ALEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0AWHERE%20o.order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20YEAR)%0AGROUP%20BY%20c.id%2C%20c.company_name%2C%20u.name%0AHAVING%20total_revenue%20%3E%2010000%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Simple aliases for readability
SELECT u.name, u.email, o.total, o.order_date
FROM users u
JOIN orders o ON u.id = o.customer_id
WHERE u.status = 'active';

-- Complex query with multiple aliases
SELECT 
    c.company_name,
    u.name as contact_name,
    COUNT(o.id) as order_count,
    SUM(o.total) as total_revenue,
    AVG(o.total) as avg_order_value
FROM customers c
JOIN users u ON c.primary_contact_id = u.id
LEFT JOIN orders o ON c.id = o.customer_id
WHERE o.order_date &gt;= DATE_SUB(NOW(), INTERVAL 1 YEAR)
GROUP BY c.id, c.company_name, u.name
HAVING total_revenue &gt; 10000;
</code></pre>
</div>

<p><strong>Column Aliases:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Descriptive%20column%20names%20in%20results%0ASELECT%20%0A%20%20%20%20CONCAT(first_name%2C%20'%20'%2C%20last_name)%20AS%20full_name%2C%0A%20%20%20%20DATE_FORMAT(created_at%2C%20'%25Y-%25m-%25d')%20AS%20registration_date%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20last_login%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%20THEN%20'Active'%0A%20%20%20%20%20%20%20%20WHEN%20last_login%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%20THEN%20'Inactive'%0A%20%20%20%20%20%20%20%20ELSE%20'Dormant'%0A%20%20%20%20END%20AS%20user_status%2C%0A%20%20%20%20TIMESTAMPDIFF(DAY%2C%20created_at%2C%20NOW())%20AS%20days_since_registration%0AFROM%20users%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Descriptive column names in results
SELECT 
    CONCAT(first_name, ' ', last_name) AS full_name,
    DATE_FORMAT(created_at, '%Y-%m-%d') AS registration_date,
    CASE 
        WHEN last_login &gt; DATE_SUB(NOW(), INTERVAL 30 DAY) THEN 'Active'
        WHEN last_login &gt; DATE_SUB(NOW(), INTERVAL 90 DAY) THEN 'Inactive'
        ELSE 'Dormant'
    END AS user_status,
    TIMESTAMPDIFF(DAY, created_at, NOW()) AS days_since_registration
FROM users;
</code></pre>
</div>

<p><strong>View Aliases (MySQL doesn't have true synonyms, but views serve similar purpose):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20view%20as%20alias%20for%20complex%20table%20structure%0ACREATE%20VIEW%20customer_summary%20AS%0ASELECT%20%0A%20%20%20%20c.id%2C%0A%20%20%20%20c.company_name%2C%0A%20%20%20%20c.industry%2C%0A%20%20%20%20u.name%20as%20primary_contact%2C%0A%20%20%20%20u.email%20as%20contact_email%2C%0A%20%20%20%20COUNT(o.id)%20as%20total_orders%2C%0A%20%20%20%20SUM(o.total)%20as%20lifetime_value%2C%0A%20%20%20%20MAX(o.order_date)%20as%20last_order_date%0AFROM%20customers%20c%0AJOIN%20users%20u%20ON%20c.primary_contact_id%20%3D%20u.id%0ALEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0AGROUP%20BY%20c.id%2C%20c.company_name%2C%20c.industry%2C%20u.name%2C%20u.email%3B%0A%0A--%20Use%20view%20as%20if%20it%20were%20a%20table%0ASELECT%20*%20FROM%20customer_summary%20%0AWHERE%20lifetime_value%20%3E%2050000%0AORDER%20BY%20lifetime_value%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create view as alias for complex table structure
CREATE VIEW customer_summary AS
SELECT 
    c.id,
    c.company_name,
    c.industry,
    u.name as primary_contact,
    u.email as contact_email,
    COUNT(o.id) as total_orders,
    SUM(o.total) as lifetime_value,
    MAX(o.order_date) as last_order_date
FROM customers c
JOIN users u ON c.primary_contact_id = u.id
LEFT JOIN orders o ON c.id = o.customer_id
GROUP BY c.id, c.company_name, c.industry, u.name, u.email;

-- Use view as if it were a table
SELECT * FROM customer_summary 
WHERE lifetime_value &gt; 50000
ORDER BY lifetime_value DESC;
</code></pre>
</div>

<p><strong>Temporary Aliases with CTEs:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Common%20Table%20Expression%20as%20temporary%20alias%0AWITH%20monthly_sales%20AS%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20DATE_FORMAT(order_date%2C%20'%25Y-%25m')%20as%20month%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20monthly_total%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%0A%20%20%20%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2012%20MONTH)%0A%20%20%20%20GROUP%20BY%20DATE_FORMAT(order_date%2C%20'%25Y-%25m')%0A)%2C%0Asales_growth%20AS%20(%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20month%2C%0A%20%20%20%20%20%20%20%20monthly_total%2C%0A%20%20%20%20%20%20%20%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month)%20as%20prev_month_total%2C%0A%20%20%20%20%20%20%20%20((monthly_total%20-%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month))%20%2F%20%0A%20%20%20%20%20%20%20%20%20LAG(monthly_total)%20OVER%20(ORDER%20BY%20month))%20*%20100%20as%20growth_rate%0A%20%20%20%20FROM%20monthly_sales%0A)%0ASELECT%20*%20FROM%20sales_growth%20WHERE%20growth_rate%20%3E%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Common Table Expression as temporary alias
WITH monthly_sales AS (
    SELECT 
        DATE_FORMAT(order_date, '%Y-%m') as month,
        SUM(total) as monthly_total,
        COUNT(*) as order_count
    FROM orders
    WHERE order_date &gt;= DATE_SUB(NOW(), INTERVAL 12 MONTH)
    GROUP BY DATE_FORMAT(order_date, '%Y-%m')
),
sales_growth AS (
    SELECT 
        month,
        monthly_total,
        LAG(monthly_total) OVER (ORDER BY month) as prev_month_total,
        ((monthly_total - LAG(monthly_total) OVER (ORDER BY month)) / 
         LAG(monthly_total) OVER (ORDER BY month)) * 100 as growth_rate
    FROM monthly_sales
)
SELECT * FROM sales_growth WHERE growth_rate &gt; 10;
</code></pre>
</div>

<p><strong>Benefits:</strong></p>

<p>- <strong>Readability:</strong> Shorter, more meaningful names</p>
<p>- <strong>Abstraction:</strong> Hide complex table structures</p>
<p>- <strong>Maintainability:</strong> Change underlying structure without affecting queries</p>
<p>- <strong>Reusability:</strong> Common aliases across multiple queries</p>


<p>---</p>

<h2 id="-362-how-do-you-work-with-database-sequences-and-auto-increment-">**362. How do you work with database sequences and auto-increment?**</h2>

<p><strong>Answer:</strong> Sequences and auto-increment provide automatic generation of unique numeric values, typically for primary keys.</p>

<p><strong>AUTO_INCREMENT in MySQL:</strong></p>

<p><strong>1. Basic Auto-Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20without%20specifying%20ID%0AINSERT%20INTO%20users%20(name%2C%20email)%20VALUES%20%0A('John%20Doe'%2C%20'john%40example.com')%2C%0A('Jane%20Smith'%2C%20'jane%40example.com')%3B%0A%0A--%20IDs%20are%20automatically%20assigned%3A%201%2C%202%2C%203%2C%20...%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert without specifying ID
INSERT INTO users (name, email) VALUES 
('John Doe', 'john@example.com'),
('Jane Smith', 'jane@example.com');

-- IDs are automatically assigned: 1, 2, 3, ...
</code></pre>
</div>

<p><strong>2. Custom Auto-Increment Starting Value:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Set%20starting%20value%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%0A)%20AUTO_INCREMENT%20%3D%201000%3B%0A%0A--%20Or%20alter%20existing%20table%0AALTER%20TABLE%20products%20AUTO_INCREMENT%20%3D%205000%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Set starting value
CREATE TABLE products (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10,2)
) AUTO_INCREMENT = 1000;

-- Or alter existing table
ALTER TABLE products AUTO_INCREMENT = 5000;
</code></pre>
</div>

<p><strong>3. Auto-Increment with Custom Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Global%20setting%20(affects%20all%20tables)%0ASET%20%40%40auto_increment_increment%20%3D%2010%3B%20%20--%20Increment%20by%2010%0ASET%20%40%40auto_increment_offset%20%3D%201%3B%20%20%20%20%20%20--%20Start%20at%201%0A%0A--%20Results%20in%3A%201%2C%2011%2C%2021%2C%2031%2C%2041%2C%20...%0A%0A--%20Session-specific%20setting%0ASET%20SESSION%20auto_increment_increment%20%3D%205%3B%0ASET%20SESSION%20auto_increment_offset%20%3D%202%3B%0A--%20Results%20in%3A%202%2C%207%2C%2012%2C%2017%2C%2022%2C%20...%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Global setting (affects all tables)
SET @@auto_increment_increment = 10;  -- Increment by 10
SET @@auto_increment_offset = 1;      -- Start at 1

-- Results in: 1, 11, 21, 31, 41, ...

-- Session-specific setting
SET SESSION auto_increment_increment = 5;
SET SESSION auto_increment_offset = 2;
-- Results in: 2, 7, 12, 17, 22, ...
</code></pre>
</div>

<p><strong>Managing Auto-Increment Values:</strong></p>

<p><strong>1. Get Current Auto-Increment Value:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20auto-increment%20value%0ASHOW%20TABLE%20STATUS%20LIKE%20'users'%3B%0A--%20Look%20at%20'Auto_increment'%20column%0A%0A--%20Or%20query%20information%20schema%0ASELECT%20AUTO_INCREMENT%20%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%20%0AAND%20table_name%20%3D%20'users'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current auto-increment value
SHOW TABLE STATUS LIKE 'users';
-- Look at 'Auto_increment' column

-- Or query information schema
SELECT AUTO_INCREMENT 
FROM information_schema.tables 
WHERE table_schema = 'your_database' 
AND table_name = 'users';
</code></pre>
</div>

<p><strong>2. Reset Auto-Increment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Reset%20to%20specific%20value%0AALTER%20TABLE%20users%20AUTO_INCREMENT%20%3D%201%3B%0A%0A--%20Reset%20to%20next%20available%20value%20after%20max%20existing%20ID%0AALTER%20TABLE%20users%20AUTO_INCREMENT%20%3D%201%3B%0A--%20MySQL%20automatically%20adjusts%20to%20MAX(id)%20%2B%201%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Reset to specific value
ALTER TABLE users AUTO_INCREMENT = 1;

-- Reset to next available value after max existing ID
ALTER TABLE users AUTO_INCREMENT = 1;
-- MySQL automatically adjusts to MAX(id) + 1
</code></pre>
</div>

<p><strong>3. Handle Auto-Increment Gaps:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Gaps%20occur%20due%20to%3A%0A--%20-%20Rolled%20back%20transactions%0A--%20-%20DELETE%20operations%0A--%20-%20Failed%20INSERT%20attempts%0A%0A--%20Find%20gaps%20in%20sequence%0ASELECT%20%0A%20%20%20%20t1.id%20%2B%201%20as%20gap_start%2C%0A%20%20%20%20MIN(t2.id)%20-%201%20as%20gap_end%0AFROM%20users%20t1%0ALEFT%20JOIN%20users%20t2%20ON%20t1.id%20%2B%201%20%3D%20t2.id%0AWHERE%20t2.id%20IS%20NULL%0AAND%20t1.id%20%3C%20(SELECT%20MAX(id)%20FROM%20users)%0AGROUP%20BY%20t1.id%0AHAVING%20gap_start%20%3C%3D%20gap_end%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Gaps occur due to:
-- - Rolled back transactions
-- - DELETE operations
-- - Failed INSERT attempts

-- Find gaps in sequence
SELECT 
    t1.id + 1 as gap_start,
    MIN(t2.id) - 1 as gap_end
FROM users t1
LEFT JOIN users t2 ON t1.id + 1 = t2.id
WHERE t2.id IS NULL
AND t1.id &lt; (SELECT MAX(id) FROM users)
GROUP BY t1.id
HAVING gap_start &lt;= gap_end;
</code></pre>
</div>

<p><strong>Sequence-Like Behavior (MySQL doesn't have native sequences):</strong></p>

<p><strong>1. Custom Sequence Table:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20sequence%20table%0ACREATE%20TABLE%20sequences%20(%0A%20%20%20%20name%20VARCHAR(50)%20PRIMARY%20KEY%2C%0A%20%20%20%20current_value%20BIGINT%20NOT%20NULL%20DEFAULT%200%2C%0A%20%20%20%20increment_by%20INT%20NOT%20NULL%20DEFAULT%201%0A)%3B%0A%0A--%20Initialize%20sequences%0AINSERT%20INTO%20sequences%20(name%2C%20current_value%2C%20increment_by)%20VALUES%0A('order_number'%2C%2010000%2C%201)%2C%0A('invoice_number'%2C%202024001%2C%201)%2C%0A('customer_code'%2C%201000%2C%2010)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create sequence table
CREATE TABLE sequences (
    name VARCHAR(50) PRIMARY KEY,
    current_value BIGINT NOT NULL DEFAULT 0,
    increment_by INT NOT NULL DEFAULT 1
);

-- Initialize sequences
INSERT INTO sequences (name, current_value, increment_by) VALUES
('order_number', 10000, 1),
('invoice_number', 2024001, 1),
('customer_code', 1000, 10);
</code></pre>
</div>

<p><strong>2. Sequence Generation Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20FUNCTION%20NextSequenceValue(seq_name%20VARCHAR(50))%0ARETURNS%20BIGINT%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20next_val%20BIGINT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20and%20increment%20sequence%20value%20atomically%0A%20%20%20%20UPDATE%20sequences%20%0A%20%20%20%20SET%20current_value%20%3D%20current_value%20%2B%20increment_by%0A%20%20%20%20WHERE%20name%20%3D%20seq_name%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20the%20new%20value%0A%20%20%20%20SELECT%20current_value%20INTO%20next_val%0A%20%20%20%20FROM%20sequences%20%0A%20%20%20%20WHERE%20name%20%3D%20seq_name%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20next_val%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A%0A--%20Usage%0ASELECT%20NextSequenceValue('order_number')%20as%20new_order_number%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE FUNCTION NextSequenceValue(seq_name VARCHAR(50))
RETURNS BIGINT
MODIFIES SQL DATA
BEGIN
    DECLARE next_val BIGINT;
    
    -- Get and increment sequence value atomically
    UPDATE sequences 
    SET current_value = current_value + increment_by
    WHERE name = seq_name;
    
    -- Return the new value
    SELECT current_value INTO next_val
    FROM sequences 
    WHERE name = seq_name;
    
    RETURN next_val;
END //
DELIMITER ;

-- Usage
SELECT NextSequenceValue('order_number') as new_order_number;
</code></pre>
</div>

<p><strong>3. UUID Alternative:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Use%20UUIDs%20for%20distributed%20systems%0ACREATE%20TABLE%20distributed_orders%20(%0A%20%20%20%20id%20CHAR(36)%20PRIMARY%20KEY%20DEFAULT%20(UUID())%2C%0A%20%20%20%20order_number%20VARCHAR(20)%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20with%20automatic%20UUID%0AINSERT%20INTO%20distributed_orders%20(order_number%2C%20customer_id%2C%20total)%0AVALUES%20('ORD-2024-001'%2C%20123%2C%20299.99)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Use UUIDs for distributed systems
CREATE TABLE distributed_orders (
    id CHAR(36) PRIMARY KEY DEFAULT (UUID()),
    order_number VARCHAR(20),
    customer_id INT,
    total DECIMAL(10,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert with automatic UUID
INSERT INTO distributed_orders (order_number, customer_id, total)
VALUES ('ORD-2024-001', 123, 299.99);
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use AUTO_INCREMENT for single-server applications</p>
<p>- Consider UUIDs for distributed systems</p>
<p>- Don't rely on AUTO_INCREMENT values being consecutive</p>
<p>- Reserve ranges for bulk operations</p>
<p>- Monitor AUTO_INCREMENT limits (INT max: 2.1 billion, BIGINT max: 9.2 quintillion)</p>
<p>- Use BIGINT for high-volume tables</p>


<p>---</p>

<h2 id="-363-what-are-database-collations-and-character-sets-">**363. What are database collations and character sets?**</h2>

<p><strong>Answer:</strong> Character sets define which characters can be stored, while collations define how characters are compared and sorted.</p>

<p><strong>Character Sets:</strong></p>

<p><strong>1. Common Character Sets:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20available%20character%20sets%0ASHOW%20CHARACTER%20SET%3B%0A%0A--%20Common%20character%20sets%3A%0A--%20utf8mb4%3A%20Full%20UTF-8%20support%20(recommended)%0A--%20utf8%3A%20Limited%20UTF-8%20(deprecated%2C%20max%203%20bytes%20per%20character)%0A--%20latin1%3A%20Western%20European%20characters%0A--%20ascii%3A%20Basic%20ASCII%20characters%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View available character sets
SHOW CHARACTER SET;

-- Common character sets:
-- utf8mb4: Full UTF-8 support (recommended)
-- utf8: Limited UTF-8 (deprecated, max 3 bytes per character)
-- latin1: Western European characters
-- ascii: Basic ASCII characters
</code></pre>
</div>

<p><strong>2. Setting Character Sets:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Database%20level%0ACREATE%20DATABASE%20myapp%20%0ACHARACTER%20SET%20utf8mb4%20%0ACOLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Table%20level%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20bio%20TEXT%0A)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Column%20level%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20description%20TEXT%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_general_ci%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Database level
CREATE DATABASE myapp 
CHARACTER SET utf8mb4 
COLLATE utf8mb4_unicode_ci;

-- Table level
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    bio TEXT
) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- Column level
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    description TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci
);
</code></pre>
</div>

<p><strong>Collations:</strong></p>

<p><strong>1. Common Collations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20View%20available%20collations%0ASHOW%20COLLATION%20LIKE%20'utf8mb4%25'%3B%0A%0A--%20Common%20UTF-8%20collations%3A%0A--%20utf8mb4_unicode_ci%3A%20Unicode%20standard%2C%20accurate%20sorting%0A--%20utf8mb4_general_ci%3A%20Faster%20but%20less%20accurate%0A--%20utf8mb4_bin%3A%20Binary%20comparison%20(case-sensitive)%0A--%20utf8mb4_0900_ai_ci%3A%20MySQL%208.0%20default%20(accent-insensitive)%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- View available collations
SHOW COLLATION LIKE 'utf8mb4%';

-- Common UTF-8 collations:
-- utf8mb4_unicode_ci: Unicode standard, accurate sorting
-- utf8mb4_general_ci: Faster but less accurate
-- utf8mb4_bin: Binary comparison (case-sensitive)
-- utf8mb4_0900_ai_ci: MySQL 8.0 default (accent-insensitive)
</code></pre>
</div>

<p><strong>2. Collation Impact on Comparisons:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Case-insensitive%20comparison%20(utf8mb4_general_ci)%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'john'%3B%20%20--%20Matches%20'John'%2C%20'JOHN'%2C%20'john'%0A%0A--%20Case-sensitive%20comparison%20(utf8mb4_bin)%0AALTER%20TABLE%20users%20MODIFY%20name%20VARCHAR(100)%20COLLATE%20utf8mb4_bin%3B%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'john'%3B%20%20--%20Only%20matches%20exact%20'john'%0A%0A--%20Accent-insensitive%20comparison%0ASELECT%20*%20FROM%20users%20WHERE%20name%20%3D%20'Jos%C3%A9'%3B%20%20--%20May%20match%20'Jose'%20depending%20on%20collation%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Case-insensitive comparison (utf8mb4_general_ci)
SELECT * FROM users WHERE name = 'john';  -- Matches 'John', 'JOHN', 'john'

-- Case-sensitive comparison (utf8mb4_bin)
ALTER TABLE users MODIFY name VARCHAR(100) COLLATE utf8mb4_bin;
SELECT * FROM users WHERE name = 'john';  -- Only matches exact 'john'

-- Accent-insensitive comparison
SELECT * FROM users WHERE name = 'José';  -- May match 'Jose' depending on collation
</code></pre>
</div>

<p><strong>Practical Examples:</strong></p>

<p><strong>1. Multi-language Support:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Table%20supporting%20multiple%20languages%0ACREATE%20TABLE%20content%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20language_code%20CHAR(2)%2C%0A%20%20%20%20title%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20content%20TEXT%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20content%20in%20different%20languages%0AINSERT%20INTO%20content%20(language_code%2C%20title%2C%20content)%20VALUES%0A('en'%2C%20'Hello%20World'%2C%20'This%20is%20English%20content')%2C%0A('es'%2C%20'Hola%20Mundo'%2C%20'Este%20es%20contenido%20en%20espa%C3%B1ol')%2C%0A('fr'%2C%20'Bonjour%20le%20Monde'%2C%20'Ceci%20est%20du%20contenu%20fran%C3%A7ais')%2C%0A('ja'%2C%20'%E3%81%93%E3%82%93%E3%81%AB%E3%81%A1%E3%81%AF%E4%B8%96%E7%95%8C'%2C%20'%E3%81%93%E3%82%8C%E3%81%AF%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%81%AE%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%81%A7%E3%81%99')%2C%0A('ar'%2C%20'%D9%85%D8%B1%D8%AD%D8%A8%D8%A7%20%D8%A8%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85'%2C%20'%D9%87%D8%B0%D8%A7%20%D9%85%D8%AD%D8%AA%D9%88%D9%89%20%D8%A8%D8%A7%D9%84%D9%84%D8%BA%D8%A9%20%D8%A7%D9%84%D8%B9%D8%B1%D8%A8%D9%8A%D8%A9')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Table supporting multiple languages
CREATE TABLE content (
    id INT PRIMARY KEY,
    language_code CHAR(2),
    title VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    content TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert content in different languages
INSERT INTO content (language_code, title, content) VALUES
('en', 'Hello World', 'This is English content'),
('es', 'Hola Mundo', 'Este es contenido en español'),
('fr', 'Bonjour le Monde', 'Ceci est du contenu français'),
('ja', 'こんにちは世界', 'これは日本語のコンテンツです'),
('ar', 'مرحبا بالعالم', 'هذا محتوى باللغة العربية');
</code></pre>
</div>

<p><strong>2. Sorting with Different Collations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20test%20data%0ACREATE%20TABLE%20names%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%0A)%20CHARACTER%20SET%20utf8mb4%3B%0A%0AINSERT%20INTO%20names%20(name)%20VALUES%20%0A('Apple')%2C%20('%C3%84pfel')%2C%20('Zebra')%2C%20('Z%C3%BCrich')%2C%20('caf%C3%A9')%2C%20('Caf%C3%A9')%3B%0A%0A--%20Sort%20with%20different%20collations%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_unicode_ci%3B%0A--%20Result%3A%20Apple%2C%20%C3%84pfel%2C%20caf%C3%A9%2C%20Caf%C3%A9%2C%20Zebra%2C%20Z%C3%BCrich%0A%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_bin%3B%0A--%20Result%3A%20Apple%2C%20Caf%C3%A9%2C%20Zebra%2C%20caf%C3%A9%2C%20%C3%84pfel%2C%20Z%C3%BCrich%20(ASCII%20order)%0A%0ASELECT%20name%20FROM%20names%20ORDER%20BY%20name%20COLLATE%20utf8mb4_general_ci%3B%0A--%20Result%3A%20Apple%2C%20%C3%84pfel%2C%20caf%C3%A9%2C%20Caf%C3%A9%2C%20Zebra%2C%20Z%C3%BCrich%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create test data
CREATE TABLE names (
    id INT PRIMARY KEY,
    name VARCHAR(100)
) CHARACTER SET utf8mb4;

INSERT INTO names (name) VALUES 
('Apple'), ('Äpfel'), ('Zebra'), ('Zürich'), ('café'), ('Café');

-- Sort with different collations
SELECT name FROM names ORDER BY name COLLATE utf8mb4_unicode_ci;
-- Result: Apple, Äpfel, café, Café, Zebra, Zürich

SELECT name FROM names ORDER BY name COLLATE utf8mb4_bin;
-- Result: Apple, Café, Zebra, café, Äpfel, Zürich (ASCII order)

SELECT name FROM names ORDER BY name COLLATE utf8mb4_general_ci;
-- Result: Apple, Äpfel, café, Café, Zebra, Zürich
</code></pre>
</div>

<p><strong>3. Performance Considerations:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Binary%20collation%20for%20exact%20matching%20(fastest)%0ACREATE%20TABLE%20tokens%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20token%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_bin%2C%0A%20%20%20%20expires_at%20TIMESTAMP%2C%0A%20%20%20%20INDEX%20idx_token%20(token)%0A)%3B%0A%0A--%20Case-insensitive%20search%20with%20performance%20optimization%0ACREATE%20TABLE%20users%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20email%20VARCHAR(255)%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%2C%0A%20%20%20%20email_lower%20VARCHAR(255)%20GENERATED%20ALWAYS%20AS%20(LOWER(email))%20STORED%2C%0A%20%20%20%20INDEX%20idx_email_lower%20(email_lower)%0A)%3B%0A%0A--%20Search%20using%20generated%20column%0ASELECT%20*%20FROM%20users%20WHERE%20email_lower%20%3D%20LOWER('John.Doe%40Example.COM')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Binary collation for exact matching (fastest)
CREATE TABLE tokens (
    id INT PRIMARY KEY,
    token VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin,
    expires_at TIMESTAMP,
    INDEX idx_token (token)
);

-- Case-insensitive search with performance optimization
CREATE TABLE users (
    id INT PRIMARY KEY,
    email VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,
    email_lower VARCHAR(255) GENERATED ALWAYS AS (LOWER(email)) STORED,
    INDEX idx_email_lower (email_lower)
);

-- Search using generated column
SELECT * FROM users WHERE email_lower = LOWER('John.Doe@Example.COM');
</code></pre>
</div>

<p><strong>Migration and Conversion:</strong></p>

<p><strong>1. Convert Existing Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20character%20set%20and%20collation%0ASELECT%20%0A%20%20%20%20table_name%2C%0A%20%20%20%20table_collation%2C%0A%20%20%20%20table_comment%0AFROM%20information_schema.tables%20%0AWHERE%20table_schema%20%3D%20'your_database'%3B%0A%0A--%20Convert%20table%20character%20set%0AALTER%20TABLE%20users%20CONVERT%20TO%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A%0A--%20Convert%20specific%20column%0AALTER%20TABLE%20users%20MODIFY%20COLUMN%20name%20VARCHAR(100)%20%0ACHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current character set and collation
SELECT 
    table_name,
    table_collation,
    table_comment
FROM information_schema.tables 
WHERE table_schema = 'your_database';

-- Convert table character set
ALTER TABLE users CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- Convert specific column
ALTER TABLE users MODIFY COLUMN name VARCHAR(100) 
CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
</code></pre>
</div>

<p><strong>2. Handle Conversion Issues:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20for%20problematic%20data%20before%20conversion%0ASELECT%20id%2C%20name%2C%20LENGTH(name)%20as%20byte_length%2C%20CHAR_LENGTH(name)%20as%20char_length%0AFROM%20users%20%0AWHERE%20LENGTH(name)%20!%3D%20CHAR_LENGTH(name)%3B%20%20--%20Multi-byte%20characters%0A%0A--%20Backup%20before%20conversion%0ACREATE%20TABLE%20users_backup%20AS%20SELECT%20*%20FROM%20users%3B%0A%0A--%20Test%20conversion%20on%20small%20subset%0ACREATE%20TABLE%20users_test%20AS%20SELECT%20*%20FROM%20users%20LIMIT%20100%3B%0AALTER%20TABLE%20users_test%20CONVERT%20TO%20CHARACTER%20SET%20utf8mb4%20COLLATE%20utf8mb4_unicode_ci%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check for problematic data before conversion
SELECT id, name, LENGTH(name) as byte_length, CHAR_LENGTH(name) as char_length
FROM users 
WHERE LENGTH(name) != CHAR_LENGTH(name);  -- Multi-byte characters

-- Backup before conversion
CREATE TABLE users_backup AS SELECT * FROM users;

-- Test conversion on small subset
CREATE TABLE users_test AS SELECT * FROM users LIMIT 100;
ALTER TABLE users_test CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Always use utf8mb4 for new applications</p>
<p>- Use utf8mb4_unicode_ci for accurate sorting</p>
<p>- Use utf8mb4_bin for case-sensitive comparisons</p>
<p>- Set character set at database creation time</p>
<p>- Test collation behavior with your specific data</p>
<p>- Consider performance impact of different collations</p>
<p>- Plan character set migrations carefully</p>


<p>---</p>

<h2 id="-364-how-do-you-implement-database-connection-pooling-">**364. How do you implement database connection pooling?**</h2>

<p><strong>Answer:</strong> Connection pooling manages a cache of database connections to improve performance and resource utilization.</p>

<p><strong>Connection Pool Concepts:</strong></p>

<p><strong>1. Pool Configuration Parameters:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20configuration%20(my.cnf)%0A%5Bmysqld%5D%0Amax_connections%20%3D%201000%20%20%20%20%20%20%20%20%20%20--%20Maximum%20total%20connections%0Amax_user_connections%20%3D%2050%20%20%20%20%20%20%20--%20Per-user%20connection%20limit%0Aconnect_timeout%20%3D%2010%20%20%20%20%20%20%20%20%20%20%20%20--%20Connection%20timeout%0Await_timeout%20%3D%2028800%20%20%20%20%20%20%20%20%20%20%20--%20Idle%20connection%20timeout%0Ainteractive_timeout%20%3D%2028800%20%20%20%20--%20Interactive%20session%20timeout%0Athread_cache_size%20%3D%20100%20%20%20%20%20%20%20%20--%20Thread%20cache%20for%20connections%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL configuration (my.cnf)
[mysqld]
max_connections = 1000          -- Maximum total connections
max_user_connections = 50       -- Per-user connection limit
connect_timeout = 10            -- Connection timeout
wait_timeout = 28800           -- Idle connection timeout
interactive_timeout = 28800    -- Interactive session timeout
thread_cache_size = 100        -- Thread cache for connections
</code></pre>
</div>

<p><strong>2. Application-Level Pool Settings:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Node.js%20example%20with%20mysql2%0Aconst%20mysql%20%3D%20require('mysql2')%3B%0A%0Aconst%20pool%20%3D%20mysql.createPool(%7B%0A%20%20%20%20host%3A%20'localhost'%2C%0A%20%20%20%20user%3A%20'app_user'%2C%0A%20%20%20%20password%3A%20'password'%2C%0A%20%20%20%20database%3A%20'myapp'%2C%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Pool%20configuration%0A%20%20%20%20connectionLimit%3A%2020%2C%20%20%20%20%20%20%20%20%2F%2F%20Maximum%20connections%20in%20pool%0A%20%20%20%20acquireTimeout%3A%2060000%2C%20%20%20%20%20%20%2F%2F%20Timeout%20to%20get%20connection%20(ms)%0A%20%20%20%20timeout%3A%2060000%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Query%20timeout%20(ms)%0A%20%20%20%20reconnect%3A%20true%2C%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Auto-reconnect%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Connection%20management%0A%20%20%20%20idleTimeout%3A%20300000%2C%20%20%20%20%20%20%20%20%2F%2F%20Close%20idle%20connections%20after%205%20minutes%0A%20%20%20%20maxIdle%3A%2010%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Maximum%20idle%20connections%0A%20%20%20%20%0A%20%20%20%20%2F%2F%20Health%20checks%0A%20%20%20%20enableKeepAlive%3A%20true%2C%0A%20%20%20%20keepAliveInitialDelay%3A%200%0A%7D)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Node.js example with mysql2
const mysql = require('mysql2');

const pool = mysql.createPool({
    host: 'localhost',
    user: 'app_user',
    password: 'password',
    database: 'myapp',
    
    // Pool configuration
    connectionLimit: 20,        // Maximum connections in pool
    acquireTimeout: 60000,      // Timeout to get connection (ms)
    timeout: 60000,             // Query timeout (ms)
    reconnect: true,            // Auto-reconnect
    
    // Connection management
    idleTimeout: 300000,        // Close idle connections after 5 minutes
    maxIdle: 10,                // Maximum idle connections
    
    // Health checks
    enableKeepAlive: true,
    keepAliveInitialDelay: 0
});
</code></pre>
</div>

<p><strong>Pool Monitoring and Management:</strong></p>

<p><strong>1. Monitor Connection Usage:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Check%20current%20connections%0ASHOW%20PROCESSLIST%3B%0A%0A--%20Connection%20statistics%0ASHOW%20STATUS%20LIKE%20'Connections'%3B%0ASHOW%20STATUS%20LIKE%20'Threads_connected'%3B%0ASHOW%20STATUS%20LIKE%20'Threads_running'%3B%0ASHOW%20STATUS%20LIKE%20'Max_used_connections'%3B%0A%0A--%20Detailed%20connection%20information%0ASELECT%20%0A%20%20%20%20ID%2C%0A%20%20%20%20USER%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20DB%2C%0A%20%20%20%20COMMAND%2C%0A%20%20%20%20TIME%2C%0A%20%20%20%20STATE%2C%0A%20%20%20%20INFO%0AFROM%20information_schema.processlist%0AWHERE%20COMMAND%20!%3D%20'Sleep'%0AORDER%20BY%20TIME%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Check current connections
SHOW PROCESSLIST;

-- Connection statistics
SHOW STATUS LIKE 'Connections';
SHOW STATUS LIKE 'Threads_connected';
SHOW STATUS LIKE 'Threads_running';
SHOW STATUS LIKE 'Max_used_connections';

-- Detailed connection information
SELECT 
    ID,
    USER,
    HOST,
    DB,
    COMMAND,
    TIME,
    STATE,
    INFO
FROM information_schema.processlist
WHERE COMMAND != 'Sleep'
ORDER BY TIME DESC;
</code></pre>
</div>

<p><strong>2. Connection Pool Health Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Pool%20event%20monitoring%0Apool.on('connection'%2C%20function%20(connection)%20%7B%0A%20%20%20%20console.log('New%20connection%20established%20as%20id%20'%20%2B%20connection.threadId)%3B%0A%7D)%3B%0A%0Apool.on('error'%2C%20function(err)%20%7B%0A%20%20%20%20console.error('Database%20pool%20error%3A'%2C%20err)%3B%0A%20%20%20%20if(err.code%20%3D%3D%3D%20'PROTOCOL_CONNECTION_LOST')%20%7B%0A%20%20%20%20%20%20%20%20%2F%2F%20Handle%20connection%20lost%0A%20%20%20%20%20%20%20%20handleDisconnect()%3B%0A%20%20%20%20%7D%0A%7D)%3B%0A%0A%2F%2F%20Pool%20statistics%0Afunction%20getPoolStats()%20%7B%0A%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20totalConnections%3A%20pool._allConnections.length%2C%0A%20%20%20%20%20%20%20%20freeConnections%3A%20pool._freeConnections.length%2C%0A%20%20%20%20%20%20%20%20acquiringConnections%3A%20pool._acquiringConnections.length%2C%0A%20%20%20%20%20%20%20%20queuedRequests%3A%20pool._connectionQueue.length%0A%20%20%20%20%7D%3B%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Pool event monitoring
pool.on('connection', function (connection) {
    console.log('New connection established as id ' + connection.threadId);
});

pool.on('error', function(err) {
    console.error('Database pool error:', err);
    if(err.code === 'PROTOCOL_CONNECTION_LOST') {
        // Handle connection lost
        handleDisconnect();
    }
});

// Pool statistics
function getPoolStats() {
    return {
        totalConnections: pool._allConnections.length,
        freeConnections: pool._freeConnections.length,
        acquiringConnections: pool._acquiringConnections.length,
        queuedRequests: pool._connectionQueue.length
    };
}
</code></pre>
</div>

<p><strong>Optimal Pool Sizing:</strong></p>

<p><strong>1. Calculate Pool Size:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Formula%3A%20Pool%20Size%20%3D%20Tn%20%C3%97%20(Cm%20-%201)%20%2B%201%0A--%20Where%3A%0A--%20Tn%20%3D%20Maximum%20number%20of%20threads%0A--%20Cm%20%3D%20Maximum%20number%20of%20simultaneous%20connections%20per%20thread%0A%0A--%20For%20web%20application%3A%0A--%20If%20you%20have%20100%20concurrent%20users%0A--%20Each%20request%20uses%201%20connection%20for%20average%20100ms%0A--%20Request%20rate%3A%2010%20requests%2Fsecond%20per%20user%0A--%20Pool%20size%20%3D%20100%20users%20%C3%97%201%20connection%20%C3%97%200.1%20seconds%20%3D%2010%20connections%0A%0A--%20Add%20buffer%20for%20spikes%3A%2010%20%C3%97%201.5%20%3D%2015%20connections%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Formula: Pool Size = Tn × (Cm - 1) + 1
-- Where:
-- Tn = Maximum number of threads
-- Cm = Maximum number of simultaneous connections per thread

-- For web application:
-- If you have 100 concurrent users
-- Each request uses 1 connection for average 100ms
-- Request rate: 10 requests/second per user
-- Pool size = 100 users × 1 connection × 0.1 seconds = 10 connections

-- Add buffer for spikes: 10 × 1.5 = 15 connections
</code></pre>
</div>

<p><strong>2. Dynamic Pool Sizing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Adaptive%20pool%20sizing%20based%20on%20load%0Aclass%20AdaptiveConnectionPool%20%7B%0A%20%20%20%20constructor(baseConfig)%20%7B%0A%20%20%20%20%20%20%20%20this.baseConfig%20%3D%20baseConfig%3B%0A%20%20%20%20%20%20%20%20this.currentLoad%20%3D%200%3B%0A%20%20%20%20%20%20%20%20this.pool%20%3D%20mysql.createPool(baseConfig)%3B%0A%20%20%20%20%20%20%20%20this.monitorLoad()%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20monitorLoad()%20%7B%0A%20%20%20%20%20%20%20%20setInterval(()%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20const%20stats%20%3D%20this.getPoolStats()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20const%20utilization%20%3D%20(stats.totalConnections%20-%20stats.freeConnections)%20%2F%20stats.totalConnections%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(utilization%20%3E%200.8%20%26%26%20stats.totalConnections%20%3C%2050)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Scale%20up%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.scalePool(Math.min(stats.totalConnections%20%2B%205%2C%2050))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20else%20if%20(utilization%20%3C%200.3%20%26%26%20stats.totalConnections%20%3E%2010)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20Scale%20down%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.scalePool(Math.max(stats.totalConnections%20-%202%2C%2010))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%2C%2030000)%3B%20%2F%2F%20Check%20every%2030%20seconds%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20scalePool(newSize)%20%7B%0A%20%20%20%20%20%20%20%20console.log(%60Scaling%20pool%20to%20%24%7BnewSize%7D%20connections%60)%3B%0A%20%20%20%20%20%20%20%20%2F%2F%20Implementation%20depends%20on%20pool%20library%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Adaptive pool sizing based on load
class AdaptiveConnectionPool {
    constructor(baseConfig) {
        this.baseConfig = baseConfig;
        this.currentLoad = 0;
        this.pool = mysql.createPool(baseConfig);
        this.monitorLoad();
    }
    
    monitorLoad() {
        setInterval(() =&gt; {
            const stats = this.getPoolStats();
            const utilization = (stats.totalConnections - stats.freeConnections) / stats.totalConnections;
            
            if (utilization &gt; 0.8 && stats.totalConnections &lt; 50) {
                // Scale up
                this.scalePool(Math.min(stats.totalConnections + 5, 50));
            } else if (utilization &lt; 0.3 && stats.totalConnections &gt; 10) {
                // Scale down
                this.scalePool(Math.max(stats.totalConnections - 2, 10));
            }
        }, 30000); // Check every 30 seconds
    }
    
    scalePool(newSize) {
        console.log(`Scaling pool to ${newSize} connections`);
        // Implementation depends on pool library
    }
}
</code></pre>
</div>

<p><strong>Connection Pool Best Practices:</strong></p>

<p><strong>1. Proper Connection Lifecycle:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Correct%20usage%20pattern%0Aasync%20function%20getUserData(userId)%20%7B%0A%20%20%20%20let%20connection%3B%0A%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20connection%20%3D%20await%20pool.getConnection()%3B%0A%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20connection.execute(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20users%20WHERE%20id%20%3D%20%3F'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%5BuserId%5D%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20return%20rows%5B0%5D%3B%0A%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20console.error('Database%20error%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20throw%20error%3B%0A%20%20%20%20%7D%20finally%20%7B%0A%20%20%20%20%20%20%20%20if%20(connection)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20connection.release()%3B%20%2F%2F%20Return%20to%20pool%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%2F%2F%20Using%20pool%20directly%20(recommended)%0Aasync%20function%20getUserDataDirect(userId)%20%7B%0A%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20pool.execute(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20users%20WHERE%20id%20%3D%20%3F'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%5BuserId%5D%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20return%20rows%5B0%5D%3B%0A%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20console.error('Database%20error%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20throw%20error%3B%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Correct usage pattern
async function getUserData(userId) {
    let connection;
    try {
        connection = await pool.getConnection();
        const [rows] = await connection.execute(
            'SELECT * FROM users WHERE id = ?', 
            [userId]
        );
        return rows[0];
    } catch (error) {
        console.error('Database error:', error);
        throw error;
    } finally {
        if (connection) {
            connection.release(); // Return to pool
        }
    }
}

// Using pool directly (recommended)
async function getUserDataDirect(userId) {
    try {
        const [rows] = await pool.execute(
            'SELECT * FROM users WHERE id = ?', 
            [userId]
        );
        return rows[0];
    } catch (error) {
        console.error('Database error:', error);
        throw error;
    }
}
</code></pre>
</div>

<p><strong>2. Handle Connection Failures:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">javascript</span>
        <button class="copy-btn" data-code="%2F%2F%20Robust%20connection%20handling%0Aclass%20DatabaseManager%20%7B%0A%20%20%20%20constructor()%20%7B%0A%20%20%20%20%20%20%20%20this.createPool()%3B%0A%20%20%20%20%20%20%20%20this.setupErrorHandling()%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20createPool()%20%7B%0A%20%20%20%20%20%20%20%20this.pool%20%3D%20mysql.createPool(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20...%20configuration%0A%20%20%20%20%20%20%20%20%20%20%20%20reconnect%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20maxReconnects%3A%203%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20reconnectDelay%3A%202000%0A%20%20%20%20%20%20%20%20%7D)%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20setupErrorHandling()%20%7B%0A%20%20%20%20%20%20%20%20this.pool.on('error'%2C%20(err)%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20(err.code%20%3D%3D%3D%20'PROTOCOL_CONNECTION_LOST')%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.log('Database%20connection%20lost%2C%20reconnecting...')%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20this.handleDisconnect()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20else%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.error('Database%20pool%20error%3A'%2C%20err)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D)%3B%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20async%20handleDisconnect()%20%7B%0A%20%20%20%20%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20this.pool.end()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20this.createPool()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20console.log('Database%20pool%20recreated')%3B%0A%20%20%20%20%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20console.error('Failed%20to%20recreate%20pool%3A'%2C%20error)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20setTimeout(()%20%3D%3E%20this.handleDisconnect()%2C%205000)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%20%20%0A%20%20%20%20async%20query(sql%2C%20params)%20%7B%0A%20%20%20%20%20%20%20%20const%20maxRetries%20%3D%203%3B%0A%20%20%20%20%20%20%20%20let%20retries%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20while%20(retries%20%3C%20maxRetries)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20try%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20const%20%5Brows%5D%20%3D%20await%20this.pool.execute(sql%2C%20params)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20rows%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%20catch%20(error)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20retries%2B%2B%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20(retries%20%3E%3D%20maxRetries)%20throw%20error%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20console.log(%60Query%20failed%2C%20retrying%20(%24%7Bretries%7D%2F%24%7BmaxRetries%7D)%60)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20await%20new%20Promise(resolve%20%3D%3E%20setTimeout(resolve%2C%201000%20*%20retries))%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A">Copy</button>
    </div>
    <pre><code class="language-javascript">// Robust connection handling
class DatabaseManager {
    constructor() {
        this.createPool();
        this.setupErrorHandling();
    }
    
    createPool() {
        this.pool = mysql.createPool({
            // ... configuration
            reconnect: true,
            maxReconnects: 3,
            reconnectDelay: 2000
        });
    }
    
    setupErrorHandling() {
        this.pool.on('error', (err) =&gt; {
            if (err.code === 'PROTOCOL_CONNECTION_LOST') {
                console.log('Database connection lost, reconnecting...');
                this.handleDisconnect();
            } else {
                console.error('Database pool error:', err);
            }
        });
    }
    
    async handleDisconnect() {
        try {
            await this.pool.end();
            this.createPool();
            console.log('Database pool recreated');
        } catch (error) {
            console.error('Failed to recreate pool:', error);
            setTimeout(() =&gt; this.handleDisconnect(), 5000);
        }
    }
    
    async query(sql, params) {
        const maxRetries = 3;
        let retries = 0;
        
        while (retries &lt; maxRetries) {
            try {
                const [rows] = await this.pool.execute(sql, params);
                return rows;
            } catch (error) {
                retries++;
                if (retries &gt;= maxRetries) throw error;
                
                console.log(`Query failed, retrying (${retries}/${maxRetries})`);
                await new Promise(resolve =&gt; setTimeout(resolve, 1000 * retries));
            }
        }
    }
}
</code></pre>
</div>

<p><strong>Performance Optimization:</strong></p>

<p>- Size pool based on actual concurrent load, not total users</p>
<p>- Monitor pool utilization and adjust accordingly</p>
<p>- Use connection validation to detect stale connections</p>
<p>- Implement proper timeout settings</p>
<p>- Consider read/write pool separation for high-load applications</p>
<p>- Use prepared statements to reduce parsing overhead</p>


<p>---</p>

<h2 id="-365-what-are-database-hints-and-optimizer-directives-">**365. What are database hints and optimizer directives?**</h2>

<p><strong>Answer:</strong> Database hints and optimizer directives provide explicit instructions to the query optimizer, overriding its automatic decisions.</p>

<p><strong>MySQL Optimizer Hints (8.0+):</strong></p>

<p><strong>1. Index Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20specific%20index%20usage%0ASELECT%20%2F*%2B%20USE_INDEX(users%20idx_email)%20*%2F%20%0A%20%20%20%20name%2C%20email%20%0AFROM%20users%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A%0A--%20Ignore%20specific%20index%0ASELECT%20%2F*%2B%20IGNORE_INDEX(users%20idx_name)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AWHERE%20name%20%3D%20'John'%20AND%20status%20%3D%20'active'%3B%0A%0A--%20Force%20index%20for%20ORDER%20BY%0ASELECT%20%2F*%2B%20USE_INDEX_FOR_ORDER_BY(users%20idx_created_at)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AORDER%20BY%20created_at%20DESC%20%0ALIMIT%2010%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force specific index usage
SELECT /*+ USE_INDEX(users idx_email) */ 
    name, email 
FROM users 
WHERE email = 'john@example.com';

-- Ignore specific index
SELECT /*+ IGNORE_INDEX(users idx_name) */ 
    * 
FROM users 
WHERE name = 'John' AND status = 'active';

-- Force index for ORDER BY
SELECT /*+ USE_INDEX_FOR_ORDER_BY(users idx_created_at) */ 
    * 
FROM users 
ORDER BY created_at DESC 
LIMIT 10;
</code></pre>
</div>

<p><strong>2. Join Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20join%20order%0ASELECT%20%2F*%2B%20STRAIGHT_JOIN%20*%2F%20%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AWHERE%20u.status%20%3D%20'active'%3B%0A%0A--%20Force%20specific%20join%20algorithm%0ASELECT%20%2F*%2B%20USE_NL(u%2C%20o)%20*%2F%20%20--%20Nested%20Loop%20Join%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A%0ASELECT%20%2F*%2B%20USE_BNL(u%2C%20o)%20*%2F%20%20--%20Block%20Nested%20Loop%20Join%0A%20%20%20%20u.name%2C%20o.total%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force join order
SELECT /*+ STRAIGHT_JOIN */ 
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id
WHERE u.status = 'active';

-- Force specific join algorithm
SELECT /*+ USE_NL(u, o) */  -- Nested Loop Join
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id;

SELECT /*+ USE_BNL(u, o) */  -- Block Nested Loop Join
    u.name, o.total
FROM users u
JOIN orders o ON u.id = o.customer_id;
</code></pre>
</div>

<p><strong>3. Subquery Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20subquery%20materialization%0ASELECT%20%2F*%2B%20SUBQUERY(MATERIALIZATION)%20*%2F%0A%20%20%20%20*%0AFROM%20users%20u%0AWHERE%20u.id%20IN%20(%0A%20%20%20%20SELECT%20customer_id%20%0A%20%20%20%20FROM%20orders%20%0A%20%20%20%20WHERE%20total%20%3E%201000%0A)%3B%0A%0A--%20Force%20subquery%20to%20semi-join%20conversion%0ASELECT%20%2F*%2B%20SEMIJOIN(FIRSTMATCH)%20*%2F%0A%20%20%20%20*%0AFROM%20users%20u%0AWHERE%20EXISTS%20(%0A%20%20%20%20SELECT%201%20%0A%20%20%20%20FROM%20orders%20o%20%0A%20%20%20%20WHERE%20o.customer_id%20%3D%20u.id%20AND%20o.total%20%3E%201000%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force subquery materialization
SELECT /*+ SUBQUERY(MATERIALIZATION) */
    *
FROM users u
WHERE u.id IN (
    SELECT customer_id 
    FROM orders 
    WHERE total &gt; 1000
);

-- Force subquery to semi-join conversion
SELECT /*+ SEMIJOIN(FIRSTMATCH) */
    *
FROM users u
WHERE EXISTS (
    SELECT 1 
    FROM orders o 
    WHERE o.customer_id = u.id AND o.total &gt; 1000
);
</code></pre>
</div>

<p><strong>Legacy Index Hints (Still Supported):</strong></p>

<p><strong>1. USE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Suggest%20index%20usage%20(optimizer%20can%20ignore)%0ASELECT%20*%20%0AFROM%20users%20USE%20INDEX%20(idx_email%2C%20idx_status)%0AWHERE%20email%20%3D%20'john%40example.com'%20OR%20status%20%3D%20'active'%3B%0A%0A--%20Force%20index%20usage%20for%20specific%20operations%0ASELECT%20*%20%0AFROM%20users%20%0AUSE%20INDEX%20FOR%20JOIN%20(idx_customer_id)%0AUSE%20INDEX%20FOR%20ORDER%20BY%20(idx_created_at)%0AWHERE%20customer_id%20%3D%20123%0AORDER%20BY%20created_at%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Suggest index usage (optimizer can ignore)
SELECT * 
FROM users USE INDEX (idx_email, idx_status)
WHERE email = 'john@example.com' OR status = 'active';

-- Force index usage for specific operations
SELECT * 
FROM users 
USE INDEX FOR JOIN (idx_customer_id)
USE INDEX FOR ORDER BY (idx_created_at)
WHERE customer_id = 123
ORDER BY created_at DESC;
</code></pre>
</div>

<p><strong>2. FORCE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Force%20index%20usage%20(optimizer%20must%20comply)%0ASELECT%20*%20%0AFROM%20orders%20FORCE%20INDEX%20(idx_order_date)%0AWHERE%20order_date%20BETWEEN%20'2024-01-01'%20AND%20'2024-12-31'%3B%0A%0A--%20Force%20multiple%20indexes%0ASELECT%20*%20%0AFROM%20products%20FORCE%20INDEX%20(idx_category%2C%20idx_price)%0AWHERE%20category%20%3D%20'electronics'%20AND%20price%20BETWEEN%20100%20AND%20500%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Force index usage (optimizer must comply)
SELECT * 
FROM orders FORCE INDEX (idx_order_date)
WHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';

-- Force multiple indexes
SELECT * 
FROM products FORCE INDEX (idx_category, idx_price)
WHERE category = 'electronics' AND price BETWEEN 100 AND 500;
</code></pre>
</div>

<p><strong>3. IGNORE INDEX:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Prevent%20index%20usage%0ASELECT%20*%20%0AFROM%20users%20IGNORE%20INDEX%20(idx_name)%0AWHERE%20name%20LIKE%20'%25john%25'%20AND%20status%20%3D%20'active'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Prevent index usage
SELECT * 
FROM users IGNORE INDEX (idx_name)
WHERE name LIKE '%john%' AND status = 'active';
</code></pre>
</div>

<p><strong>Advanced Optimizer Control:</strong></p>

<p><strong>1. Memory and Resource Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Control%20memory%20usage%20for%20sorting%0ASELECT%20%2F*%2B%20SET_VAR(sort_buffer_size%20%3D%202097152)%20*%2F%0A%20%20%20%20*%0AFROM%20large_table%0AORDER%20BY%20complex_calculation(column1%2C%20column2)%3B%0A%0A--%20Control%20join%20buffer%20size%0ASELECT%20%2F*%2B%20SET_VAR(join_buffer_size%20%3D%201048576)%20*%2F%0A%20%20%20%20u.*%2C%20o.*%0AFROM%20users%20u%0AJOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Control memory usage for sorting
SELECT /*+ SET_VAR(sort_buffer_size = 2097152) */
    *
FROM large_table
ORDER BY complex_calculation(column1, column2);

-- Control join buffer size
SELECT /*+ SET_VAR(join_buffer_size = 1048576) */
    u.*, o.*
FROM users u
JOIN orders o ON u.id = o.customer_id;
</code></pre>
</div>

<p><strong>2. Parallel Execution Hints:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20MySQL%20doesn't%20support%20parallel%20query%20execution%20natively%0A--%20But%20you%20can%20hint%20for%20specific%20algorithms%20that%20may%20be%20more%20efficient%0A%0A--%20Force%20hash%20join%20(if%20available)%0ASELECT%20%2F*%2B%20HASH_JOIN(u%2C%20o)%20*%2F%0A%20%20%20%20u.name%2C%20COUNT(o.id)%20as%20order_count%0AFROM%20users%20u%0ALEFT%20JOIN%20orders%20o%20ON%20u.id%20%3D%20o.customer_id%0AGROUP%20BY%20u.id%2C%20u.name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- MySQL doesn't support parallel query execution natively
-- But you can hint for specific algorithms that may be more efficient

-- Force hash join (if available)
SELECT /*+ HASH_JOIN(u, o) */
    u.name, COUNT(o.id) as order_count
FROM users u
LEFT JOIN orders o ON u.id = o.customer_id
GROUP BY u.id, u.name;
</code></pre>
</div>

<p><strong>When to Use Hints:</strong></p>

<p><strong>1. Optimizer Mistakes:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20When%20optimizer%20chooses%20wrong%20index%0AEXPLAIN%20SELECT%20*%20FROM%20orders%20WHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%3B%0A--%20If%20it%20uses%20idx_status%20instead%20of%20idx_customer_id%0A%0A--%20Force%20better%20index%0ASELECT%20%2F*%2B%20USE_INDEX(orders%20idx_customer_id)%20*%2F%0A%20%20%20%20*%0AFROM%20orders%20%0AWHERE%20customer_id%20%3D%20123%20AND%20status%20%3D%20'pending'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- When optimizer chooses wrong index
EXPLAIN SELECT * FROM orders WHERE customer_id = 123 AND status = 'pending';
-- If it uses idx_status instead of idx_customer_id

-- Force better index
SELECT /*+ USE_INDEX(orders idx_customer_id) */
    *
FROM orders 
WHERE customer_id = 123 AND status = 'pending';
</code></pre>
</div>

<p><strong>2. Complex Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Multi-table%20joins%20where%20optimizer%20struggles%0ASELECT%20%2F*%2B%20STRAIGHT_JOIN%20USE_INDEX(o%20idx_date)%20USE_INDEX(u%20idx_status)%20*%2F%0A%20%20%20%20u.name%2C%20o.total%2C%20p.name%20as%20product_name%0AFROM%20orders%20o%0AJOIN%20users%20u%20ON%20o.customer_id%20%3D%20u.id%0AJOIN%20order_items%20oi%20ON%20o.id%20%3D%20oi.order_id%0AJOIN%20products%20p%20ON%20oi.product_id%20%3D%20p.id%0AWHERE%20o.order_date%20%3E%3D%20'2024-01-01'%0AAND%20u.status%20%3D%20'premium'%0AAND%20p.category%20%3D%20'electronics'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Multi-table joins where optimizer struggles
SELECT /*+ STRAIGHT_JOIN USE_INDEX(o idx_date) USE_INDEX(u idx_status) */
    u.name, o.total, p.name as product_name
FROM orders o
JOIN users u ON o.customer_id = u.id
JOIN order_items oi ON o.id = oi.order_id
JOIN products p ON oi.product_id = p.id
WHERE o.order_date &gt;= '2024-01-01'
AND u.status = 'premium'
AND p.category = 'electronics';
</code></pre>
</div>

<p><strong>Monitoring Hint Effectiveness:</strong></p>

<p><strong>1. Compare Execution Plans:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Without%20hint%0AEXPLAIN%20FORMAT%3DJSON%20%0ASELECT%20*%20FROM%20users%20WHERE%20email%20%3D%20'john%40example.com'%3B%0A%0A--%20With%20hint%0AEXPLAIN%20FORMAT%3DJSON%20%0ASELECT%20%2F*%2B%20USE_INDEX(users%20idx_email)%20*%2F%20%0A%20%20%20%20*%20%0AFROM%20users%20%0AWHERE%20email%20%3D%20'john%40example.com'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Without hint
EXPLAIN FORMAT=JSON 
SELECT * FROM users WHERE email = 'john@example.com';

-- With hint
EXPLAIN FORMAT=JSON 
SELECT /*+ USE_INDEX(users idx_email) */ 
    * 
FROM users 
WHERE email = 'john@example.com';
</code></pre>
</div>

<p><strong>2. Performance Testing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Measure%20query%20performance%0ASELECT%20BENCHMARK(1000%2C%20(%0A%20%20%20%20SELECT%20COUNT(*)%20FROM%20users%20WHERE%20status%20%3D%20'active'%0A))%3B%0A%0A--%20Compare%20with%20hint%0ASELECT%20BENCHMARK(1000%2C%20(%0A%20%20%20%20SELECT%20%2F*%2B%20USE_INDEX(users%20idx_status)%20*%2F%20%0A%20%20%20%20%20%20%20%20COUNT(*)%20%0A%20%20%20%20FROM%20users%20%0A%20%20%20%20WHERE%20status%20%3D%20'active'%0A))%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Measure query performance
SELECT BENCHMARK(1000, (
    SELECT COUNT(*) FROM users WHERE status = 'active'
));

-- Compare with hint
SELECT BENCHMARK(1000, (
    SELECT /*+ USE_INDEX(users idx_status) */ 
        COUNT(*) 
    FROM users 
    WHERE status = 'active'
));
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use hints sparingly - optimizer is usually correct</p>
<p>- Document why hints are necessary</p>
<p>- Test hint effectiveness with EXPLAIN</p>
<p>- Review hints after MySQL upgrades</p>
<p>- Monitor query performance regularly</p>
<p>- Consider query rewriting before using hints</p>
<p>- Remove hints that no longer provide benefit</p>


<p><strong>Common Pitfalls:</strong></p>

<p>- Over-relying on hints instead of proper indexing</p>
<p>- Using outdated hints after schema changes</p>
<p>- Hints that hurt performance in different data distributions</p>
<p>- Ignoring optimizer improvements in newer MySQL versions</p>

<h2 id="-366-what-are-database-cursors-and-how-do-you-use-them-">**366. What are database cursors and how do you use them?**</h2>

<p><strong>Answer:</strong> Database cursors provide a mechanism to traverse result sets row by row, useful for complex row-by-row processing that can't be handled with set-based operations.</p>

<p><strong>Cursor Types in MySQL:</strong></p>

<p><strong>1. Basic Cursor Declaration and Usage:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20ProcessLargeOrders()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20order_id%20INT%3B%0A%20%20%20%20DECLARE%20customer_id%20INT%3B%0A%20%20%20%20DECLARE%20total%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Declare%20cursor%0A%20%20%20%20DECLARE%20order_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20customer_id%2C%20total%0A%20%20%20%20%20%20%20%20FROM%20orders%0A%20%20%20%20%20%20%20%20WHERE%20total%20%3E%201000%0A%20%20%20%20%20%20%20%20ORDER%20BY%20total%20DESC%3B%0A%20%20%20%20%0A%20%20%20%20--%20Declare%20handler%20for%20end%20of%20cursor%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Open%20cursor%0A%20%20%20%20OPEN%20order_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Loop%20through%20results%0A%20%20%20%20order_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20order_cursor%20INTO%20order_id%2C%20customer_id%2C%20total%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20order_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Process%20each%20row%0A%20%20%20%20%20%20%20%20CALL%20ProcessLargeOrder(order_id%2C%20customer_id%2C%20total)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20order%20status%0A%20%20%20%20%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'processed'%2C%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20order_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Close%20cursor%0A%20%20%20%20CLOSE%20order_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE ProcessLargeOrders()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE order_id INT;
    DECLARE customer_id INT;
    DECLARE total DECIMAL(10,2);
    
    -- Declare cursor
    DECLARE order_cursor CURSOR FOR
        SELECT id, customer_id, total
        FROM orders
        WHERE total &gt; 1000
        ORDER BY total DESC;
    
    -- Declare handler for end of cursor
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Open cursor
    OPEN order_cursor;
    
    -- Loop through results
    order_loop: LOOP
        FETCH order_cursor INTO order_id, customer_id, total;
        
        IF done THEN
            LEAVE order_loop;
        END IF;
        
        -- Process each row
        CALL ProcessLargeOrder(order_id, customer_id, total);
        
        -- Update order status
        UPDATE orders 
        SET status = 'processed', processed_at = NOW()
        WHERE id = order_id;
        
    END LOOP;
    
    -- Close cursor
    CLOSE order_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Cursor with Complex Processing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20CalculateCustomerLoyaltyPoints()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20cust_id%20INT%3B%0A%20%20%20%20DECLARE%20total_spent%20DECIMAL(12%2C2)%3B%0A%20%20%20%20DECLARE%20order_count%20INT%3B%0A%20%20%20%20DECLARE%20loyalty_points%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20customer_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20c.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(SUM(o.total)%2C%200)%20as%20total_spent%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20order_count%0A%20%20%20%20%20%20%20%20FROM%20customers%20c%0A%20%20%20%20%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0A%20%20%20%20%20%20%20%20WHERE%20c.status%20%3D%20'active'%0A%20%20%20%20%20%20%20%20GROUP%20BY%20c.id%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20customer_cursor%3B%0A%20%20%20%20%0A%20%20%20%20customer_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20customer_cursor%20INTO%20cust_id%2C%20total_spent%2C%20order_count%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20customer_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20loyalty%20points%20based%20on%20business%20rules%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Base%20points%20from%20spending%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20FLOOR(total_spent%20%2F%2010)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Bonus%20points%20for%20frequent%20orders%0A%20%20%20%20%20%20%20%20IF%20order_count%20%3E%3D%2010%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20100%3B%0A%20%20%20%20%20%20%20%20ELSEIF%20order_count%20%3E%3D%205%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%2050%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20VIP%20bonus%20for%20high%20spenders%0A%20%20%20%20%20%20%20%20IF%20total_spent%20%3E%3D%205000%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%20%2B%20200%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20customer%20record%0A%20%20%20%20%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20%20%20%20%20SET%20loyalty_points%20%3D%20loyalty_points%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20loyalty_tier%20%3D%20CASE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%201000%20THEN%20'platinum'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%20500%20THEN%20'gold'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20loyalty_points%20%3E%3D%20200%20THEN%20'silver'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'bronze'%0A%20%20%20%20%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20last_points_calculation%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20cust_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20customer_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20completion%0A%20%20%20%20INSERT%20INTO%20process_log%20(process_name%2C%20completed_at%2C%20records_processed)%0A%20%20%20%20SELECT%20'loyalty_calculation'%2C%20NOW()%2C%20COUNT(*)%20FROM%20customers%20WHERE%20status%20%3D%20'active'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE CalculateCustomerLoyaltyPoints()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE cust_id INT;
    DECLARE total_spent DECIMAL(12,2);
    DECLARE order_count INT;
    DECLARE loyalty_points INT DEFAULT 0;
    
    DECLARE customer_cursor CURSOR FOR
        SELECT 
            c.id,
            COALESCE(SUM(o.total), 0) as total_spent,
            COUNT(o.id) as order_count
        FROM customers c
        LEFT JOIN orders o ON c.id = o.customer_id
        WHERE c.status = 'active'
        GROUP BY c.id;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN customer_cursor;
    
    customer_loop: LOOP
        FETCH customer_cursor INTO cust_id, total_spent, order_count;
        
        IF done THEN
            LEAVE customer_loop;
        END IF;
        
        -- Calculate loyalty points based on business rules
        SET loyalty_points = 0;
        
        -- Base points from spending
        SET loyalty_points = loyalty_points + FLOOR(total_spent / 10);
        
        -- Bonus points for frequent orders
        IF order_count &gt;= 10 THEN
            SET loyalty_points = loyalty_points + 100;
        ELSEIF order_count &gt;= 5 THEN
            SET loyalty_points = loyalty_points + 50;
        END IF;
        
        -- VIP bonus for high spenders
        IF total_spent &gt;= 5000 THEN
            SET loyalty_points = loyalty_points + 200;
        END IF;
        
        -- Update customer record
        UPDATE customers 
        SET loyalty_points = loyalty_points,
            loyalty_tier = CASE
                WHEN loyalty_points &gt;= 1000 THEN 'platinum'
                WHEN loyalty_points &gt;= 500 THEN 'gold'
                WHEN loyalty_points &gt;= 200 THEN 'silver'
                ELSE 'bronze'
            END,
            last_points_calculation = NOW()
        WHERE id = cust_id;
        
    END LOOP;
    
    CLOSE customer_cursor;
    
    -- Log completion
    INSERT INTO process_log (process_name, completed_at, records_processed)
    SELECT 'loyalty_calculation', NOW(), COUNT(*) FROM customers WHERE status = 'active';
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Cursor Performance Considerations:</strong></p>

<p><strong>1. Memory-Efficient Cursor:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20ProcessLargeDataset()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20batch_size%20INT%20DEFAULT%201000%3B%0A%20%20%20%20DECLARE%20processed_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20record_id%20INT%3B%0A%20%20%20%20DECLARE%20record_data%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20in%20batches%20to%20avoid%20memory%20issues%0A%20%20%20%20DECLARE%20batch_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20data_column%0A%20%20%20%20%20%20%20%20FROM%20large_table%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%200%0A%20%20%20%20%20%20%20%20ORDER%20BY%20id%0A%20%20%20%20%20%20%20%20LIMIT%20batch_size%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20batch_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20SET%20done%20%3D%20FALSE%3B%0A%20%20%20%20%20%20%20%20OPEN%20batch_cursor%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20record_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20%20%20%20%20FETCH%20batch_cursor%20INTO%20record_id%2C%20record_data%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20record_loop%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Process%20individual%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20ProcessRecord(record_id%2C%20record_data)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20%20%20%20%20UPDATE%20large_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20processed%20%3D%201%2C%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20record_id%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20processed_count%20%3D%20processed_count%20%2B%201%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20CLOSE%20batch_cursor%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Exit%20if%20no%20more%20records%20to%20process%0A%20%20%20%20%20%20%20%20IF%20processed_count%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20batch_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Reset%20counter%20for%20next%20batch%0A%20%20%20%20%20%20%20%20SET%20processed_count%20%3D%200%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE ProcessLargeDataset()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE batch_size INT DEFAULT 1000;
    DECLARE processed_count INT DEFAULT 0;
    DECLARE record_id INT;
    DECLARE record_data TEXT;
    
    -- Process in batches to avoid memory issues
    DECLARE batch_cursor CURSOR FOR
        SELECT id, data_column
        FROM large_table
        WHERE processed = 0
        ORDER BY id
        LIMIT batch_size;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    batch_loop: LOOP
        SET done = FALSE;
        OPEN batch_cursor;
        
        record_loop: LOOP
            FETCH batch_cursor INTO record_id, record_data;
            
            IF done THEN
                LEAVE record_loop;
            END IF;
            
            -- Process individual record
            CALL ProcessRecord(record_id, record_data);
            
            -- Mark as processed
            UPDATE large_table 
            SET processed = 1, processed_at = NOW()
            WHERE id = record_id;
            
            SET processed_count = processed_count + 1;
            
        END LOOP;
        
        CLOSE batch_cursor;
        
        -- Exit if no more records to process
        IF processed_count = 0 THEN
            LEAVE batch_loop;
        END IF;
        
        -- Reset counter for next batch
        SET processed_count = 0;
        
    END LOOP;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>When to Use Cursors:</strong></p>

<p>- Complex row-by-row calculations that can't be done with SQL</p>
<p>- Sequential processing requirements</p>
<p>- When you need to call stored procedures for each row</p>
<p>- Migrating data with complex transformation logic</p>


<p><strong>Alternatives to Cursors:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Instead%20of%20cursor%20for%20simple%20updates%3A%0A--%20BAD%20(using%20cursor)%3A%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20UpdatePricesWithCursor()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20prod_id%20INT%3B%0A%20%20%20%20DECLARE%20current_price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20price_cursor%20CURSOR%20FOR%20SELECT%20id%2C%20price%20FROM%20products%3B%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20price_cursor%3B%0A%20%20%20%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20price_cursor%20INTO%20prod_id%2C%20current_price%3B%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%20LEAVE%3B%20END%20IF%3B%0A%20%20%20%20%20%20%20%20UPDATE%20products%20SET%20price%20%3D%20current_price%20*%201.1%20WHERE%20id%20%3D%20prod_id%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20CLOSE%20price_cursor%3B%0AEND%20%2F%2F%0A%0A--%20GOOD%20(set-based%20operation)%3A%0AUPDATE%20products%20SET%20price%20%3D%20price%20*%201.1%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Instead of cursor for simple updates:
-- BAD (using cursor):
DELIMITER //
CREATE PROCEDURE UpdatePricesWithCursor()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE prod_id INT;
    DECLARE current_price DECIMAL(10,2);
    
    DECLARE price_cursor CURSOR FOR SELECT id, price FROM products;
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN price_cursor;
    LOOP
        FETCH price_cursor INTO prod_id, current_price;
        IF done THEN LEAVE; END IF;
        UPDATE products SET price = current_price * 1.1 WHERE id = prod_id;
    END LOOP;
    CLOSE price_cursor;
END //

-- GOOD (set-based operation):
UPDATE products SET price = price * 1.1;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Avoid cursors when set-based operations can achieve the same result</p>
<p>- Use cursors only for complex row-by-row processing</p>
<p>- Process in batches for large datasets</p>
<p>- Always close cursors to free resources</p>
<p>- Handle NOT FOUND conditions properly</p>
<p>- Consider performance impact on concurrent operations</p>


<p>---</p>

<h2 id="-367-what-are-database-packages-and-modules-">**367. What are database packages and modules?**</h2>

<p><strong>Answer:</strong> MySQL doesn't have native packages like Oracle or PostgreSQL, but you can organize related procedures, functions, and logic using naming conventions and modular design patterns.</p>

<p><strong>Organizing Related Procedures:</strong></p>

<p><strong>1. Naming Convention Approach:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20User%20management%20%22package%22%0ADELIMITER%20%2F%2F%0A%0A--%20User%20creation%0ACREATE%20PROCEDURE%20user_pkg_create_user(%0A%20%20%20%20IN%20p_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_email%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_password%20VARCHAR(255)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20user_exists%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20if%20user%20already%20exists%0A%20%20%20%20SELECT%20COUNT(*)%20INTO%20user_exists%20%0A%20%20%20%20FROM%20users%20WHERE%20email%20%3D%20p_email%3B%0A%20%20%20%20%0A%20%20%20%20IF%20user_exists%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'User%20already%20exists'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20users%20(name%2C%20email%2C%20password_hash%2C%20created_at)%0A%20%20%20%20VALUES%20(p_name%2C%20p_email%2C%20SHA2(p_password%2C%20256)%2C%20NOW())%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20LAST_INSERT_ID()%20as%20user_id%3B%0AEND%20%2F%2F%0A%0A--%20User%20authentication%0ACREATE%20FUNCTION%20user_pkg_authenticate(%0A%20%20%20%20p_email%20VARCHAR(255)%2C%0A%20%20%20%20p_password%20VARCHAR(255)%0A)%0ARETURNS%20INT%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20user_id%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20id%20INTO%20user_id%0A%20%20%20%20FROM%20users%20%0A%20%20%20%20WHERE%20email%20%3D%20p_email%20%0A%20%20%20%20AND%20password_hash%20%3D%20SHA2(p_password%2C%20256)%0A%20%20%20%20AND%20status%20%3D%20'active'%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20COALESCE(user_id%2C%200)%3B%0AEND%20%2F%2F%0A%0A--%20User%20profile%20update%0ACREATE%20PROCEDURE%20user_pkg_update_profile(%0A%20%20%20%20IN%20p_user_id%20INT%2C%0A%20%20%20%20IN%20p_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_phone%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20p_name%2C%20%0A%20%20%20%20%20%20%20%20phone%20%3D%20p_phone%2C%0A%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_user_id%3B%0A%20%20%20%20%0A%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'User%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0A%0A--%20User%20deactivation%0ACREATE%20PROCEDURE%20user_pkg_deactivate_user(IN%20p_user_id%20INT)%0ABEGIN%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20status%20%3D%20'inactive'%2C%20%0A%20%20%20%20%20%20%20%20deactivated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_user_id%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- User management "package"
DELIMITER //

-- User creation
CREATE PROCEDURE user_pkg_create_user(
    IN p_name VARCHAR(100),
    IN p_email VARCHAR(255),
    IN p_password VARCHAR(255)
)
BEGIN
    DECLARE user_exists INT DEFAULT 0;
    
    -- Check if user already exists
    SELECT COUNT(*) INTO user_exists 
    FROM users WHERE email = p_email;
    
    IF user_exists &gt; 0 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'User already exists';
    END IF;
    
    INSERT INTO users (name, email, password_hash, created_at)
    VALUES (p_name, p_email, SHA2(p_password, 256), NOW());
    
    SELECT LAST_INSERT_ID() as user_id;
END //

-- User authentication
CREATE FUNCTION user_pkg_authenticate(
    p_email VARCHAR(255),
    p_password VARCHAR(255)
)
RETURNS INT
READS SQL DATA
BEGIN
    DECLARE user_id INT DEFAULT 0;
    
    SELECT id INTO user_id
    FROM users 
    WHERE email = p_email 
    AND password_hash = SHA2(p_password, 256)
    AND status = 'active';
    
    RETURN COALESCE(user_id, 0);
END //

-- User profile update
CREATE PROCEDURE user_pkg_update_profile(
    IN p_user_id INT,
    IN p_name VARCHAR(100),
    IN p_phone VARCHAR(20)
)
BEGIN
    UPDATE users 
    SET name = p_name, 
        phone = p_phone,
        updated_at = NOW()
    WHERE id = p_user_id;
    
    IF ROW_COUNT() = 0 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'User not found';
    END IF;
END //

-- User deactivation
CREATE PROCEDURE user_pkg_deactivate_user(IN p_user_id INT)
BEGIN
    UPDATE users 
    SET status = 'inactive', 
        deactivated_at = NOW()
    WHERE id = p_user_id;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>2. Order Management "Package":</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Create%20order%0ACREATE%20PROCEDURE%20order_pkg_create_order(%0A%20%20%20%20IN%20p_customer_id%20INT%2C%0A%20%20%20%20IN%20p_items%20JSON%2C%0A%20%20%20%20OUT%20p_order_id%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20total_amount%20DECIMAL(10%2C2)%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20item_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20product_id%20INT%3B%0A%20%20%20%20DECLARE%20quantity%20INT%3B%0A%20%20%20%20DECLARE%20price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Start%20transaction%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20order%20record%0A%20%20%20%20INSERT%20INTO%20orders%20(customer_id%2C%20status%2C%20created_at)%0A%20%20%20%20VALUES%20(p_customer_id%2C%20'pending'%2C%20NOW())%3B%0A%20%20%20%20%0A%20%20%20%20SET%20p_order_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20order%20items%0A%20%20%20%20SET%20item_count%20%3D%20JSON_LENGTH(p_items)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20item_count%20DO%0A%20%20%20%20%20%20%20%20SET%20product_id%20%3D%20JSON_EXTRACT(p_items%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.product_id'))%3B%0A%20%20%20%20%20%20%20%20SET%20quantity%20%3D%20JSON_EXTRACT(p_items%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.quantity'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20product%20price%0A%20%20%20%20%20%20%20%20SELECT%20price%20INTO%20price%20FROM%20products%20WHERE%20id%20%3D%20product_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20order%20item%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20order_items%20(order_id%2C%20product_id%2C%20quantity%2C%20price)%0A%20%20%20%20%20%20%20%20VALUES%20(p_order_id%2C%20product_id%2C%20quantity%2C%20price)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Add%20to%20total%0A%20%20%20%20%20%20%20%20SET%20total_amount%20%3D%20total_amount%20%2B%20(quantity%20*%20price)%3B%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20order%20total%0A%20%20%20%20UPDATE%20orders%20SET%20total%20%3D%20total_amount%20WHERE%20id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0A%0A--%20Calculate%20order%20total%0ACREATE%20FUNCTION%20order_pkg_calculate_total(p_order_id%20INT)%0ARETURNS%20DECIMAL(10%2C2)%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20order_total%20DECIMAL(10%2C2)%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20SUM(quantity%20*%20price)%20INTO%20order_total%0A%20%20%20%20FROM%20order_items%0A%20%20%20%20WHERE%20order_id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20COALESCE(order_total%2C%200)%3B%0AEND%20%2F%2F%0A%0A--%20Update%20order%20status%0ACREATE%20PROCEDURE%20order_pkg_update_status(%0A%20%20%20%20IN%20p_order_id%20INT%2C%0A%20%20%20%20IN%20p_status%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20valid_status%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Validate%20status%0A%20%20%20%20IF%20p_status%20IN%20('pending'%2C%20'confirmed'%2C%20'shipped'%2C%20'delivered'%2C%20'cancelled')%20THEN%0A%20%20%20%20%20%20%20%20SET%20valid_status%20%3D%20TRUE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20NOT%20valid_status%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Invalid%20order%20status'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20SET%20status%20%3D%20p_status%2C%0A%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_order_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20status%20change%0A%20%20%20%20INSERT%20INTO%20order_status_log%20(order_id%2C%20old_status%2C%20new_status%2C%20changed_at)%0A%20%20%20%20SELECT%20p_order_id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20(SELECT%20status%20FROM%20orders%20WHERE%20id%20%3D%20p_order_id)%2C%0A%20%20%20%20%20%20%20%20%20%20%20p_status%2C%0A%20%20%20%20%20%20%20%20%20%20%20NOW()%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Create order
CREATE PROCEDURE order_pkg_create_order(
    IN p_customer_id INT,
    IN p_items JSON,
    OUT p_order_id INT
)
BEGIN
    DECLARE total_amount DECIMAL(10,2) DEFAULT 0;
    DECLARE item_count INT DEFAULT 0;
    DECLARE i INT DEFAULT 0;
    DECLARE product_id INT;
    DECLARE quantity INT;
    DECLARE price DECIMAL(10,2);
    
    -- Start transaction
    START TRANSACTION;
    
    -- Create order record
    INSERT INTO orders (customer_id, status, created_at)
    VALUES (p_customer_id, 'pending', NOW());
    
    SET p_order_id = LAST_INSERT_ID();
    
    -- Process order items
    SET item_count = JSON_LENGTH(p_items);
    
    WHILE i &lt; item_count DO
        SET product_id = JSON_EXTRACT(p_items, CONCAT('$[', i, '].product_id'));
        SET quantity = JSON_EXTRACT(p_items, CONCAT('$[', i, '].quantity'));
        
        -- Get product price
        SELECT price INTO price FROM products WHERE id = product_id;
        
        -- Insert order item
        INSERT INTO order_items (order_id, product_id, quantity, price)
        VALUES (p_order_id, product_id, quantity, price);
        
        -- Add to total
        SET total_amount = total_amount + (quantity * price);
        SET i = i + 1;
    END WHILE;
    
    -- Update order total
    UPDATE orders SET total = total_amount WHERE id = p_order_id;
    
    COMMIT;
END //

-- Calculate order total
CREATE FUNCTION order_pkg_calculate_total(p_order_id INT)
RETURNS DECIMAL(10,2)
READS SQL DATA
BEGIN
    DECLARE order_total DECIMAL(10,2) DEFAULT 0;
    
    SELECT SUM(quantity * price) INTO order_total
    FROM order_items
    WHERE order_id = p_order_id;
    
    RETURN COALESCE(order_total, 0);
END //

-- Update order status
CREATE PROCEDURE order_pkg_update_status(
    IN p_order_id INT,
    IN p_status VARCHAR(20)
)
BEGIN
    DECLARE valid_status BOOLEAN DEFAULT FALSE;
    
    -- Validate status
    IF p_status IN ('pending', 'confirmed', 'shipped', 'delivered', 'cancelled') THEN
        SET valid_status = TRUE;
    END IF;
    
    IF NOT valid_status THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Invalid order status';
    END IF;
    
    UPDATE orders 
    SET status = p_status,
        updated_at = NOW()
    WHERE id = p_order_id;
    
    -- Log status change
    INSERT INTO order_status_log (order_id, old_status, new_status, changed_at)
    SELECT p_order_id, 
           (SELECT status FROM orders WHERE id = p_order_id),
           p_status,
           NOW();
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Reporting "Package":</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Sales%20report%0ACREATE%20PROCEDURE%20report_pkg_sales_summary(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20DATE(o.created_at)%20as%20sale_date%2C%0A%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(o.total)%20as%20total_sales%2C%0A%20%20%20%20%20%20%20%20AVG(o.total)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20COUNT(DISTINCT%20o.customer_id)%20as%20unique_customers%0A%20%20%20%20FROM%20orders%20o%0A%20%20%20%20WHERE%20DATE(o.created_at)%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20AND%20o.status%20!%3D%20'cancelled'%0A%20%20%20%20GROUP%20BY%20DATE(o.created_at)%0A%20%20%20%20ORDER%20BY%20sale_date%3B%0AEND%20%2F%2F%0A%0A--%20Customer%20analytics%0ACREATE%20PROCEDURE%20report_pkg_customer_analytics(IN%20p_customer_id%20INT)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20c.name%2C%0A%20%20%20%20%20%20%20%20c.email%2C%0A%20%20%20%20%20%20%20%20COUNT(o.id)%20as%20total_orders%2C%0A%20%20%20%20%20%20%20%20SUM(o.total)%20as%20lifetime_value%2C%0A%20%20%20%20%20%20%20%20AVG(o.total)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20MIN(o.created_at)%20as%20first_order%2C%0A%20%20%20%20%20%20%20%20MAX(o.created_at)%20as%20last_order%2C%0A%20%20%20%20%20%20%20%20DATEDIFF(NOW()%2C%20MAX(o.created_at))%20as%20days_since_last_order%0A%20%20%20%20FROM%20customers%20c%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20c.id%20%3D%20o.customer_id%0A%20%20%20%20WHERE%20c.id%20%3D%20p_customer_id%0A%20%20%20%20GROUP%20BY%20c.id%2C%20c.name%2C%20c.email%3B%0AEND%20%2F%2F%0A%0A--%20Product%20performance%0ACREATE%20FUNCTION%20report_pkg_product_performance(%0A%20%20%20%20p_product_id%20INT%2C%0A%20%20%20%20p_days%20INT%0A)%0ARETURNS%20JSON%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20result%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'product_id'%2C%20p.id%2C%0A%20%20%20%20%20%20%20%20'product_name'%2C%20p.name%2C%0A%20%20%20%20%20%20%20%20'total_sold'%2C%20COALESCE(SUM(oi.quantity)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'total_revenue'%2C%20COALESCE(SUM(oi.quantity%20*%20oi.price)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'avg_price'%2C%20COALESCE(AVG(oi.price)%2C%200)%2C%0A%20%20%20%20%20%20%20%20'order_count'%2C%20COUNT(DISTINCT%20oi.order_id)%0A%20%20%20%20)%20INTO%20result%0A%20%20%20%20FROM%20products%20p%0A%20%20%20%20LEFT%20JOIN%20order_items%20oi%20ON%20p.id%20%3D%20oi.product_id%0A%20%20%20%20LEFT%20JOIN%20orders%20o%20ON%20oi.order_id%20%3D%20o.id%0A%20%20%20%20WHERE%20p.id%20%3D%20p_product_id%0A%20%20%20%20AND%20(p_days%20%3D%200%20OR%20o.created_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%20p_days%20DAY))%0A%20%20%20%20GROUP%20BY%20p.id%2C%20p.name%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20result%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Sales report
CREATE PROCEDURE report_pkg_sales_summary(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    SELECT 
        DATE(o.created_at) as sale_date,
        COUNT(o.id) as order_count,
        SUM(o.total) as total_sales,
        AVG(o.total) as avg_order_value,
        COUNT(DISTINCT o.customer_id) as unique_customers
    FROM orders o
    WHERE DATE(o.created_at) BETWEEN p_start_date AND p_end_date
    AND o.status != 'cancelled'
    GROUP BY DATE(o.created_at)
    ORDER BY sale_date;
END //

-- Customer analytics
CREATE PROCEDURE report_pkg_customer_analytics(IN p_customer_id INT)
BEGIN
    SELECT 
        c.name,
        c.email,
        COUNT(o.id) as total_orders,
        SUM(o.total) as lifetime_value,
        AVG(o.total) as avg_order_value,
        MIN(o.created_at) as first_order,
        MAX(o.created_at) as last_order,
        DATEDIFF(NOW(), MAX(o.created_at)) as days_since_last_order
    FROM customers c
    LEFT JOIN orders o ON c.id = o.customer_id
    WHERE c.id = p_customer_id
    GROUP BY c.id, c.name, c.email;
END //

-- Product performance
CREATE FUNCTION report_pkg_product_performance(
    p_product_id INT,
    p_days INT
)
RETURNS JSON
READS SQL DATA
BEGIN
    DECLARE result JSON;
    
    SELECT JSON_OBJECT(
        'product_id', p.id,
        'product_name', p.name,
        'total_sold', COALESCE(SUM(oi.quantity), 0),
        'total_revenue', COALESCE(SUM(oi.quantity * oi.price), 0),
        'avg_price', COALESCE(AVG(oi.price), 0),
        'order_count', COUNT(DISTINCT oi.order_id)
    ) INTO result
    FROM products p
    LEFT JOIN order_items oi ON p.id = oi.product_id
    LEFT JOIN orders o ON oi.order_id = o.id
    WHERE p.id = p_product_id
    AND (p_days = 0 OR o.created_at &gt;= DATE_SUB(NOW(), INTERVAL p_days DAY))
    GROUP BY p.id, p.name;
    
    RETURN result;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Package Documentation and Management:</strong></p>

<p><strong>1. Create Documentation Table:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="CREATE%20TABLE%20procedure_documentation%20(%0A%20%20%20%20procedure_name%20VARCHAR(100)%20PRIMARY%20KEY%2C%0A%20%20%20%20package_name%20VARCHAR(50)%2C%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20parameters%20JSON%2C%0A%20%20%20%20return_type%20VARCHAR(50)%2C%0A%20%20%20%20example_usage%20TEXT%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Document%20procedures%0AINSERT%20INTO%20procedure_documentation%20VALUES%0A('user_pkg_create_user'%2C%20'user_management'%2C%20%0A%20'Creates%20a%20new%20user%20account%20with%20validation'%2C%0A%20'%7B%22p_name%22%3A%20%22VARCHAR(100)%22%2C%20%22p_email%22%3A%20%22VARCHAR(255)%22%2C%20%22p_password%22%3A%20%22VARCHAR(255)%22%7D'%2C%0A%20'INT%20(user_id)'%2C%0A%20'CALL%20user_pkg_create_user(%5C'John%20Doe%5C'%2C%20%5C'john%40example.com%5C'%2C%20%5C'password123%5C')%3B'%2C%0A%20'admin'%2C%20NOW()%2C%20NOW())%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">CREATE TABLE procedure_documentation (
    procedure_name VARCHAR(100) PRIMARY KEY,
    package_name VARCHAR(50),
    description TEXT,
    parameters JSON,
    return_type VARCHAR(50),
    example_usage TEXT,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Document procedures
INSERT INTO procedure_documentation VALUES
('user_pkg_create_user', 'user_management', 
 'Creates a new user account with validation',
 '{"p_name": "VARCHAR(100)", "p_email": "VARCHAR(255)", "p_password": "VARCHAR(255)"}',
 'INT (user_id)',
 'CALL user_pkg_create_user(\'John Doe\', \'john@example.com\', \'password123\');',
 'admin', NOW(), NOW());
</code></pre>
</div>

<p><strong>2. Package Deployment Script:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Package%20deployment%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20deploy_package(IN%20package_name%20VARCHAR(50))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20proc_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20proc_definition%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20package_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20routine_name%2C%20routine_definition%0A%20%20%20%20%20%20%20%20FROM%20information_schema.routines%0A%20%20%20%20%20%20%20%20WHERE%20routine_schema%20%3D%20DATABASE()%0A%20%20%20%20%20%20%20%20AND%20routine_name%20LIKE%20CONCAT(package_name%2C%20'_pkg_%25')%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20CONCAT('Deploying%20package%3A%20'%2C%20package_name)%20as%20status%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20package_cursor%3B%0A%20%20%20%20%0A%20%20%20%20deploy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20package_cursor%20INTO%20proc_name%2C%20proc_definition%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20deploy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20CONCAT('Deployed%3A%20'%2C%20proc_name)%20as%20procedure_status%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20package_cursor%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20'Package%20deployment%20completed'%20as%20final_status%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Package deployment procedure
DELIMITER //
CREATE PROCEDURE deploy_package(IN package_name VARCHAR(50))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE proc_name VARCHAR(100);
    DECLARE proc_definition TEXT;
    
    DECLARE package_cursor CURSOR FOR
        SELECT routine_name, routine_definition
        FROM information_schema.routines
        WHERE routine_schema = DATABASE()
        AND routine_name LIKE CONCAT(package_name, '_pkg_%');
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    SELECT CONCAT('Deploying package: ', package_name) as status;
    
    OPEN package_cursor;
    
    deploy_loop: LOOP
        FETCH package_cursor INTO proc_name, proc_definition;
        
        IF done THEN
            LEAVE deploy_loop;
        END IF;
        
        SELECT CONCAT('Deployed: ', proc_name) as procedure_status;
        
    END LOOP;
    
    CLOSE package_cursor;
    
    SELECT 'Package deployment completed' as final_status;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices for MySQL "Packages":</strong></p>

<p>- Use consistent naming conventions (package_name_function_name)</p>
<p>- Group related functionality together</p>
<p>- Document all procedures and functions</p>
<p>- Implement proper error handling</p>
<p>- Use transactions where appropriate</p>
<p>- Version control your stored procedures</p>
<p>- Create deployment and rollback scripts</p>


<p>---</p>

<h2 id="-368-how-do-you-implement-database-auditing-and-compliance-">**368. How do you implement database auditing and compliance?**</h2>

<p><strong>Answer:</strong> Database auditing and compliance involve tracking data access, changes, and ensuring adherence to regulatory requirements like GDPR, HIPAA, or SOX.</p>

<p><strong>Comprehensive Audit Framework:</strong></p>

<p><strong>1. Audit Infrastructure Setup:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20audit%20log%20table%0ACREATE%20TABLE%20audit_trail%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20event_id%20VARCHAR(36)%20NOT%20NULL%20DEFAULT%20(UUID())%2C%0A%20%20%20%20event_type%20ENUM('SELECT'%2C%20'INSERT'%2C%20'UPDATE'%2C%20'DELETE'%2C%20'LOGIN'%2C%20'LOGOUT'%2C%20'SCHEMA_CHANGE')%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(64)%2C%0A%20%20%20%20record_id%20VARCHAR(255)%2C%0A%20%20%20%20user_id%20VARCHAR(100)%2C%0A%20%20%20%20session_id%20VARCHAR(100)%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20application_name%20VARCHAR(100)%2C%0A%20%20%20%20sql_statement%20TEXT%2C%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20affected_rows%20INT%2C%0A%20%20%20%20execution_time_ms%20INT%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20compliance_tags%20JSON%2C%0A%20%20%20%20risk_level%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'LOW'%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_table_name%20(table_name)%2C%0A%20%20%20%20INDEX%20idx_user_id%20(user_id)%2C%0A%20%20%20%20INDEX%20idx_timestamp%20(event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_risk_level%20(risk_level)%2C%0A%20%20%20%20INDEX%20idx_compliance_tags%20((CAST(compliance_tags%20AS%20CHAR(255)%20ARRAY)))%0A)%3B%0A%0A--%20Sensitive%20data%20access%20log%0ACREATE%20TABLE%20sensitive_data_access%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20audit_id%20BIGINT%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%20NOT%20NULL%2C%0A%20%20%20%20data_category%20VARCHAR(50)%2C%20--%20PII%2C%20PHI%2C%20Financial%2C%20etc.%0A%20%20%20%20field_name%20VARCHAR(100)%2C%0A%20%20%20%20access_reason%20VARCHAR(255)%2C%0A%20%20%20%20approval_required%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20approval_status%20ENUM('PENDING'%2C%20'APPROVED'%2C%20'DENIED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20approved_by%20VARCHAR(100)%2C%0A%20%20%20%20approved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20retention_period%20INT%2C%20--%20Days%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(audit_id)%20REFERENCES%20audit_trail(id)%2C%0A%20%20%20%20INDEX%20idx_classification%20(data_classification)%2C%0A%20%20%20%20INDEX%20idx_category%20(data_category)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main audit log table
CREATE TABLE audit_trail (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    event_id VARCHAR(36) NOT NULL DEFAULT (UUID()),
    event_type ENUM('SELECT', 'INSERT', 'UPDATE', 'DELETE', 'LOGIN', 'LOGOUT', 'SCHEMA_CHANGE') NOT NULL,
    table_name VARCHAR(64),
    record_id VARCHAR(255),
    user_id VARCHAR(100),
    session_id VARCHAR(100),
    ip_address VARCHAR(45),
    user_agent TEXT,
    application_name VARCHAR(100),
    sql_statement TEXT,
    old_values JSON,
    new_values JSON,
    affected_rows INT,
    execution_time_ms INT,
    event_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    compliance_tags JSON,
    risk_level ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'LOW',
    
    INDEX idx_event_type (event_type),
    INDEX idx_table_name (table_name),
    INDEX idx_user_id (user_id),
    INDEX idx_timestamp (event_timestamp),
    INDEX idx_risk_level (risk_level),
    INDEX idx_compliance_tags ((CAST(compliance_tags AS CHAR(255) ARRAY)))
);

-- Sensitive data access log
CREATE TABLE sensitive_data_access (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    audit_id BIGINT,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED') NOT NULL,
    data_category VARCHAR(50), -- PII, PHI, Financial, etc.
    field_name VARCHAR(100),
    access_reason VARCHAR(255),
    approval_required BOOLEAN DEFAULT FALSE,
    approval_status ENUM('PENDING', 'APPROVED', 'DENIED') DEFAULT 'PENDING',
    approved_by VARCHAR(100),
    approved_at TIMESTAMP NULL,
    retention_period INT, -- Days
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (audit_id) REFERENCES audit_trail(id),
    INDEX idx_classification (data_classification),
    INDEX idx_category (data_category),
    INDEX idx_approval_status (approval_status)
);
</code></pre>
</div>

<p><strong>2. Comprehensive Audit Triggers:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generic%20audit%20trigger%20for%20sensitive%20tables%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_audit_trigger(%0A%20%20%20%20IN%20table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20sensitive_columns%20JSON%0A)%0ABEGIN%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('%0A%20%20%20%20CREATE%20TRIGGER%20'%2C%20table_name%2C%20'_audit_insert%0A%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20table_name%2C%20'%0A%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20CALL%20log_audit_event(''INSERT''%2C%20'''%2C%20table_name%2C%20'''%2C%20NEW.id%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NULL%2C%20NEW%2C%20%40audit_user%2C%20%40audit_session%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40audit_ip%2C%20%40audit_app%2C%20%40audit_sql)%3B%0A%20%20%20%20%20%20%20%20CALL%20log_sensitive_access('''%2C%20table_name%2C%20'''%2C%20NEW.id%2C%20''INSERT''%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20sensitive_columns%2C%20''')%3B%0A%20%20%20%20END')%3B%0A%20%20%20%20%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Similar%20for%20UPDATE%20and%20DELETE%20triggers%0AEND%20%2F%2F%0A%0A--%20Audit%20logging%20procedure%0ACREATE%20PROCEDURE%20log_audit_event(%0A%20%20%20%20IN%20p_event_type%20VARCHAR(20)%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_old_values%20JSON%2C%0A%20%20%20%20IN%20p_new_values%20JSON%2C%0A%20%20%20%20IN%20p_user_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_session_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_ip_address%20VARCHAR(45)%2C%0A%20%20%20%20IN%20p_application%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_sql_statement%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20risk_level%20VARCHAR(20)%20DEFAULT%20'LOW'%3B%0A%20%20%20%20DECLARE%20compliance_tags%20JSON%20DEFAULT%20JSON_ARRAY()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Determine%20risk%20level%20based%20on%20table%20and%20operation%0A%20%20%20%20IF%20p_table_name%20IN%20('users'%2C%20'customers'%2C%20'payments')%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'HIGH'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('PII'%2C%20'GDPR')%3B%0A%20%20%20%20ELSEIF%20p_table_name%20LIKE%20'%25financial%25'%20OR%20p_table_name%20LIKE%20'%25payment%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('FINANCIAL'%2C%20'SOX'%2C%20'PCI_DSS')%3B%0A%20%20%20%20ELSEIF%20p_table_name%20LIKE%20'%25medical%25'%20OR%20p_table_name%20LIKE%20'%25health%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20risk_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20SET%20compliance_tags%20%3D%20JSON_ARRAY('PHI'%2C%20'HIPAA')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20audit_trail%20(%0A%20%20%20%20%20%20%20%20event_type%2C%20table_name%2C%20record_id%2C%20user_id%2C%20session_id%2C%0A%20%20%20%20%20%20%20%20ip_address%2C%20application_name%2C%20sql_statement%2C%20old_values%2C%20%0A%20%20%20%20%20%20%20%20new_values%2C%20risk_level%2C%20compliance_tags%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_event_type%2C%20p_table_name%2C%20p_record_id%2C%20p_user_id%2C%20p_session_id%2C%0A%20%20%20%20%20%20%20%20p_ip_address%2C%20p_application%2C%20p_sql_statement%2C%20p_old_values%2C%0A%20%20%20%20%20%20%20%20p_new_values%2C%20risk_level%2C%20compliance_tags%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generic audit trigger for sensitive tables
DELIMITER //
CREATE PROCEDURE create_audit_trigger(
    IN table_name VARCHAR(64),
    IN sensitive_columns JSON
)
BEGIN
    SET @sql = CONCAT('
    CREATE TRIGGER ', table_name, '_audit_insert
    AFTER INSERT ON ', table_name, '
    FOR EACH ROW
    BEGIN
        CALL log_audit_event(''INSERT'', ''', table_name, ''', NEW.id, 
                             NULL, NEW, @audit_user, @audit_session, 
                             @audit_ip, @audit_app, @audit_sql);
        CALL log_sensitive_access(''', table_name, ''', NEW.id, ''INSERT'', 
                                 ''', sensitive_columns, ''');
    END');
    
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Similar for UPDATE and DELETE triggers
END //

-- Audit logging procedure
CREATE PROCEDURE log_audit_event(
    IN p_event_type VARCHAR(20),
    IN p_table_name VARCHAR(64),
    IN p_record_id VARCHAR(255),
    IN p_old_values JSON,
    IN p_new_values JSON,
    IN p_user_id VARCHAR(100),
    IN p_session_id VARCHAR(100),
    IN p_ip_address VARCHAR(45),
    IN p_application VARCHAR(100),
    IN p_sql_statement TEXT
)
BEGIN
    DECLARE risk_level VARCHAR(20) DEFAULT 'LOW';
    DECLARE compliance_tags JSON DEFAULT JSON_ARRAY();
    
    -- Determine risk level based on table and operation
    IF p_table_name IN ('users', 'customers', 'payments') THEN
        SET risk_level = 'HIGH';
        SET compliance_tags = JSON_ARRAY('PII', 'GDPR');
    ELSEIF p_table_name LIKE '%financial%' OR p_table_name LIKE '%payment%' THEN
        SET risk_level = 'CRITICAL';
        SET compliance_tags = JSON_ARRAY('FINANCIAL', 'SOX', 'PCI_DSS');
    ELSEIF p_table_name LIKE '%medical%' OR p_table_name LIKE '%health%' THEN
        SET risk_level = 'CRITICAL';
        SET compliance_tags = JSON_ARRAY('PHI', 'HIPAA');
    END IF;
    
    INSERT INTO audit_trail (
        event_type, table_name, record_id, user_id, session_id,
        ip_address, application_name, sql_statement, old_values, 
        new_values, risk_level, compliance_tags
    ) VALUES (
        p_event_type, p_table_name, p_record_id, p_user_id, p_session_id,
        p_ip_address, p_application, p_sql_statement, p_old_values,
        p_new_values, risk_level, compliance_tags
    );
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. GDPR Compliance Features:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20GDPR%20data%20subject%20rights%20implementation%0ADELIMITER%20%2F%2F%0A%0A--%20Right%20to%20be%20informed%20(audit%20trail)%0ACREATE%20PROCEDURE%20gdpr_data_processing_log(%0A%20%20%20%20IN%20p_subject_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_processing_purpose%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_legal_basis%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_categories%20JSON%0A)%0ABEGIN%0A%20%20%20%20INSERT%20INTO%20gdpr_processing_log%20(%0A%20%20%20%20%20%20%20%20data_subject_id%2C%20processing_purpose%2C%20legal_basis%2C%0A%20%20%20%20%20%20%20%20data_categories%2C%20processed_at%2C%20retention_period%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_subject_id%2C%20p_processing_purpose%2C%20p_legal_basis%2C%0A%20%20%20%20%20%20%20%20p_data_categories%2C%20NOW()%2C%20%0A%20%20%20%20%20%20%20%20CASE%20p_legal_basis%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'consent'%20THEN%20365%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'contract'%20THEN%202555%20%20--%207%20years%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'legal_obligation'%20THEN%202555%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%201095%20%20--%203%20years%20default%0A%20%20%20%20%20%20%20%20END%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0A%0A--%20Right%20of%20access%20(data%20export)%0ACREATE%20PROCEDURE%20gdpr_export_personal_data(IN%20p_subject_id%20VARCHAR(255))%0ABEGIN%0A%20%20%20%20--%20Export%20all%20personal%20data%20for%20the%20subject%0A%20%20%20%20SELECT%20'users'%20as%20table_name%2C%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'id'%2C%20id%2C%20'name'%2C%20name%2C%20'email'%2C%20email%2C%20'phone'%2C%20phone%2C%0A%20%20%20%20%20%20%20%20'address'%2C%20address%2C%20'created_at'%2C%20created_at%0A%20%20%20%20)%20as%20data%0A%20%20%20%20FROM%20users%20WHERE%20id%20%3D%20p_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'orders'%20as%20table_name%2C%20JSON_ARRAYAGG(JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'id'%2C%20id%2C%20'total'%2C%20total%2C%20'order_date'%2C%20order_date%2C%0A%20%20%20%20%20%20%20%20'shipping_address'%2C%20shipping_address%0A%20%20%20%20))%20as%20data%0A%20%20%20%20FROM%20orders%20WHERE%20customer_id%20%3D%20p_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'audit_trail'%20as%20table_name%2C%20JSON_ARRAYAGG(JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'event_type'%2C%20event_type%2C%20'timestamp'%2C%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20'table_name'%2C%20table_name%2C%20'ip_address'%2C%20ip_address%0A%20%20%20%20))%20as%20data%0A%20%20%20%20FROM%20audit_trail%20WHERE%20user_id%20%3D%20p_subject_id%3B%0AEND%20%2F%2F%0A%0A--%20Right%20to%20erasure%20(right%20to%20be%20forgotten)%0ACREATE%20PROCEDURE%20gdpr_erase_personal_data(%0A%20%20%20%20IN%20p_subject_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_erasure_reason%20VARCHAR(255)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20erasure%20request%0A%20%20%20%20INSERT%20INTO%20gdpr_erasure_log%20(%0A%20%20%20%20%20%20%20%20data_subject_id%2C%20erasure_reason%2C%20requested_at%2C%20status%0A%20%20%20%20)%20VALUES%20(p_subject_id%2C%20p_erasure_reason%2C%20NOW()%2C%20'IN_PROGRESS')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20instead%20of%20delete%20to%20maintain%20referential%20integrity%0A%20%20%20%20UPDATE%20users%20%0A%20%20%20%20SET%20name%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20email%20%3D%20CONCAT('erased_'%2C%20id%2C%20'%40deleted.local')%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20address%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20date_of_birth%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20id%20%3D%20p_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20related%20records%0A%20%20%20%20UPDATE%20orders%20%0A%20%20%20%20SET%20shipping_address%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20billing_address%20%3D%20'ERASED'%0A%20%20%20%20WHERE%20customer_id%20%3D%20p_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20erasure%20log%0A%20%20%20%20UPDATE%20gdpr_erasure_log%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%20completed_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20data_subject_id%20%3D%20p_subject_id%20%0A%20%20%20%20AND%20status%20%3D%20'IN_PROGRESS'%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- GDPR data subject rights implementation
DELIMITER //

-- Right to be informed (audit trail)
CREATE PROCEDURE gdpr_data_processing_log(
    IN p_subject_id VARCHAR(255),
    IN p_processing_purpose VARCHAR(255),
    IN p_legal_basis VARCHAR(100),
    IN p_data_categories JSON
)
BEGIN
    INSERT INTO gdpr_processing_log (
        data_subject_id, processing_purpose, legal_basis,
        data_categories, processed_at, retention_period
    ) VALUES (
        p_subject_id, p_processing_purpose, p_legal_basis,
        p_data_categories, NOW(), 
        CASE p_legal_basis
            WHEN 'consent' THEN 365
            WHEN 'contract' THEN 2555  -- 7 years
            WHEN 'legal_obligation' THEN 2555
            ELSE 1095  -- 3 years default
        END
    );
END //

-- Right of access (data export)
CREATE PROCEDURE gdpr_export_personal_data(IN p_subject_id VARCHAR(255))
BEGIN
    -- Export all personal data for the subject
    SELECT 'users' as table_name, JSON_OBJECT(
        'id', id, 'name', name, 'email', email, 'phone', phone,
        'address', address, 'created_at', created_at
    ) as data
    FROM users WHERE id = p_subject_id
    
    UNION ALL
    
    SELECT 'orders' as table_name, JSON_ARRAYAGG(JSON_OBJECT(
        'id', id, 'total', total, 'order_date', order_date,
        'shipping_address', shipping_address
    )) as data
    FROM orders WHERE customer_id = p_subject_id
    
    UNION ALL
    
    SELECT 'audit_trail' as table_name, JSON_ARRAYAGG(JSON_OBJECT(
        'event_type', event_type, 'timestamp', event_timestamp,
        'table_name', table_name, 'ip_address', ip_address
    )) as data
    FROM audit_trail WHERE user_id = p_subject_id;
END //

-- Right to erasure (right to be forgotten)
CREATE PROCEDURE gdpr_erase_personal_data(
    IN p_subject_id VARCHAR(255),
    IN p_erasure_reason VARCHAR(255)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Log erasure request
    INSERT INTO gdpr_erasure_log (
        data_subject_id, erasure_reason, requested_at, status
    ) VALUES (p_subject_id, p_erasure_reason, NOW(), 'IN_PROGRESS');
    
    -- Anonymize instead of delete to maintain referential integrity
    UPDATE users 
    SET name = 'ERASED',
        email = CONCAT('erased_', id, '@deleted.local'),
        phone = NULL,
        address = NULL,
        date_of_birth = NULL,
        erased_at = NOW()
    WHERE id = p_subject_id;
    
    -- Update related records
    UPDATE orders 
    SET shipping_address = 'ERASED',
        billing_address = 'ERASED'
    WHERE customer_id = p_subject_id;
    
    -- Update erasure log
    UPDATE gdpr_erasure_log 
    SET status = 'COMPLETED', completed_at = NOW()
    WHERE data_subject_id = p_subject_id 
    AND status = 'IN_PROGRESS';
    
    COMMIT;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Compliance Monitoring and Reporting:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Compliance%20dashboard%20views%0ACREATE%20VIEW%20compliance_summary%20AS%0ASELECT%20%0A%20%20%20%20DATE(event_timestamp)%20as%20audit_date%2C%0A%20%20%20%20event_type%2C%0A%20%20%20%20risk_level%2C%0A%20%20%20%20COUNT(*)%20as%20event_count%2C%0A%20%20%20%20COUNT(DISTINCT%20user_id)%20as%20unique_users%2C%0A%20%20%20%20COUNT(DISTINCT%20table_name)%20as%20tables_affected%0AFROM%20audit_trail%0AWHERE%20event_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20DATE(event_timestamp)%2C%20event_type%2C%20risk_level%3B%0A%0A--%20Suspicious%20activity%20detection%0ACREATE%20VIEW%20suspicious_activity%20AS%0ASELECT%20%0A%20%20%20%20user_id%2C%0A%20%20%20%20ip_address%2C%0A%20%20%20%20COUNT(*)%20as%20event_count%2C%0A%20%20%20%20COUNT(DISTINCT%20table_name)%20as%20tables_accessed%2C%0A%20%20%20%20MIN(event_timestamp)%20as%20first_event%2C%0A%20%20%20%20MAX(event_timestamp)%20as%20last_event%2C%0A%20%20%20%20GROUP_CONCAT(DISTINCT%20event_type)%20as%20event_types%0AFROM%20audit_trail%0AWHERE%20event_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0AGROUP%20BY%20user_id%2C%20ip_address%0AHAVING%20event_count%20%3E%20100%20%20--%20Threshold%20for%20suspicious%20activity%0AOR%20tables_accessed%20%3E%2010%3B%0A%0A--%20Data%20retention%20compliance%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20cleanup_expired_audit_data()%0ABEGIN%0A%20%20%20%20DECLARE%20records_deleted%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20audit%20records%20older%20than%20retention%20period%0A%20%20%20%20DELETE%20FROM%20audit_trail%20%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%207%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('LOW'%2C%20'MEDIUM')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_deleted%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20cleanup%20activity%0A%20%20%20%20INSERT%20INTO%20maintenance_log%20(%0A%20%20%20%20%20%20%20%20activity%2C%20records_affected%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'audit_data_cleanup'%2C%20records_deleted%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20high-risk%20records%20instead%20of%20deleting%0A%20%20%20%20INSERT%20INTO%20audit_archive%20%0A%20%20%20%20SELECT%20*%20FROM%20audit_trail%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('HIGH'%2C%20'CRITICAL')%3B%0A%20%20%20%20%0A%20%20%20%20DELETE%20FROM%20audit_trail%0A%20%20%20%20WHERE%20event_timestamp%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20risk_level%20IN%20('HIGH'%2C%20'CRITICAL')%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Compliance dashboard views
CREATE VIEW compliance_summary AS
SELECT 
    DATE(event_timestamp) as audit_date,
    event_type,
    risk_level,
    COUNT(*) as event_count,
    COUNT(DISTINCT user_id) as unique_users,
    COUNT(DISTINCT table_name) as tables_affected
FROM audit_trail
WHERE event_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY DATE(event_timestamp), event_type, risk_level;

-- Suspicious activity detection
CREATE VIEW suspicious_activity AS
SELECT 
    user_id,
    ip_address,
    COUNT(*) as event_count,
    COUNT(DISTINCT table_name) as tables_accessed,
    MIN(event_timestamp) as first_event,
    MAX(event_timestamp) as last_event,
    GROUP_CONCAT(DISTINCT event_type) as event_types
FROM audit_trail
WHERE event_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
GROUP BY user_id, ip_address
HAVING event_count &gt; 100  -- Threshold for suspicious activity
OR tables_accessed &gt; 10;

-- Data retention compliance
DELIMITER //
CREATE PROCEDURE cleanup_expired_audit_data()
BEGIN
    DECLARE records_deleted INT DEFAULT 0;
    
    -- Delete audit records older than retention period
    DELETE FROM audit_trail 
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 7 YEAR)
    AND risk_level IN ('LOW', 'MEDIUM');
    
    SET records_deleted = ROW_COUNT();
    
    -- Log cleanup activity
    INSERT INTO maintenance_log (
        activity, records_affected, completed_at
    ) VALUES (
        'audit_data_cleanup', records_deleted, NOW()
    );
    
    -- Archive high-risk records instead of deleting
    INSERT INTO audit_archive 
    SELECT * FROM audit_trail
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND risk_level IN ('HIGH', 'CRITICAL');
    
    DELETE FROM audit_trail
    WHERE event_timestamp &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND risk_level IN ('HIGH', 'CRITICAL');
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Implement audit trails for all sensitive data access</p>
<p>- Use immutable audit logs (append-only)</p>
<p>- Encrypt audit data at rest and in transit</p>
<p>- Regular compliance reporting and monitoring</p>
<p>- Implement data retention and purging policies</p>
<p>- Separate audit database from operational database</p>
<p>- Monitor for suspicious access patterns</p>
<p>- Document all compliance procedures</p>


<p>---</p>

<h2 id="-369-what-are-database-federation-and-distributed-queries-">**369. What are database federation and distributed queries?**</h2>

<p><strong>Answer:</strong> Database federation allows querying across multiple databases as if they were a single system, while distributed queries execute across multiple database instances.</p>

<p><strong>MySQL Federation Setup:</strong></p>

<p><strong>1. FEDERATED Storage Engine:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Enable%20FEDERATED%20storage%20engine%20(if%20not%20already%20enabled)%0A--%20Add%20to%20my.cnf%3A%20federated%0A%0A--%20Create%20federated%20table%20pointing%20to%20remote%20database%0ACREATE%20TABLE%20remote_customers%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20created_at%20TIMESTAMP%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fusername%3Apassword%40remote_host%3A3306%2Fremote_db%2Fcustomers'%3B%0A%0A--%20Query%20federated%20table%20as%20if%20it%20were%20local%0ASELECT%20*%20FROM%20remote_customers%20WHERE%20region%20%3D%20'US'%3B%0A%0A--%20Join%20local%20and%20remote%20data%0ASELECT%20%0A%20%20%20%20lc.id%2C%0A%20%20%20%20lc.name%2C%0A%20%20%20%20rc.region%2C%0A%20%20%20%20COUNT(lo.id)%20as%20local_orders%0AFROM%20local_customers%20lc%0AJOIN%20remote_customers%20rc%20ON%20lc.email%20%3D%20rc.email%0ALEFT%20JOIN%20local_orders%20lo%20ON%20lc.id%20%3D%20lo.customer_id%0AGROUP%20BY%20lc.id%2C%20lc.name%2C%20rc.region%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Enable FEDERATED storage engine (if not already enabled)
-- Add to my.cnf: federated

-- Create federated table pointing to remote database
CREATE TABLE remote_customers (
    id INT NOT NULL,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50),
    created_at TIMESTAMP
) ENGINE=FEDERATED
CONNECTION='mysql://username:password@remote_host:3306/remote_db/customers';

-- Query federated table as if it were local
SELECT * FROM remote_customers WHERE region = 'US';

-- Join local and remote data
SELECT 
    lc.id,
    lc.name,
    rc.region,
    COUNT(lo.id) as local_orders
FROM local_customers lc
JOIN remote_customers rc ON lc.email = rc.email
LEFT JOIN local_orders lo ON lc.id = lo.customer_id
GROUP BY lc.id, lc.name, rc.region;
</code></pre>
</div>

<p><strong>2. Multi-Database Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20across%20multiple%20databases%20on%20same%20server%0ASELECT%20%0A%20%20%20%20u.name%2C%0A%20%20%20%20u.email%2C%0A%20%20%20%20COUNT(sales_db.orders.id)%20as%20order_count%2C%0A%20%20%20%20SUM(sales_db.orders.total)%20as%20total_spent%2C%0A%20%20%20%20MAX(analytics_db.user_sessions.last_activity)%20as%20last_activity%0AFROM%20user_db.users%20u%0ALEFT%20JOIN%20sales_db.orders%20ON%20u.id%20%3D%20sales_db.orders.customer_id%0ALEFT%20JOIN%20analytics_db.user_sessions%20ON%20u.id%20%3D%20analytics_db.user_sessions.user_id%0AWHERE%20u.status%20%3D%20'active'%0AGROUP%20BY%20u.id%2C%20u.name%2C%20u.email%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query across multiple databases on same server
SELECT 
    u.name,
    u.email,
    COUNT(sales_db.orders.id) as order_count,
    SUM(sales_db.orders.total) as total_spent,
    MAX(analytics_db.user_sessions.last_activity) as last_activity
FROM user_db.users u
LEFT JOIN sales_db.orders ON u.id = sales_db.orders.customer_id
LEFT JOIN analytics_db.user_sessions ON u.id = analytics_db.user_sessions.user_id
WHERE u.status = 'active'
GROUP BY u.id, u.name, u.email;
</code></pre>
</div>

<p><strong>Distributed Query Patterns:</strong></p>

<p><strong>1. Horizontal Partitioning (Sharding):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Shard%20customers%20by%20region%0A--%20Shard%201%3A%20US%20customers%0ACREATE%20TABLE%20us_customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%20DEFAULT%20'US'%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Shard%202%3A%20EU%20customers%20%20%0ACREATE%20TABLE%20eu_customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%20DEFAULT%20'EU'%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Federated%20view%20combining%20shards%0ACREATE%20TABLE%20all_customers%20(%0A%20%20%20%20id%20INT%20NOT%20NULL%2C%0A%20%20%20%20name%20VARCHAR(100)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20region%20VARCHAR(50)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40shard1%3A3306%2Fdb%2Fus_customers'%3B%0A%0A--%20Union%20view%20for%20querying%20all%20shards%0ACREATE%20VIEW%20global_customers%20AS%0ASELECT%20id%2C%20name%2C%20email%2C%20region%2C%20'shard1'%20as%20shard_location%20FROM%20us_customers%0AUNION%20ALL%0ASELECT%20id%2C%20name%2C%20email%2C%20region%2C%20'shard2'%20as%20shard_location%20FROM%20eu_customers%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Shard customers by region
-- Shard 1: US customers
CREATE TABLE us_customers (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50) DEFAULT 'US'
) ENGINE=InnoDB;

-- Shard 2: EU customers  
CREATE TABLE eu_customers (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50) DEFAULT 'EU'
) ENGINE=InnoDB;

-- Federated view combining shards
CREATE TABLE all_customers (
    id INT NOT NULL,
    name VARCHAR(100),
    email VARCHAR(255),
    region VARCHAR(50)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@shard1:3306/db/us_customers';

-- Union view for querying all shards
CREATE VIEW global_customers AS
SELECT id, name, email, region, 'shard1' as shard_location FROM us_customers
UNION ALL
SELECT id, name, email, region, 'shard2' as shard_location FROM eu_customers;
</code></pre>
</div>

<p><strong>2. Application-Level Federation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Stored%20procedure%20for%20distributed%20queries%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20query_distributed_orders(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20--%20Create%20temporary%20table%20for%20results%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20temp_distributed_results%20(%0A%20%20%20%20%20%20%20%20shard_name%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20order_count%20INT%2C%0A%20%20%20%20%20%20%20%20total_revenue%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%20%20%20%20avg_order_value%20DECIMAL(10%2C2)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Query%20Shard%201%20(US)%0A%20%20%20%20INSERT%20INTO%20temp_distributed_results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'US_SHARD'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20federated_us_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Query%20Shard%202%20(EU)%0A%20%20%20%20INSERT%20INTO%20temp_distributed_results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'EU_SHARD'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total)%20as%20avg_order_value%0A%20%20%20%20FROM%20federated_eu_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20aggregated%20results%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20shard_name%2C%0A%20%20%20%20%20%20%20%20order_count%2C%0A%20%20%20%20%20%20%20%20total_revenue%2C%0A%20%20%20%20%20%20%20%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20(total_revenue%20%2F%20SUM(total_revenue)%20OVER())%20*%20100%20as%20revenue_percentage%0A%20%20%20%20FROM%20temp_distributed_results%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'TOTAL'%20as%20shard_name%2C%0A%20%20%20%20%20%20%20%20SUM(order_count)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total_revenue)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(avg_order_value)%20as%20avg_order_value%2C%0A%20%20%20%20%20%20%20%20100.0%20as%20revenue_percentage%0A%20%20%20%20FROM%20temp_distributed_results%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20temp_distributed_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Stored procedure for distributed queries
DELIMITER //
CREATE PROCEDURE query_distributed_orders(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    -- Create temporary table for results
    CREATE TEMPORARY TABLE temp_distributed_results (
        shard_name VARCHAR(50),
        order_count INT,
        total_revenue DECIMAL(12,2),
        avg_order_value DECIMAL(10,2)
    );
    
    -- Query Shard 1 (US)
    INSERT INTO temp_distributed_results
    SELECT 
        'US_SHARD' as shard_name,
        COUNT(*) as order_count,
        SUM(total) as total_revenue,
        AVG(total) as avg_order_value
    FROM federated_us_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date;
    
    -- Query Shard 2 (EU)
    INSERT INTO temp_distributed_results
    SELECT 
        'EU_SHARD' as shard_name,
        COUNT(*) as order_count,
        SUM(total) as total_revenue,
        AVG(total) as avg_order_value
    FROM federated_eu_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date;
    
    -- Return aggregated results
    SELECT 
        shard_name,
        order_count,
        total_revenue,
        avg_order_value,
        (total_revenue / SUM(total_revenue) OVER()) * 100 as revenue_percentage
    FROM temp_distributed_results
    
    UNION ALL
    
    SELECT 
        'TOTAL' as shard_name,
        SUM(order_count) as order_count,
        SUM(total_revenue) as total_revenue,
        AVG(avg_order_value) as avg_order_value,
        100.0 as revenue_percentage
    FROM temp_distributed_results;
    
    DROP TEMPORARY TABLE temp_distributed_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Cross-Database Analytics:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Federated%20analytics%20across%20multiple%20systems%0ACREATE%20TABLE%20federated_sales_data%20(%0A%20%20%20%20sale_id%20INT%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20sale_amount%20DECIMAL(10%2C2)%2C%0A%20%20%20%20sale_date%20DATE%2C%0A%20%20%20%20source_system%20VARCHAR(50)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40analytics_server%3A3306%2Fwarehouse%2Fsales_data'%3B%0A%0ACREATE%20TABLE%20federated_customer_data%20(%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20lifetime_value%20DECIMAL(12%2C2)%2C%0A%20%20%20%20acquisition_channel%20VARCHAR(100)%0A)%20ENGINE%3DFEDERATED%0ACONNECTION%3D'mysql%3A%2F%2Fuser%3Apass%40crm_server%3A3306%2Fcrm%2Fcustomer_profiles'%3B%0A%0A--%20Cross-system%20analytics%20query%0ASELECT%20%0A%20%20%20%20cd.customer_segment%2C%0A%20%20%20%20cd.acquisition_channel%2C%0A%20%20%20%20COUNT(DISTINCT%20sd.customer_id)%20as%20active_customers%2C%0A%20%20%20%20SUM(sd.sale_amount)%20as%20total_revenue%2C%0A%20%20%20%20AVG(sd.sale_amount)%20as%20avg_transaction%2C%0A%20%20%20%20AVG(cd.lifetime_value)%20as%20avg_lifetime_value%0AFROM%20federated_sales_data%20sd%0AJOIN%20federated_customer_data%20cd%20ON%20sd.customer_id%20%3D%20cd.customer_id%0AWHERE%20sd.sale_date%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2090%20DAY)%0AGROUP%20BY%20cd.customer_segment%2C%20cd.acquisition_channel%0AORDER%20BY%20total_revenue%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Federated analytics across multiple systems
CREATE TABLE federated_sales_data (
    sale_id INT,
    product_id INT,
    customer_id INT,
    sale_amount DECIMAL(10,2),
    sale_date DATE,
    source_system VARCHAR(50)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@analytics_server:3306/warehouse/sales_data';

CREATE TABLE federated_customer_data (
    customer_id INT,
    customer_segment VARCHAR(50),
    lifetime_value DECIMAL(12,2),
    acquisition_channel VARCHAR(100)
) ENGINE=FEDERATED
CONNECTION='mysql://user:pass@crm_server:3306/crm/customer_profiles';

-- Cross-system analytics query
SELECT 
    cd.customer_segment,
    cd.acquisition_channel,
    COUNT(DISTINCT sd.customer_id) as active_customers,
    SUM(sd.sale_amount) as total_revenue,
    AVG(sd.sale_amount) as avg_transaction,
    AVG(cd.lifetime_value) as avg_lifetime_value
FROM federated_sales_data sd
JOIN federated_customer_data cd ON sd.customer_id = cd.customer_id
WHERE sd.sale_date &gt;= DATE_SUB(NOW(), INTERVAL 90 DAY)
GROUP BY cd.customer_segment, cd.acquisition_channel
ORDER BY total_revenue DESC;
</code></pre>
</div>

<p><strong>Performance Optimization for Distributed Queries:</strong></p>

<p><strong>1. Query Pushdown Optimization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Push%20filtering%20to%20remote%20servers%0A--%20BAD%3A%20Brings%20all%20data%20locally%20then%20filters%0ASELECT%20*%20FROM%20(%0A%20%20%20%20SELECT%20*%20FROM%20remote_orders%0A)%20filtered%20WHERE%20order_date%20%3E%3D%20'2024-01-01'%3B%0A%0A--%20GOOD%3A%20Filter%20is%20pushed%20to%20remote%20server%0ASELECT%20*%20FROM%20remote_orders%20%0AWHERE%20order_date%20%3E%3D%20'2024-01-01'%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Push filtering to remote servers
-- BAD: Brings all data locally then filters
SELECT * FROM (
    SELECT * FROM remote_orders
) filtered WHERE order_date &gt;= '2024-01-01';

-- GOOD: Filter is pushed to remote server
SELECT * FROM remote_orders 
WHERE order_date &gt;= '2024-01-01';
</code></pre>
</div>

<p><strong>2. Distributed Aggregation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Efficient%20distributed%20aggregation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20distributed_sales_summary(%0A%20%20%20%20IN%20p_start_date%20DATE%2C%0A%20%20%20%20IN%20p_end_date%20DATE%0A)%0ABEGIN%0A%20%20%20%20--%20Pre-aggregate%20on%20each%20shard%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20shard_summaries%20(%0A%20%20%20%20%20%20%20%20shard_id%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20daily_date%20DATE%2C%0A%20%20%20%20%20%20%20%20order_count%20INT%2C%0A%20%20%20%20%20%20%20%20total_revenue%20DECIMAL(12%2C2)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20from%20US%20shard%0A%20%20%20%20INSERT%20INTO%20shard_summaries%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'US'%20as%20shard_id%2C%0A%20%20%20%20%20%20%20%20DATE(order_date)%20as%20daily_date%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%0A%20%20%20%20FROM%20federated_us_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20GROUP%20BY%20DATE(order_date)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Aggregate%20from%20EU%20shard%0A%20%20%20%20INSERT%20INTO%20shard_summaries%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'EU'%20as%20shard_id%2C%0A%20%20%20%20%20%20%20%20DATE(order_date)%20as%20daily_date%2C%0A%20%20%20%20%20%20%20%20COUNT(*)%20as%20order_count%2C%0A%20%20%20%20%20%20%20%20SUM(total)%20as%20total_revenue%0A%20%20%20%20FROM%20federated_eu_orders%0A%20%20%20%20WHERE%20order_date%20BETWEEN%20p_start_date%20AND%20p_end_date%0A%20%20%20%20GROUP%20BY%20DATE(order_date)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Final%20aggregation%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20daily_date%2C%0A%20%20%20%20%20%20%20%20SUM(order_count)%20as%20total_orders%2C%0A%20%20%20%20%20%20%20%20SUM(total_revenue)%20as%20total_revenue%2C%0A%20%20%20%20%20%20%20%20AVG(total_revenue%2Forder_count)%20as%20avg_order_value%0A%20%20%20%20FROM%20shard_summaries%0A%20%20%20%20GROUP%20BY%20daily_date%0A%20%20%20%20ORDER%20BY%20daily_date%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20shard_summaries%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Efficient distributed aggregation
DELIMITER //
CREATE PROCEDURE distributed_sales_summary(
    IN p_start_date DATE,
    IN p_end_date DATE
)
BEGIN
    -- Pre-aggregate on each shard
    CREATE TEMPORARY TABLE shard_summaries (
        shard_id VARCHAR(50),
        daily_date DATE,
        order_count INT,
        total_revenue DECIMAL(12,2)
    );
    
    -- Aggregate from US shard
    INSERT INTO shard_summaries
    SELECT 
        'US' as shard_id,
        DATE(order_date) as daily_date,
        COUNT(*) as order_count,
        SUM(total) as total_revenue
    FROM federated_us_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date
    GROUP BY DATE(order_date);
    
    -- Aggregate from EU shard
    INSERT INTO shard_summaries
    SELECT 
        'EU' as shard_id,
        DATE(order_date) as daily_date,
        COUNT(*) as order_count,
        SUM(total) as total_revenue
    FROM federated_eu_orders
    WHERE order_date BETWEEN p_start_date AND p_end_date
    GROUP BY DATE(order_date);
    
    -- Final aggregation
    SELECT 
        daily_date,
        SUM(order_count) as total_orders,
        SUM(total_revenue) as total_revenue,
        AVG(total_revenue/order_count) as avg_order_value
    FROM shard_summaries
    GROUP BY daily_date
    ORDER BY daily_date;
    
    DROP TEMPORARY TABLE shard_summaries;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Challenges and Solutions:</strong></p>

<p><strong>1. Transaction Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Distributed%20transaction%20simulation%20(MySQL%20doesn't%20support%20XA%20fully)%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20distributed_transfer(%0A%20%20%20%20IN%20p_from_account%20INT%2C%0A%20%20%20%20IN%20p_to_account%20INT%2C%0A%20%20%20%20IN%20p_amount%20DECIMAL(10%2C2)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20--%20Rollback%20all%20shards%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20CALL%20rollback_shard1_transaction()%3B%0A%20%20%20%20%20%20%20%20CALL%20rollback_shard2_transaction()%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Phase%201%3A%20Prepare%20all%20shards%0A%20%20%20%20CALL%20prepare_shard1_debit(p_from_account%2C%20p_amount)%3B%0A%20%20%20%20CALL%20prepare_shard2_credit(p_to_account%2C%20p_amount)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Phase%202%3A%20Commit%20all%20shards%0A%20%20%20%20CALL%20commit_shard1_transaction()%3B%0A%20%20%20%20CALL%20commit_shard2_transaction()%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Distributed transaction simulation (MySQL doesn't support XA fully)
DELIMITER //
CREATE PROCEDURE distributed_transfer(
    IN p_from_account INT,
    IN p_to_account INT,
    IN p_amount DECIMAL(10,2)
)
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        -- Rollback all shards
        ROLLBACK;
        CALL rollback_shard1_transaction();
        CALL rollback_shard2_transaction();
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Phase 1: Prepare all shards
    CALL prepare_shard1_debit(p_from_account, p_amount);
    CALL prepare_shard2_credit(p_to_account, p_amount);
    
    -- Phase 2: Commit all shards
    CALL commit_shard1_transaction();
    CALL commit_shard2_transaction();
    
    COMMIT;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Minimize cross-shard queries</p>
<p>- Use connection pooling for federated tables</p>
<p>- Implement proper error handling for network failures</p>
<p>- Cache frequently accessed remote data locally</p>
<p>- Monitor network latency and query performance</p>
<p>- Consider eventual consistency for distributed systems</p>
<p>- Use appropriate indexing on federated tables</p>


<p>---</p>

<h2 id="-370-how-do-you-implement-database-monitoring-and-alerting-">**370. How do you implement database monitoring and alerting?**</h2>

<p><strong>Answer:</strong> Database monitoring and alerting involve tracking performance metrics, resource usage, and system health to proactively identify and resolve issues.</p>

<p><strong>Performance Schema Monitoring:</strong></p>

<p><strong>1. Key Metrics Collection:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Query%20performance%20monitoring%0ASELECT%20%0A%20%20%20%20DIGEST_TEXT%20as%20query_pattern%2C%0A%20%20%20%20COUNT_STAR%20as%20execution_count%2C%0A%20%20%20%20AVG_TIMER_WAIT%2F1000000000%20as%20avg_execution_time_sec%2C%0A%20%20%20%20MAX_TIMER_WAIT%2F1000000000%20as%20max_execution_time_sec%2C%0A%20%20%20%20SUM_ROWS_EXAMINED%2FCOUNT_STAR%20as%20avg_rows_examined%2C%0A%20%20%20%20SUM_ROWS_SENT%2FCOUNT_STAR%20as%20avg_rows_returned%2C%0A%20%20%20%20FIRST_SEEN%2C%0A%20%20%20%20LAST_SEEN%0AFROM%20performance_schema.events_statements_summary_by_digest%0AWHERE%20DIGEST_TEXT%20IS%20NOT%20NULL%0AORDER%20BY%20AVG_TIMER_WAIT%20DESC%0ALIMIT%2020%3B%0A%0A--%20Connection%20monitoring%0ASELECT%20%0A%20%20%20%20USER%2C%0A%20%20%20%20HOST%2C%0A%20%20%20%20COUNT(*)%20as%20connection_count%2C%0A%20%20%20%20SUM(CASE%20WHEN%20COMMAND%20%3D%20'Sleep'%20THEN%201%20ELSE%200%20END)%20as%20idle_connections%2C%0A%20%20%20%20AVG(TIME)%20as%20avg_connection_time%0AFROM%20information_schema.processlist%0AGROUP%20BY%20USER%2C%20HOST%0AORDER%20BY%20connection_count%20DESC%3B%0A%0A--%20Table%20I%2FO%20statistics%0ASELECT%20%0A%20%20%20%20OBJECT_SCHEMA%2C%0A%20%20%20%20OBJECT_NAME%2C%0A%20%20%20%20COUNT_READ%2C%0A%20%20%20%20COUNT_WRITE%2C%0A%20%20%20%20COUNT_FETCH%2C%0A%20%20%20%20SUM_TIMER_READ%2F1000000000%20as%20total_read_time_sec%2C%0A%20%20%20%20SUM_TIMER_WRITE%2F1000000000%20as%20total_write_time_sec%0AFROM%20performance_schema.table_io_waits_summary_by_table%0AWHERE%20OBJECT_SCHEMA%20NOT%20IN%20('mysql'%2C%20'performance_schema'%2C%20'information_schema')%0AORDER%20BY%20(COUNT_READ%20%2B%20COUNT_WRITE)%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Query performance monitoring
SELECT 
    DIGEST_TEXT as query_pattern,
    COUNT_STAR as execution_count,
    AVG_TIMER_WAIT/1000000000 as avg_execution_time_sec,
    MAX_TIMER_WAIT/1000000000 as max_execution_time_sec,
    SUM_ROWS_EXAMINED/COUNT_STAR as avg_rows_examined,
    SUM_ROWS_SENT/COUNT_STAR as avg_rows_returned,
    FIRST_SEEN,
    LAST_SEEN
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
ORDER BY AVG_TIMER_WAIT DESC
LIMIT 20;

-- Connection monitoring
SELECT 
    USER,
    HOST,
    COUNT(*) as connection_count,
    SUM(CASE WHEN COMMAND = 'Sleep' THEN 1 ELSE 0 END) as idle_connections,
    AVG(TIME) as avg_connection_time
FROM information_schema.processlist
GROUP BY USER, HOST
ORDER BY connection_count DESC;

-- Table I/O statistics
SELECT 
    OBJECT_SCHEMA,
    OBJECT_NAME,
    COUNT_READ,
    COUNT_WRITE,
    COUNT_FETCH,
    SUM_TIMER_READ/1000000000 as total_read_time_sec,
    SUM_TIMER_WRITE/1000000000 as total_write_time_sec
FROM performance_schema.table_io_waits_summary_by_table
WHERE OBJECT_SCHEMA NOT IN ('mysql', 'performance_schema', 'information_schema')
ORDER BY (COUNT_READ + COUNT_WRITE) DESC;
</code></pre>
</div>

<p><strong>2. Custom Monitoring Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20System%20metrics%20collection%0ACREATE%20TABLE%20system_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_unit%20VARCHAR(20)%2C%0A%20%20%20%20server_name%20VARCHAR(100)%2C%0A%20%20%20%20collected_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_time%20(metric_name%2C%20collected_at)%2C%0A%20%20%20%20INDEX%20idx_server_time%20(server_name%2C%20collected_at)%0A)%3B%0A%0A--%20Performance%20baselines%0ACREATE%20TABLE%20performance_baselines%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20baseline_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_warning%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_critical%20DECIMAL(15%2C4)%2C%0A%20%20%20%20measurement_period%20ENUM('1min'%2C%20'5min'%2C%20'15min'%2C%20'1hour'%2C%20'1day')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_metric_period%20(metric_name%2C%20measurement_period)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- System metrics collection
CREATE TABLE system_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(15,4),
    metric_unit VARCHAR(20),
    server_name VARCHAR(100),
    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_time (metric_name, collected_at),
    INDEX idx_server_time (server_name, collected_at)
);

-- Performance baselines
CREATE TABLE performance_baselines (
    id INT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    baseline_value DECIMAL(15,4),
    threshold_warning DECIMAL(15,4),
    threshold_critical DECIMAL(15,4),
    measurement_period ENUM('1min', '5min', '15min', '1hour', '1day'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_metric_period (metric_name, measurement_period)
);
</code></pre>
</div>

<p><strong>3. Automated Metrics Collection:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Collect%20system%20metrics%0ACREATE%20PROCEDURE%20collect_system_metrics()%0ABEGIN%0A%20%20%20%20DECLARE%20server_name%20VARCHAR(100)%20DEFAULT%20%40%40hostname%3B%0A%20%20%20%20%0A%20%20%20%20--%20Connection%20metrics%0A%20%20%20%20INSERT%20INTO%20system_metrics%20(metric_name%2C%20metric_value%2C%20metric_unit%2C%20server_name)%0A%20%20%20%20SELECT%20'connections_current'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20SELECT%20'connections_max_used'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Max_used_connections'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Query%20metrics%0A%20%20%20%20SELECT%20'queries_per_second'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20VARIABLE_VALUE%20%2F%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Uptime')%2C%0A%20%20%20%20%20%20%20%20%20%20%20'qps'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Questions'%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20InnoDB%20metrics%0A%20%20%20%20SELECT%20'innodb_buffer_pool_hit_rate'%2C%0A%20%20%20%20%20%20%20%20%20%20%20(1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20*%20100%2C%0A%20%20%20%20%20%20%20%20%20%20%20'percent'%2C%20server_name%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Slow%20query%20metrics%0A%20%20%20%20SELECT%20'slow_queries'%2C%20VARIABLE_VALUE%2C%20'count'%2C%20server_name%0A%20%20%20%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Slow_queries'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Check%20performance%20thresholds%0ACREATE%20PROCEDURE%20check_performance_thresholds()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20metric_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20current_value%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20warning_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20critical_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20alert_level%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20threshold_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.metric_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20AVG(sm.metric_value)%20as%20current_avg%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.threshold_warning%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20pb.threshold_critical%0A%20%20%20%20%20%20%20%20FROM%20performance_baselines%20pb%0A%20%20%20%20%20%20%20%20JOIN%20system_metrics%20sm%20ON%20pb.metric_name%20%3D%20sm.metric_name%0A%20%20%20%20%20%20%20%20WHERE%20sm.collected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%205%20MINUTE)%0A%20%20%20%20%20%20%20%20GROUP%20BY%20pb.metric_name%2C%20pb.threshold_warning%2C%20pb.threshold_critical%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20threshold_cursor%3B%0A%20%20%20%20%0A%20%20%20%20check_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20threshold_cursor%20INTO%20metric_name%2C%20current_value%2C%20warning_threshold%2C%20critical_threshold%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20check_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Determine%20alert%20level%0A%20%20%20%20%20%20%20%20IF%20current_value%20%3E%3D%20critical_threshold%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'CRITICAL'%3B%0A%20%20%20%20%20%20%20%20ELSEIF%20current_value%20%3E%3D%20warning_threshold%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'WARNING'%3B%0A%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_level%20%3D%20'OK'%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Generate%20alert%20if%20needed%0A%20%20%20%20%20%20%20%20IF%20alert_level%20!%3D%20'OK'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20generate_alert(metric_name%2C%20current_value%2C%20alert_level)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20threshold_cursor%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Collect system metrics
CREATE PROCEDURE collect_system_metrics()
BEGIN
    DECLARE server_name VARCHAR(100) DEFAULT @@hostname;
    
    -- Connection metrics
    INSERT INTO system_metrics (metric_name, metric_value, metric_unit, server_name)
    SELECT 'connections_current', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected'
    
    UNION ALL
    
    SELECT 'connections_max_used', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Max_used_connections'
    
    UNION ALL
    
    -- Query metrics
    SELECT 'queries_per_second', 
           VARIABLE_VALUE / (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Uptime'),
           'qps', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Questions'
    
    UNION ALL
    
    -- InnoDB metrics
    SELECT 'innodb_buffer_pool_hit_rate',
           (1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) * 100,
           'percent', server_name
    
    UNION ALL
    
    -- Slow query metrics
    SELECT 'slow_queries', VARIABLE_VALUE, 'count', server_name
    FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Slow_queries';
    
END //

-- Check performance thresholds
CREATE PROCEDURE check_performance_thresholds()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE metric_name VARCHAR(100);
    DECLARE current_value DECIMAL(15,4);
    DECLARE warning_threshold DECIMAL(15,4);
    DECLARE critical_threshold DECIMAL(15,4);
    DECLARE alert_level VARCHAR(20);
    
    DECLARE threshold_cursor CURSOR FOR
        SELECT 
            pb.metric_name,
            AVG(sm.metric_value) as current_avg,
            pb.threshold_warning,
            pb.threshold_critical
        FROM performance_baselines pb
        JOIN system_metrics sm ON pb.metric_name = sm.metric_name
        WHERE sm.collected_at &gt;= DATE_SUB(NOW(), INTERVAL 5 MINUTE)
        GROUP BY pb.metric_name, pb.threshold_warning, pb.threshold_critical;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN threshold_cursor;
    
    check_loop: LOOP
        FETCH threshold_cursor INTO metric_name, current_value, warning_threshold, critical_threshold;
        
        IF done THEN
            LEAVE check_loop;
        END IF;
        
        -- Determine alert level
        IF current_value &gt;= critical_threshold THEN
            SET alert_level = 'CRITICAL';
        ELSEIF current_value &gt;= warning_threshold THEN
            SET alert_level = 'WARNING';
        ELSE
            SET alert_level = 'OK';
        END IF;
        
        -- Generate alert if needed
        IF alert_level != 'OK' THEN
            CALL generate_alert(metric_name, current_value, alert_level);
        END IF;
        
    END LOOP;
    
    CLOSE threshold_cursor;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Alert Management System:</strong></p>

<p><strong>1. Alert Infrastructure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Alert%20definitions%0ACREATE%20TABLE%20alert_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20condition_operator%20ENUM('%3E'%2C%20'%3C'%2C%20'%3E%3D'%2C%20'%3C%3D'%2C%20'%3D'%2C%20'!%3D')%20NOT%20NULL%2C%0A%20%20%20%20threshold_value%20DECIMAL(15%2C4)%20NOT%20NULL%2C%0A%20%20%20%20severity%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20NOT%20NULL%2C%0A%20%20%20%20evaluation_period%20INT%20DEFAULT%20300%2C%20--%20seconds%0A%20%20%20%20notification_channels%20JSON%2C%0A%20%20%20%20enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_enabled%20(metric_name%2C%20enabled)%0A)%3B%0A%0A--%20Alert%20history%0ACREATE%20TABLE%20alert_history%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_id%20INT%2C%0A%20%20%20%20alert_level%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%2C%0A%20%20%20%20current_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20threshold_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20message%20TEXT%2C%0A%20%20%20%20status%20ENUM('ACTIVE'%2C%20'RESOLVED'%2C%20'ACKNOWLEDGED')%20DEFAULT%20'ACTIVE'%2C%0A%20%20%20%20triggered_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20acknowledged_by%20VARCHAR(100)%2C%0A%20%20%20%20acknowledged_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(rule_id)%20REFERENCES%20alert_rules(id)%2C%0A%20%20%20%20INDEX%20idx_status_triggered%20(status%2C%20triggered_at)%2C%0A%20%20%20%20INDEX%20idx_metric_status%20(metric_name%2C%20status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Alert definitions
CREATE TABLE alert_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    condition_operator ENUM('&gt;', '&lt;', '&gt;=', '&lt;=', '=', '!=') NOT NULL,
    threshold_value DECIMAL(15,4) NOT NULL,
    severity ENUM('INFO', 'WARNING', 'CRITICAL') NOT NULL,
    evaluation_period INT DEFAULT 300, -- seconds
    notification_channels JSON,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_enabled (metric_name, enabled)
);

-- Alert history
CREATE TABLE alert_history (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    rule_id INT,
    alert_level ENUM('INFO', 'WARNING', 'CRITICAL') NOT NULL,
    metric_name VARCHAR(100),
    current_value DECIMAL(15,4),
    threshold_value DECIMAL(15,4),
    message TEXT,
    status ENUM('ACTIVE', 'RESOLVED', 'ACKNOWLEDGED') DEFAULT 'ACTIVE',
    triggered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP NULL,
    acknowledged_by VARCHAR(100),
    acknowledged_at TIMESTAMP NULL,
    
    FOREIGN KEY (rule_id) REFERENCES alert_rules(id),
    INDEX idx_status_triggered (status, triggered_at),
    INDEX idx_metric_status (metric_name, status)
);
</code></pre>
</div>

<p><strong>2. Alert Generation and Notification:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0A%0A--%20Generate%20alert%0ACREATE%20PROCEDURE%20generate_alert(%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_current_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20IN%20p_alert_level%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20rule_id%20INT%3B%0A%20%20%20%20DECLARE%20threshold_val%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20notification_channels%20JSON%3B%0A%20%20%20%20DECLARE%20alert_message%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20alert%20rule%20details%0A%20%20%20%20SELECT%20id%2C%20threshold_value%2C%20notification_channels%0A%20%20%20%20INTO%20rule_id%2C%20threshold_val%2C%20notification_channels%0A%20%20%20%20FROM%20alert_rules%0A%20%20%20%20WHERE%20metric_name%20%3D%20p_metric_name%0A%20%20%20%20AND%20severity%20%3D%20p_alert_level%0A%20%20%20%20AND%20enabled%20%3D%20TRUE%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20IF%20rule_id%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20--%20Check%20if%20alert%20already%20exists%20and%20is%20active%0A%20%20%20%20%20%20%20%20IF%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20alert_history%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20rule_id%20%3D%20rule_id%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20triggered_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20%20%20%20%20)%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20alert%20message%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20alert_message%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'ALERT%3A%20'%2C%20p_metric_name%2C%20'%20is%20'%2C%20p_current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20(threshold%3A%20'%2C%20threshold_val%2C%20')'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20-%20Severity%3A%20'%2C%20p_alert_level%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20alert%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20alert_history%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20alert_level%2C%20metric_name%2C%20current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_value%2C%20message%2C%20status%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20p_alert_level%2C%20p_metric_name%2C%20p_current_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_val%2C%20alert_message%2C%20'ACTIVE'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Send%20notifications%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20send_notifications(notification_channels%2C%20alert_message%2C%20p_alert_level)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0A%0A--%20Send%20notifications%20(placeholder%20-%20would%20integrate%20with%20external%20systems)%0ACREATE%20PROCEDURE%20send_notifications(%0A%20%20%20%20IN%20p_channels%20JSON%2C%0A%20%20%20%20IN%20p_message%20TEXT%2C%0A%20%20%20%20IN%20p_severity%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20channel_count%20INT%3B%0A%20%20%20%20DECLARE%20channel_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20channel_config%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20SET%20channel_count%20%3D%20JSON_LENGTH(p_channels)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20channel_count%20DO%0A%20%20%20%20%20%20%20%20SET%20channel_type%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_channels%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.type')))%3B%0A%20%20%20%20%20%20%20%20SET%20channel_config%20%3D%20JSON_EXTRACT(p_channels%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D.config'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20notification%20attempt%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20notification_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20channel_type%2C%20message%2C%20severity%2C%20sent_at%2C%20status%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20channel_type%2C%20p_message%2C%20p_severity%2C%20NOW()%2C%20'SENT'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //

-- Generate alert
CREATE PROCEDURE generate_alert(
    IN p_metric_name VARCHAR(100),
    IN p_current_value DECIMAL(15,4),
    IN p_alert_level VARCHAR(20)
)
BEGIN
    DECLARE rule_id INT;
    DECLARE threshold_val DECIMAL(15,4);
    DECLARE notification_channels JSON;
    DECLARE alert_message TEXT;
    
    -- Get alert rule details
    SELECT id, threshold_value, notification_channels
    INTO rule_id, threshold_val, notification_channels
    FROM alert_rules
    WHERE metric_name = p_metric_name
    AND severity = p_alert_level
    AND enabled = TRUE
    LIMIT 1;
    
    IF rule_id IS NOT NULL THEN
        -- Check if alert already exists and is active
        IF NOT EXISTS (
            SELECT 1 FROM alert_history
            WHERE rule_id = rule_id
            AND status = 'ACTIVE'
            AND triggered_at &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
        ) THEN
            -- Create alert message
            SET alert_message = CONCAT(
                'ALERT: ', p_metric_name, ' is ', p_current_value,
                ' (threshold: ', threshold_val, ')',
                ' - Severity: ', p_alert_level
            );
            
            -- Insert alert
            INSERT INTO alert_history (
                rule_id, alert_level, metric_name, current_value,
                threshold_value, message, status
            ) VALUES (
                rule_id, p_alert_level, p_metric_name, p_current_value,
                threshold_val, alert_message, 'ACTIVE'
            );
            
            -- Send notifications
            CALL send_notifications(notification_channels, alert_message, p_alert_level);
        END IF;
    END IF;
END //

-- Send notifications (placeholder - would integrate with external systems)
CREATE PROCEDURE send_notifications(
    IN p_channels JSON,
    IN p_message TEXT,
    IN p_severity VARCHAR(20)
)
BEGIN
    DECLARE i INT DEFAULT 0;
    DECLARE channel_count INT;
    DECLARE channel_type VARCHAR(50);
    DECLARE channel_config JSON;
    
    SET channel_count = JSON_LENGTH(p_channels);
    
    WHILE i &lt; channel_count DO
        SET channel_type = JSON_UNQUOTE(JSON_EXTRACT(p_channels, CONCAT('$[', i, '].type')));
        SET channel_config = JSON_EXTRACT(p_channels, CONCAT('$[', i, '].config'));
        
        -- Log notification attempt
        INSERT INTO notification_log (
            channel_type, message, severity, sent_at, status
        ) VALUES (
            channel_type, p_message, p_severity, NOW(), 'SENT'
        );
        
        SET i = i + 1;
    END WHILE;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Monitoring Dashboard Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Real-time%20system%20overview%0ACREATE%20VIEW%20system_health_dashboard%20AS%0ASELECT%20%0A%20%20%20%20'Database%20Connections'%20as%20metric_category%2C%0A%20%20%20%20CONCAT(%0A%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected')%2C%0A%20%20%20%20%20%20%20%20'%20%2F%20'%2C%0A%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_variables%20WHERE%20VARIABLE_NAME%20%3D%20'max_connections')%0A%20%20%20%20)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Threads_connected')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_variables%20WHERE%20VARIABLE_NAME%20%3D%20'max_connections')%20%3E%200.8%0A%20%20%20%20%20%20%20%20THEN%20'WARNING'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0A%0AUNION%20ALL%0A%0ASELECT%20%0A%20%20%20%20'Buffer%20Pool%20Hit%20Rate'%20as%20metric_category%2C%0A%20%20%20%20CONCAT(%0A%20%20%20%20%20%20%20%20ROUND((1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20*%20100%2C%202)%2C%0A%20%20%20%20%20%20%20%20'%25'%0A%20%20%20%20)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20(1%20-%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_reads')%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20VARIABLE_VALUE%20FROM%20performance_schema.global_status%20WHERE%20VARIABLE_NAME%20%3D%20'Innodb_buffer_pool_read_requests'))%20%3C%200.95%0A%20%20%20%20%20%20%20%20THEN%20'WARNING'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0A%0AUNION%20ALL%0A%0ASELECT%20%0A%20%20%20%20'Active%20Alerts'%20as%20metric_category%2C%0A%20%20%20%20CAST(COUNT(*)%20AS%20CHAR)%20as%20current_status%2C%0A%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20COUNT(*)%20%3E%200%20THEN%20'CRITICAL'%0A%20%20%20%20%20%20%20%20ELSE%20'OK'%0A%20%20%20%20END%20as%20health_status%0AFROM%20alert_history%0AWHERE%20status%20%3D%20'ACTIVE'%3B%0A%0A--%20Performance%20trends%0ASELECT%20%0A%20%20%20%20DATE(collected_at)%20as%20trend_date%2C%0A%20%20%20%20metric_name%2C%0A%20%20%20%20AVG(metric_value)%20as%20avg_value%2C%0A%20%20%20%20MIN(metric_value)%20as%20min_value%2C%0A%20%20%20%20MAX(metric_value)%20as%20max_value%2C%0A%20%20%20%20STDDEV(metric_value)%20as%20std_deviation%0AFROM%20system_metrics%0AWHERE%20collected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%207%20DAY)%0AGROUP%20BY%20DATE(collected_at)%2C%20metric_name%0AORDER%20BY%20trend_date%20DESC%2C%20metric_name%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Real-time system overview
CREATE VIEW system_health_dashboard AS
SELECT 
    'Database Connections' as metric_category,
    CONCAT(
        (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected'),
        ' / ',
        (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections')
    ) as current_status,
    CASE 
        WHEN (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Threads_connected') /
             (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections') &gt; 0.8
        THEN 'WARNING'
        ELSE 'OK'
    END as health_status

UNION ALL

SELECT 
    'Buffer Pool Hit Rate' as metric_category,
    CONCAT(
        ROUND((1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                   (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) * 100, 2),
        '%'
    ) as current_status,
    CASE 
        WHEN (1 - (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') /
                  (SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests')) &lt; 0.95
        THEN 'WARNING'
        ELSE 'OK'
    END as health_status

UNION ALL

SELECT 
    'Active Alerts' as metric_category,
    CAST(COUNT(*) AS CHAR) as current_status,
    CASE 
        WHEN COUNT(*) &gt; 0 THEN 'CRITICAL'
        ELSE 'OK'
    END as health_status
FROM alert_history
WHERE status = 'ACTIVE';

-- Performance trends
SELECT 
    DATE(collected_at) as trend_date,
    metric_name,
    AVG(metric_value) as avg_value,
    MIN(metric_value) as min_value,
    MAX(metric_value) as max_value,
    STDDEV(metric_value) as std_deviation
FROM system_metrics
WHERE collected_at &gt;= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY DATE(collected_at), metric_name
ORDER BY trend_date DESC, metric_name;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Set up automated metric collection every 1-5 minutes</p>
<p>- Define appropriate thresholds based on historical data</p>
<p>- Implement alert escalation and notification channels</p>
<p>- Monitor both system and application-level metrics</p>
<p>- Use dashboards for real-time visibility</p>
<p>- Implement alert fatigue prevention (grouping, suppression)</p>
<p>- Regular review and tuning of monitoring rules</p>
<p>- Archive old metrics data to manage storage</p>

<h2 id="-371-what-are-data-warehousing-concepts-in-mysql-">**371. What are data warehousing concepts in MySQL?**</h2>

<p><strong>Answer:</strong> Data warehousing involves collecting, storing, and analyzing large volumes of data from multiple sources for business intelligence and reporting purposes.</p>

<p><strong>Data Warehouse Architecture:</strong></p>

<p><strong>1. Dimensional Modeling:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Fact%20table%20(central%20table%20with%20metrics)%0ACREATE%20TABLE%20sales_fact%20(%0A%20%20%20%20sale_id%20BIGINT%20PRIMARY%20KEY%2C%0A%20%20%20%20date_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20store_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20quantity%20INT%20NOT%20NULL%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%20NOT%20NULL%2C%0A%20%20%20%20discount_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20tax_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Foreign%20keys%20to%20dimension%20tables%0A%20%20%20%20FOREIGN%20KEY%20(date_key)%20REFERENCES%20date_dimension(date_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_key)%20REFERENCES%20customer_dimension(customer_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_key)%20REFERENCES%20product_dimension(product_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(store_key)%20REFERENCES%20store_dimension(store_key)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Indexes%20for%20performance%0A%20%20%20%20INDEX%20idx_date%20(date_key)%2C%0A%20%20%20%20INDEX%20idx_customer%20(customer_key)%2C%0A%20%20%20%20INDEX%20idx_product%20(product_key)%2C%0A%20%20%20%20INDEX%20idx_store%20(store_key)%0A)%3B%0A%0A--%20Date%20dimension%20(time%20hierarchy)%0ACREATE%20TABLE%20date_dimension%20(%0A%20%20%20%20date_key%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20full_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20day_of_week%20INT%20NOT%20NULL%2C%0A%20%20%20%20day_name%20VARCHAR(10)%20NOT%20NULL%2C%0A%20%20%20%20day_of_month%20INT%20NOT%20NULL%2C%0A%20%20%20%20day_of_year%20INT%20NOT%20NULL%2C%0A%20%20%20%20week_of_year%20INT%20NOT%20NULL%2C%0A%20%20%20%20month_number%20INT%20NOT%20NULL%2C%0A%20%20%20%20month_name%20VARCHAR(10)%20NOT%20NULL%2C%0A%20%20%20%20quarter%20INT%20NOT%20NULL%2C%0A%20%20%20%20year%20INT%20NOT%20NULL%2C%0A%20%20%20%20is_weekend%20BOOLEAN%20NOT%20NULL%2C%0A%20%20%20%20is_holiday%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20fiscal_year%20INT%2C%0A%20%20%20%20fiscal_quarter%20INT%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_full_date%20(full_date)%2C%0A%20%20%20%20INDEX%20idx_year_month%20(year%2C%20month_number)%2C%0A%20%20%20%20INDEX%20idx_quarter%20(year%2C%20quarter)%0A)%3B%0A%0A--%20Customer%20dimension%20(slowly%20changing%20dimension)%0ACREATE%20TABLE%20customer_dimension%20(%0A%20%20%20%20customer_key%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%20NOT%20NULL%2C%20--%20Business%20key%0A%20%20%20%20customer_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20customer_type%20VARCHAR(50)%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20city%20VARCHAR(100)%2C%0A%20%20%20%20state%20VARCHAR(50)%2C%0A%20%20%20%20country%20VARCHAR(50)%2C%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SCD%20Type%202%20fields%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20is_current%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20version_number%20INT%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_current%20(is_current)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Fact table (central table with metrics)
CREATE TABLE sales_fact (
    sale_id BIGINT PRIMARY KEY,
    date_key INT NOT NULL,
    customer_key INT NOT NULL,
    product_key INT NOT NULL,
    store_key INT NOT NULL,
    quantity INT NOT NULL,
    unit_price DECIMAL(10,2) NOT NULL,
    total_amount DECIMAL(12,2) NOT NULL,
    discount_amount DECIMAL(10,2) DEFAULT 0,
    tax_amount DECIMAL(10,2) DEFAULT 0,
    
    -- Foreign keys to dimension tables
    FOREIGN KEY (date_key) REFERENCES date_dimension(date_key),
    FOREIGN KEY (customer_key) REFERENCES customer_dimension(customer_key),
    FOREIGN KEY (product_key) REFERENCES product_dimension(product_key),
    FOREIGN KEY (store_key) REFERENCES store_dimension(store_key),
    
    -- Indexes for performance
    INDEX idx_date (date_key),
    INDEX idx_customer (customer_key),
    INDEX idx_product (product_key),
    INDEX idx_store (store_key)
);

-- Date dimension (time hierarchy)
CREATE TABLE date_dimension (
    date_key INT PRIMARY KEY,
    full_date DATE NOT NULL,
    day_of_week INT NOT NULL,
    day_name VARCHAR(10) NOT NULL,
    day_of_month INT NOT NULL,
    day_of_year INT NOT NULL,
    week_of_year INT NOT NULL,
    month_number INT NOT NULL,
    month_name VARCHAR(10) NOT NULL,
    quarter INT NOT NULL,
    year INT NOT NULL,
    is_weekend BOOLEAN NOT NULL,
    is_holiday BOOLEAN DEFAULT FALSE,
    fiscal_year INT,
    fiscal_quarter INT,
    
    UNIQUE KEY uk_full_date (full_date),
    INDEX idx_year_month (year, month_number),
    INDEX idx_quarter (year, quarter)
);

-- Customer dimension (slowly changing dimension)
CREATE TABLE customer_dimension (
    customer_key INT AUTO_INCREMENT PRIMARY KEY,
    customer_id INT NOT NULL, -- Business key
    customer_name VARCHAR(255) NOT NULL,
    customer_type VARCHAR(50),
    customer_segment VARCHAR(50),
    city VARCHAR(100),
    state VARCHAR(50),
    country VARCHAR(50),
    region VARCHAR(50),
    
    -- SCD Type 2 fields
    effective_date DATE NOT NULL,
    expiry_date DATE DEFAULT '9999-12-31',
    is_current BOOLEAN DEFAULT TRUE,
    version_number INT DEFAULT 1,
    
    INDEX idx_customer_id (customer_id),
    INDEX idx_current (is_current),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. ETL Process Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Staging%20tables%20for%20data%20extraction%0ACREATE%20TABLE%20staging_sales%20(%0A%20%20%20%20source_system%20VARCHAR(50)%2C%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20transaction_date%20DATE%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20product_code%20VARCHAR(50)%2C%0A%20%20%20%20store_code%20VARCHAR(20)%2C%0A%20%20%20%20quantity%20INT%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%2C%0A%20%20%20%20extracted_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20processed%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_processed%20(processed)%2C%0A%20%20%20%20INDEX%20idx_extracted_at%20(extracted_at)%0A)%3B%0A%0A--%20ETL%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20etl_load_sales_data()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_transaction_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_transaction_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_customer_id%20INT%3B%0A%20%20%20%20DECLARE%20v_product_code%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_store_code%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_quantity%20INT%3B%0A%20%20%20%20DECLARE%20v_unit_price%20DECIMAL(10%2C2)%3B%0A%20%20%20%20DECLARE%20v_total_amount%20DECIMAL(12%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Dimension%20keys%0A%20%20%20%20DECLARE%20v_date_key%20INT%3B%0A%20%20%20%20DECLARE%20v_customer_key%20INT%3B%0A%20%20%20%20DECLARE%20v_product_key%20INT%3B%0A%20%20%20%20DECLARE%20v_store_key%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20sales_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20transaction_id%2C%20transaction_date%2C%20customer_id%2C%20product_code%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20store_code%2C%20quantity%2C%20unit_price%2C%20total_amount%0A%20%20%20%20%20%20%20%20FROM%20staging_sales%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20sales_cursor%3B%0A%20%20%20%20%0A%20%20%20%20etl_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20sales_cursor%20INTO%20v_transaction_id%2C%20v_transaction_date%2C%20v_customer_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_product_code%2C%20v_store_code%2C%20v_quantity%2C%20v_unit_price%2C%20v_total_amount%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20etl_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Lookup%20dimension%20keys%0A%20%20%20%20%20%20%20%20SELECT%20date_key%20INTO%20v_date_key%20%0A%20%20%20%20%20%20%20%20FROM%20date_dimension%20WHERE%20full_date%20%3D%20v_transaction_date%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20customer_key%20INTO%20v_customer_key%0A%20%20%20%20%20%20%20%20FROM%20customer_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20customer_id%20%3D%20v_customer_id%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20product_key%20INTO%20v_product_key%0A%20%20%20%20%20%20%20%20FROM%20product_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20product_code%20%3D%20v_product_code%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SELECT%20store_key%20INTO%20v_store_key%0A%20%20%20%20%20%20%20%20FROM%20store_dimension%20%0A%20%20%20%20%20%20%20%20WHERE%20store_code%20%3D%20v_store_code%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20into%20fact%20table%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20sales_fact%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20sale_id%2C%20date_key%2C%20customer_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20quantity%2C%20unit_price%2C%20total_amount%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_transaction_id%2C%20v_date_key%2C%20v_customer_key%2C%20v_product_key%2C%20v_store_key%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20v_quantity%2C%20v_unit_price%2C%20v_total_amount%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20UPDATE%20staging_sales%20%0A%20%20%20%20%20%20%20%20SET%20processed%20%3D%20TRUE%20%0A%20%20%20%20%20%20%20%20WHERE%20transaction_id%20%3D%20v_transaction_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20sales_cursor%3B%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20ETL%20completion%0A%20%20%20%20INSERT%20INTO%20etl_log%20(process_name%2C%20records_processed%2C%20completed_at)%0A%20%20%20%20SELECT%20'sales_etl'%2C%20COUNT(*)%2C%20NOW()%20%0A%20%20%20%20FROM%20staging_sales%20WHERE%20processed%20%3D%20TRUE%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Staging tables for data extraction
CREATE TABLE staging_sales (
    source_system VARCHAR(50),
    transaction_id VARCHAR(100),
    transaction_date DATE,
    customer_id INT,
    product_code VARCHAR(50),
    store_code VARCHAR(20),
    quantity INT,
    unit_price DECIMAL(10,2),
    total_amount DECIMAL(12,2),
    extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed BOOLEAN DEFAULT FALSE,
    
    INDEX idx_processed (processed),
    INDEX idx_extracted_at (extracted_at)
);

-- ETL procedure
DELIMITER //
CREATE PROCEDURE etl_load_sales_data()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_transaction_id VARCHAR(100);
    DECLARE v_transaction_date DATE;
    DECLARE v_customer_id INT;
    DECLARE v_product_code VARCHAR(50);
    DECLARE v_store_code VARCHAR(20);
    DECLARE v_quantity INT;
    DECLARE v_unit_price DECIMAL(10,2);
    DECLARE v_total_amount DECIMAL(12,2);
    
    -- Dimension keys
    DECLARE v_date_key INT;
    DECLARE v_customer_key INT;
    DECLARE v_product_key INT;
    DECLARE v_store_key INT;
    
    DECLARE sales_cursor CURSOR FOR
        SELECT transaction_id, transaction_date, customer_id, product_code,
               store_code, quantity, unit_price, total_amount
        FROM staging_sales
        WHERE processed = FALSE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    START TRANSACTION;
    
    OPEN sales_cursor;
    
    etl_loop: LOOP
        FETCH sales_cursor INTO v_transaction_id, v_transaction_date, v_customer_id,
                               v_product_code, v_store_code, v_quantity, v_unit_price, v_total_amount;
        
        IF done THEN
            LEAVE etl_loop;
        END IF;
        
        -- Lookup dimension keys
        SELECT date_key INTO v_date_key 
        FROM date_dimension WHERE full_date = v_transaction_date;
        
        SELECT customer_key INTO v_customer_key
        FROM customer_dimension 
        WHERE customer_id = v_customer_id AND is_current = TRUE;
        
        SELECT product_key INTO v_product_key
        FROM product_dimension 
        WHERE product_code = v_product_code AND is_current = TRUE;
        
        SELECT store_key INTO v_store_key
        FROM store_dimension 
        WHERE store_code = v_store_code;
        
        -- Insert into fact table
        INSERT INTO sales_fact (
            sale_id, date_key, customer_key, product_key, store_key,
            quantity, unit_price, total_amount
        ) VALUES (
            v_transaction_id, v_date_key, v_customer_key, v_product_key, v_store_key,
            v_quantity, v_unit_price, v_total_amount
        );
        
        -- Mark as processed
        UPDATE staging_sales 
        SET processed = TRUE 
        WHERE transaction_id = v_transaction_id;
        
    END LOOP;
    
    CLOSE sales_cursor;
    COMMIT;
    
    -- Log ETL completion
    INSERT INTO etl_log (process_name, records_processed, completed_at)
    SELECT 'sales_etl', COUNT(*), NOW() 
    FROM staging_sales WHERE processed = TRUE;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Slowly Changing Dimensions (SCD):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20SCD%20Type%202%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20update_customer_dimension(%0A%20%20%20%20IN%20p_customer_id%20INT%2C%0A%20%20%20%20IN%20p_customer_name%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_city%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_state%20VARCHAR(50)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_current_segment%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_current_city%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_current_state%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_customer_key%20INT%3B%0A%20%20%20%20DECLARE%20changes_detected%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20values%0A%20%20%20%20SELECT%20customer_key%2C%20customer_segment%2C%20city%2C%20state%0A%20%20%20%20INTO%20v_customer_key%2C%20v_current_segment%2C%20v_current_city%2C%20v_current_state%0A%20%20%20%20FROM%20customer_dimension%0A%20%20%20%20WHERE%20customer_id%20%3D%20p_customer_id%20AND%20is_current%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20for%20changes%0A%20%20%20%20IF%20(v_current_segment%20!%3D%20p_customer_segment%20OR%20%0A%20%20%20%20%20%20%20%20v_current_city%20!%3D%20p_city%20OR%20%0A%20%20%20%20%20%20%20%20v_current_state%20!%3D%20p_state)%20THEN%0A%20%20%20%20%20%20%20%20SET%20changes_detected%20%3D%20TRUE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20changes_detected%20THEN%0A%20%20%20%20%20%20%20%20--%20Close%20current%20record%0A%20%20%20%20%20%20%20%20UPDATE%20customer_dimension%0A%20%20%20%20%20%20%20%20SET%20expiry_date%20%3D%20CURDATE()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_current%20%3D%20FALSE%0A%20%20%20%20%20%20%20%20WHERE%20customer_key%20%3D%20v_customer_key%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20new%20record%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_dimension%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20customer_id%2C%20customer_name%2C%20customer_segment%2C%20city%2C%20state%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20effective_date%2C%20is_current%2C%20version_number%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_customer_id%2C%20p_customer_name%2C%20p_customer_segment%2C%20p_city%2C%20p_state%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CURDATE()%2C%20TRUE%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20MAX(version_number)%20%2B%201%20FROM%20customer_dimension%20WHERE%20customer_id%20%3D%20p_customer_id)%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20--%20Update%20current%20record%20(Type%201%20changes%20like%20name)%0A%20%20%20%20%20%20%20%20UPDATE%20customer_dimension%0A%20%20%20%20%20%20%20%20SET%20customer_name%20%3D%20p_customer_name%0A%20%20%20%20%20%20%20%20WHERE%20customer_key%20%3D%20v_customer_key%3B%0A%20%20%20%20END%20IF%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- SCD Type 2 implementation
DELIMITER //
CREATE PROCEDURE update_customer_dimension(
    IN p_customer_id INT,
    IN p_customer_name VARCHAR(255),
    IN p_customer_segment VARCHAR(50),
    IN p_city VARCHAR(100),
    IN p_state VARCHAR(50)
)
BEGIN
    DECLARE v_current_segment VARCHAR(50);
    DECLARE v_current_city VARCHAR(100);
    DECLARE v_current_state VARCHAR(50);
    DECLARE v_customer_key INT;
    DECLARE changes_detected BOOLEAN DEFAULT FALSE;
    
    -- Get current values
    SELECT customer_key, customer_segment, city, state
    INTO v_customer_key, v_current_segment, v_current_city, v_current_state
    FROM customer_dimension
    WHERE customer_id = p_customer_id AND is_current = TRUE;
    
    -- Check for changes
    IF (v_current_segment != p_customer_segment OR 
        v_current_city != p_city OR 
        v_current_state != p_state) THEN
        SET changes_detected = TRUE;
    END IF;
    
    IF changes_detected THEN
        -- Close current record
        UPDATE customer_dimension
        SET expiry_date = CURDATE(),
            is_current = FALSE
        WHERE customer_key = v_customer_key;
        
        -- Insert new record
        INSERT INTO customer_dimension (
            customer_id, customer_name, customer_segment, city, state,
            effective_date, is_current, version_number
        ) VALUES (
            p_customer_id, p_customer_name, p_customer_segment, p_city, p_state,
            CURDATE(), TRUE, 
            (SELECT MAX(version_number) + 1 FROM customer_dimension WHERE customer_id = p_customer_id)
        );
    ELSE
        -- Update current record (Type 1 changes like name)
        UPDATE customer_dimension
        SET customer_name = p_customer_name
        WHERE customer_key = v_customer_key;
    END IF;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Mart Creation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Sales%20data%20mart%20for%20specific%20department%0ACREATE%20TABLE%20sales_datamart%20AS%0ASELECT%20%0A%20%20%20%20d.year%2C%0A%20%20%20%20d.quarter%2C%0A%20%20%20%20d.month_name%2C%0A%20%20%20%20c.customer_segment%2C%0A%20%20%20%20c.region%2C%0A%20%20%20%20p.product_category%2C%0A%20%20%20%20p.product_subcategory%2C%0A%20%20%20%20s.store_type%2C%0A%20%20%20%20s.store_region%2C%0A%20%20%20%20SUM(f.quantity)%20as%20total_quantity%2C%0A%20%20%20%20SUM(f.total_amount)%20as%20total_sales%2C%0A%20%20%20%20AVG(f.unit_price)%20as%20avg_unit_price%2C%0A%20%20%20%20COUNT(DISTINCT%20f.customer_key)%20as%20unique_customers%2C%0A%20%20%20%20COUNT(*)%20as%20transaction_count%0AFROM%20sales_fact%20f%0AJOIN%20date_dimension%20d%20ON%20f.date_key%20%3D%20d.date_key%0AJOIN%20customer_dimension%20c%20ON%20f.customer_key%20%3D%20c.customer_key%0AJOIN%20product_dimension%20p%20ON%20f.product_key%20%3D%20p.product_key%0AJOIN%20store_dimension%20s%20ON%20f.store_key%20%3D%20s.store_key%0AWHERE%20d.year%20%3E%3D%20YEAR(CURDATE())%20-%202%20%20--%20Last%202%20years%0AGROUP%20BY%20d.year%2C%20d.quarter%2C%20d.month_name%2C%20c.customer_segment%2C%20c.region%2C%0A%20%20%20%20%20%20%20%20%20p.product_category%2C%20p.product_subcategory%2C%20s.store_type%2C%20s.store_region%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Sales data mart for specific department
CREATE TABLE sales_datamart AS
SELECT 
    d.year,
    d.quarter,
    d.month_name,
    c.customer_segment,
    c.region,
    p.product_category,
    p.product_subcategory,
    s.store_type,
    s.store_region,
    SUM(f.quantity) as total_quantity,
    SUM(f.total_amount) as total_sales,
    AVG(f.unit_price) as avg_unit_price,
    COUNT(DISTINCT f.customer_key) as unique_customers,
    COUNT(*) as transaction_count
FROM sales_fact f
JOIN date_dimension d ON f.date_key = d.date_key
JOIN customer_dimension c ON f.customer_key = c.customer_key
JOIN product_dimension p ON f.product_key = p.product_key
JOIN store_dimension s ON f.store_key = s.store_key
WHERE d.year &gt;= YEAR(CURDATE()) - 2  -- Last 2 years
GROUP BY d.year, d.quarter, d.month_name, c.customer_segment, c.region,
         p.product_category, p.product_subcategory, s.store_type, s.store_region;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Use star or snowflake schema design</p>
<p>- Implement proper indexing on fact and dimension tables</p>
<p>- Use surrogate keys for dimension tables</p>
<p>- Handle slowly changing dimensions appropriately</p>
<p>- Implement data quality checks in ETL process</p>
<p>- Partition large fact tables by date</p>
<p>- Create aggregated summary tables for performance</p>


<p>---</p>

<h2 id="-372-how-do-you-implement-data-archiving-strategies-">**372. How do you implement data archiving strategies?**</h2>

<p><strong>Answer:</strong> Data archiving involves moving older, less frequently accessed data to separate storage while maintaining accessibility and compliance requirements.</p>

<p><strong>Archiving Strategy Design:</strong></p>

<p><strong>1. Time-Based Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20table%20structure%20(same%20as%20source%20but%20with%20archive%20suffix)%0ACREATE%20TABLE%20orders_archive%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20INT%2C%0A%20%20%20%20order_date%20DATE%2C%0A%20%20%20%20total%20DECIMAL(10%2C2)%2C%0A%20%20%20%20status%20VARCHAR(20)%2C%0A%20%20%20%20created_at%20TIMESTAMP%2C%0A%20%20%20%20archived_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_order_date%20(order_date)%2C%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_archived_at%20(archived_at)%0A)%20ENGINE%3DInnoDB%3B%0A%0A--%20Automated%20archiving%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_old_orders(IN%20p_archive_months%20INT)%0ABEGIN%0A%20%20%20%20DECLARE%20archive_date%20DATE%3B%0A%20%20%20%20DECLARE%20records_archived%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20SET%20archive_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_archive_months%20MONTH)%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Copy%20old%20records%20to%20archive%20table%0A%20%20%20%20INSERT%20INTO%20orders_archive%20(%0A%20%20%20%20%20%20%20%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%0A%20%20%20%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3C%20archive_date%0A%20%20%20%20AND%20status%20IN%20('completed'%2C%20'cancelled'%2C%20'refunded')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_archived%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20archived%20records%20from%20main%20table%0A%20%20%20%20DELETE%20FROM%20orders%0A%20%20%20%20WHERE%20order_date%20%3C%20archive_date%0A%20%20%20%20AND%20status%20IN%20('completed'%2C%20'cancelled'%2C%20'refunded')%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20archiving%20activity%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_date%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'orders'%2C%20archive_date%2C%20records_archived%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20CONCAT('Archived%20'%2C%20records_archived%2C%20'%20orders%20older%20than%20'%2C%20archive_date)%20as%20result%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive table structure (same as source but with archive suffix)
CREATE TABLE orders_archive (
    id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    total DECIMAL(10,2),
    status VARCHAR(20),
    created_at TIMESTAMP,
    archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_order_date (order_date),
    INDEX idx_customer_id (customer_id),
    INDEX idx_archived_at (archived_at)
) ENGINE=InnoDB;

-- Automated archiving procedure
DELIMITER //
CREATE PROCEDURE archive_old_orders(IN p_archive_months INT)
BEGIN
    DECLARE archive_date DATE;
    DECLARE records_archived INT DEFAULT 0;
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    SET archive_date = DATE_SUB(CURDATE(), INTERVAL p_archive_months MONTH);
    
    START TRANSACTION;
    
    -- Copy old records to archive table
    INSERT INTO orders_archive (
        id, customer_id, order_date, total, status, created_at
    )
    SELECT id, customer_id, order_date, total, status, created_at
    FROM orders
    WHERE order_date &lt; archive_date
    AND status IN ('completed', 'cancelled', 'refunded');
    
    SET records_archived = ROW_COUNT();
    
    -- Delete archived records from main table
    DELETE FROM orders
    WHERE order_date &lt; archive_date
    AND status IN ('completed', 'cancelled', 'refunded');
    
    COMMIT;
    
    -- Log archiving activity
    INSERT INTO archive_log (
        table_name, archive_date, records_archived, archived_at
    ) VALUES (
        'orders', archive_date, records_archived, NOW()
    );
    
    SELECT CONCAT('Archived ', records_archived, ' orders older than ', archive_date) as result;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Conditional Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20based%20on%20business%20rules%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_inactive_customers()%0ABEGIN%0A%20%20%20%20DECLARE%20customers_archived%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20customers%20with%20no%20activity%20for%203%2B%20years%0A%20%20%20%20INSERT%20INTO%20customers_archive%20(%0A%20%20%20%20%20%20%20%20id%2C%20name%2C%20email%2C%20phone%2C%20address%2C%20status%2C%20%0A%20%20%20%20%20%20%20%20last_login%2C%20last_order_date%2C%20created_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20c.id%2C%20c.name%2C%20c.email%2C%20c.phone%2C%20c.address%2C%20c.status%2C%0A%20%20%20%20%20%20%20%20c.last_login%2C%20%0A%20%20%20%20%20%20%20%20(SELECT%20MAX(order_date)%20FROM%20orders%20WHERE%20customer_id%20%3D%20c.id)%20as%20last_order_date%2C%0A%20%20%20%20%20%20%20%20c.created_at%0A%20%20%20%20FROM%20customers%20c%0A%20%20%20%20WHERE%20c.status%20%3D%20'inactive'%0A%20%20%20%20AND%20c.last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20orders%20o%20%0A%20%20%20%20%20%20%20%20WHERE%20o.customer_id%20%3D%20c.id%20%0A%20%20%20%20%20%20%20%20AND%20o.order_date%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20customers_archived%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20archived%20customers%20from%20main%20table%0A%20%20%20%20DELETE%20c%20FROM%20customers%20c%0A%20%20%20%20WHERE%20c.status%20%3D%20'inactive'%0A%20%20%20%20AND%20c.last_login%20%3C%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20orders%20o%20%0A%20%20%20%20%20%20%20%20WHERE%20o.customer_id%20%3D%20c.id%20%0A%20%20%20%20%20%20%20%20AND%20o.order_date%20%3E%20DATE_SUB(NOW()%2C%20INTERVAL%203%20YEAR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_criteria%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'customers'%2C%20'inactive_3_years'%2C%20customers_archived%2C%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive based on business rules
DELIMITER //
CREATE PROCEDURE archive_inactive_customers()
BEGIN
    DECLARE customers_archived INT DEFAULT 0;
    
    START TRANSACTION;
    
    -- Archive customers with no activity for 3+ years
    INSERT INTO customers_archive (
        id, name, email, phone, address, status, 
        last_login, last_order_date, created_at
    )
    SELECT 
        c.id, c.name, c.email, c.phone, c.address, c.status,
        c.last_login, 
        (SELECT MAX(order_date) FROM orders WHERE customer_id = c.id) as last_order_date,
        c.created_at
    FROM customers c
    WHERE c.status = 'inactive'
    AND c.last_login &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND NOT EXISTS (
        SELECT 1 FROM orders o 
        WHERE o.customer_id = c.id 
        AND o.order_date &gt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    );
    
    SET customers_archived = ROW_COUNT();
    
    -- Remove archived customers from main table
    DELETE c FROM customers c
    WHERE c.status = 'inactive'
    AND c.last_login &lt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    AND NOT EXISTS (
        SELECT 1 FROM orders o 
        WHERE o.customer_id = c.id 
        AND o.order_date &gt; DATE_SUB(NOW(), INTERVAL 3 YEAR)
    );
    
    COMMIT;
    
    INSERT INTO archive_log (
        table_name, archive_criteria, records_archived, archived_at
    ) VALUES (
        'customers', 'inactive_3_years', customers_archived, NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Partitioned Archiving:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20partitioned%20table%20for%20automatic%20archiving%0ACREATE%20TABLE%20user_activities%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%2C%0A%20%20%20%20user_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20activity_type%20VARCHAR(50)%2C%0A%20%20%20%20activity_data%20JSON%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20created_at%20TIMESTAMP%20NOT%20NULL%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20PRIMARY%20KEY%20(id%2C%20created_at)%2C%0A%20%20%20%20INDEX%20idx_user_id%20(user_id)%2C%0A%20%20%20%20INDEX%20idx_activity_type%20(activity_type)%0A)%20ENGINE%3DInnoDB%0APARTITION%20BY%20RANGE%20(YEAR(created_at))%20(%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_current%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A%0A--%20Archive%20old%20partitions%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20archive_old_partitions()%0ABEGIN%0A%20%20%20%20DECLARE%20partition_name%20VARCHAR(64)%3B%0A%20%20%20%20DECLARE%20archive_year%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20partitions%20older%20than%202%20years%0A%20%20%20%20SET%20archive_year%20%3D%20YEAR(CURDATE())%20-%202%3B%0A%20%20%20%20SET%20partition_name%20%3D%20CONCAT('p'%2C%20archive_year)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%20for%20the%20partition%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('CREATE%20TABLE%20user_activities_archive_'%2C%20archive_year%2C%20'%20AS%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%20*%20FROM%20user_activities%20PARTITION%20('%2C%20partition_name%2C%20')')%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Drop%20the%20old%20partition%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('ALTER%20TABLE%20user_activities%20DROP%20PARTITION%20'%2C%20partition_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20the%20archiving%0A%20%20%20%20INSERT%20INTO%20archive_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20archive_criteria%2C%20records_archived%2C%20archived_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'user_activities'%2C%20CONCAT('partition_'%2C%20partition_name)%2C%20%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(*)%20FROM%20user_activities_archive_2022)%2C%20NOW()%0A%20%20%20%20)%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create partitioned table for automatic archiving
CREATE TABLE user_activities (
    id BIGINT AUTO_INCREMENT,
    user_id INT NOT NULL,
    activity_type VARCHAR(50),
    activity_data JSON,
    ip_address VARCHAR(45),
    user_agent TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (id, created_at),
    INDEX idx_user_id (user_id),
    INDEX idx_activity_type (activity_type)
) ENGINE=InnoDB
PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_current VALUES LESS THAN MAXVALUE
);

-- Archive old partitions
DELIMITER //
CREATE PROCEDURE archive_old_partitions()
BEGIN
    DECLARE partition_name VARCHAR(64);
    DECLARE archive_year INT;
    
    -- Get partitions older than 2 years
    SET archive_year = YEAR(CURDATE()) - 2;
    SET partition_name = CONCAT('p', archive_year);
    
    -- Create archive table for the partition
    SET @sql = CONCAT('CREATE TABLE user_activities_archive_', archive_year, ' AS 
                      SELECT * FROM user_activities PARTITION (', partition_name, ')');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Drop the old partition
    SET @sql = CONCAT('ALTER TABLE user_activities DROP PARTITION ', partition_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log the archiving
    INSERT INTO archive_log (
        table_name, archive_criteria, records_archived, archived_at
    ) VALUES (
        'user_activities', CONCAT('partition_', partition_name), 
        (SELECT COUNT(*) FROM user_activities_archive_2022), NOW()
    );
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Archive Access and Retrieval:</strong></p>

<p><strong>1. Unified View for Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Create%20view%20that%20combines%20current%20and%20archived%20data%0ACREATE%20VIEW%20orders_complete%20AS%0ASELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%2C%20%0A%20%20%20%20%20%20%20'current'%20as%20data_source%0AFROM%20orders%0A%0AUNION%20ALL%0A%0ASELECT%20id%2C%20customer_id%2C%20order_date%2C%20total%2C%20status%2C%20created_at%2C%0A%20%20%20%20%20%20%20'archived'%20as%20data_source%0AFROM%20orders_archive%3B%0A%0A--%20Query%20across%20current%20and%20archived%20data%0ASELECT%20%0A%20%20%20%20customer_id%2C%0A%20%20%20%20COUNT(*)%20as%20total_orders%2C%0A%20%20%20%20SUM(total)%20as%20total_spent%2C%0A%20%20%20%20MIN(order_date)%20as%20first_order%2C%0A%20%20%20%20MAX(order_date)%20as%20last_order%0AFROM%20orders_complete%0AWHERE%20customer_id%20%3D%2012345%0AGROUP%20BY%20customer_id%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Create view that combines current and archived data
CREATE VIEW orders_complete AS
SELECT id, customer_id, order_date, total, status, created_at, 
       'current' as data_source
FROM orders

UNION ALL

SELECT id, customer_id, order_date, total, status, created_at,
       'archived' as data_source
FROM orders_archive;

-- Query across current and archived data
SELECT 
    customer_id,
    COUNT(*) as total_orders,
    SUM(total) as total_spent,
    MIN(order_date) as first_order,
    MAX(order_date) as last_order
FROM orders_complete
WHERE customer_id = 12345
GROUP BY customer_id;
</code></pre>
</div>

<p><strong>2. Archive Search Function:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20search_archived_data(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(64)%2C%0A%20%20%20%20IN%20p_search_criteria%20JSON%2C%0A%20%20%20%20IN%20p_date_range_start%20DATE%2C%0A%20%20%20%20IN%20p_date_range_end%20DATE%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20search_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20archive_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20archive_table%20%3D%20CONCAT(p_table_name%2C%20'_archive')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Build%20dynamic%20search%20query%0A%20%20%20%20SET%20search_sql%20%3D%20CONCAT('SELECT%20*%20FROM%20'%2C%20archive_table%2C%20'%20WHERE%201%3D1')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20date%20range%20filter%0A%20%20%20%20IF%20p_date_range_start%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20AND%20order_date%20%3E%3D%20'''%2C%20p_date_range_start%2C%20'''')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_date_range_end%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20AND%20order_date%20%3C%3D%20'''%2C%20p_date_range_end%2C%20'''')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20JSON-based%20criteria%0A%20%20%20%20IF%20JSON_LENGTH(p_search_criteria)%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20--%20Add%20custom%20search%20logic%20based%20on%20JSON%20criteria%0A%20%20%20%20%20%20%20%20--%20This%20would%20be%20expanded%20based%20on%20specific%20search%20requirements%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20search_sql%20%3D%20CONCAT(search_sql%2C%20'%20ORDER%20BY%20order_date%20DESC%20LIMIT%201000')%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20search_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE search_archived_data(
    IN p_table_name VARCHAR(64),
    IN p_search_criteria JSON,
    IN p_date_range_start DATE,
    IN p_date_range_end DATE
)
BEGIN
    DECLARE search_sql TEXT;
    DECLARE archive_table VARCHAR(100);
    
    SET archive_table = CONCAT(p_table_name, '_archive');
    
    -- Build dynamic search query
    SET search_sql = CONCAT('SELECT * FROM ', archive_table, ' WHERE 1=1');
    
    -- Add date range filter
    IF p_date_range_start IS NOT NULL THEN
        SET search_sql = CONCAT(search_sql, ' AND order_date &gt;= ''', p_date_range_start, '''');
    END IF;
    
    IF p_date_range_end IS NOT NULL THEN
        SET search_sql = CONCAT(search_sql, ' AND order_date &lt;= ''', p_date_range_end, '''');
    END IF;
    
    -- Add JSON-based criteria
    IF JSON_LENGTH(p_search_criteria) &gt; 0 THEN
        -- Add custom search logic based on JSON criteria
        -- This would be expanded based on specific search requirements
    END IF;
    
    SET search_sql = CONCAT(search_sql, ' ORDER BY order_date DESC LIMIT 1000');
    
    SET @sql = search_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Compliance and Retention Management:</strong></p>

<p><strong>1. Retention Policy Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Retention%20policy%20configuration%0ACREATE%20TABLE%20retention_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(64)%20NOT%20NULL%2C%0A%20%20%20%20retention_period_months%20INT%20NOT%20NULL%2C%0A%20%20%20%20archive_after_months%20INT%20NOT%20NULL%2C%0A%20%20%20%20delete_after_months%20INT%2C%0A%20%20%20%20compliance_requirement%20VARCHAR(100)%2C%0A%20%20%20%20policy_effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_policy%20(table_name%2C%20policy_effective_date)%0A)%3B%0A%0A--%20Insert%20retention%20policies%0AINSERT%20INTO%20retention_policies%20(%0A%20%20%20%20table_name%2C%20retention_period_months%2C%20archive_after_months%2C%20%0A%20%20%20%20delete_after_months%2C%20compliance_requirement%0A)%20VALUES%0A('orders'%2C%2084%2C%2024%2C%20NULL%2C%20'Business%20requirement%20-%207%20years')%2C%0A('user_activities'%2C%2036%2C%2012%2C%2084%2C%20'GDPR%20-%207%20years%20max%20retention')%2C%0A('audit_logs'%2C%2084%2C%2012%2C%20NULL%2C%20'SOX%20compliance%20-%207%20years')%2C%0A('payment_transactions'%2C%2084%2C%2024%2C%20NULL%2C%20'PCI%20DSS%20-%207%20years')%3B%0A%0A--%20Automated%20retention%20enforcement%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20enforce_retention_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(64)%3B%0A%20%20%20%20DECLARE%20v_archive_months%20INT%3B%0A%20%20%20%20DECLARE%20v_delete_months%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20archive_after_months%2C%20delete_after_months%0A%20%20%20%20%20%20%20%20FROM%20retention_policies%0A%20%20%20%20%20%20%20%20WHERE%20policy_effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_table_name%2C%20v_archive_months%2C%20v_delete_months%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Archive%20old%20data%0A%20%20%20%20%20%20%20%20CALL%20archive_table_data(v_table_name%2C%20v_archive_months)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Delete%20very%20old%20data%20if%20policy%20allows%0A%20%20%20%20%20%20%20%20IF%20v_delete_months%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20delete_old_archived_data(v_table_name%2C%20v_delete_months)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Retention policy configuration
CREATE TABLE retention_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64) NOT NULL,
    retention_period_months INT NOT NULL,
    archive_after_months INT NOT NULL,
    delete_after_months INT,
    compliance_requirement VARCHAR(100),
    policy_effective_date DATE NOT NULL,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_policy (table_name, policy_effective_date)
);

-- Insert retention policies
INSERT INTO retention_policies (
    table_name, retention_period_months, archive_after_months, 
    delete_after_months, compliance_requirement
) VALUES
('orders', 84, 24, NULL, 'Business requirement - 7 years'),
('user_activities', 36, 12, 84, 'GDPR - 7 years max retention'),
('audit_logs', 84, 12, NULL, 'SOX compliance - 7 years'),
('payment_transactions', 84, 24, NULL, 'PCI DSS - 7 years');

-- Automated retention enforcement
DELIMITER //
CREATE PROCEDURE enforce_retention_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(64);
    DECLARE v_archive_months INT;
    DECLARE v_delete_months INT;
    
    DECLARE policy_cursor CURSOR FOR
        SELECT table_name, archive_after_months, delete_after_months
        FROM retention_policies
        WHERE policy_effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_table_name, v_archive_months, v_delete_months;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Archive old data
        CALL archive_table_data(v_table_name, v_archive_months);
        
        -- Delete very old data if policy allows
        IF v_delete_months IS NOT NULL THEN
            CALL delete_old_archived_data(v_table_name, v_delete_months);
        END IF;
        
    END LOOP;
    
    CLOSE policy_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Performance Optimization:</strong></p>

<p>- Use separate storage engines for archives (MyISAM for read-only)</p>
<p>- Implement compression for archived data</p>
<p>- Create appropriate indexes on archive tables</p>
<p>- Use partitioning for large archive tables</p>
<p>- Regular maintenance of archive table statistics</p>
<p>- Consider external storage solutions for very old data</p>


<p>---</p>

<h2 id="-373-what-are-data-migration-best-practices-">**373. What are data migration best practices?**</h2>

<p><strong>Answer:</strong> Data migration involves transferring data between systems, databases, or formats while ensuring data integrity, minimal downtime, and business continuity.</p>

<p><strong>Migration Planning and Strategy:</strong></p>

<p><strong>1. Pre-Migration Assessment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20profiling%20and%20assessment%0ACREATE%20TABLE%20migration_assessment%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20record_count%20BIGINT%2C%0A%20%20%20%20data_size_mb%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_updated%20TIMESTAMP%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20complexity_level%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH')%2C%0A%20%20%20%20migration_priority%20INT%2C%0A%20%20%20%20estimated_duration_hours%20DECIMAL(5%2C2)%2C%0A%20%20%20%20dependencies%20TEXT%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Assess%20source%20data%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20assess_migration_data()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20record_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20data_size_mb%20DECIMAL(10%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20table_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20TABLE_NAME%0A%20%20%20%20%20%20%20%20FROM%20information_schema.tables%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20'source_database'%0A%20%20%20%20%20%20%20%20AND%20table_type%20%3D%20'BASE%20TABLE'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20assessment_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20table_cursor%20INTO%20table_name%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20assessment_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20record%20count%20and%20size%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20table_name)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20record_count%20variable%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20ROUND((data_length%20%2B%20index_length)%20%2F%201024%20%2F%201024%2C%202)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20FROM%20information_schema.tables%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20'''%2C%20table_name%2C%20'''')%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20data_size_mb%20variable%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20assessment%20data%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20migration_assessment%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20source_table%2C%20record_count%2C%20data_size_mb%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20complexity_level%2C%20migration_priority%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20record_count%2C%20data_size_mb%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20record_count%20%3E%2010000000%20THEN%20'HIGH'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20record_count%20%3E%201000000%20THEN%20'MEDIUM'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'LOW'%0A%20%20%20%20%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20table_name%20LIKE%20'%25user%25'%20OR%20table_name%20LIKE%20'%25customer%25'%20THEN%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20table_name%20LIKE%20'%25order%25'%20OR%20table_name%20LIKE%20'%25transaction%25'%20THEN%202%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%203%0A%20%20%20%20%20%20%20%20%20%20%20%20END%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20table_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data profiling and assessment
CREATE TABLE migration_assessment (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source_table VARCHAR(100),
    record_count BIGINT,
    data_size_mb DECIMAL(10,2),
    last_updated TIMESTAMP,
    data_quality_score DECIMAL(3,2),
    complexity_level ENUM('LOW', 'MEDIUM', 'HIGH'),
    migration_priority INT,
    estimated_duration_hours DECIMAL(5,2),
    dependencies TEXT,
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Assess source data
DELIMITER //
CREATE PROCEDURE assess_migration_data()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE table_name VARCHAR(100);
    DECLARE record_count BIGINT;
    DECLARE data_size_mb DECIMAL(10,2);
    
    DECLARE table_cursor CURSOR FOR
        SELECT TABLE_NAME
        FROM information_schema.tables
        WHERE table_schema = 'source_database'
        AND table_type = 'BASE TABLE';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN table_cursor;
    
    assessment_loop: LOOP
        FETCH table_cursor INTO table_name;
        
        IF done THEN
            LEAVE assessment_loop;
        END IF;
        
        -- Get record count and size
        SET @sql = CONCAT('SELECT COUNT(*) FROM ', table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in record_count variable
        
        SET @sql = CONCAT('SELECT ROUND((data_length + index_length) / 1024 / 1024, 2) 
                          FROM information_schema.tables 
                          WHERE table_name = ''', table_name, '''');
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in data_size_mb variable
        
        -- Insert assessment data
        INSERT INTO migration_assessment (
            source_table, record_count, data_size_mb, 
            complexity_level, migration_priority
        ) VALUES (
            table_name, record_count, data_size_mb,
            CASE 
                WHEN record_count &gt; 10000000 THEN 'HIGH'
                WHEN record_count &gt; 1000000 THEN 'MEDIUM'
                ELSE 'LOW'
            END,
            CASE 
                WHEN table_name LIKE '%user%' OR table_name LIKE '%customer%' THEN 1
                WHEN table_name LIKE '%order%' OR table_name LIKE '%transaction%' THEN 2
                ELSE 3
            END
        );
        
        DEALLOCATE PREPARE stmt;
        
    END LOOP;
    
    CLOSE table_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Migration Execution Framework:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Migration%20tracking%20table%0ACREATE%20TABLE%20migration_execution%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20migration_batch%20VARCHAR(50)%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20target_table%20VARCHAR(100)%2C%0A%20%20%20%20migration_type%20ENUM('FULL'%2C%20'INCREMENTAL'%2C%20'DELTA')%2C%0A%20%20%20%20status%20ENUM('PENDING'%2C%20'IN_PROGRESS'%2C%20'COMPLETED'%2C%20'FAILED'%2C%20'ROLLBACK')%2C%0A%20%20%20%20records_source%20BIGINT%2C%0A%20%20%20%20records_migrated%20BIGINT%2C%0A%20%20%20%20records_failed%20BIGINT%2C%0A%20%20%20%20start_time%20TIMESTAMP%2C%0A%20%20%20%20end_time%20TIMESTAMP%2C%0A%20%20%20%20duration_seconds%20INT%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20validation_status%20ENUM('PENDING'%2C%20'PASSED'%2C%20'FAILED')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Generic%20migration%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20migrate_table_data(%0A%20%20%20%20IN%20p_source_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_batch_size%20INT%2C%0A%20%20%20%20IN%20p_migration_type%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_migration_id%20INT%3B%0A%20%20%20%20DECLARE%20v_total_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_migrated_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_failed_records%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_batch_start%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_batch_end%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'FAILED'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20error_message%20%3D%20'Migration%20failed%20with%20SQL%20exception'%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Initialize%20migration%20record%0A%20%20%20%20INSERT%20INTO%20migration_execution%20(%0A%20%20%20%20%20%20%20%20source_table%2C%20target_table%2C%20migration_type%2C%20status%2C%20start_time%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_source_table%2C%20p_target_table%2C%20p_migration_type%2C%20'IN_PROGRESS'%2C%20v_start_time%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_migration_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20total%20record%20count%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_total_records%0A%20%20%20%20%0A%20%20%20%20--%20Update%20migration%20record%20with%20total%20count%0A%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20SET%20records_source%20%3D%20v_total_records%20%0A%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Migrate%20in%20batches%0A%20%20%20%20WHILE%20v_batch_start%20%3C%20v_total_records%20DO%0A%20%20%20%20%20%20%20%20SET%20v_batch_end%20%3D%20v_batch_start%20%2B%20p_batch_size%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Migrate%20batch%0A%20%20%20%20%20%20%20%20SET%20%40migrate_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_target_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20p_source_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_start%2C%20'%2C%20'%2C%20p_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20migrate_stmt%20FROM%20%40migrate_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20migrate_stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20migrate_stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_migrated_records%20%3D%20v_migrated_records%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20SET%20v_batch_start%20%3D%20v_batch_end%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20progress%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20records_migrated%20%3D%20v_migrated_records%20%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Complete%20migration%0A%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%0A%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20duration_seconds%20%3D%20TIMESTAMPDIFF(SECOND%2C%20v_start_time%2C%20NOW())%2C%0A%20%20%20%20%20%20%20%20records_migrated%20%3D%20v_migrated_records%0A%20%20%20%20WHERE%20id%20%3D%20v_migration_id%3B%0A%20%20%20%20%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Migration tracking table
CREATE TABLE migration_execution (
    id INT AUTO_INCREMENT PRIMARY KEY,
    migration_batch VARCHAR(50),
    source_table VARCHAR(100),
    target_table VARCHAR(100),
    migration_type ENUM('FULL', 'INCREMENTAL', 'DELTA'),
    status ENUM('PENDING', 'IN_PROGRESS', 'COMPLETED', 'FAILED', 'ROLLBACK'),
    records_source BIGINT,
    records_migrated BIGINT,
    records_failed BIGINT,
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    duration_seconds INT,
    error_message TEXT,
    validation_status ENUM('PENDING', 'PASSED', 'FAILED'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Generic migration procedure
DELIMITER //
CREATE PROCEDURE migrate_table_data(
    IN p_source_table VARCHAR(100),
    IN p_target_table VARCHAR(100),
    IN p_batch_size INT,
    IN p_migration_type VARCHAR(20)
)
BEGIN
    DECLARE v_migration_id INT;
    DECLARE v_total_records BIGINT DEFAULT 0;
    DECLARE v_migrated_records BIGINT DEFAULT 0;
    DECLARE v_failed_records BIGINT DEFAULT 0;
    DECLARE v_batch_start BIGINT DEFAULT 0;
    DECLARE v_batch_end BIGINT;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        UPDATE migration_execution 
        SET status = 'FAILED', 
            end_time = NOW(),
            error_message = 'Migration failed with SQL exception'
        WHERE id = v_migration_id;
        RESIGNAL;
    END;
    
    -- Initialize migration record
    INSERT INTO migration_execution (
        source_table, target_table, migration_type, status, start_time
    ) VALUES (
        p_source_table, p_target_table, p_migration_type, 'IN_PROGRESS', v_start_time
    );
    
    SET v_migration_id = LAST_INSERT_ID();
    
    -- Get total record count
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_total_records
    
    -- Update migration record with total count
    UPDATE migration_execution 
    SET records_source = v_total_records 
    WHERE id = v_migration_id;
    
    -- Migrate in batches
    WHILE v_batch_start &lt; v_total_records DO
        SET v_batch_end = v_batch_start + p_batch_size;
        
        -- Migrate batch
        SET @migrate_sql = CONCAT(
            'INSERT INTO ', p_target_table, ' ',
            'SELECT * FROM ', p_source_table, ' ',
            'LIMIT ', v_batch_start, ', ', p_batch_size
        );
        
        PREPARE migrate_stmt FROM @migrate_sql;
        EXECUTE migrate_stmt;
        DEALLOCATE PREPARE migrate_stmt;
        
        SET v_migrated_records = v_migrated_records + ROW_COUNT();
        SET v_batch_start = v_batch_end;
        
        -- Update progress
        UPDATE migration_execution 
        SET records_migrated = v_migrated_records 
        WHERE id = v_migration_id;
        
    END WHILE;
    
    -- Complete migration
    UPDATE migration_execution 
    SET status = 'COMPLETED',
        end_time = NOW(),
        duration_seconds = TIMESTAMPDIFF(SECOND, v_start_time, NOW()),
        records_migrated = v_migrated_records
    WHERE id = v_migration_id;
    
    DEALLOCATE PREPARE stmt;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Validation and Quality Checks:</strong></p>

<p><strong>1. Comprehensive Validation Framework:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Validation%20rules%20configuration%0ACREATE%20TABLE%20validation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20rule_type%20ENUM('NOT_NULL'%2C%20'UNIQUE'%2C%20'RANGE'%2C%20'FORMAT'%2C%20'REFERENCE'%2C%20'CUSTOM')%2C%0A%20%20%20%20rule_definition%20JSON%2C%0A%20%20%20%20severity%20ENUM('ERROR'%2C%20'WARNING'%2C%20'INFO')%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20validation%20rules%0AINSERT%20INTO%20validation_rules%20(table_name%2C%20column_name%2C%20rule_type%2C%20rule_definition%2C%20severity)%20VALUES%0A('customers'%2C%20'email'%2C%20'FORMAT'%2C%20'%7B%22pattern%22%3A%20%22%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C%5C.%5BA-Za-z%5D%7B2%2C%7D%24%22%7D'%2C%20'ERROR')%2C%0A('customers'%2C%20'phone'%2C%20'FORMAT'%2C%20'%7B%22pattern%22%3A%20%22%5E%5C%5C%2B%3F%5B1-9%5D%5C%5Cd%7B1%2C14%7D%24%22%7D'%2C%20'WARNING')%2C%0A('orders'%2C%20'total'%2C%20'RANGE'%2C%20'%7B%22min%22%3A%200%2C%20%22max%22%3A%20999999.99%7D'%2C%20'ERROR')%2C%0A('orders'%2C%20'customer_id'%2C%20'REFERENCE'%2C%20'%7B%22table%22%3A%20%22customers%22%2C%20%22column%22%3A%20%22id%22%7D'%2C%20'ERROR')%3B%0A%0A--%20Validation%20execution%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_migrated_data(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_rule_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_rule_definition%20JSON%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_error_count%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20validation_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20rule_type%2C%20rule_definition%2C%20severity%0A%20%20%20%20%20%20%20%20FROM%20validation_rules%0A%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20validation%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20validation_results%20(%0A%20%20%20%20%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20rule_type%20VARCHAR(20)%2C%0A%20%20%20%20%20%20%20%20severity%20VARCHAR(10)%2C%0A%20%20%20%20%20%20%20%20error_count%20INT%2C%0A%20%20%20%20%20%20%20%20sample_errors%20TEXT%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20validation_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20validation_cursor%20INTO%20v_column_name%2C%20v_rule_type%2C%20v_rule_definition%2C%20v_severity%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20validation_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20validation%20query%20based%20on%20rule%20type%0A%20%20%20%20%20%20%20%20CASE%20v_rule_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'NOT_NULL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20IS%20NULL'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'FORMAT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20NOT%20REGEXP%20'''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(v_rule_definition%2C%20'%24.pattern'))%2C%20''''%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'RANGE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20%3C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_rule_definition%2C%20'%24.min')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20OR%20'%2C%20v_column_name%2C%20'%20%3E%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_rule_definition%2C%20'%24.max')%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20NULL%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20validation%0A%20%20%20%20%20%20%20%20IF%20v_validation_sql%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Get%20result%20into%20v_error_count%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20validation%20result%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20validation_results%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p_table_name%2C%20v_column_name%2C%20v_rule_type%2C%20v_severity%2C%20v_error_count%2C%20NULL%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20validation%20results%0A%20%20%20%20SELECT%20*%20FROM%20validation_results%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20validation_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Validation rules configuration
CREATE TABLE validation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100),
    column_name VARCHAR(100),
    rule_type ENUM('NOT_NULL', 'UNIQUE', 'RANGE', 'FORMAT', 'REFERENCE', 'CUSTOM'),
    rule_definition JSON,
    severity ENUM('ERROR', 'WARNING', 'INFO'),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert validation rules
INSERT INTO validation_rules (table_name, column_name, rule_type, rule_definition, severity) VALUES
('customers', 'email', 'FORMAT', '{"pattern": "^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$"}', 'ERROR'),
('customers', 'phone', 'FORMAT', '{"pattern": "^\\+?[1-9]\\d{1,14}$"}', 'WARNING'),
('orders', 'total', 'RANGE', '{"min": 0, "max": 999999.99}', 'ERROR'),
('orders', 'customer_id', 'REFERENCE', '{"table": "customers", "column": "id"}', 'ERROR');

-- Validation execution procedure
DELIMITER //
CREATE PROCEDURE validate_migrated_data(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_rule_type VARCHAR(20);
    DECLARE v_rule_definition JSON;
    DECLARE v_severity VARCHAR(10);
    DECLARE v_validation_sql TEXT;
    DECLARE v_error_count INT;
    
    DECLARE validation_cursor CURSOR FOR
        SELECT column_name, rule_type, rule_definition, severity
        FROM validation_rules
        WHERE table_name = p_table_name AND is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create validation results table
    CREATE TEMPORARY TABLE validation_results (
        table_name VARCHAR(100),
        column_name VARCHAR(100),
        rule_type VARCHAR(20),
        severity VARCHAR(10),
        error_count INT,
        sample_errors TEXT
    );
    
    OPEN validation_cursor;
    
    validation_loop: LOOP
        FETCH validation_cursor INTO v_column_name, v_rule_type, v_rule_definition, v_severity;
        
        IF done THEN
            LEAVE validation_loop;
        END IF;
        
        -- Build validation query based on rule type
        CASE v_rule_type
            WHEN 'NOT_NULL' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name, 
                    ' WHERE ', v_column_name, ' IS NULL'
                );
            
            WHEN 'FORMAT' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name,
                    ' WHERE ', v_column_name, ' NOT REGEXP ''',
                    JSON_UNQUOTE(JSON_EXTRACT(v_rule_definition, '$.pattern')), ''''
                );
            
            WHEN 'RANGE' THEN
                SET v_validation_sql = CONCAT(
                    'SELECT COUNT(*) FROM ', p_table_name,
                    ' WHERE ', v_column_name, ' &lt; ',
                    JSON_EXTRACT(v_rule_definition, '$.min'),
                    ' OR ', v_column_name, ' &gt; ',
                    JSON_EXTRACT(v_rule_definition, '$.max')
                );
            
            ELSE
                SET v_validation_sql = NULL;
        END CASE;
        
        -- Execute validation
        IF v_validation_sql IS NOT NULL THEN
            SET @sql = v_validation_sql;
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            -- Get result into v_error_count
            DEALLOCATE PREPARE stmt;
            
            -- Insert validation result
            INSERT INTO validation_results VALUES (
                p_table_name, v_column_name, v_rule_type, v_severity, v_error_count, NULL
            );
        END IF;
        
    END LOOP;
    
    CLOSE validation_cursor;
    
    -- Return validation results
    SELECT * FROM validation_results;
    
    DROP TEMPORARY TABLE validation_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Reconciliation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Reconciliation%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20reconcile_migration_data(%0A%20%20%20%20IN%20p_source_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_source_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_target_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_source_checksum%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_target_checksum%20BIGINT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20comparison%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_source_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_target_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_target_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Checksum%20comparison%20(for%20numeric%20columns)%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20SUM(CRC32(CONCAT_WS(%22%7C%22%2C%20*)))%20FROM%20'%2C%20p_source_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_source_checksum%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20SUM(CRC32(CONCAT_WS(%22%7C%22%2C%20*)))%20FROM%20'%2C%20p_target_table)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_target_checksum%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Insert%20reconciliation%20results%0A%20%20%20%20INSERT%20INTO%20migration_reconciliation%20(%0A%20%20%20%20%20%20%20%20source_table%2C%20target_table%2C%20source_count%2C%20target_count%2C%0A%20%20%20%20%20%20%20%20source_checksum%2C%20target_checksum%2C%20%0A%20%20%20%20%20%20%20%20count_match%2C%20checksum_match%2C%20reconciled_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_source_table%2C%20p_target_table%2C%20v_source_count%2C%20v_target_count%2C%0A%20%20%20%20%20%20%20%20v_source_checksum%2C%20v_target_checksum%2C%0A%20%20%20%20%20%20%20%20(v_source_count%20%3D%20v_target_count)%2C%0A%20%20%20%20%20%20%20%20(v_source_checksum%20%3D%20v_target_checksum)%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Reconciliation procedure
DELIMITER //
CREATE PROCEDURE reconcile_migration_data(
    IN p_source_table VARCHAR(100),
    IN p_target_table VARCHAR(100)
)
BEGIN
    DECLARE v_source_count BIGINT;
    DECLARE v_target_count BIGINT;
    DECLARE v_source_checksum BIGINT;
    DECLARE v_target_checksum BIGINT;
    
    -- Count comparison
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_source_count
    DEALLOCATE PREPARE stmt;
    
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_target_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_target_count
    DEALLOCATE PREPARE stmt;
    
    -- Checksum comparison (for numeric columns)
    SET @sql = CONCAT('SELECT SUM(CRC32(CONCAT_WS("|", *))) FROM ', p_source_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_source_checksum
    DEALLOCATE PREPARE stmt;
    
    SET @sql = CONCAT('SELECT SUM(CRC32(CONCAT_WS("|", *))) FROM ', p_target_table);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store in v_target_checksum
    DEALLOCATE PREPARE stmt;
    
    -- Insert reconciliation results
    INSERT INTO migration_reconciliation (
        source_table, target_table, source_count, target_count,
        source_checksum, target_checksum, 
        count_match, checksum_match, reconciled_at
    ) VALUES (
        p_source_table, p_target_table, v_source_count, v_target_count,
        v_source_checksum, v_target_checksum,
        (v_source_count = v_target_count),
        (v_source_checksum = v_target_checksum),
        NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Rollback and Recovery:</strong></p>

<p><strong>1. Rollback Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Rollback%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20rollback_migration(IN%20p_migration_batch%20VARCHAR(50))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_target_table%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_backup_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20rollback_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20DISTINCT%20target_table%0A%20%20%20%20%20%20%20%20FROM%20migration_execution%0A%20%20%20%20%20%20%20%20WHERE%20migration_batch%20%3D%20p_migration_batch%0A%20%20%20%20%20%20%20%20AND%20status%20%3D%20'COMPLETED'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20rollback_cursor%3B%0A%20%20%20%20%0A%20%20%20%20rollback_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20rollback_cursor%20INTO%20v_target_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20rollback_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_backup_table%20%3D%20CONCAT(v_target_table%2C%20'_backup_'%2C%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d'))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Restore%20from%20backup%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('DROP%20TABLE%20IF%20EXISTS%20'%2C%20v_target_table)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('RENAME%20TABLE%20'%2C%20v_backup_table%2C%20'%20TO%20'%2C%20v_target_table)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20migration%20status%0A%20%20%20%20%20%20%20%20UPDATE%20migration_execution%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'ROLLBACK'%0A%20%20%20%20%20%20%20%20WHERE%20migration_batch%20%3D%20p_migration_batch%0A%20%20%20%20%20%20%20%20AND%20target_table%20%3D%20v_target_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20rollback_cursor%3B%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Rollback procedure
DELIMITER //
CREATE PROCEDURE rollback_migration(IN p_migration_batch VARCHAR(50))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_target_table VARCHAR(100);
    DECLARE v_backup_table VARCHAR(100);
    
    DECLARE rollback_cursor CURSOR FOR
        SELECT DISTINCT target_table
        FROM migration_execution
        WHERE migration_batch = p_migration_batch
        AND status = 'COMPLETED';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    START TRANSACTION;
    
    OPEN rollback_cursor;
    
    rollback_loop: LOOP
        FETCH rollback_cursor INTO v_target_table;
        
        IF done THEN
            LEAVE rollback_loop;
        END IF;
        
        SET v_backup_table = CONCAT(v_target_table, '_backup_', DATE_FORMAT(NOW(), '%Y%m%d'));
        
        -- Restore from backup
        SET @sql = CONCAT('DROP TABLE IF EXISTS ', v_target_table);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        SET @sql = CONCAT('RENAME TABLE ', v_backup_table, ' TO ', v_target_table);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- Update migration status
        UPDATE migration_execution 
        SET status = 'ROLLBACK'
        WHERE migration_batch = p_migration_batch
        AND target_table = v_target_table;
        
    END LOOP;
    
    CLOSE rollback_cursor;
    COMMIT;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Best Practices:</strong></p>

<p>- Always create backups before migration</p>
<p>- Test migration process on subset of data first</p>
<p>- Implement comprehensive validation and reconciliation</p>
<p>- Use batched processing for large datasets</p>
<p>- Monitor migration progress and performance</p>
<p>- Plan for rollback scenarios</p>
<p>- Document all migration steps and decisions</p>
<p>- Validate business logic after migration</p>

<h2 id="-374-how-do-you-implement-data-backup-and-recovery-strategies-">**374. How do you implement data backup and recovery strategies?**</h2>

<p><strong>Answer:</strong> Data backup and recovery strategies ensure business continuity and data protection through systematic backup procedures and tested recovery processes.</p>

<p><strong>Backup Strategy Types:</strong></p>

<p><strong>1. Full Backup Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Automated%20full%20backup%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_full_backup(IN%20p_backup_location%20VARCHAR(500))%0ABEGIN%0A%20%20%20%20DECLARE%20backup_filename%20VARCHAR(600)%3B%0A%20%20%20%20DECLARE%20backup_command%20TEXT%3B%0A%20%20%20%20DECLARE%20backup_start%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20SET%20backup_filename%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20p_backup_location%2C%20'%2F'%2C%0A%20%20%20%20%20%20%20%20DATABASE()%2C%20'_full_backup_'%2C%0A%20%20%20%20%20%20%20%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s')%2C%20'.sql'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20backup%20start%0A%20%20%20%20INSERT%20INTO%20backup_log%20(backup_type%2C%20backup_location%2C%20status%2C%20start_time)%0A%20%20%20%20VALUES%20('FULL'%2C%20backup_filename%2C%20'IN_PROGRESS'%2C%20backup_start)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20mysqldump%20command%20(would%20be%20done%20via%20external%20script)%0A%20%20%20%20SET%20backup_command%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'mysqldump%20--single-transaction%20--routines%20--triggers%20'%2C%0A%20%20%20%20%20%20%20%20'--host%3D'%2C%20%40%40hostname%2C%20'%20--user%3Dbackup_user%20'%2C%0A%20%20%20%20%20%20%20%20'--password%3Dbackup_password%20'%2C%20DATABASE()%2C%20%0A%20%20%20%20%20%20%20%20'%20%3E%20'%2C%20backup_filename%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20backup%20log%20on%20completion%0A%20%20%20%20UPDATE%20backup_log%20%0A%20%20%20%20SET%20status%20%3D%20'COMPLETED'%2C%20%0A%20%20%20%20%20%20%20%20end_time%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20duration_minutes%20%3D%20TIMESTAMPDIFF(MINUTE%2C%20backup_start%2C%20NOW())%2C%0A%20%20%20%20%20%20%20%20file_size_mb%20%3D%20(SELECT%20ROUND(SUM(data_length%20%2B%20index_length)%20%2F%201024%20%2F%201024%2C%202)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20FROM%20information_schema.tables%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20DATABASE())%0A%20%20%20%20WHERE%20backup_location%20%3D%20backup_filename%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Automated full backup procedure
DELIMITER //
CREATE PROCEDURE create_full_backup(IN p_backup_location VARCHAR(500))
BEGIN
    DECLARE backup_filename VARCHAR(600);
    DECLARE backup_command TEXT;
    DECLARE backup_start TIMESTAMP DEFAULT NOW();
    
    SET backup_filename = CONCAT(
        p_backup_location, '/',
        DATABASE(), '_full_backup_',
        DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'), '.sql'
    );
    
    -- Log backup start
    INSERT INTO backup_log (backup_type, backup_location, status, start_time)
    VALUES ('FULL', backup_filename, 'IN_PROGRESS', backup_start);
    
    -- Execute mysqldump command (would be done via external script)
    SET backup_command = CONCAT(
        'mysqldump --single-transaction --routines --triggers ',
        '--host=', @@hostname, ' --user=backup_user ',
        '--password=backup_password ', DATABASE(), 
        ' &gt; ', backup_filename
    );
    
    -- Update backup log on completion
    UPDATE backup_log 
    SET status = 'COMPLETED', 
        end_time = NOW(),
        duration_minutes = TIMESTAMPDIFF(MINUTE, backup_start, NOW()),
        file_size_mb = (SELECT ROUND(SUM(data_length + index_length) / 1024 / 1024, 2)
                       FROM information_schema.tables 
                       WHERE table_schema = DATABASE())
    WHERE backup_location = backup_filename;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Incremental Backup Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Binary%20log-based%20incremental%20backup%0ACREATE%20TABLE%20backup_positions%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20backup_type%20ENUM('FULL'%2C%20'INCREMENTAL')%2C%0A%20%20%20%20binlog_file%20VARCHAR(255)%2C%0A%20%20%20%20binlog_position%20BIGINT%2C%0A%20%20%20%20backup_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20backup_location%20VARCHAR(500)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_incremental_backup()%0ABEGIN%0A%20%20%20%20DECLARE%20last_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20last_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20current_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20current_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20backup_location%20VARCHAR(500)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20last%20backup%20position%0A%20%20%20%20SELECT%20binlog_file%2C%20binlog_position%20%0A%20%20%20%20INTO%20last_binlog_file%2C%20last_binlog_position%0A%20%20%20%20FROM%20backup_positions%20%0A%20%20%20%20ORDER%20BY%20backup_timestamp%20DESC%20%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20master%20status%0A%20%20%20%20SELECT%20File%2C%20Position%20%0A%20%20%20%20INTO%20current_binlog_file%2C%20current_binlog_position%0A%20%20%20%20FROM%20(SHOW%20MASTER%20STATUS)%20ms%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20incremental%20backup%20filename%0A%20%20%20%20SET%20backup_location%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'%2Fbackups%2Fincremental%2F'%2C%0A%20%20%20%20%20%20%20%20DATABASE()%2C%20'_incremental_'%2C%0A%20%20%20%20%20%20%20%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s')%2C%20'.sql'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20binary%20log%20changes%20(would%20use%20mysqlbinlog%20externally)%0A%20%20%20%20--%20mysqlbinlog%20--start-position%3Dlast_position%20--stop-position%3Dcurrent_position%0A%20%20%20%20%0A%20%20%20%20--%20Record%20new%20backup%20position%0A%20%20%20%20INSERT%20INTO%20backup_positions%20(%0A%20%20%20%20%20%20%20%20backup_type%2C%20binlog_file%2C%20binlog_position%2C%20backup_location%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'INCREMENTAL'%2C%20current_binlog_file%2C%20current_binlog_position%2C%20backup_location%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Binary log-based incremental backup
CREATE TABLE backup_positions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    backup_type ENUM('FULL', 'INCREMENTAL'),
    binlog_file VARCHAR(255),
    binlog_position BIGINT,
    backup_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    backup_location VARCHAR(500)
);

DELIMITER //
CREATE PROCEDURE create_incremental_backup()
BEGIN
    DECLARE last_binlog_file VARCHAR(255);
    DECLARE last_binlog_position BIGINT;
    DECLARE current_binlog_file VARCHAR(255);
    DECLARE current_binlog_position BIGINT;
    DECLARE backup_location VARCHAR(500);
    
    -- Get last backup position
    SELECT binlog_file, binlog_position 
    INTO last_binlog_file, last_binlog_position
    FROM backup_positions 
    ORDER BY backup_timestamp DESC 
    LIMIT 1;
    
    -- Get current master status
    SELECT File, Position 
    INTO current_binlog_file, current_binlog_position
    FROM (SHOW MASTER STATUS) ms;
    
    -- Create incremental backup filename
    SET backup_location = CONCAT(
        '/backups/incremental/',
        DATABASE(), '_incremental_',
        DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'), '.sql'
    );
    
    -- Extract binary log changes (would use mysqlbinlog externally)
    -- mysqlbinlog --start-position=last_position --stop-position=current_position
    
    -- Record new backup position
    INSERT INTO backup_positions (
        backup_type, binlog_file, binlog_position, backup_location
    ) VALUES (
        'INCREMENTAL', current_binlog_file, current_binlog_position, backup_location
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Recovery Procedures:</strong></p>

<p><strong>1. Point-in-Time Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20point_in_time_recovery(%0A%20%20%20%20IN%20p_recovery_timestamp%20TIMESTAMP%2C%0A%20%20%20%20IN%20p_full_backup_file%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20recovery_binlog_file%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20recovery_binlog_position%20BIGINT%3B%0A%20%20%20%20DECLARE%20recovery_commands%20TEXT%20DEFAULT%20''%3B%0A%20%20%20%20%0A%20%20%20%20--%20Find%20the%20appropriate%20backup%20point%0A%20%20%20%20SELECT%20binlog_file%2C%20binlog_position%0A%20%20%20%20INTO%20recovery_binlog_file%2C%20recovery_binlog_position%0A%20%20%20%20FROM%20backup_positions%0A%20%20%20%20WHERE%20backup_timestamp%20%3C%3D%20p_recovery_timestamp%0A%20%20%20%20ORDER%20BY%20backup_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20recovery%20start%0A%20%20%20%20INSERT%20INTO%20recovery_log%20(%0A%20%20%20%20%20%20%20%20recovery_type%2C%20target_timestamp%2C%20full_backup_file%2C%20%0A%20%20%20%20%20%20%20%20binlog_file%2C%20binlog_position%2C%20status%2C%20start_time%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'POINT_IN_TIME'%2C%20p_recovery_timestamp%2C%20p_full_backup_file%2C%0A%20%20%20%20%20%20%20%20recovery_binlog_file%2C%20recovery_binlog_position%2C%20'IN_PROGRESS'%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20recovery%20commands%20(would%20be%20executed%20externally)%0A%20%20%20%20SET%20recovery_commands%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'1.%20Stop%20MySQL%20service%5Cn'%2C%0A%20%20%20%20%20%20%20%20'2.%20Restore%20full%20backup%3A%20mysql%20%3C%20'%2C%20p_full_backup_file%2C%20'%5Cn'%2C%0A%20%20%20%20%20%20%20%20'3.%20Apply%20binary%20logs%3A%20mysqlbinlog%20--start-position%3D'%2C%20recovery_binlog_position%2C%0A%20%20%20%20%20%20%20%20'%20--stop-datetime%3D%22'%2C%20p_recovery_timestamp%2C%20'%22%20'%2C%20recovery_binlog_file%2C%20'%20%7C%20mysql%5Cn'%2C%0A%20%20%20%20%20%20%20%20'4.%20Start%20MySQL%20service%5Cn'%2C%0A%20%20%20%20%20%20%20%20'5.%20Verify%20data%20consistency'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20recovery%20log%20with%20commands%0A%20%20%20%20UPDATE%20recovery_log%20%0A%20%20%20%20SET%20recovery_commands%20%3D%20recovery_commands%2C%0A%20%20%20%20%20%20%20%20status%20%3D%20'READY_FOR_EXECUTION'%0A%20%20%20%20WHERE%20target_timestamp%20%3D%20p_recovery_timestamp%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE point_in_time_recovery(
    IN p_recovery_timestamp TIMESTAMP,
    IN p_full_backup_file VARCHAR(500)
)
BEGIN
    DECLARE recovery_binlog_file VARCHAR(255);
    DECLARE recovery_binlog_position BIGINT;
    DECLARE recovery_commands TEXT DEFAULT '';
    
    -- Find the appropriate backup point
    SELECT binlog_file, binlog_position
    INTO recovery_binlog_file, recovery_binlog_position
    FROM backup_positions
    WHERE backup_timestamp &lt;= p_recovery_timestamp
    ORDER BY backup_timestamp DESC
    LIMIT 1;
    
    -- Log recovery start
    INSERT INTO recovery_log (
        recovery_type, target_timestamp, full_backup_file, 
        binlog_file, binlog_position, status, start_time
    ) VALUES (
        'POINT_IN_TIME', p_recovery_timestamp, p_full_backup_file,
        recovery_binlog_file, recovery_binlog_position, 'IN_PROGRESS', NOW()
    );
    
    -- Generate recovery commands (would be executed externally)
    SET recovery_commands = CONCAT(
        '1. Stop MySQL service\n',
        '2. Restore full backup: mysql &lt; ', p_full_backup_file, '\n',
        '3. Apply binary logs: mysqlbinlog --start-position=', recovery_binlog_position,
        ' --stop-datetime="', p_recovery_timestamp, '" ', recovery_binlog_file, ' | mysql\n',
        '4. Start MySQL service\n',
        '5. Verify data consistency'
    );
    
    -- Update recovery log with commands
    UPDATE recovery_log 
    SET recovery_commands = recovery_commands,
        status = 'READY_FOR_EXECUTION'
    WHERE target_timestamp = p_recovery_timestamp;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Table-Level Recovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20recover_single_table(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_recovery_timestamp%20TIMESTAMP%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20temp_db_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20recovery_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20SET%20temp_db_name%20%3D%20CONCAT('recovery_'%2C%20UNIX_TIMESTAMP())%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20database%20for%20recovery%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('CREATE%20DATABASE%20'%2C%20temp_db_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Restore%20full%20backup%20to%20temporary%20database%0A%20%20%20%20--%20(External%20command%3A%20mysql%20temp_db%20%3C%20backup.sql)%0A%20%20%20%20%0A%20%20%20%20--%20Copy%20specific%20table%20data%0A%20%20%20%20SET%20recovery_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20DATABASE()%2C%20'.'%2C%20p_table_name%2C%20'_recovered%20'%2C%0A%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20temp_db_name%2C%20'.'%2C%20p_table_name%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20recovery_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clean%20up%20temporary%20database%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('DROP%20DATABASE%20'%2C%20temp_db_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20recovery%20completion%0A%20%20%20%20INSERT%20INTO%20recovery_log%20(%0A%20%20%20%20%20%20%20%20recovery_type%2C%20table_name%2C%20target_timestamp%2C%20status%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'TABLE_LEVEL'%2C%20p_table_name%2C%20p_recovery_timestamp%2C%20'COMPLETED'%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE recover_single_table(
    IN p_table_name VARCHAR(100),
    IN p_recovery_timestamp TIMESTAMP
)
BEGIN
    DECLARE temp_db_name VARCHAR(100);
    DECLARE recovery_sql TEXT;
    
    SET temp_db_name = CONCAT('recovery_', UNIX_TIMESTAMP());
    
    -- Create temporary database for recovery
    SET @sql = CONCAT('CREATE DATABASE ', temp_db_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Restore full backup to temporary database
    -- (External command: mysql temp_db &lt; backup.sql)
    
    -- Copy specific table data
    SET recovery_sql = CONCAT(
        'INSERT INTO ', DATABASE(), '.', p_table_name, '_recovered ',
        'SELECT * FROM ', temp_db_name, '.', p_table_name
    );
    
    SET @sql = recovery_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Clean up temporary database
    SET @sql = CONCAT('DROP DATABASE ', temp_db_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log recovery completion
    INSERT INTO recovery_log (
        recovery_type, table_name, target_timestamp, status, completed_at
    ) VALUES (
        'TABLE_LEVEL', p_table_name, p_recovery_timestamp, 'COMPLETED', NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-375-what-are-data-quality-management-techniques-">**375. What are data quality management techniques?**</h2>

<p><strong>Answer:</strong> Data quality management ensures data accuracy, completeness, consistency, and reliability through systematic validation, cleansing, and monitoring processes.</p>

<p><strong>Data Quality Framework:</strong></p>

<p><strong>1. Data Profiling and Assessment:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20quality%20metrics%20table%0ACREATE%20TABLE%20data_quality_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20metric_type%20ENUM('COMPLETENESS'%2C%20'ACCURACY'%2C%20'CONSISTENCY'%2C%20'VALIDITY'%2C%20'UNIQUENESS')%2C%0A%20%20%20%20metric_value%20DECIMAL(5%2C2)%2C%0A%20%20%20%20total_records%20BIGINT%2C%0A%20%20%20%20quality_issues%20BIGINT%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_column%20(table_name%2C%20column_name)%2C%0A%20%20%20%20INDEX%20idx_metric_type%20(metric_type)%2C%0A%20%20%20%20INDEX%20idx_assessment_date%20(assessment_date)%0A)%3B%0A%0A--%20Data%20profiling%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20profile_data_quality(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_data_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_total_records%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_null_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_unique_count%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_completeness%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_uniqueness%20DECIMAL(5%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20column_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20data_type%0A%20%20%20%20%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20DATABASE()%0A%20%20%20%20%20%20%20%20AND%20table_name%20%3D%20p_table_name%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20total%20record%20count%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20v_total_records%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20column_cursor%3B%0A%20%20%20%20%0A%20%20%20%20profile_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20column_cursor%20INTO%20v_column_name%2C%20v_data_type%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20profile_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20completeness%20(non-null%20percentage)%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_column_name%2C%20'%20IS%20NULL')%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20in%20v_null_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_completeness%20%3D%20((v_total_records%20-%20v_null_count)%20%2F%20v_total_records)%20*%20100%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20uniqueness%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20CONCAT('SELECT%20COUNT(DISTINCT%20'%2C%20v_column_name%2C%20')%20FROM%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20in%20v_unique_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_uniqueness%20%3D%20(v_unique_count%20%2F%20v_total_records)%20*%20100%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20quality%20metrics%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_quality_metrics%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20column_name%2C%20metric_type%2C%20metric_value%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20total_records%2C%20quality_issues%0A%20%20%20%20%20%20%20%20)%20VALUES%20%0A%20%20%20%20%20%20%20%20(p_table_name%2C%20v_column_name%2C%20'COMPLETENESS'%2C%20v_completeness%2C%20v_total_records%2C%20v_null_count)%2C%0A%20%20%20%20%20%20%20%20(p_table_name%2C%20v_column_name%2C%20'UNIQUENESS'%2C%20v_uniqueness%2C%20v_total_records%2C%20v_total_records%20-%20v_unique_count)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20column_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data quality metrics table
CREATE TABLE data_quality_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100),
    column_name VARCHAR(100),
    metric_type ENUM('COMPLETENESS', 'ACCURACY', 'CONSISTENCY', 'VALIDITY', 'UNIQUENESS'),
    metric_value DECIMAL(5,2),
    total_records BIGINT,
    quality_issues BIGINT,
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_table_column (table_name, column_name),
    INDEX idx_metric_type (metric_type),
    INDEX idx_assessment_date (assessment_date)
);

-- Data profiling procedure
DELIMITER //
CREATE PROCEDURE profile_data_quality(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_data_type VARCHAR(50);
    DECLARE v_total_records BIGINT;
    DECLARE v_null_count BIGINT;
    DECLARE v_unique_count BIGINT;
    DECLARE v_completeness DECIMAL(5,2);
    DECLARE v_uniqueness DECIMAL(5,2);
    
    DECLARE column_cursor CURSOR FOR
        SELECT column_name, data_type
        FROM information_schema.columns
        WHERE table_schema = DATABASE()
        AND table_name = p_table_name;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Get total record count
    SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_table_name);
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store result in v_total_records
    DEALLOCATE PREPARE stmt;
    
    OPEN column_cursor;
    
    profile_loop: LOOP
        FETCH column_cursor INTO v_column_name, v_data_type;
        
        IF done THEN
            LEAVE profile_loop;
        END IF;
        
        -- Calculate completeness (non-null percentage)
        SET @sql = CONCAT('SELECT COUNT(*) FROM ', p_table_name, 
                         ' WHERE ', v_column_name, ' IS NULL');
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store in v_null_count
        DEALLOCATE PREPARE stmt;
        
        SET v_completeness = ((v_total_records - v_null_count) / v_total_records) * 100;
        
        -- Calculate uniqueness
        SET @sql = CONCAT('SELECT COUNT(DISTINCT ', v_column_name, ') FROM ', p_table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store in v_unique_count
        DEALLOCATE PREPARE stmt;
        
        SET v_uniqueness = (v_unique_count / v_total_records) * 100;
        
        -- Insert quality metrics
        INSERT INTO data_quality_metrics (
            table_name, column_name, metric_type, metric_value, 
            total_records, quality_issues
        ) VALUES 
        (p_table_name, v_column_name, 'COMPLETENESS', v_completeness, v_total_records, v_null_count),
        (p_table_name, v_column_name, 'UNIQUENESS', v_uniqueness, v_total_records, v_total_records - v_unique_count);
        
    END LOOP;
    
    CLOSE column_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Validation Rules:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Comprehensive%20validation%20framework%0ACREATE%20TABLE%20data_validation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20validation_type%20ENUM('FORMAT'%2C%20'RANGE'%2C%20'LOOKUP'%2C%20'BUSINESS_RULE'%2C%20'CROSS_FIELD')%2C%0A%20%20%20%20validation_expression%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20error_message%20VARCHAR(500)%2C%0A%20%20%20%20severity%20ENUM('ERROR'%2C%20'WARNING'%2C%20'INFO')%20DEFAULT%20'ERROR'%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%0A)%3B%0A%0A--%20Insert%20validation%20rules%0AINSERT%20INTO%20data_validation_rules%20(rule_name%2C%20table_name%2C%20column_name%2C%20validation_type%2C%20validation_expression%2C%20error_message)%20VALUES%0A('Email%20Format'%2C%20'customers'%2C%20'email'%2C%20'FORMAT'%2C%20'email%20REGEXP%20%22%5E%5BA-Za-z0-9._%25%2B-%5D%2B%40%5BA-Za-z0-9.-%5D%2B%5C%5C.%5BA-Za-z%5D%7B2%2C%7D%24%22'%2C%20'Invalid%20email%20format')%2C%0A('Phone%20Format'%2C%20'customers'%2C%20'phone'%2C%20'FORMAT'%2C%20'phone%20REGEXP%20%22%5E%5C%5C%2B%3F%5B1-9%5D%5C%5Cd%7B1%2C14%7D%24%22'%2C%20'Invalid%20phone%20number%20format')%2C%0A('Age%20Range'%2C%20'customers'%2C%20'age'%2C%20'RANGE'%2C%20'age%20BETWEEN%200%20AND%20120'%2C%20'Age%20must%20be%20between%200%20and%20120')%2C%0A('Order%20Total%20Positive'%2C%20'orders'%2C%20'total'%2C%20'RANGE'%2C%20'total%20%3E%200'%2C%20'Order%20total%20must%20be%20positive')%2C%0A('Customer%20Reference'%2C%20'orders'%2C%20'customer_id'%2C%20'LOOKUP'%2C%20'customer_id%20IN%20(SELECT%20id%20FROM%20customers)'%2C%20'Invalid%20customer%20reference')%3B%0A%0A--%20Validation%20execution%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_data_quality(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_validation_expression%20TEXT%3B%0A%20%20%20%20DECLARE%20v_error_message%20VARCHAR(500)%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_violation_count%20INT%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20validation_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20rule_name%2C%20column_name%2C%20validation_expression%2C%20error_message%2C%20severity%0A%20%20%20%20%20%20%20%20FROM%20data_validation_rules%0A%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20validation_results%20(%0A%20%20%20%20%20%20%20%20rule_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20violation_count%20INT%2C%0A%20%20%20%20%20%20%20%20error_message%20VARCHAR(500)%2C%0A%20%20%20%20%20%20%20%20severity%20VARCHAR(10)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20validation_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20validation_cursor%20INTO%20v_rule_name%2C%20v_column_name%2C%20v_validation_expression%2C%20v_error_message%2C%20v_severity%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20validation_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20validation%20query%0A%20%20%20%20%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20NOT%20('%2C%20v_validation_expression%2C%20')'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20validation%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20--%20Store%20result%20in%20v_violation_count%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20result%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20validation_results%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_rule_name%2C%20v_column_name%2C%20v_violation_count%2C%20v_error_message%2C%20v_severity%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20validation_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20results%0A%20%20%20%20SELECT%20*%20FROM%20validation_results%20WHERE%20violation_count%20%3E%200%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20validation_results%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Comprehensive validation framework
CREATE TABLE data_validation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    column_name VARCHAR(100),
    validation_type ENUM('FORMAT', 'RANGE', 'LOOKUP', 'BUSINESS_RULE', 'CROSS_FIELD'),
    validation_expression TEXT NOT NULL,
    error_message VARCHAR(500),
    severity ENUM('ERROR', 'WARNING', 'INFO') DEFAULT 'ERROR',
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert validation rules
INSERT INTO data_validation_rules (rule_name, table_name, column_name, validation_type, validation_expression, error_message) VALUES
('Email Format', 'customers', 'email', 'FORMAT', 'email REGEXP "^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$"', 'Invalid email format'),
('Phone Format', 'customers', 'phone', 'FORMAT', 'phone REGEXP "^\\+?[1-9]\\d{1,14}$"', 'Invalid phone number format'),
('Age Range', 'customers', 'age', 'RANGE', 'age BETWEEN 0 AND 120', 'Age must be between 0 and 120'),
('Order Total Positive', 'orders', 'total', 'RANGE', 'total &gt; 0', 'Order total must be positive'),
('Customer Reference', 'orders', 'customer_id', 'LOOKUP', 'customer_id IN (SELECT id FROM customers)', 'Invalid customer reference');

-- Validation execution
DELIMITER //
CREATE PROCEDURE validate_data_quality(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_name VARCHAR(100);
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_validation_expression TEXT;
    DECLARE v_error_message VARCHAR(500);
    DECLARE v_severity VARCHAR(10);
    DECLARE v_violation_count INT;
    DECLARE v_validation_sql TEXT;
    
    DECLARE validation_cursor CURSOR FOR
        SELECT rule_name, column_name, validation_expression, error_message, severity
        FROM data_validation_rules
        WHERE table_name = p_table_name AND is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create temporary results table
    CREATE TEMPORARY TABLE validation_results (
        rule_name VARCHAR(100),
        column_name VARCHAR(100),
        violation_count INT,
        error_message VARCHAR(500),
        severity VARCHAR(10)
    );
    
    OPEN validation_cursor;
    
    validation_loop: LOOP
        FETCH validation_cursor INTO v_rule_name, v_column_name, v_validation_expression, v_error_message, v_severity;
        
        IF done THEN
            LEAVE validation_loop;
        END IF;
        
        -- Build validation query
        SET v_validation_sql = CONCAT(
            'SELECT COUNT(*) FROM ', p_table_name, 
            ' WHERE NOT (', v_validation_expression, ')'
        );
        
        -- Execute validation
        SET @sql = v_validation_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        -- Store result in v_violation_count
        DEALLOCATE PREPARE stmt;
        
        -- Insert result
        INSERT INTO validation_results VALUES (
            v_rule_name, v_column_name, v_violation_count, v_error_message, v_severity
        );
        
    END LOOP;
    
    CLOSE validation_cursor;
    
    -- Return results
    SELECT * FROM validation_results WHERE violation_count &gt; 0;
    
    DROP TEMPORARY TABLE validation_results;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Data Cleansing Procedures:</strong></p>

<p><strong>1. Automated Data Cleansing:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="DELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20cleanse_customer_data()%0ABEGIN%0A%20%20%20%20DECLARE%20records_updated%20INT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Standardize%20email%20addresses%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20email%20%3D%20LOWER(TRIM(email))%0A%20%20%20%20WHERE%20email%20!%3D%20LOWER(TRIM(email))%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Standardize%20phone%20numbers%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20phone%20%3D%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%2B%5D'%2C%20'')%0A%20%20%20%20WHERE%20phone%20REGEXP%20'%5B%5E0-9%2B%5D'%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Fix%20common%20name%20issues%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20name%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20UPPER(SUBSTRING(TRIM(name)%2C%201%2C%201))%2C%0A%20%20%20%20%20%20%20%20LOWER(SUBSTRING(TRIM(name)%2C%202))%0A%20%20%20%20)%0A%20%20%20%20WHERE%20name%20!%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20UPPER(SUBSTRING(TRIM(name)%2C%201%2C%201))%2C%0A%20%20%20%20%20%20%20%20LOWER(SUBSTRING(TRIM(name)%2C%202))%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20duplicate%20spaces%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20address%20%3D%20REGEXP_REPLACE(address%2C%20'%20%2B'%2C%20'%20')%0A%20%20%20%20WHERE%20address%20REGEXP%20'%20%7B2%2C%7D'%3B%0A%20%20%20%20%0A%20%20%20%20SET%20records_updated%20%3D%20records_updated%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20cleansing%20activity%0A%20%20%20%20INSERT%20INTO%20data_cleansing_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20cleansing_type%2C%20records_affected%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20'customers'%2C%20'STANDARDIZATION'%2C%20records_updated%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">DELIMITER //
CREATE PROCEDURE cleanse_customer_data()
BEGIN
    DECLARE records_updated INT DEFAULT 0;
    
    START TRANSACTION;
    
    -- Standardize email addresses
    UPDATE customers 
    SET email = LOWER(TRIM(email))
    WHERE email != LOWER(TRIM(email));
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Standardize phone numbers
    UPDATE customers 
    SET phone = REGEXP_REPLACE(phone, '[^0-9+]', '')
    WHERE phone REGEXP '[^0-9+]';
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Fix common name issues
    UPDATE customers 
    SET name = CONCAT(
        UPPER(SUBSTRING(TRIM(name), 1, 1)),
        LOWER(SUBSTRING(TRIM(name), 2))
    )
    WHERE name != CONCAT(
        UPPER(SUBSTRING(TRIM(name), 1, 1)),
        LOWER(SUBSTRING(TRIM(name), 2))
    );
    
    SET records_updated = records_updated + ROW_COUNT();
    
    -- Remove duplicate spaces
    UPDATE customers 
    SET address = REGEXP_REPLACE(address, ' +', ' ')
    WHERE address REGEXP ' {2,}';
    
    SET records_updated = records_updated + ROW_COUNT();
    
    COMMIT;
    
    -- Log cleansing activity
    INSERT INTO data_cleansing_log (
        table_name, cleansing_type, records_affected, completed_at
    ) VALUES (
        'customers', 'STANDARDIZATION', records_updated, NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-376-how-do-you-implement-data-lineage-tracking-">**376. How do you implement data lineage tracking?**</h2>

<p><strong>Answer:</strong> Data lineage tracking documents the flow and transformation of data from source to destination, providing visibility into data origins, transformations, and dependencies.</p>

<p><strong>Lineage Tracking Infrastructure:</strong></p>

<p><strong>1. Metadata Repository:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20sources%20registry%0ACREATE%20TABLE%20data_sources%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_type%20ENUM('DATABASE'%2C%20'FILE'%2C%20'API'%2C%20'STREAM')%20NOT%20NULL%2C%0A%20%20%20%20connection_string%20VARCHAR(500)%2C%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20owner%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_source_name%20(source_name)%0A)%3B%0A%0A--%20Data%20assets%20(tables%2C%20views%2C%20files)%0ACREATE%20TABLE%20data_assets%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20asset_type%20ENUM('TABLE'%2C%20'VIEW'%2C%20'FILE'%2C%20'REPORT')%20NOT%20NULL%2C%0A%20%20%20%20source_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20schema_definition%20JSON%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20technical_description%20TEXT%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(source_id)%20REFERENCES%20data_sources(id)%2C%0A%20%20%20%20INDEX%20idx_asset_type%20(asset_type)%2C%0A%20%20%20%20INDEX%20idx_source_id%20(source_id)%0A)%3B%0A%0A--%20Data%20lineage%20relationships%0ACREATE%20TABLE%20data_lineage%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_asset_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20target_asset_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20transformation_type%20ENUM('COPY'%2C%20'TRANSFORM'%2C%20'AGGREGATE'%2C%20'JOIN'%2C%20'FILTER'%2C%20'UNION')%2C%0A%20%20%20%20transformation_logic%20TEXT%2C%0A%20%20%20%20transformation_tool%20VARCHAR(100)%2C%0A%20%20%20%20dependency_type%20ENUM('DIRECT'%2C%20'INDIRECT')%20DEFAULT%20'DIRECT'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(source_asset_id)%20REFERENCES%20data_assets(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(target_asset_id)%20REFERENCES%20data_assets(id)%2C%0A%20%20%20%20INDEX%20idx_source_target%20(source_asset_id%2C%20target_asset_id)%2C%0A%20%20%20%20INDEX%20idx_transformation_type%20(transformation_type)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data sources registry
CREATE TABLE data_sources (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source_name VARCHAR(100) NOT NULL,
    source_type ENUM('DATABASE', 'FILE', 'API', 'STREAM') NOT NULL,
    connection_string VARCHAR(500),
    description TEXT,
    owner VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_source_name (source_name)
);

-- Data assets (tables, views, files)
CREATE TABLE data_assets (
    id INT AUTO_INCREMENT PRIMARY KEY,
    asset_name VARCHAR(200) NOT NULL,
    asset_type ENUM('TABLE', 'VIEW', 'FILE', 'REPORT') NOT NULL,
    source_id INT NOT NULL,
    schema_definition JSON,
    business_description TEXT,
    technical_description TEXT,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    FOREIGN KEY (source_id) REFERENCES data_sources(id),
    INDEX idx_asset_type (asset_type),
    INDEX idx_source_id (source_id)
);

-- Data lineage relationships
CREATE TABLE data_lineage (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_asset_id INT NOT NULL,
    target_asset_id INT NOT NULL,
    transformation_type ENUM('COPY', 'TRANSFORM', 'AGGREGATE', 'JOIN', 'FILTER', 'UNION'),
    transformation_logic TEXT,
    transformation_tool VARCHAR(100),
    dependency_type ENUM('DIRECT', 'INDIRECT') DEFAULT 'DIRECT',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    
    FOREIGN KEY (source_asset_id) REFERENCES data_assets(id),
    FOREIGN KEY (target_asset_id) REFERENCES data_assets(id),
    INDEX idx_source_target (source_asset_id, target_asset_id),
    INDEX idx_transformation_type (transformation_type)
);
</code></pre>
</div>

<p><strong>2. Automated Lineage Capture:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20process%20lineage%20tracking%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20track_etl_lineage(%0A%20%20%20%20IN%20p_process_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_source_tables%20JSON%2C%0A%20%20%20%20IN%20p_target_table%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_transformation_sql%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_source_asset_id%20INT%3B%0A%20%20%20%20DECLARE%20v_target_asset_id%20INT%3B%0A%20%20%20%20DECLARE%20v_source_count%20INT%3B%0A%20%20%20%20DECLARE%20i%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_source_table%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20target%20asset%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_target_asset_id%0A%20%20%20%20FROM%20data_assets%0A%20%20%20%20WHERE%20asset_name%20%3D%20p_target_table%3B%0A%20%20%20%20%0A%20%20%20%20--%20Process%20each%20source%20table%0A%20%20%20%20SET%20v_source_count%20%3D%20JSON_LENGTH(p_source_tables)%3B%0A%20%20%20%20%0A%20%20%20%20WHILE%20i%20%3C%20v_source_count%20DO%0A%20%20%20%20%20%20%20%20SET%20v_source_table%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_source_tables%2C%20CONCAT('%24%5B'%2C%20i%2C%20'%5D')))%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Get%20source%20asset%20ID%0A%20%20%20%20%20%20%20%20SELECT%20id%20INTO%20v_source_asset_id%0A%20%20%20%20%20%20%20%20FROM%20data_assets%0A%20%20%20%20%20%20%20%20WHERE%20asset_name%20%3D%20v_source_table%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20lineage%20relationship%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_lineage%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20source_asset_id%2C%20target_asset_id%2C%20transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20transformation_logic%2C%20transformation_tool%2C%20created_by%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_source_asset_id%2C%20v_target_asset_id%2C%20'TRANSFORM'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_transformation_sql%2C%20p_process_name%2C%20USER()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20i%20%3D%20i%20%2B%201%3B%0A%20%20%20%20END%20WHILE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20lineage%20capture%0A%20%20%20%20INSERT%20INTO%20lineage_capture_log%20(%0A%20%20%20%20%20%20%20%20process_name%2C%20source_count%2C%20target_table%2C%20captured_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_process_name%2C%20v_source_count%2C%20p_target_table%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL process lineage tracking
DELIMITER //
CREATE PROCEDURE track_etl_lineage(
    IN p_process_name VARCHAR(100),
    IN p_source_tables JSON,
    IN p_target_table VARCHAR(100),
    IN p_transformation_sql TEXT
)
BEGIN
    DECLARE v_source_asset_id INT;
    DECLARE v_target_asset_id INT;
    DECLARE v_source_count INT;
    DECLARE i INT DEFAULT 0;
    DECLARE v_source_table VARCHAR(100);
    
    -- Get target asset ID
    SELECT id INTO v_target_asset_id
    FROM data_assets
    WHERE asset_name = p_target_table;
    
    -- Process each source table
    SET v_source_count = JSON_LENGTH(p_source_tables);
    
    WHILE i &lt; v_source_count DO
        SET v_source_table = JSON_UNQUOTE(JSON_EXTRACT(p_source_tables, CONCAT('$[', i, ']')));
        
        -- Get source asset ID
        SELECT id INTO v_source_asset_id
        FROM data_assets
        WHERE asset_name = v_source_table;
        
        -- Insert lineage relationship
        INSERT INTO data_lineage (
            source_asset_id, target_asset_id, transformation_type,
            transformation_logic, transformation_tool, created_by
        ) VALUES (
            v_source_asset_id, v_target_asset_id, 'TRANSFORM',
            p_transformation_sql, p_process_name, USER()
        );
        
        SET i = i + 1;
    END WHILE;
    
    -- Log lineage capture
    INSERT INTO lineage_capture_log (
        process_name, source_count, target_table, captured_at
    ) VALUES (
        p_process_name, v_source_count, p_target_table, NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>Lineage Analysis and Reporting:</strong></p>

<p><strong>1. Impact Analysis:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Find%20downstream%20dependencies%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20find_downstream_impact(IN%20p_asset_name%20VARCHAR(200))%0ABEGIN%0A%20%20%20%20WITH%20RECURSIVE%20downstream_lineage%20AS%20(%0A%20%20%20%20%20%20%20%20--%20Base%20case%3A%20direct%20dependencies%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%201%20as%20level%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CAST(da_target.asset_name%20AS%20CHAR(1000))%20as%20path%0A%20%20%20%20%20%20%20%20FROM%20data_assets%20da_source%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20da_source.id%20%3D%20dl.source_asset_id%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%0A%20%20%20%20%20%20%20%20WHERE%20da_source.asset_name%20%3D%20p_asset_name%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20indirect%20dependencies%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20da_target.asset_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dsl.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(dsl.path%2C%20'%20-%3E%20'%2C%20da_target.asset_name)%0A%20%20%20%20%20%20%20%20FROM%20downstream_lineage%20dsl%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_source%20ON%20dsl.asset_name%20%3D%20da_source.asset_name%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20da_source.id%20%3D%20dl.source_asset_id%0A%20%20%20%20%20%20%20%20JOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%0A%20%20%20%20%20%20%20%20WHERE%20dsl.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20asset_name%2C%0A%20%20%20%20%20%20%20%20asset_type%2C%0A%20%20%20%20%20%20%20%20transformation_type%2C%0A%20%20%20%20%20%20%20%20level%2C%0A%20%20%20%20%20%20%20%20path%0A%20%20%20%20FROM%20downstream_lineage%0A%20%20%20%20ORDER%20BY%20level%2C%20asset_name%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Find downstream dependencies
DELIMITER //
CREATE PROCEDURE find_downstream_impact(IN p_asset_name VARCHAR(200))
BEGIN
    WITH RECURSIVE downstream_lineage AS (
        -- Base case: direct dependencies
        SELECT 
            da_target.asset_name,
            da_target.asset_type,
            dl.transformation_type,
            1 as level,
            CAST(da_target.asset_name AS CHAR(1000)) as path
        FROM data_assets da_source
        JOIN data_lineage dl ON da_source.id = dl.source_asset_id
        JOIN data_assets da_target ON dl.target_asset_id = da_target.id
        WHERE da_source.asset_name = p_asset_name
        
        UNION ALL
        
        -- Recursive case: indirect dependencies
        SELECT 
            da_target.asset_name,
            da_target.asset_type,
            dl.transformation_type,
            dsl.level + 1,
            CONCAT(dsl.path, ' -&gt; ', da_target.asset_name)
        FROM downstream_lineage dsl
        JOIN data_assets da_source ON dsl.asset_name = da_source.asset_name
        JOIN data_lineage dl ON da_source.id = dl.source_asset_id
        JOIN data_assets da_target ON dl.target_asset_id = da_target.id
        WHERE dsl.level &lt; 10  -- Prevent infinite recursion
    )
    SELECT 
        asset_name,
        asset_type,
        transformation_type,
        level,
        path
    FROM downstream_lineage
    ORDER BY level, asset_name;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Data Lineage Visualization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Generate%20lineage%20graph%20data%0ACREATE%20VIEW%20lineage_graph%20AS%0ASELECT%20%0A%20%20%20%20CONCAT('asset_'%2C%20dl.source_asset_id)%20as%20source_node%2C%0A%20%20%20%20CONCAT('asset_'%2C%20dl.target_asset_id)%20as%20target_node%2C%0A%20%20%20%20da_source.asset_name%20as%20source_name%2C%0A%20%20%20%20da_target.asset_name%20as%20target_name%2C%0A%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20dl.transformation_logic%2C%0A%20%20%20%20da_source.asset_type%20as%20source_type%2C%0A%20%20%20%20da_target.asset_type%20as%20target_type%0AFROM%20data_lineage%20dl%0AJOIN%20data_assets%20da_source%20ON%20dl.source_asset_id%20%3D%20da_source.id%0AJOIN%20data_assets%20da_target%20ON%20dl.target_asset_id%20%3D%20da_target.id%3B%0A%0A--%20Lineage%20summary%20report%0ASELECT%20%0A%20%20%20%20ds.source_name%2C%0A%20%20%20%20da.asset_name%2C%0A%20%20%20%20da.asset_type%2C%0A%20%20%20%20COUNT(DISTINCT%20dl_in.source_asset_id)%20as%20input_dependencies%2C%0A%20%20%20%20COUNT(DISTINCT%20dl_out.target_asset_id)%20as%20output_dependencies%2C%0A%20%20%20%20da.data_classification%2C%0A%20%20%20%20da.updated_at%0AFROM%20data_assets%20da%0AJOIN%20data_sources%20ds%20ON%20da.source_id%20%3D%20ds.id%0ALEFT%20JOIN%20data_lineage%20dl_in%20ON%20da.id%20%3D%20dl_in.target_asset_id%0ALEFT%20JOIN%20data_lineage%20dl_out%20ON%20da.id%20%3D%20dl_out.source_asset_id%0AGROUP%20BY%20ds.source_name%2C%20da.asset_name%2C%20da.asset_type%2C%20da.data_classification%2C%20da.updated_at%0AORDER%20BY%20input_dependencies%20%2B%20output_dependencies%20DESC%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Generate lineage graph data
CREATE VIEW lineage_graph AS
SELECT 
    CONCAT('asset_', dl.source_asset_id) as source_node,
    CONCAT('asset_', dl.target_asset_id) as target_node,
    da_source.asset_name as source_name,
    da_target.asset_name as target_name,
    dl.transformation_type,
    dl.transformation_logic,
    da_source.asset_type as source_type,
    da_target.asset_type as target_type
FROM data_lineage dl
JOIN data_assets da_source ON dl.source_asset_id = da_source.id
JOIN data_assets da_target ON dl.target_asset_id = da_target.id;

-- Lineage summary report
SELECT 
    ds.source_name,
    da.asset_name,
    da.asset_type,
    COUNT(DISTINCT dl_in.source_asset_id) as input_dependencies,
    COUNT(DISTINCT dl_out.target_asset_id) as output_dependencies,
    da.data_classification,
    da.updated_at
FROM data_assets da
JOIN data_sources ds ON da.source_id = ds.id
LEFT JOIN data_lineage dl_in ON da.id = dl_in.target_asset_id
LEFT JOIN data_lineage dl_out ON da.id = dl_out.source_asset_id
GROUP BY ds.source_name, da.asset_name, da.asset_type, da.data_classification, da.updated_at
ORDER BY input_dependencies + output_dependencies DESC;
</code></pre>
</div>

<p>---</p>

<h2 id="-377-what-are-master-data-management-mdm-principles-">**377. What are master data management (MDM) principles?**</h2>

<p><strong>Answer:</strong> Master Data Management ensures consistent, accurate, and authoritative master data across the enterprise through centralized governance, standardization, and synchronization processes.</p>

<p><strong>MDM Architecture:</strong></p>

<p><strong>1. Golden Record Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Master%20customer%20record%0ACREATE%20TABLE%20master_customers%20(%0A%20%20%20%20master_id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20global_customer_id%20VARCHAR(50)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Core%20attributes%0A%20%20%20%20legal_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20common_name%20VARCHAR(255)%2C%0A%20%20%20%20customer_type%20ENUM('INDIVIDUAL'%2C%20'BUSINESS'%2C%20'GOVERNMENT')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Contact%20information%0A%20%20%20%20primary_email%20VARCHAR(255)%2C%0A%20%20%20%20primary_phone%20VARCHAR(20)%2C%0A%20%20%20%20primary_address%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20attributes%0A%20%20%20%20industry_code%20VARCHAR(10)%2C%0A%20%20%20%20credit_rating%20VARCHAR(10)%2C%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20governance%0A%20%20%20%20data_steward%20VARCHAR(100)%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20last_verified%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Audit%20fields%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20updated_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_global_id%20(global_customer_id)%2C%0A%20%20%20%20INDEX%20idx_legal_name%20(legal_name)%2C%0A%20%20%20%20INDEX%20idx_customer_type%20(customer_type)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Source%20system%20mappings%0ACREATE%20TABLE%20customer_source_mappings%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20master_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(50)%20NOT%20NULL%2C%0A%20%20%20%20source_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_record%20JSON%2C%0A%20%20%20%20confidence_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20last_synchronized%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20sync_status%20ENUM('ACTIVE'%2C%20'INACTIVE'%2C%20'CONFLICT')%20DEFAULT%20'ACTIVE'%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(master_id)%20REFERENCES%20master_customers(master_id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_source_mapping%20(source_system%2C%20source_id)%2C%0A%20%20%20%20INDEX%20idx_master_id%20(master_id)%2C%0A%20%20%20%20INDEX%20idx_sync_status%20(sync_status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Master customer record
CREATE TABLE master_customers (
    master_id INT AUTO_INCREMENT PRIMARY KEY,
    global_customer_id VARCHAR(50) UNIQUE NOT NULL,
    
    -- Core attributes
    legal_name VARCHAR(255) NOT NULL,
    common_name VARCHAR(255),
    customer_type ENUM('INDIVIDUAL', 'BUSINESS', 'GOVERNMENT'),
    
    -- Contact information
    primary_email VARCHAR(255),
    primary_phone VARCHAR(20),
    primary_address JSON,
    
    -- Business attributes
    industry_code VARCHAR(10),
    credit_rating VARCHAR(10),
    customer_segment VARCHAR(50),
    
    -- Data governance
    data_steward VARCHAR(100),
    data_quality_score DECIMAL(3,2),
    last_verified TIMESTAMP,
    
    -- Audit fields
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    updated_by VARCHAR(100),
    
    INDEX idx_global_id (global_customer_id),
    INDEX idx_legal_name (legal_name),
    INDEX idx_customer_type (customer_type),
    INDEX idx_data_quality (data_quality_score)
);

-- Source system mappings
CREATE TABLE customer_source_mappings (
    id INT AUTO_INCREMENT PRIMARY KEY,
    master_id INT NOT NULL,
    source_system VARCHAR(50) NOT NULL,
    source_id VARCHAR(100) NOT NULL,
    source_record JSON,
    confidence_score DECIMAL(3,2),
    last_synchronized TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    sync_status ENUM('ACTIVE', 'INACTIVE', 'CONFLICT') DEFAULT 'ACTIVE',
    
    FOREIGN KEY (master_id) REFERENCES master_customers(master_id),
    UNIQUE KEY uk_source_mapping (source_system, source_id),
    INDEX idx_master_id (master_id),
    INDEX idx_sync_status (sync_status)
);
</code></pre>
</div>

<p><strong>2. Data Matching and Deduplication:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Matching%20algorithm%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20match_customer_records()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_source_id%20INT%3B%0A%20%20%20%20DECLARE%20v_name%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_email%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_phone%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_match_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_master_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20staging_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20name%2C%20email%2C%20phone%0A%20%20%20%20%20%20%20%20FROM%20customer_staging%0A%20%20%20%20%20%20%20%20WHERE%20processed%20%3D%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20staging_cursor%3B%0A%20%20%20%20%0A%20%20%20%20matching_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20staging_cursor%20INTO%20v_source_id%2C%20v_name%2C%20v_email%2C%20v_phone%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20matching_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20match%20scores%20against%20existing%20master%20records%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Name%20similarity%20(using%20SOUNDEX%20and%20Levenshtein-like%20logic)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20SOUNDEX(legal_name)%20%3D%20SOUNDEX(v_name)%20THEN%2040%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20legal_name%20LIKE%20CONCAT('%25'%2C%20v_name%2C%20'%25')%20THEN%2020%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Email%20exact%20match%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20primary_email%20%3D%20v_email%20THEN%2040%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Phone%20match%20(normalized)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20REGEXP_REPLACE(primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20%3D%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REGEXP_REPLACE(v_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20THEN%2020%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSE%200%20END%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20as%20match_score%0A%20%20%20%20%20%20%20%20INTO%20v_master_id%2C%20v_match_score%0A%20%20%20%20%20%20%20%20FROM%20master_customers%0A%20%20%20%20%20%20%20%20HAVING%20match_score%20%3E%3D%2070%20%20--%20Threshold%20for%20match%0A%20%20%20%20%20%20%20%20ORDER%20BY%20match_score%20DESC%0A%20%20%20%20%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20v_master_id%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Link%20to%20existing%20master%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_source_mappings%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%20source_system%2C%20source_id%2C%20confidence_score%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_master_id%2C%20'STAGING'%2C%20v_source_id%2C%20v_match_score%2F100%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20new%20master%20record%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20master_customers%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20global_customer_id%2C%20legal_name%2C%20primary_email%2C%20primary_phone%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20data_quality_score%2C%20created_by%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT('CUST_'%2C%20LPAD(LAST_INSERT_ID()%2C%2010%2C%20'0'))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_name%2C%20v_email%2C%20v_phone%2C%200.8%2C%20'MDM_SYSTEM'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_master_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Create%20source%20mapping%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20customer_source_mappings%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20master_id%2C%20source_system%2C%20source_id%2C%20confidence_score%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_master_id%2C%20'STAGING'%2C%20v_source_id%2C%201.0%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20processed%0A%20%20%20%20%20%20%20%20UPDATE%20customer_staging%20SET%20processed%20%3D%20TRUE%20WHERE%20id%20%3D%20v_source_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20staging_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Matching algorithm implementation
DELIMITER //
CREATE PROCEDURE match_customer_records()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_source_id INT;
    DECLARE v_name VARCHAR(255);
    DECLARE v_email VARCHAR(255);
    DECLARE v_phone VARCHAR(20);
    DECLARE v_match_score DECIMAL(5,2);
    DECLARE v_master_id INT;
    
    DECLARE staging_cursor CURSOR FOR
        SELECT id, name, email, phone
        FROM customer_staging
        WHERE processed = FALSE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN staging_cursor;
    
    matching_loop: LOOP
        FETCH staging_cursor INTO v_source_id, v_name, v_email, v_phone;
        
        IF done THEN
            LEAVE matching_loop;
        END IF;
        
        -- Calculate match scores against existing master records
        SELECT 
            master_id,
            (
                -- Name similarity (using SOUNDEX and Levenshtein-like logic)
                CASE WHEN SOUNDEX(legal_name) = SOUNDEX(v_name) THEN 40
                     WHEN legal_name LIKE CONCAT('%', v_name, '%') THEN 20
                     ELSE 0 END +
                
                -- Email exact match
                CASE WHEN primary_email = v_email THEN 40
                     ELSE 0 END +
                
                -- Phone match (normalized)
                CASE WHEN REGEXP_REPLACE(primary_phone, '[^0-9]', '') = 
                          REGEXP_REPLACE(v_phone, '[^0-9]', '') THEN 20
                     ELSE 0 END
            ) as match_score
        INTO v_master_id, v_match_score
        FROM master_customers
        HAVING match_score &gt;= 70  -- Threshold for match
        ORDER BY match_score DESC
        LIMIT 1;
        
        IF v_master_id IS NOT NULL THEN
            -- Link to existing master record
            INSERT INTO customer_source_mappings (
                master_id, source_system, source_id, confidence_score
            ) VALUES (
                v_master_id, 'STAGING', v_source_id, v_match_score/100
            );
        ELSE
            -- Create new master record
            INSERT INTO master_customers (
                global_customer_id, legal_name, primary_email, primary_phone,
                data_quality_score, created_by
            ) VALUES (
                CONCAT('CUST_', LPAD(LAST_INSERT_ID(), 10, '0')),
                v_name, v_email, v_phone, 0.8, 'MDM_SYSTEM'
            );
            
            SET v_master_id = LAST_INSERT_ID();
            
            -- Create source mapping
            INSERT INTO customer_source_mappings (
                master_id, source_system, source_id, confidence_score
            ) VALUES (
                v_master_id, 'STAGING', v_source_id, 1.0
            );
        END IF;
        
        -- Mark as processed
        UPDATE customer_staging SET processed = TRUE WHERE id = v_source_id;
        
    END LOOP;
    
    CLOSE staging_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Governance and Quality:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20stewardship%20workflow%0ACREATE%20TABLE%20data_stewardship_tasks%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20task_type%20ENUM('DUPLICATE_REVIEW'%2C%20'QUALITY_ISSUE'%2C%20'MERGE_REQUEST'%2C%20'ATTRIBUTE_UPDATE')%2C%0A%20%20%20%20master_id%20INT%2C%0A%20%20%20%20related_master_id%20INT%2C%0A%20%20%20%20issue_description%20TEXT%2C%0A%20%20%20%20proposed_resolution%20JSON%2C%0A%20%20%20%20assigned_steward%20VARCHAR(100)%2C%0A%20%20%20%20priority%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'MEDIUM'%2C%0A%20%20%20%20status%20ENUM('OPEN'%2C%20'IN_PROGRESS'%2C%20'RESOLVED'%2C%20'REJECTED')%20DEFAULT%20'OPEN'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20resolution_notes%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(master_id)%20REFERENCES%20master_customers(master_id)%2C%0A%20%20%20%20INDEX%20idx_assigned_steward%20(assigned_steward)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%2C%0A%20%20%20%20INDEX%20idx_priority%20(priority)%0A)%3B%0A%0A--%20Automated%20quality%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_master_data_quality()%0ABEGIN%0A%20%20%20%20--%20Identify%20potential%20duplicates%0A%20%20%20%20INSERT%20INTO%20data_stewardship_tasks%20(%0A%20%20%20%20%20%20%20%20task_type%2C%20master_id%2C%20related_master_id%2C%20issue_description%2C%20assigned_steward%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'DUPLICATE_REVIEW'%2C%0A%20%20%20%20%20%20%20%20mc1.master_id%2C%0A%20%20%20%20%20%20%20%20mc2.master_id%2C%0A%20%20%20%20%20%20%20%20CONCAT('Potential%20duplicate%3A%20'%2C%20mc1.legal_name%2C%20'%20vs%20'%2C%20mc2.legal_name)%2C%0A%20%20%20%20%20%20%20%20'data_steward_team'%0A%20%20%20%20FROM%20master_customers%20mc1%0A%20%20%20%20JOIN%20master_customers%20mc2%20ON%20mc1.master_id%20%3C%20mc2.master_id%0A%20%20%20%20WHERE%20(%0A%20%20%20%20%20%20%20%20SOUNDEX(mc1.legal_name)%20%3D%20SOUNDEX(mc2.legal_name)%20OR%0A%20%20%20%20%20%20%20%20mc1.primary_email%20%3D%20mc2.primary_email%20OR%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(mc1.primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%20%3D%20%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(mc2.primary_phone%2C%20'%5B%5E0-9%5D'%2C%20'')%0A%20%20%20%20)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_stewardship_tasks%20dst%0A%20%20%20%20%20%20%20%20WHERE%20dst.master_id%20%3D%20mc1.master_id%20%0A%20%20%20%20%20%20%20%20AND%20dst.related_master_id%20%3D%20mc2.master_id%0A%20%20%20%20%20%20%20%20AND%20dst.task_type%20%3D%20'DUPLICATE_REVIEW'%0A%20%20%20%20%20%20%20%20AND%20dst.status%20IN%20('OPEN'%2C%20'IN_PROGRESS')%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Identify%20quality%20issues%0A%20%20%20%20INSERT%20INTO%20data_stewardship_tasks%20(%0A%20%20%20%20%20%20%20%20task_type%2C%20master_id%2C%20issue_description%2C%20assigned_steward%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'QUALITY_ISSUE'%2C%0A%20%20%20%20%20%20%20%20master_id%2C%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20primary_email%20IS%20NULL%20THEN%20'Missing%20primary%20email'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20primary_phone%20IS%20NULL%20THEN%20'Missing%20primary%20phone'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20data_quality_score%20%3C%200.7%20THEN%20'Low%20data%20quality%20score'%0A%20%20%20%20%20%20%20%20END%2C%0A%20%20%20%20%20%20%20%20'data_steward_team'%0A%20%20%20%20FROM%20master_customers%0A%20%20%20%20WHERE%20(primary_email%20IS%20NULL%20OR%20primary_phone%20IS%20NULL%20OR%20data_quality_score%20%3C%200.7)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_stewardship_tasks%20dst%0A%20%20%20%20%20%20%20%20WHERE%20dst.master_id%20%3D%20master_customers.master_id%0A%20%20%20%20%20%20%20%20AND%20dst.task_type%20%3D%20'QUALITY_ISSUE'%0A%20%20%20%20%20%20%20%20AND%20dst.status%20IN%20('OPEN'%2C%20'IN_PROGRESS')%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data stewardship workflow
CREATE TABLE data_stewardship_tasks (
    id INT AUTO_INCREMENT PRIMARY KEY,
    task_type ENUM('DUPLICATE_REVIEW', 'QUALITY_ISSUE', 'MERGE_REQUEST', 'ATTRIBUTE_UPDATE'),
    master_id INT,
    related_master_id INT,
    issue_description TEXT,
    proposed_resolution JSON,
    assigned_steward VARCHAR(100),
    priority ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'MEDIUM',
    status ENUM('OPEN', 'IN_PROGRESS', 'RESOLVED', 'REJECTED') DEFAULT 'OPEN',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP NULL,
    resolution_notes TEXT,
    
    FOREIGN KEY (master_id) REFERENCES master_customers(master_id),
    INDEX idx_assigned_steward (assigned_steward),
    INDEX idx_status (status),
    INDEX idx_priority (priority)
);

-- Automated quality monitoring
DELIMITER //
CREATE PROCEDURE monitor_master_data_quality()
BEGIN
    -- Identify potential duplicates
    INSERT INTO data_stewardship_tasks (
        task_type, master_id, related_master_id, issue_description, assigned_steward
    )
    SELECT 
        'DUPLICATE_REVIEW',
        mc1.master_id,
        mc2.master_id,
        CONCAT('Potential duplicate: ', mc1.legal_name, ' vs ', mc2.legal_name),
        'data_steward_team'
    FROM master_customers mc1
    JOIN master_customers mc2 ON mc1.master_id &lt; mc2.master_id
    WHERE (
        SOUNDEX(mc1.legal_name) = SOUNDEX(mc2.legal_name) OR
        mc1.primary_email = mc2.primary_email OR
        REGEXP_REPLACE(mc1.primary_phone, '[^0-9]', '') = 
        REGEXP_REPLACE(mc2.primary_phone, '[^0-9]', '')
    )
    AND NOT EXISTS (
        SELECT 1 FROM data_stewardship_tasks dst
        WHERE dst.master_id = mc1.master_id 
        AND dst.related_master_id = mc2.master_id
        AND dst.task_type = 'DUPLICATE_REVIEW'
        AND dst.status IN ('OPEN', 'IN_PROGRESS')
    );
    
    -- Identify quality issues
    INSERT INTO data_stewardship_tasks (
        task_type, master_id, issue_description, assigned_steward
    )
    SELECT 
        'QUALITY_ISSUE',
        master_id,
        CASE 
            WHEN primary_email IS NULL THEN 'Missing primary email'
            WHEN primary_phone IS NULL THEN 'Missing primary phone'
            WHEN data_quality_score &lt; 0.7 THEN 'Low data quality score'
        END,
        'data_steward_team'
    FROM master_customers
    WHERE (primary_email IS NULL OR primary_phone IS NULL OR data_quality_score &lt; 0.7)
    AND NOT EXISTS (
        SELECT 1 FROM data_stewardship_tasks dst
        WHERE dst.master_id = master_customers.master_id
        AND dst.task_type = 'QUALITY_ISSUE'
        AND dst.status IN ('OPEN', 'IN_PROGRESS')
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-378-how-do-you-implement-data-cataloging-and-metadata-management-">**378. How do you implement data cataloging and metadata management?**</h2>

<p><strong>Answer:</strong> Data cataloging and metadata management create a centralized inventory of data assets with comprehensive metadata to improve data discovery, understanding, and governance.</p>

<p><strong>Data Catalog Infrastructure:</strong></p>

<p><strong>1. Metadata Repository:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20catalog%20core%20tables%0ACREATE%20TABLE%20data_catalog%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20asset_type%20ENUM('TABLE'%2C%20'VIEW'%2C%20'PROCEDURE'%2C%20'FUNCTION'%2C%20'REPORT'%2C%20'DATASET')%20NOT%20NULL%2C%0A%20%20%20%20database_name%20VARCHAR(100)%2C%0A%20%20%20%20schema_name%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metadata%0A%20%20%20%20business_name%20VARCHAR(200)%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20business_owner%20VARCHAR(100)%2C%0A%20%20%20%20business_domain%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20metadata%0A%20%20%20%20technical_description%20TEXT%2C%0A%20%20%20%20data_type_info%20JSON%2C%0A%20%20%20%20size_info%20JSON%2C%0A%20%20%20%20performance_stats%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%20metadata%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20retention_policy%20VARCHAR(100)%2C%0A%20%20%20%20compliance_tags%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20metadata%0A%20%20%20%20usage_frequency%20ENUM('DAILY'%2C%20'WEEKLY'%2C%20'MONTHLY'%2C%20'RARELY'%2C%20'UNKNOWN')%2C%0A%20%20%20%20last_accessed%20TIMESTAMP%2C%0A%20%20%20%20access_count%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%20metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20deprecated_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_asset%20(database_name%2C%20schema_name%2C%20asset_name)%2C%0A%20%20%20%20INDEX%20idx_asset_type%20(asset_type)%2C%0A%20%20%20%20INDEX%20idx_business_domain%20(business_domain)%2C%0A%20%20%20%20INDEX%20idx_data_classification%20(data_classification)%2C%0A%20%20%20%20FULLTEXT%20idx_description%20(business_description%2C%20technical_description)%0A)%3B%0A%0A--%20Column-level%20metadata%0ACREATE%20TABLE%20data_catalog_columns%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20catalog_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_position%20INT%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20max_length%20INT%2C%0A%20%20%20%20is_nullable%20BOOLEAN%2C%0A%20%20%20%20default_value%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metadata%0A%20%20%20%20business_name%20VARCHAR(200)%2C%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20business_rules%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%20metadata%0A%20%20%20%20completeness_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20uniqueness_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20validity_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Sensitivity%20metadata%0A%20%20%20%20is_pii%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20is_sensitive%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20masking_rule%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(catalog_id)%20REFERENCES%20data_catalog(id)%20ON%20DELETE%20CASCADE%2C%0A%20%20%20%20INDEX%20idx_catalog_id%20(catalog_id)%2C%0A%20%20%20%20INDEX%20idx_column_name%20(column_name)%2C%0A%20%20%20%20INDEX%20idx_is_pii%20(is_pii)%2C%0A%20%20%20%20FULLTEXT%20idx_column_description%20(business_description)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data catalog core tables
CREATE TABLE data_catalog (
    id INT AUTO_INCREMENT PRIMARY KEY,
    asset_name VARCHAR(200) NOT NULL,
    asset_type ENUM('TABLE', 'VIEW', 'PROCEDURE', 'FUNCTION', 'REPORT', 'DATASET') NOT NULL,
    database_name VARCHAR(100),
    schema_name VARCHAR(100),
    
    -- Business metadata
    business_name VARCHAR(200),
    business_description TEXT,
    business_owner VARCHAR(100),
    business_domain VARCHAR(100),
    
    -- Technical metadata
    technical_description TEXT,
    data_type_info JSON,
    size_info JSON,
    performance_stats JSON,
    
    -- Governance metadata
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    retention_policy VARCHAR(100),
    compliance_tags JSON,
    
    -- Usage metadata
    usage_frequency ENUM('DAILY', 'WEEKLY', 'MONTHLY', 'RARELY', 'UNKNOWN'),
    last_accessed TIMESTAMP,
    access_count BIGINT DEFAULT 0,
    
    -- Lifecycle metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deprecated_at TIMESTAMP NULL,
    
    UNIQUE KEY uk_asset (database_name, schema_name, asset_name),
    INDEX idx_asset_type (asset_type),
    INDEX idx_business_domain (business_domain),
    INDEX idx_data_classification (data_classification),
    FULLTEXT idx_description (business_description, technical_description)
);

-- Column-level metadata
CREATE TABLE data_catalog_columns (
    id INT AUTO_INCREMENT PRIMARY KEY,
    catalog_id INT NOT NULL,
    column_name VARCHAR(100) NOT NULL,
    column_position INT,
    data_type VARCHAR(50),
    max_length INT,
    is_nullable BOOLEAN,
    default_value TEXT,
    
    -- Business metadata
    business_name VARCHAR(200),
    business_description TEXT,
    business_rules TEXT,
    
    -- Data quality metadata
    completeness_score DECIMAL(5,2),
    uniqueness_score DECIMAL(5,2),
    validity_score DECIMAL(5,2),
    
    -- Sensitivity metadata
    is_pii BOOLEAN DEFAULT FALSE,
    is_sensitive BOOLEAN DEFAULT FALSE,
    masking_rule VARCHAR(100),
    
    FOREIGN KEY (catalog_id) REFERENCES data_catalog(id) ON DELETE CASCADE,
    INDEX idx_catalog_id (catalog_id),
    INDEX idx_column_name (column_name),
    INDEX idx_is_pii (is_pii),
    FULLTEXT idx_column_description (business_description)
);
</code></pre>
</div>

<p><strong>2. Automated Metadata Discovery:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Metadata%20harvesting%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20harvest_database_metadata(IN%20p_database_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_table_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_table_comment%20TEXT%3B%0A%20%20%20%20DECLARE%20v_catalog_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20table_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20table_type%2C%20table_comment%0A%20%20%20%20%20%20%20%20FROM%20information_schema.tables%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20p_database_name%0A%20%20%20%20%20%20%20%20AND%20table_type%20IN%20('BASE%20TABLE'%2C%20'VIEW')%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20harvest_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20table_cursor%20INTO%20v_table_name%2C%20v_table_type%2C%20v_table_comment%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20harvest_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20or%20update%20catalog%20entry%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_catalog%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20asset_name%2C%20asset_type%2C%20database_name%2C%20schema_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20technical_description%2C%20data_type_info%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20v_table_type%20WHEN%20'BASE%20TABLE'%20THEN%20'TABLE'%20ELSE%20'VIEW'%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_database_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'public'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('harvested_at'%2C%20NOW())%0A%20%20%20%20%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20%20%20%20%20technical_description%20%3D%20v_table_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20updated_at%20%3D%20NOW()%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20v_catalog_id%20%3D%20LAST_INSERT_ID()%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Harvest%20column%20metadata%0A%20%20%20%20%20%20%20%20CALL%20harvest_column_metadata(v_catalog_id%2C%20p_database_name%2C%20v_table_name)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20table_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20harvesting%20completion%0A%20%20%20%20INSERT%20INTO%20metadata_harvest_log%20(%0A%20%20%20%20%20%20%20%20database_name%2C%20harvest_type%2C%20completed_at%2C%20tables_processed%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_database_name%2C%20'FULL_HARVEST'%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(*)%20FROM%20data_catalog%20WHERE%20database_name%20%3D%20p_database_name)%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ACREATE%20PROCEDURE%20harvest_column_metadata(%0A%20%20%20%20IN%20p_catalog_id%20INT%2C%0A%20%20%20%20IN%20p_database_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_data_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_is_nullable%20VARCHAR(3)%3B%0A%20%20%20%20DECLARE%20v_column_default%20TEXT%3B%0A%20%20%20%20DECLARE%20v_ordinal_position%20INT%3B%0A%20%20%20%20DECLARE%20v_column_comment%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20column_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20column_name%2C%20data_type%2C%20is_nullable%2C%20column_default%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ordinal_position%2C%20column_comment%0A%20%20%20%20%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20%20%20%20%20WHERE%20table_schema%20%3D%20p_database_name%0A%20%20%20%20%20%20%20%20AND%20table_name%20%3D%20p_table_name%0A%20%20%20%20%20%20%20%20ORDER%20BY%20ordinal_position%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Clear%20existing%20column%20metadata%0A%20%20%20%20DELETE%20FROM%20data_catalog_columns%20WHERE%20catalog_id%20%3D%20p_catalog_id%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20column_cursor%3B%0A%20%20%20%20%0A%20%20%20%20column_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20column_cursor%20INTO%20v_column_name%2C%20v_data_type%2C%20v_is_nullable%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_column_default%2C%20v_ordinal_position%2C%20v_column_comment%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20column_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Insert%20column%20metadata%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20data_catalog_columns%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20catalog_id%2C%20column_name%2C%20column_position%2C%20data_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_nullable%2C%20default_value%2C%20business_description%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20is_pii%2C%20is_sensitive%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_catalog_id%2C%20v_column_name%2C%20v_ordinal_position%2C%20v_data_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_is_nullable%20%3D%20'YES')%2C%20v_column_default%2C%20v_column_comment%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Auto-detect%20PII%20based%20on%20column%20names%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_column_name%20REGEXP%20'(email%7Cphone%7Cssn%7Csocial%7Caddress%7Cname)')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20(v_column_name%20REGEXP%20'(password%7Csecret%7Ckey%7Ctoken%7Ccredit%7Csalary)')%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20column_cursor%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Metadata harvesting procedure
DELIMITER //
CREATE PROCEDURE harvest_database_metadata(IN p_database_name VARCHAR(100))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_table_type VARCHAR(20);
    DECLARE v_table_comment TEXT;
    DECLARE v_catalog_id INT;
    
    DECLARE table_cursor CURSOR FOR
        SELECT table_name, table_type, table_comment
        FROM information_schema.tables
        WHERE table_schema = p_database_name
        AND table_type IN ('BASE TABLE', 'VIEW');
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN table_cursor;
    
    harvest_loop: LOOP
        FETCH table_cursor INTO v_table_name, v_table_type, v_table_comment;
        
        IF done THEN
            LEAVE harvest_loop;
        END IF;
        
        -- Insert or update catalog entry
        INSERT INTO data_catalog (
            asset_name, asset_type, database_name, schema_name,
            technical_description, data_type_info
        ) VALUES (
            v_table_name,
            CASE v_table_type WHEN 'BASE TABLE' THEN 'TABLE' ELSE 'VIEW' END,
            p_database_name,
            'public',
            v_table_comment,
            JSON_OBJECT('harvested_at', NOW())
        ) ON DUPLICATE KEY UPDATE
            technical_description = v_table_comment,
            updated_at = NOW();
        
        SET v_catalog_id = LAST_INSERT_ID();
        
        -- Harvest column metadata
        CALL harvest_column_metadata(v_catalog_id, p_database_name, v_table_name);
        
    END LOOP;
    
    CLOSE table_cursor;
    
    -- Log harvesting completion
    INSERT INTO metadata_harvest_log (
        database_name, harvest_type, completed_at, tables_processed
    ) VALUES (
        p_database_name, 'FULL_HARVEST', NOW(),
        (SELECT COUNT(*) FROM data_catalog WHERE database_name = p_database_name)
    );
    
END //

CREATE PROCEDURE harvest_column_metadata(
    IN p_catalog_id INT,
    IN p_database_name VARCHAR(100),
    IN p_table_name VARCHAR(100)
)
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_data_type VARCHAR(50);
    DECLARE v_is_nullable VARCHAR(3);
    DECLARE v_column_default TEXT;
    DECLARE v_ordinal_position INT;
    DECLARE v_column_comment TEXT;
    
    DECLARE column_cursor CURSOR FOR
        SELECT column_name, data_type, is_nullable, column_default, 
               ordinal_position, column_comment
        FROM information_schema.columns
        WHERE table_schema = p_database_name
        AND table_name = p_table_name
        ORDER BY ordinal_position;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Clear existing column metadata
    DELETE FROM data_catalog_columns WHERE catalog_id = p_catalog_id;
    
    OPEN column_cursor;
    
    column_loop: LOOP
        FETCH column_cursor INTO v_column_name, v_data_type, v_is_nullable, 
                                v_column_default, v_ordinal_position, v_column_comment;
        
        IF done THEN
            LEAVE column_loop;
        END IF;
        
        -- Insert column metadata
        INSERT INTO data_catalog_columns (
            catalog_id, column_name, column_position, data_type,
            is_nullable, default_value, business_description,
            is_pii, is_sensitive
        ) VALUES (
            p_catalog_id, v_column_name, v_ordinal_position, v_data_type,
            (v_is_nullable = 'YES'), v_column_default, v_column_comment,
            -- Auto-detect PII based on column names
            (v_column_name REGEXP '(email|phone|ssn|social|address|name)'),
            (v_column_name REGEXP '(password|secret|key|token|credit|salary)')
        );
        
    END LOOP;
    
    CLOSE column_cursor;
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Discovery and Search:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Advanced%20search%20functionality%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20search_data_catalog(%0A%20%20%20%20IN%20p_search_term%20VARCHAR(500)%2C%0A%20%20%20%20IN%20p_asset_type%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_business_domain%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_classification%20VARCHAR(50)%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20dc.id%2C%0A%20%20%20%20%20%20%20%20dc.asset_name%2C%0A%20%20%20%20%20%20%20%20dc.asset_type%2C%0A%20%20%20%20%20%20%20%20dc.business_name%2C%0A%20%20%20%20%20%20%20%20dc.business_description%2C%0A%20%20%20%20%20%20%20%20dc.business_owner%2C%0A%20%20%20%20%20%20%20%20dc.business_domain%2C%0A%20%20%20%20%20%20%20%20dc.data_classification%2C%0A%20%20%20%20%20%20%20%20dc.usage_frequency%2C%0A%20%20%20%20%20%20%20%20dc.last_accessed%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Relevance%20scoring%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dc.asset_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%2010%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dc.business_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%208%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20MATCH(dc.business_description%2C%20dc.technical_description)%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20THEN%205%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_catalog_columns%20dcc%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20THEN%203%20ELSE%200%20END%0A%20%20%20%20%20%20%20%20)%20as%20relevance_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Column%20matches%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20SELECT%20GROUP_CONCAT(dcc.column_name%20SEPARATOR%20'%2C%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20FROM%20data_catalog_columns%20dcc%0A%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%0A%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20)%20as%20matching_columns%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20FROM%20data_catalog%20dc%0A%20%20%20%20WHERE%20(p_search_term%20IS%20NULL%20OR%20%0A%20%20%20%20%20%20%20%20%20%20%20dc.asset_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20dc.business_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20MATCH(dc.business_description%2C%20dc.technical_description)%20%0A%20%20%20%20%20%20%20%20%20%20%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20OR%0A%20%20%20%20%20%20%20%20%20%20%20EXISTS%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SELECT%201%20FROM%20data_catalog_columns%20dcc%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20dcc.catalog_id%20%3D%20dc.id%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20(dcc.column_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20MATCH(dcc.business_description)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE))%0A%20%20%20%20%20%20%20%20%20%20%20))%0A%20%20%20%20AND%20(p_asset_type%20IS%20NULL%20OR%20dc.asset_type%20%3D%20p_asset_type)%0A%20%20%20%20AND%20(p_business_domain%20IS%20NULL%20OR%20dc.business_domain%20%3D%20p_business_domain)%0A%20%20%20%20AND%20(p_data_classification%20IS%20NULL%20OR%20dc.data_classification%20%3D%20p_data_classification)%0A%20%20%20%20AND%20dc.deprecated_at%20IS%20NULL%0A%20%20%20%20%0A%20%20%20%20HAVING%20relevance_score%20%3E%200%0A%20%20%20%20ORDER%20BY%20relevance_score%20DESC%2C%20dc.usage_frequency%20DESC%2C%20dc.last_accessed%20DESC%0A%20%20%20%20LIMIT%2050%3B%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Advanced search functionality
DELIMITER //
CREATE PROCEDURE search_data_catalog(
    IN p_search_term VARCHAR(500),
    IN p_asset_type VARCHAR(50),
    IN p_business_domain VARCHAR(100),
    IN p_data_classification VARCHAR(50)
)
BEGIN
    SELECT 
        dc.id,
        dc.asset_name,
        dc.asset_type,
        dc.business_name,
        dc.business_description,
        dc.business_owner,
        dc.business_domain,
        dc.data_classification,
        dc.usage_frequency,
        dc.last_accessed,
        
        -- Relevance scoring
        (
            CASE WHEN dc.asset_name LIKE CONCAT('%', p_search_term, '%') THEN 10 ELSE 0 END +
            CASE WHEN dc.business_name LIKE CONCAT('%', p_search_term, '%') THEN 8 ELSE 0 END +
            CASE WHEN MATCH(dc.business_description, dc.technical_description) 
                      AGAINST(p_search_term IN NATURAL LANGUAGE MODE) THEN 5 ELSE 0 END +
            CASE WHEN EXISTS (
                SELECT 1 FROM data_catalog_columns dcc 
                WHERE dcc.catalog_id = dc.id 
                AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                     MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
            ) THEN 3 ELSE 0 END
        ) as relevance_score,
        
        -- Column matches
        (
            SELECT GROUP_CONCAT(dcc.column_name SEPARATOR ', ')
            FROM data_catalog_columns dcc
            WHERE dcc.catalog_id = dc.id
            AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                 MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
        ) as matching_columns
        
    FROM data_catalog dc
    WHERE (p_search_term IS NULL OR 
           dc.asset_name LIKE CONCAT('%', p_search_term, '%') OR
           dc.business_name LIKE CONCAT('%', p_search_term, '%') OR
           MATCH(dc.business_description, dc.technical_description) 
           AGAINST(p_search_term IN NATURAL LANGUAGE MODE) OR
           EXISTS (
               SELECT 1 FROM data_catalog_columns dcc 
               WHERE dcc.catalog_id = dc.id 
               AND (dcc.column_name LIKE CONCAT('%', p_search_term, '%') OR
                    MATCH(dcc.business_description) AGAINST(p_search_term IN NATURAL LANGUAGE MODE))
           ))
    AND (p_asset_type IS NULL OR dc.asset_type = p_asset_type)
    AND (p_business_domain IS NULL OR dc.business_domain = p_business_domain)
    AND (p_data_classification IS NULL OR dc.data_classification = p_data_classification)
    AND dc.deprecated_at IS NULL
    
    HAVING relevance_score &gt; 0
    ORDER BY relevance_score DESC, dc.usage_frequency DESC, dc.last_accessed DESC
    LIMIT 50;
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-379-what-are-data-governance-frameworks-and-policies-">**379. What are data governance frameworks and policies?**</h2>

<p><strong>Answer:</strong> Data governance frameworks establish policies, procedures, and controls to ensure data quality, security, compliance, and effective data management across the organization.</p>

<p><strong>Governance Framework Structure:</strong></p>

<p><strong>1. Data Governance Organization:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Governance%20roles%20and%20responsibilities%0ACREATE%20TABLE%20governance_roles%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20role_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20role_type%20ENUM('EXECUTIVE'%2C%20'STEWARD'%2C%20'CUSTODIAN'%2C%20'USER')%20NOT%20NULL%2C%0A%20%20%20%20responsibilities%20TEXT%2C%0A%20%20%20%20authority_level%20ENUM('STRATEGIC'%2C%20'TACTICAL'%2C%20'OPERATIONAL')%20NOT%20NULL%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_role_name%20(role_name)%0A)%3B%0A%0A--%20Data%20domain%20assignments%0ACREATE%20TABLE%20data_domains%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_description%20TEXT%2C%0A%20%20%20%20business_owner%20VARCHAR(100)%2C%0A%20%20%20%20technical_owner%20VARCHAR(100)%2C%0A%20%20%20%20data_steward%20VARCHAR(100)%2C%0A%20%20%20%20criticality%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%20DEFAULT%20'MEDIUM'%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_criticality%20(criticality)%0A)%3B%0A%0A--%20Policy%20framework%0ACREATE%20TABLE%20data_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20policy_type%20ENUM('QUALITY'%2C%20'SECURITY'%2C%20'PRIVACY'%2C%20'RETENTION'%2C%20'ACCESS'%2C%20'USAGE')%2C%0A%20%20%20%20policy_category%20ENUM('MANDATORY'%2C%20'RECOMMENDED'%2C%20'GUIDELINE')%2C%0A%20%20%20%20policy_description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20policy_rules%20JSON%2C%0A%20%20%20%20applicable_domains%20JSON%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_date%20DATE%2C%0A%20%20%20%20approval_status%20ENUM('DRAFT'%2C%20'APPROVED'%2C%20'ACTIVE'%2C%20'DEPRECATED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20approved_by%20VARCHAR(100)%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_policy_type%20(policy_type)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Governance roles and responsibilities
CREATE TABLE governance_roles (
    id INT AUTO_INCREMENT PRIMARY KEY,
    role_name VARCHAR(100) NOT NULL,
    role_type ENUM('EXECUTIVE', 'STEWARD', 'CUSTODIAN', 'USER') NOT NULL,
    responsibilities TEXT,
    authority_level ENUM('STRATEGIC', 'TACTICAL', 'OPERATIONAL') NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_role_name (role_name)
);

-- Data domain assignments
CREATE TABLE data_domains (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_name VARCHAR(100) NOT NULL,
    domain_description TEXT,
    business_owner VARCHAR(100),
    technical_owner VARCHAR(100),
    data_steward VARCHAR(100),
    criticality ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL') DEFAULT 'MEDIUM',
    
    UNIQUE KEY uk_domain_name (domain_name),
    INDEX idx_criticality (criticality)
);

-- Policy framework
CREATE TABLE data_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    policy_type ENUM('QUALITY', 'SECURITY', 'PRIVACY', 'RETENTION', 'ACCESS', 'USAGE'),
    policy_category ENUM('MANDATORY', 'RECOMMENDED', 'GUIDELINE'),
    policy_description TEXT NOT NULL,
    policy_rules JSON,
    applicable_domains JSON,
    effective_date DATE NOT NULL,
    review_date DATE,
    approval_status ENUM('DRAFT', 'APPROVED', 'ACTIVE', 'DEPRECATED') DEFAULT 'DRAFT',
    approved_by VARCHAR(100),
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_policy_type (policy_type),
    INDEX idx_approval_status (approval_status),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. Policy Implementation and Monitoring:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Policy%20compliance%20tracking%0ACREATE%20TABLE%20policy_compliance%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20asset_id%20INT%2C%0A%20%20%20%20compliance_status%20ENUM('COMPLIANT'%2C%20'NON_COMPLIANT'%2C%20'PARTIAL'%2C%20'NOT_ASSESSED')%2C%0A%20%20%20%20compliance_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20assessment_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20assessment_method%20ENUM('AUTOMATED'%2C%20'MANUAL'%2C%20'AUDIT')%2C%0A%20%20%20%20findings%20TEXT%2C%0A%20%20%20%20remediation_plan%20TEXT%2C%0A%20%20%20%20remediation_due_date%20DATE%2C%0A%20%20%20%20assessed_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(policy_id)%20REFERENCES%20data_policies(id)%2C%0A%20%20%20%20INDEX%20idx_policy_status%20(policy_id%2C%20compliance_status)%2C%0A%20%20%20%20INDEX%20idx_assessment_date%20(assessment_date)%0A)%3B%0A%0A--%20Automated%20policy%20enforcement%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20enforce_data_quality_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_policy_id%20INT%3B%0A%20%20%20%20DECLARE%20v_policy_rules%20JSON%3B%0A%20%20%20%20DECLARE%20v_applicable_domains%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20policy_rules%2C%20applicable_domains%0A%20%20%20%20%20%20%20%20FROM%20data_policies%0A%20%20%20%20%20%20%20%20WHERE%20policy_type%20%3D%20'QUALITY'%0A%20%20%20%20%20%20%20%20AND%20approval_status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20AND%20effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20policy%20rules%20(example%3A%20completeness%20check)%0A%20%20%20%20%20%20%20%20IF%20JSON_EXTRACT(v_policy_rules%2C%20'%24.completeness_threshold')%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_completeness_policy(v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20other%20policy%20types%0A%20%20%20%20%20%20%20%20IF%20JSON_EXTRACT(v_policy_rules%2C%20'%24.uniqueness_threshold')%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_uniqueness_policy(v_policy_id%2C%20v_policy_rules%2C%20v_applicable_domains)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0A%0ACREATE%20PROCEDURE%20check_completeness_policy(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_policy_rules%20JSON%2C%0A%20%20%20%20IN%20p_applicable_domains%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_threshold%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_completeness_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20DECLARE%20v_compliance_status%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_threshold%20%3D%20JSON_EXTRACT(p_policy_rules%2C%20'%24.completeness_threshold')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20completeness%20for%20each%20applicable%20table%0A%20%20%20%20--%20This%20would%20iterate%20through%20tables%20in%20applicable%20domains%0A%20%20%20%20--%20and%20calculate%20completeness%20scores%0A%20%20%20%20%0A%20%20%20%20--%20Example%20implementation%20for%20a%20specific%20table%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20(COUNT(*)%20-%20COUNT(CASE%20WHEN%20email%20IS%20NULL%20THEN%201%20END))%20%2F%20COUNT(*)%20*%20100%0A%20%20%20%20INTO%20v_completeness_score%0A%20%20%20%20FROM%20customers%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_compliance_status%20%3D%20CASE%20%0A%20%20%20%20%20%20%20%20WHEN%20v_completeness_score%20%3E%3D%20v_threshold%20THEN%20'COMPLIANT'%0A%20%20%20%20%20%20%20%20WHEN%20v_completeness_score%20%3E%3D%20v_threshold%20*%200.8%20THEN%20'PARTIAL'%0A%20%20%20%20%20%20%20%20ELSE%20'NON_COMPLIANT'%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Record%20compliance%20assessment%0A%20%20%20%20INSERT%20INTO%20policy_compliance%20(%0A%20%20%20%20%20%20%20%20policy_id%2C%20compliance_status%2C%20compliance_score%2C%0A%20%20%20%20%20%20%20%20assessment_method%2C%20findings%2C%20assessed_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_policy_id%2C%20v_compliance_status%2C%20v_completeness_score%2C%0A%20%20%20%20%20%20%20%20'AUTOMATED'%2C%20%0A%20%20%20%20%20%20%20%20CONCAT('Email%20completeness%3A%20'%2C%20v_completeness_score%2C%20'%25')%2C%0A%20%20%20%20%20%20%20%20'SYSTEM'%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Policy compliance tracking
CREATE TABLE policy_compliance (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    policy_id INT NOT NULL,
    asset_id INT,
    compliance_status ENUM('COMPLIANT', 'NON_COMPLIANT', 'PARTIAL', 'NOT_ASSESSED'),
    compliance_score DECIMAL(5,2),
    assessment_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    assessment_method ENUM('AUTOMATED', 'MANUAL', 'AUDIT'),
    findings TEXT,
    remediation_plan TEXT,
    remediation_due_date DATE,
    assessed_by VARCHAR(100),
    
    FOREIGN KEY (policy_id) REFERENCES data_policies(id),
    INDEX idx_policy_status (policy_id, compliance_status),
    INDEX idx_assessment_date (assessment_date)
);

-- Automated policy enforcement
DELIMITER //
CREATE PROCEDURE enforce_data_quality_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_policy_id INT;
    DECLARE v_policy_rules JSON;
    DECLARE v_applicable_domains JSON;
    
    DECLARE policy_cursor CURSOR FOR
        SELECT id, policy_rules, applicable_domains
        FROM data_policies
        WHERE policy_type = 'QUALITY'
        AND approval_status = 'ACTIVE'
        AND effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_policy_id, v_policy_rules, v_applicable_domains;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Execute policy rules (example: completeness check)
        IF JSON_EXTRACT(v_policy_rules, '$.completeness_threshold') IS NOT NULL THEN
            CALL check_completeness_policy(v_policy_id, v_policy_rules, v_applicable_domains);
        END IF;
        
        -- Execute other policy types
        IF JSON_EXTRACT(v_policy_rules, '$.uniqueness_threshold') IS NOT NULL THEN
            CALL check_uniqueness_policy(v_policy_id, v_policy_rules, v_applicable_domains);
        END IF;
        
    END LOOP;
    
    CLOSE policy_cursor;
END //

CREATE PROCEDURE check_completeness_policy(
    IN p_policy_id INT,
    IN p_policy_rules JSON,
    IN p_applicable_domains JSON
)
BEGIN
    DECLARE v_threshold DECIMAL(5,2);
    DECLARE v_completeness_score DECIMAL(5,2);
    DECLARE v_compliance_status VARCHAR(20);
    
    SET v_threshold = JSON_EXTRACT(p_policy_rules, '$.completeness_threshold');
    
    -- Check completeness for each applicable table
    -- This would iterate through tables in applicable domains
    -- and calculate completeness scores
    
    -- Example implementation for a specific table
    SELECT 
        (COUNT(*) - COUNT(CASE WHEN email IS NULL THEN 1 END)) / COUNT(*) * 100
    INTO v_completeness_score
    FROM customers;
    
    SET v_compliance_status = CASE 
        WHEN v_completeness_score &gt;= v_threshold THEN 'COMPLIANT'
        WHEN v_completeness_score &gt;= v_threshold * 0.8 THEN 'PARTIAL'
        ELSE 'NON_COMPLIANT'
    END;
    
    -- Record compliance assessment
    INSERT INTO policy_compliance (
        policy_id, compliance_status, compliance_score,
        assessment_method, findings, assessed_by
    ) VALUES (
        p_policy_id, v_compliance_status, v_completeness_score,
        'AUTOMATED', 
        CONCAT('Email completeness: ', v_completeness_score, '%'),
        'SYSTEM'
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Access and Usage Governance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Access%20control%20policies%0ACREATE%20TABLE%20access_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20access_type%20ENUM('READ'%2C%20'WRITE'%2C%20'DELETE'%2C%20'ADMIN')%2C%0A%20%20%20%20allowed_roles%20JSON%2C%0A%20%20%20%20access_conditions%20JSON%2C%0A%20%20%20%20approval_required%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20approval_workflow%20VARCHAR(100)%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_data_classification%20(data_classification)%2C%0A%20%20%20%20INDEX%20idx_access_type%20(access_type)%0A)%3B%0A%0A--%20Usage%20monitoring%20and%20compliance%0ACREATE%20TABLE%20data_usage_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20user_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20asset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20access_type%20ENUM('READ'%2C%20'write'%2C%20'delete'%2C%20'export')%2C%0A%20%20%20%20access_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20application%20VARCHAR(100)%2C%0A%20%20%20%20purpose%20VARCHAR(500)%2C%0A%20%20%20%20data_volume%20BIGINT%2C%0A%20%20%20%20compliance_status%20ENUM('APPROVED'%2C%20'VIOLATION'%2C%20'UNDER_REVIEW')%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_user_timestamp%20(user_id%2C%20access_timestamp)%2C%0A%20%20%20%20INDEX%20idx_asset_access%20(asset_name%2C%20access_type)%2C%0A%20%20%20%20INDEX%20idx_compliance_status%20(compliance_status)%0A)%3B%0A%0A--%20Usage%20compliance%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_usage_compliance()%0ABEGIN%0A%20%20%20%20--%20Detect%20unusual%20access%20patterns%0A%20%20%20%20INSERT%20INTO%20compliance_violations%20(%0A%20%20%20%20%20%20%20%20violation_type%2C%20user_id%2C%20asset_name%2C%20violation_description%2C%0A%20%20%20%20%20%20%20%20severity%2C%20detected_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'UNUSUAL_ACCESS_PATTERN'%2C%0A%20%20%20%20%20%20%20%20user_id%2C%0A%20%20%20%20%20%20%20%20asset_name%2C%0A%20%20%20%20%20%20%20%20CONCAT('User%20accessed%20'%2C%20COUNT(*)%2C%20'%20records%20in%20last%20hour')%2C%0A%20%20%20%20%20%20%20%20'HIGH'%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20FROM%20data_usage_log%0A%20%20%20%20WHERE%20access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20access_type%20%3D%20'read'%0A%20%20%20%20GROUP%20BY%20user_id%2C%20asset_name%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%2010000%20%20--%20Threshold%20for%20unusual%20access%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20compliance_violations%20cv%0A%20%20%20%20%20%20%20%20WHERE%20cv.user_id%20%3D%20data_usage_log.user_id%0A%20%20%20%20%20%20%20%20AND%20cv.asset_name%20%3D%20data_usage_log.asset_name%0A%20%20%20%20%20%20%20%20AND%20cv.violation_type%20%3D%20'UNUSUAL_ACCESS_PATTERN'%0A%20%20%20%20%20%20%20%20AND%20cv.detected_at%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Detect%20unauthorized%20access%20to%20restricted%20data%0A%20%20%20%20INSERT%20INTO%20compliance_violations%20(%0A%20%20%20%20%20%20%20%20violation_type%2C%20user_id%2C%20asset_name%2C%20violation_description%2C%0A%20%20%20%20%20%20%20%20severity%2C%20detected_at%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'UNAUTHORIZED_ACCESS'%2C%0A%20%20%20%20%20%20%20%20dul.user_id%2C%0A%20%20%20%20%20%20%20%20dul.asset_name%2C%0A%20%20%20%20%20%20%20%20'Access%20to%20restricted%20data%20without%20proper%20authorization'%2C%0A%20%20%20%20%20%20%20%20'CRITICAL'%2C%0A%20%20%20%20%20%20%20%20NOW()%0A%20%20%20%20FROM%20data_usage_log%20dul%0A%20%20%20%20JOIN%20data_catalog%20dc%20ON%20dul.asset_name%20%3D%20dc.asset_name%0A%20%20%20%20WHERE%20dc.data_classification%20%3D%20'RESTRICTED'%0A%20%20%20%20AND%20dul.access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20AND%20NOT%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20user_access_approvals%20uaa%0A%20%20%20%20%20%20%20%20WHERE%20uaa.user_id%20%3D%20dul.user_id%0A%20%20%20%20%20%20%20%20AND%20uaa.asset_name%20%3D%20dul.asset_name%0A%20%20%20%20%20%20%20%20AND%20uaa.approval_status%20%3D%20'APPROVED'%0A%20%20%20%20%20%20%20%20AND%20uaa.expiry_date%20%3E%3D%20CURDATE()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Access control policies
CREATE TABLE access_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    access_type ENUM('READ', 'WRITE', 'DELETE', 'ADMIN'),
    allowed_roles JSON,
    access_conditions JSON,
    approval_required BOOLEAN DEFAULT FALSE,
    approval_workflow VARCHAR(100),
    effective_date DATE NOT NULL,
    expiry_date DATE,
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_data_classification (data_classification),
    INDEX idx_access_type (access_type)
);

-- Usage monitoring and compliance
CREATE TABLE data_usage_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL,
    asset_name VARCHAR(200) NOT NULL,
    access_type ENUM('READ', 'write', 'delete', 'export'),
    access_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address VARCHAR(45),
    application VARCHAR(100),
    purpose VARCHAR(500),
    data_volume BIGINT,
    compliance_status ENUM('APPROVED', 'VIOLATION', 'UNDER_REVIEW'),
    
    INDEX idx_user_timestamp (user_id, access_timestamp),
    INDEX idx_asset_access (asset_name, access_type),
    INDEX idx_compliance_status (compliance_status)
);

-- Usage compliance monitoring
DELIMITER //
CREATE PROCEDURE monitor_usage_compliance()
BEGIN
    -- Detect unusual access patterns
    INSERT INTO compliance_violations (
        violation_type, user_id, asset_name, violation_description,
        severity, detected_at
    )
    SELECT 
        'UNUSUAL_ACCESS_PATTERN',
        user_id,
        asset_name,
        CONCAT('User accessed ', COUNT(*), ' records in last hour'),
        'HIGH',
        NOW()
    FROM data_usage_log
    WHERE access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    AND access_type = 'read'
    GROUP BY user_id, asset_name
    HAVING COUNT(*) &gt; 10000  -- Threshold for unusual access
    AND NOT EXISTS (
        SELECT 1 FROM compliance_violations cv
        WHERE cv.user_id = data_usage_log.user_id
        AND cv.asset_name = data_usage_log.asset_name
        AND cv.violation_type = 'UNUSUAL_ACCESS_PATTERN'
        AND cv.detected_at &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    );
    
    -- Detect unauthorized access to restricted data
    INSERT INTO compliance_violations (
        violation_type, user_id, asset_name, violation_description,
        severity, detected_at
    )
    SELECT 
        'UNAUTHORIZED_ACCESS',
        dul.user_id,
        dul.asset_name,
        'Access to restricted data without proper authorization',
        'CRITICAL',
        NOW()
    FROM data_usage_log dul
    JOIN data_catalog dc ON dul.asset_name = dc.asset_name
    WHERE dc.data_classification = 'RESTRICTED'
    AND dul.access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    AND NOT EXISTS (
        SELECT 1 FROM user_access_approvals uaa
        WHERE uaa.user_id = dul.user_id
        AND uaa.asset_name = dul.asset_name
        AND uaa.approval_status = 'APPROVED'
        AND uaa.expiry_date &gt;= CURDATE()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-380-how-do-you-implement-data-privacy-and-gdpr-compliance-">**380. How do you implement data privacy and GDPR compliance?**</h2>

<p><strong>Answer:</strong> Data privacy and GDPR compliance require comprehensive data protection measures, consent management, and individual rights fulfillment through systematic processes and controls.</p>

<p><strong>GDPR Compliance Framework:</strong></p>

<p><strong>1. Data Subject Rights Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20subject%20registry%0ACREATE%20TABLE%20data_subjects%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20subject_identifier%20VARCHAR(255)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20subject_type%20ENUM('CUSTOMER'%2C%20'EMPLOYEE'%2C%20'PROSPECT'%2C%20'VENDOR')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Contact%20information%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Consent%20management%0A%20%20%20%20consent_status%20JSON%2C%0A%20%20%20%20consent_timestamp%20TIMESTAMP%2C%0A%20%20%20%20consent_source%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rights%20exercise%20tracking%0A%20%20%20%20rights_exercised%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20retention%0A%20%20%20%20retention_category%20VARCHAR(100)%2C%0A%20%20%20%20retention_expiry%20DATE%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_subject_identifier%20(subject_identifier)%2C%0A%20%20%20%20INDEX%20idx_email%20(email)%2C%0A%20%20%20%20INDEX%20idx_retention_expiry%20(retention_expiry)%0A)%3B%0A%0A--%20Data%20processing%20activities%0ACREATE%20TABLE%20processing_activities%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20activity_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20processing_purpose%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20legal_basis%20ENUM('CONSENT'%2C%20'CONTRACT'%2C%20'LEGAL_OBLIGATION'%2C%20'VITAL_INTERESTS'%2C%20'PUBLIC_TASK'%2C%20'LEGITIMATE_INTERESTS')%2C%0A%20%20%20%20data_categories%20JSON%2C%0A%20%20%20%20data_sources%20JSON%2C%0A%20%20%20%20recipients%20JSON%2C%0A%20%20%20%20retention_period%20INT%2C%20--%20months%0A%20%20%20%20cross_border_transfers%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20safeguards_applied%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20controller%20VARCHAR(200)%2C%0A%20%20%20%20processor%20VARCHAR(200)%2C%0A%20%20%20%20dpo_contact%20VARCHAR(200)%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_legal_basis%20(legal_basis)%2C%0A%20%20%20%20INDEX%20idx_controller%20(controller)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data subject registry
CREATE TABLE data_subjects (
    id INT AUTO_INCREMENT PRIMARY KEY,
    subject_identifier VARCHAR(255) UNIQUE NOT NULL,
    subject_type ENUM('CUSTOMER', 'EMPLOYEE', 'PROSPECT', 'VENDOR'),
    
    -- Contact information
    email VARCHAR(255),
    phone VARCHAR(20),
    
    -- Consent management
    consent_status JSON,
    consent_timestamp TIMESTAMP,
    consent_source VARCHAR(100),
    
    -- Rights exercise tracking
    rights_exercised JSON,
    
    -- Data retention
    retention_category VARCHAR(100),
    retention_expiry DATE,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_subject_identifier (subject_identifier),
    INDEX idx_email (email),
    INDEX idx_retention_expiry (retention_expiry)
);

-- Data processing activities
CREATE TABLE processing_activities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    activity_name VARCHAR(200) NOT NULL,
    processing_purpose TEXT NOT NULL,
    legal_basis ENUM('CONSENT', 'CONTRACT', 'LEGAL_OBLIGATION', 'VITAL_INTERESTS', 'PUBLIC_TASK', 'LEGITIMATE_INTERESTS'),
    data_categories JSON,
    data_sources JSON,
    recipients JSON,
    retention_period INT, -- months
    cross_border_transfers BOOLEAN DEFAULT FALSE,
    safeguards_applied JSON,
    
    controller VARCHAR(200),
    processor VARCHAR(200),
    dpo_contact VARCHAR(200),
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_legal_basis (legal_basis),
    INDEX idx_controller (controller)
);
</code></pre>
</div>

<p><strong>2. Right to Access Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20export%20for%20subject%20access%20requests%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20export_subject_data(IN%20p_subject_identifier%20VARCHAR(255))%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_subject_id%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_subject_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Data%20subject%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20comprehensive%20data%20export%0A%20%20%20%20SELECT%20'Personal%20Information'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'subject_id'%2C%20subject_identifier%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'email'%2C%20email%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'phone'%2C%20phone%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'consent_status'%2C%20consent_status%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'consent_timestamp'%2C%20consent_timestamp%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20created_at%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20id%20%3D%20v_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Customer%20data%0A%20%20%20%20SELECT%20'Customer%20Profile'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'address'%2C%20address%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'date_of_birth'%2C%20date_of_birth%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'preferences'%2C%20preferences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'created_at'%2C%20created_at%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'last_updated'%2C%20updated_at%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20customers%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Transaction%20history%0A%20%20%20%20SELECT%20'Transaction%20History'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAYAGG(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'transaction_id'%2C%20id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'amount'%2C%20amount%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'transaction_date'%2C%20transaction_date%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'description'%2C%20description%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20transactions%0A%20%20%20%20WHERE%20customer_id%20%3D%20(SELECT%20customer_id%20FROM%20customers%20WHERE%20subject_id%20%3D%20v_subject_id)%0A%20%20%20%20%0A%20%20%20%20UNION%20ALL%0A%20%20%20%20%0A%20%20%20%20--%20Communication%20history%0A%20%20%20%20SELECT%20'Communications'%20as%20data_category%2C%0A%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAYAGG(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'communication_type'%2C%20communication_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'content'%2C%20content%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'sent_date'%2C%20sent_date%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'channel'%2C%20channel%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20)%20as%20data_content%0A%20%20%20%20FROM%20communications%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20the%20access%20request%0A%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20requested_at%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_subject_id%2C%20'ACCESS'%2C%20'COMPLETED'%2C%20NOW()%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data export for subject access requests
DELIMITER //
CREATE PROCEDURE export_subject_data(IN p_subject_identifier VARCHAR(255))
BEGIN
    DECLARE v_subject_id INT;
    
    -- Get subject ID
    SELECT id INTO v_subject_id
    FROM data_subjects
    WHERE subject_identifier = p_subject_identifier;
    
    IF v_subject_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Data subject not found';
    END IF;
    
    -- Create comprehensive data export
    SELECT 'Personal Information' as data_category,
           JSON_OBJECT(
               'subject_id', subject_identifier,
               'email', email,
               'phone', phone,
               'consent_status', consent_status,
               'consent_timestamp', consent_timestamp,
               'created_at', created_at
           ) as data_content
    FROM data_subjects
    WHERE id = v_subject_id
    
    UNION ALL
    
    -- Customer data
    SELECT 'Customer Profile' as data_category,
           JSON_OBJECT(
               'name', name,
               'address', address,
               'date_of_birth', date_of_birth,
               'preferences', preferences,
               'created_at', created_at,
               'last_updated', updated_at
           ) as data_content
    FROM customers
    WHERE subject_id = v_subject_id
    
    UNION ALL
    
    -- Transaction history
    SELECT 'Transaction History' as data_category,
           JSON_ARRAYAGG(
               JSON_OBJECT(
                   'transaction_id', id,
                   'amount', amount,
                   'transaction_date', transaction_date,
                   'description', description
               )
           ) as data_content
    FROM transactions
    WHERE customer_id = (SELECT customer_id FROM customers WHERE subject_id = v_subject_id)
    
    UNION ALL
    
    -- Communication history
    SELECT 'Communications' as data_category,
           JSON_ARRAYAGG(
               JSON_OBJECT(
                   'communication_type', communication_type,
                   'content', content,
                   'sent_date', sent_date,
                   'channel', channel
               )
           ) as data_content
    FROM communications
    WHERE subject_id = v_subject_id;
    
    -- Log the access request
    INSERT INTO gdpr_requests (
        subject_id, request_type, status, requested_at, completed_at
    ) VALUES (
        v_subject_id, 'ACCESS', 'COMPLETED', NOW(), NOW()
    );
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>3. Right to Erasure (Right to be Forgotten):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20erasure%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20erase_subject_data(%0A%20%20%20%20IN%20p_subject_identifier%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_erasure_reason%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20DECLARE%20v_customer_id%20INT%3B%0A%20%20%20%20DECLARE%20erasure_timestamp%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20START%20TRANSACTION%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20and%20customer%20IDs%0A%20%20%20%20SELECT%20ds.id%2C%20c.id%0A%20%20%20%20INTO%20v_subject_id%2C%20v_customer_id%0A%20%20%20%20FROM%20data_subjects%20ds%0A%20%20%20%20LEFT%20JOIN%20customers%20c%20ON%20ds.id%20%3D%20c.subject_id%0A%20%20%20%20WHERE%20ds.subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_subject_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Data%20subject%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20if%20erasure%20is%20legally%20permissible%0A%20%20%20%20IF%20EXISTS%20(%0A%20%20%20%20%20%20%20%20SELECT%201%20FROM%20processing_activities%20pa%0A%20%20%20%20%20%20%20%20WHERE%20JSON_CONTAINS(pa.data_categories%2C%20'%22CUSTOMER_DATA%22')%0A%20%20%20%20%20%20%20%20AND%20pa.legal_basis%20IN%20('LEGAL_OBLIGATION'%2C%20'PUBLIC_TASK')%0A%20%20%20%20)%20THEN%0A%20%20%20%20%20%20%20%20--%20Cannot%20erase%20data%20required%20for%20legal%20obligations%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20reason%2C%20requested_at%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_subject_id%2C%20'ERASURE'%2C%20'REJECTED'%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20'Data%20required%20for%20legal%20obligations'%2C%20NOW()%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20ROLLBACK%3B%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Erasure%20not%20permitted%20due%20to%20legal%20obligations'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Perform%20erasure%20(anonymization%20rather%20than%20deletion%20for%20referential%20integrity)%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20customer%20data%0A%20%20%20%20UPDATE%20customers%20%0A%20%20%20%20SET%20name%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20email%20%3D%20CONCAT('erased_'%2C%20id%2C%20'%40deleted.local')%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20address%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20date_of_birth%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20preferences%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%2C%0A%20%20%20%20%20%20%20%20erasure_reason%20%3D%20p_erasure_reason%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Anonymize%20communication%20data%0A%20%20%20%20UPDATE%20communications%0A%20%20%20%20SET%20content%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20personal_data_removed%20%3D%20TRUE%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20transaction%20data%20(keep%20for%20financial%20records%20but%20remove%20personal%20identifiers)%0A%20%20%20%20UPDATE%20transactions%0A%20%20%20%20SET%20customer_reference%20%3D%20'ERASED'%2C%0A%20%20%20%20%20%20%20%20personal_notes%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%0A%20%20%20%20WHERE%20customer_id%20%3D%20v_customer_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20data%20subject%20record%0A%20%20%20%20UPDATE%20data_subjects%0A%20%20%20%20SET%20email%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20phone%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20consent_status%20%3D%20NULL%2C%0A%20%20%20%20%20%20%20%20erased_at%20%3D%20erasure_timestamp%2C%0A%20%20%20%20%20%20%20%20erasure_reason%20%3D%20p_erasure_reason%0A%20%20%20%20WHERE%20id%20%3D%20v_subject_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20successful%20erasure%0A%20%20%20%20INSERT%20INTO%20gdpr_requests%20(%0A%20%20%20%20%20%20%20%20subject_id%2C%20request_type%2C%20status%2C%20reason%2C%20requested_at%2C%20completed_at%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_subject_id%2C%20'ERASURE'%2C%20'COMPLETED'%2C%20p_erasure_reason%2C%20NOW()%2C%20NOW()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20COMMIT%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data erasure implementation
DELIMITER //
CREATE PROCEDURE erase_subject_data(
    IN p_subject_identifier VARCHAR(255),
    IN p_erasure_reason TEXT
)
BEGIN
    DECLARE v_subject_id INT;
    DECLARE v_customer_id INT;
    DECLARE erasure_timestamp TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        ROLLBACK;
        RESIGNAL;
    END;
    
    START TRANSACTION;
    
    -- Get subject and customer IDs
    SELECT ds.id, c.id
    INTO v_subject_id, v_customer_id
    FROM data_subjects ds
    LEFT JOIN customers c ON ds.id = c.subject_id
    WHERE ds.subject_identifier = p_subject_identifier;
    
    IF v_subject_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Data subject not found';
    END IF;
    
    -- Check if erasure is legally permissible
    IF EXISTS (
        SELECT 1 FROM processing_activities pa
        WHERE JSON_CONTAINS(pa.data_categories, '"CUSTOMER_DATA"')
        AND pa.legal_basis IN ('LEGAL_OBLIGATION', 'PUBLIC_TASK')
    ) THEN
        -- Cannot erase data required for legal obligations
        INSERT INTO gdpr_requests (
            subject_id, request_type, status, reason, requested_at
        ) VALUES (
            v_subject_id, 'ERASURE', 'REJECTED', 
            'Data required for legal obligations', NOW()
        );
        
        ROLLBACK;
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Erasure not permitted due to legal obligations';
    END IF;
    
    -- Perform erasure (anonymization rather than deletion for referential integrity)
    
    -- Anonymize customer data
    UPDATE customers 
    SET name = 'ERASED',
        email = CONCAT('erased_', id, '@deleted.local'),
        phone = NULL,
        address = NULL,
        date_of_birth = NULL,
        preferences = NULL,
        erased_at = erasure_timestamp,
        erasure_reason = p_erasure_reason
    WHERE subject_id = v_subject_id;
    
    -- Anonymize communication data
    UPDATE communications
    SET content = 'ERASED',
        personal_data_removed = TRUE,
        erased_at = erasure_timestamp
    WHERE subject_id = v_subject_id;
    
    -- Handle transaction data (keep for financial records but remove personal identifiers)
    UPDATE transactions
    SET customer_reference = 'ERASED',
        personal_notes = NULL,
        erased_at = erasure_timestamp
    WHERE customer_id = v_customer_id;
    
    -- Update data subject record
    UPDATE data_subjects
    SET email = NULL,
        phone = NULL,
        consent_status = NULL,
        erased_at = erasure_timestamp,
        erasure_reason = p_erasure_reason
    WHERE id = v_subject_id;
    
    -- Log successful erasure
    INSERT INTO gdpr_requests (
        subject_id, request_type, status, reason, requested_at, completed_at
    ) VALUES (
        v_subject_id, 'ERASURE', 'COMPLETED', p_erasure_reason, NOW(), NOW()
    );
    
    COMMIT;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>4. Consent Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Consent%20tracking%20and%20management%0ACREATE%20TABLE%20consent_records%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20subject_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20processing_purpose%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20consent_given%20BOOLEAN%20NOT%20NULL%2C%0A%20%20%20%20consent_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20consent_method%20ENUM('WEBSITE'%2C%20'EMAIL'%2C%20'PHONE'%2C%20'PAPER'%2C%20'API')%2C%0A%20%20%20%20consent_evidence%20JSON%2C%0A%20%20%20%20withdrawn_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20withdrawal_method%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Consent%20details%0A%20%20%20%20granular_consents%20JSON%2C%0A%20%20%20%20consent_version%20VARCHAR(20)%2C%0A%20%20%20%20privacy_policy_version%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(subject_id)%20REFERENCES%20data_subjects(id)%2C%0A%20%20%20%20INDEX%20idx_subject_purpose%20(subject_id%2C%20processing_purpose)%2C%0A%20%20%20%20INDEX%20idx_consent_timestamp%20(consent_timestamp)%0A)%3B%0A%0A--%20Consent%20validation%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20validate_processing_consent(%0A%20%20%20%20IN%20p_subject_identifier%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_processing_purpose%20VARCHAR(200)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_subject_id%20INT%3B%0A%20%20%20%20DECLARE%20v_consent_valid%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_consent_timestamp%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20subject%20ID%0A%20%20%20%20SELECT%20id%20INTO%20v_subject_id%0A%20%20%20%20FROM%20data_subjects%0A%20%20%20%20WHERE%20subject_identifier%20%3D%20p_subject_identifier%3B%0A%20%20%20%20%0A%20%20%20%20--%20Check%20for%20valid%20consent%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20consent_given%20AND%20withdrawn_at%20IS%20NULL%2C%0A%20%20%20%20%20%20%20%20consent_timestamp%0A%20%20%20%20INTO%20v_consent_valid%2C%20v_consent_timestamp%0A%20%20%20%20FROM%20consent_records%0A%20%20%20%20WHERE%20subject_id%20%3D%20v_subject_id%0A%20%20%20%20AND%20processing_purpose%20%3D%20p_processing_purpose%0A%20%20%20%20ORDER%20BY%20consent_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20consent%20status%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20v_consent_valid%20as%20consent_valid%2C%0A%20%20%20%20%20%20%20%20v_consent_timestamp%20as%20consent_date%2C%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20v_consent_valid%20THEN%20'VALID'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20v_consent_timestamp%20IS%20NULL%20THEN%20'NO_CONSENT'%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'WITHDRAWN'%0A%20%20%20%20%20%20%20%20END%20as%20consent_status%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Consent tracking and management
CREATE TABLE consent_records (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    subject_id INT NOT NULL,
    processing_purpose VARCHAR(200) NOT NULL,
    consent_given BOOLEAN NOT NULL,
    consent_timestamp TIMESTAMP NOT NULL,
    consent_method ENUM('WEBSITE', 'EMAIL', 'PHONE', 'PAPER', 'API'),
    consent_evidence JSON,
    withdrawn_at TIMESTAMP NULL,
    withdrawal_method VARCHAR(100),
    
    -- Consent details
    granular_consents JSON,
    consent_version VARCHAR(20),
    privacy_policy_version VARCHAR(20),
    
    FOREIGN KEY (subject_id) REFERENCES data_subjects(id),
    INDEX idx_subject_purpose (subject_id, processing_purpose),
    INDEX idx_consent_timestamp (consent_timestamp)
);

-- Consent validation procedure
DELIMITER //
CREATE PROCEDURE validate_processing_consent(
    IN p_subject_identifier VARCHAR(255),
    IN p_processing_purpose VARCHAR(200)
)
BEGIN
    DECLARE v_subject_id INT;
    DECLARE v_consent_valid BOOLEAN DEFAULT FALSE;
    DECLARE v_consent_timestamp TIMESTAMP;
    
    -- Get subject ID
    SELECT id INTO v_subject_id
    FROM data_subjects
    WHERE subject_identifier = p_subject_identifier;
    
    -- Check for valid consent
    SELECT 
        consent_given AND withdrawn_at IS NULL,
        consent_timestamp
    INTO v_consent_valid, v_consent_timestamp
    FROM consent_records
    WHERE subject_id = v_subject_id
    AND processing_purpose = p_processing_purpose
    ORDER BY consent_timestamp DESC
    LIMIT 1;
    
    -- Return consent status
    SELECT 
        v_consent_valid as consent_valid,
        v_consent_timestamp as consent_date,
        CASE 
            WHEN v_consent_valid THEN 'VALID'
            WHEN v_consent_timestamp IS NULL THEN 'NO_CONSENT'
            ELSE 'WITHDRAWN'
        END as consent_status;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>5. Data Breach Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20breach%20incident%20tracking%0ACREATE%20TABLE%20data_breaches%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20breach_reference%20VARCHAR(100)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20breach_type%20ENUM('CONFIDENTIALITY'%2C%20'INTEGRITY'%2C%20'AVAILABILITY')%2C%0A%20%20%20%20severity%20ENUM('LOW'%2C%20'MEDIUM'%2C%20'HIGH'%2C%20'CRITICAL')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Incident%20details%0A%20%20%20%20discovered_at%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20occurred_at%20TIMESTAMP%2C%0A%20%20%20%20description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20affected_data_categories%20JSON%2C%0A%20%20%20%20estimated_affected_subjects%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Response%20tracking%0A%20%20%20%20containment_measures%20TEXT%2C%0A%20%20%20%20notification_required%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20authority_notified_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20subjects_notified_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Resolution%0A%20%20%20%20resolved_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20resolution_summary%20TEXT%2C%0A%20%20%20%20lessons_learned%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%0A%20%20%20%20reportable_to_authority%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20authority_reference%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_severity%20(severity)%2C%0A%20%20%20%20INDEX%20idx_discovered_at%20(discovered_at)%2C%0A%20%20%20%20INDEX%20idx_notification_required%20(notification_required)%0A)%3B%0A%0A--%20Automated%20breach%20detection%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20detect_potential_breaches()%0ABEGIN%0A%20%20%20%20--%20Detect%20unusual%20data%20access%20patterns%0A%20%20%20%20INSERT%20INTO%20potential_breaches%20(%0A%20%20%20%20%20%20%20%20breach_type%2C%20description%2C%20severity%2C%20detected_at%2C%20evidence%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'CONFIDENTIALITY'%2C%0A%20%20%20%20%20%20%20%20CONCAT('Unusual%20access%20pattern%20detected%20for%20user%3A%20'%2C%20user_id)%2C%0A%20%20%20%20%20%20%20%20'HIGH'%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'user_id'%2C%20user_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'access_count'%2C%20COUNT(*)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'time_period'%2C%20'1%20hour'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'assets_accessed'%2C%20COUNT(DISTINCT%20asset_name)%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20FROM%20data_usage_log%0A%20%20%20%20WHERE%20access_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%201%20HOUR)%0A%20%20%20%20GROUP%20BY%20user_id%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%201000%20OR%20COUNT(DISTINCT%20asset_name)%20%3E%2050%3B%0A%20%20%20%20%0A%20%20%20%20--%20Detect%20failed%20access%20attempts%0A%20%20%20%20INSERT%20INTO%20potential_breaches%20(%0A%20%20%20%20%20%20%20%20breach_type%2C%20description%2C%20severity%2C%20detected_at%2C%20evidence%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'CONFIDENTIALITY'%2C%0A%20%20%20%20%20%20%20%20CONCAT('Multiple%20failed%20access%20attempts%20from%20IP%3A%20'%2C%20ip_address)%2C%0A%20%20%20%20%20%20%20%20'MEDIUM'%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'ip_address'%2C%20ip_address%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'failed_attempts'%2C%20COUNT(*)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'time_period'%2C%20'15%20minutes'%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20FROM%20failed_access_log%0A%20%20%20%20WHERE%20attempt_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%2015%20MINUTE)%0A%20%20%20%20GROUP%20BY%20ip_address%0A%20%20%20%20HAVING%20COUNT(*)%20%3E%2010%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data breach incident tracking
CREATE TABLE data_breaches (
    id INT AUTO_INCREMENT PRIMARY KEY,
    breach_reference VARCHAR(100) UNIQUE NOT NULL,
    breach_type ENUM('CONFIDENTIALITY', 'INTEGRITY', 'AVAILABILITY'),
    severity ENUM('LOW', 'MEDIUM', 'HIGH', 'CRITICAL'),
    
    -- Incident details
    discovered_at TIMESTAMP NOT NULL,
    occurred_at TIMESTAMP,
    description TEXT NOT NULL,
    affected_data_categories JSON,
    estimated_affected_subjects INT,
    
    -- Response tracking
    containment_measures TEXT,
    notification_required BOOLEAN DEFAULT TRUE,
    authority_notified_at TIMESTAMP NULL,
    subjects_notified_at TIMESTAMP NULL,
    
    -- Resolution
    resolved_at TIMESTAMP NULL,
    resolution_summary TEXT,
    lessons_learned TEXT,
    
    -- Compliance
    reportable_to_authority BOOLEAN DEFAULT TRUE,
    authority_reference VARCHAR(100),
    
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_severity (severity),
    INDEX idx_discovered_at (discovered_at),
    INDEX idx_notification_required (notification_required)
);

-- Automated breach detection
DELIMITER //
CREATE PROCEDURE detect_potential_breaches()
BEGIN
    -- Detect unusual data access patterns
    INSERT INTO potential_breaches (
        breach_type, description, severity, detected_at, evidence
    )
    SELECT 
        'CONFIDENTIALITY',
        CONCAT('Unusual access pattern detected for user: ', user_id),
        'HIGH',
        NOW(),
        JSON_OBJECT(
            'user_id', user_id,
            'access_count', COUNT(*),
            'time_period', '1 hour',
            'assets_accessed', COUNT(DISTINCT asset_name)
        )
    FROM data_usage_log
    WHERE access_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR)
    GROUP BY user_id
    HAVING COUNT(*) &gt; 1000 OR COUNT(DISTINCT asset_name) &gt; 50;
    
    -- Detect failed access attempts
    INSERT INTO potential_breaches (
        breach_type, description, severity, detected_at, evidence
    )
    SELECT 
        'CONFIDENTIALITY',
        CONCAT('Multiple failed access attempts from IP: ', ip_address),
        'MEDIUM',
        NOW(),
        JSON_OBJECT(
            'ip_address', ip_address,
            'failed_attempts', COUNT(*),
            'time_period', '15 minutes'
        )
    FROM failed_access_log
    WHERE attempt_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 15 MINUTE)
    GROUP BY ip_address
    HAVING COUNT(*) &gt; 10;
    
END //
DELIMITER ;
</code></pre>
</div>

<h2 id="-381-what-are-data-retention-and-purging-strategies-">**381. What are data retention and purging strategies?**</h2>

<p><strong>Answer:</strong> Data retention and purging strategies manage data lifecycle by automatically removing or archiving data based on legal requirements, business needs, and storage optimization.</p>

<p><strong>Retention Policy Framework:</strong></p>

<p><strong>1. Retention Policy Configuration:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Retention%20policy%20definitions%0ACREATE%20TABLE%20retention_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20retention_period_days%20INT%20NOT%20NULL%2C%0A%20%20%20%20retention_criteria%20JSON%2C%0A%20%20%20%20purge_method%20ENUM('DELETE'%2C%20'ARCHIVE'%2C%20'ANONYMIZE')%20DEFAULT%20'DELETE'%2C%0A%20%20%20%20legal_basis%20VARCHAR(200)%2C%0A%20%20%20%20business_justification%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Policy%20metadata%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_date%20DATE%2C%0A%20%20%20%20policy_owner%20VARCHAR(100)%2C%0A%20%20%20%20approval_status%20ENUM('DRAFT'%2C%20'APPROVED'%2C%20'ACTIVE'%2C%20'SUSPENDED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_policy%20(table_name%2C%20policy_name)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%2C%0A%20%20%20%20INDEX%20idx_approval_status%20(approval_status)%0A)%3B%0A%0A--%20Insert%20retention%20policies%0AINSERT%20INTO%20retention_policies%20(%0A%20%20%20%20policy_name%2C%20table_name%2C%20retention_period_days%2C%20retention_criteria%2C%0A%20%20%20%20purge_method%2C%20legal_basis%2C%20effective_date%2C%20policy_owner%2C%20approval_status%0A)%20VALUES%0A('Customer%20Data%20Retention'%2C%20'customers'%2C%202555%2C%20%0A%20'%7B%22date_column%22%3A%20%22last_activity%22%2C%20%22status_filter%22%3A%20%22inactive%22%7D'%2C%0A%20'ANONYMIZE'%2C%20'GDPR%20Article%205%20-%20Storage%20limitation'%2C%20CURDATE()%2C%20'data_officer'%2C%20'ACTIVE')%2C%0A%0A('Transaction%20Log%20Retention'%2C%20'transaction_logs'%2C%202555%2C%0A%20'%7B%22date_column%22%3A%20%22created_at%22%7D'%2C%0A%20'ARCHIVE'%2C%20'Financial%20regulations%20-%207%20years'%2C%20CURDATE()%2C%20'compliance_officer'%2C%20'ACTIVE')%2C%0A%0A('Session%20Data%20Retention'%2C%20'user_sessions'%2C%2090%2C%0A%20'%7B%22date_column%22%3A%20%22last_accessed%22%7D'%2C%0A%20'DELETE'%2C%20'Business%20requirement%20-%2090%20days'%2C%20CURDATE()%2C%20'security_officer'%2C%20'ACTIVE')%2C%0A%0A('Audit%20Log%20Retention'%2C%20'audit_logs'%2C%203650%2C%0A%20'%7B%22date_column%22%3A%20%22event_timestamp%22%2C%20%22severity_filter%22%3A%20%22HIGH%2CCRITICAL%22%7D'%2C%0A%20'ARCHIVE'%2C%20'SOX%20compliance%20-%2010%20years'%2C%20CURDATE()%2C%20'audit_manager'%2C%20'ACTIVE')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Retention policy definitions
CREATE TABLE retention_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    retention_period_days INT NOT NULL,
    retention_criteria JSON,
    purge_method ENUM('DELETE', 'ARCHIVE', 'ANONYMIZE') DEFAULT 'DELETE',
    legal_basis VARCHAR(200),
    business_justification TEXT,
    
    -- Policy metadata
    effective_date DATE NOT NULL,
    review_date DATE,
    policy_owner VARCHAR(100),
    approval_status ENUM('DRAFT', 'APPROVED', 'ACTIVE', 'SUSPENDED') DEFAULT 'DRAFT',
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_policy (table_name, policy_name),
    INDEX idx_effective_date (effective_date),
    INDEX idx_approval_status (approval_status)
);

-- Insert retention policies
INSERT INTO retention_policies (
    policy_name, table_name, retention_period_days, retention_criteria,
    purge_method, legal_basis, effective_date, policy_owner, approval_status
) VALUES
('Customer Data Retention', 'customers', 2555, 
 '{"date_column": "last_activity", "status_filter": "inactive"}',
 'ANONYMIZE', 'GDPR Article 5 - Storage limitation', CURDATE(), 'data_officer', 'ACTIVE'),

('Transaction Log Retention', 'transaction_logs', 2555,
 '{"date_column": "created_at"}',
 'ARCHIVE', 'Financial regulations - 7 years', CURDATE(), 'compliance_officer', 'ACTIVE'),

('Session Data Retention', 'user_sessions', 90,
 '{"date_column": "last_accessed"}',
 'DELETE', 'Business requirement - 90 days', CURDATE(), 'security_officer', 'ACTIVE'),

('Audit Log Retention', 'audit_logs', 3650,
 '{"date_column": "event_timestamp", "severity_filter": "HIGH,CRITICAL"}',
 'ARCHIVE', 'SOX compliance - 10 years', CURDATE(), 'audit_manager', 'ACTIVE');
</code></pre>
</div>

<p><strong>2. Automated Purging Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Purging%20execution%20log%0ACREATE%20TABLE%20purge_execution_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20execution_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20records_identified%20BIGINT%2C%0A%20%20%20%20records_processed%20BIGINT%2C%0A%20%20%20%20records_failed%20BIGINT%2C%0A%20%20%20%20execution_status%20ENUM('SUCCESS'%2C%20'PARTIAL'%2C%20'FAILED')%2C%0A%20%20%20%20execution_duration_seconds%20INT%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(policy_id)%20REFERENCES%20retention_policies(id)%2C%0A%20%20%20%20INDEX%20idx_execution_date%20(execution_date)%2C%0A%20%20%20%20INDEX%20idx_policy_status%20(policy_id%2C%20execution_status)%0A)%3B%0A%0A--%20Main%20purging%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_retention_policies()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_policy_id%20INT%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_retention_days%20INT%3B%0A%20%20%20%20DECLARE%20v_retention_criteria%20JSON%3B%0A%20%20%20%20DECLARE%20v_purge_method%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_records_identified%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20policy_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20table_name%2C%20retention_period_days%2C%20retention_criteria%2C%20purge_method%0A%20%20%20%20%20%20%20%20FROM%20retention_policies%0A%20%20%20%20%20%20%20%20WHERE%20approval_status%20%3D%20'ACTIVE'%0A%20%20%20%20%20%20%20%20AND%20effective_date%20%3C%3D%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20policy_cursor%3B%0A%20%20%20%20%0A%20%20%20%20policy_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20policy_cursor%20INTO%20v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_purge_method%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20policy_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20purging%20based%20on%20method%0A%20%20%20%20%20%20%20%20CASE%20v_purge_method%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'DELETE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_deletion(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ARCHIVE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_archiving(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ANONYMIZE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20purge_by_anonymization(v_policy_id%2C%20v_table_name%2C%20v_retention_days%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_retention_criteria%2C%20v_records_identified%2C%20v_records_processed)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20execution%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20purge_execution_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20policy_id%2C%20records_identified%2C%20records_processed%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20execution_status%2C%20execution_duration_seconds%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_policy_id%2C%20v_records_identified%2C%20v_records_processed%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20v_records_processed%20%3D%20v_records_identified%20THEN%20'SUCCESS'%20ELSE%20'PARTIAL'%20END%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(SECOND%2C%20v_start_time%2C%20NOW())%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20policy_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Deletion-based%20purging%0ACREATE%20PROCEDURE%20purge_by_deletion(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_retention_days%20INT%2C%0A%20%20%20%20IN%20p_criteria%20JSON%2C%0A%20%20%20%20OUT%20p_identified%20BIGINT%2C%0A%20%20%20%20OUT%20p_processed%20BIGINT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_date_column%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_status_filter%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_cutoff_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_delete_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_count_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20criteria%0A%20%20%20%20SET%20v_date_column%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.date_column'))%3B%0A%20%20%20%20SET%20v_status_filter%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.status_filter'))%3B%0A%20%20%20%20SET%20v_cutoff_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_retention_days%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20records%20to%20be%20deleted%0A%20%20%20%20SET%20v_count_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_status_filter%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_count_sql%20%3D%20CONCAT(v_count_sql%2C%20'%20AND%20status%20IN%20('''%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REPLACE(v_status_filter%2C%20'%2C'%2C%20'''%2C''')%2C%20''')')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_count_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20p_identified%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Delete%20records%20in%20batches%0A%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'DELETE%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_status_filter%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(v_delete_sql%2C%20'%20AND%20status%20IN%20('''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20REPLACE(v_status_filter%2C%20'%2C'%2C%20'''%2C''')%2C%20''')')%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_delete_sql%20%3D%20CONCAT(v_delete_sql%2C%20'%20LIMIT%2010000')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20deletion%20in%20batches%0A%20%20%20%20deletion_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_delete_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20p_processed%20%3D%20p_processed%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20deletion_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Prevent%20long-running%20transactions%0A%20%20%20%20%20%20%20%20DO%20SLEEP(0.1)%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Purging execution log
CREATE TABLE purge_execution_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    policy_id INT NOT NULL,
    execution_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    records_identified BIGINT,
    records_processed BIGINT,
    records_failed BIGINT,
    execution_status ENUM('SUCCESS', 'PARTIAL', 'FAILED'),
    execution_duration_seconds INT,
    error_message TEXT,
    
    FOREIGN KEY (policy_id) REFERENCES retention_policies(id),
    INDEX idx_execution_date (execution_date),
    INDEX idx_policy_status (policy_id, execution_status)
);

-- Main purging procedure
DELIMITER //
CREATE PROCEDURE execute_retention_policies()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_policy_id INT;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_retention_days INT;
    DECLARE v_retention_criteria JSON;
    DECLARE v_purge_method VARCHAR(20);
    DECLARE v_records_identified BIGINT DEFAULT 0;
    DECLARE v_records_processed BIGINT DEFAULT 0;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE policy_cursor CURSOR FOR
        SELECT id, table_name, retention_period_days, retention_criteria, purge_method
        FROM retention_policies
        WHERE approval_status = 'ACTIVE'
        AND effective_date &lt;= CURDATE();
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN policy_cursor;
    
    policy_loop: LOOP
        FETCH policy_cursor INTO v_policy_id, v_table_name, v_retention_days, 
                                v_retention_criteria, v_purge_method;
        
        IF done THEN
            LEAVE policy_loop;
        END IF;
        
        -- Execute purging based on method
        CASE v_purge_method
            WHEN 'DELETE' THEN
                CALL purge_by_deletion(v_policy_id, v_table_name, v_retention_days, 
                                     v_retention_criteria, v_records_identified, v_records_processed);
            
            WHEN 'ARCHIVE' THEN
                CALL purge_by_archiving(v_policy_id, v_table_name, v_retention_days,
                                      v_retention_criteria, v_records_identified, v_records_processed);
            
            WHEN 'ANONYMIZE' THEN
                CALL purge_by_anonymization(v_policy_id, v_table_name, v_retention_days,
                                          v_retention_criteria, v_records_identified, v_records_processed);
        END CASE;
        
        -- Log execution
        INSERT INTO purge_execution_log (
            policy_id, records_identified, records_processed,
            execution_status, execution_duration_seconds
        ) VALUES (
            v_policy_id, v_records_identified, v_records_processed,
            CASE WHEN v_records_processed = v_records_identified THEN 'SUCCESS' ELSE 'PARTIAL' END,
            TIMESTAMPDIFF(SECOND, v_start_time, NOW())
        );
        
    END LOOP;
    
    CLOSE policy_cursor;
END //

-- Deletion-based purging
CREATE PROCEDURE purge_by_deletion(
    IN p_policy_id INT,
    IN p_table_name VARCHAR(100),
    IN p_retention_days INT,
    IN p_criteria JSON,
    OUT p_identified BIGINT,
    OUT p_processed BIGINT
)
BEGIN
    DECLARE v_date_column VARCHAR(100);
    DECLARE v_status_filter VARCHAR(200);
    DECLARE v_cutoff_date DATE;
    DECLARE v_delete_sql TEXT;
    DECLARE v_count_sql TEXT;
    
    -- Extract criteria
    SET v_date_column = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.date_column'));
    SET v_status_filter = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.status_filter'));
    SET v_cutoff_date = DATE_SUB(CURDATE(), INTERVAL p_retention_days DAY);
    
    -- Count records to be deleted
    SET v_count_sql = CONCAT(
        'SELECT COUNT(*) FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    
    IF v_status_filter IS NOT NULL THEN
        SET v_count_sql = CONCAT(v_count_sql, ' AND status IN (''', 
                                REPLACE(v_status_filter, ',', ''','''), ''')');
    END IF;
    
    SET @sql = v_count_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Store result in p_identified
    DEALLOCATE PREPARE stmt;
    
    -- Delete records in batches
    SET v_delete_sql = CONCAT(
        'DELETE FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    
    IF v_status_filter IS NOT NULL THEN
        SET v_delete_sql = CONCAT(v_delete_sql, ' AND status IN (''',
                                 REPLACE(v_status_filter, ',', ''','''), ''')');
    END IF;
    
    SET v_delete_sql = CONCAT(v_delete_sql, ' LIMIT 10000');
    
    -- Execute deletion in batches
    deletion_loop: LOOP
        SET @sql = v_delete_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        SET p_processed = p_processed + ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        IF ROW_COUNT() = 0 THEN
            LEAVE deletion_loop;
        END IF;
        
        -- Prevent long-running transactions
        DO SLEEP(0.1);
    END LOOP;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Archival Strategy:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Archive%20table%20creation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_archive_table(IN%20p_source_table%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_archive_table%20VARCHAR(120)%3B%0A%20%20%20%20DECLARE%20v_create_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_archive_table%20%3D%20CONCAT(p_source_table%2C%20'_archive_'%2C%20YEAR(CURDATE()))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%20with%20same%20structure%0A%20%20%20%20SET%20v_create_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'CREATE%20TABLE%20IF%20NOT%20EXISTS%20'%2C%20v_archive_table%2C%20'%20AS%20'%2C%0A%20%20%20%20%20%20%20%20'SELECT%20*%20FROM%20'%2C%20p_source_table%2C%20'%20WHERE%201%3D0'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_create_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Add%20archive-specific%20columns%0A%20%20%20%20SET%20%40sql%20%3D%20CONCAT('ALTER%20TABLE%20'%2C%20v_archive_table%2C%20'%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ADD%20COLUMN%20IF%20NOT%20EXISTS%20archived_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ADD%20COLUMN%20IF%20NOT%20EXISTS%20archive_reason%20VARCHAR(200)')%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Archival%20procedure%0ACREATE%20PROCEDURE%20purge_by_archiving(%0A%20%20%20%20IN%20p_policy_id%20INT%2C%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_retention_days%20INT%2C%0A%20%20%20%20IN%20p_criteria%20JSON%2C%0A%20%20%20%20OUT%20p_identified%20BIGINT%2C%0A%20%20%20%20OUT%20p_processed%20BIGINT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_archive_table%20VARCHAR(120)%3B%0A%20%20%20%20DECLARE%20v_date_column%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_cutoff_date%20DATE%3B%0A%20%20%20%20DECLARE%20v_batch_size%20INT%20DEFAULT%2010000%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_archive_table%20%3D%20CONCAT(p_table_name%2C%20'_archive_'%2C%20YEAR(CURDATE()))%3B%0A%20%20%20%20SET%20v_date_column%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_criteria%2C%20'%24.date_column'))%3B%0A%20%20%20%20SET%20v_cutoff_date%20%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%20p_retention_days%20DAY)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20archive%20table%0A%20%20%20%20CALL%20create_archive_table(p_table_name)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Count%20records%20to%20archive%0A%20%20%20%20SET%20%40count_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20''''%0A%20%20%20%20)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40count_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20p_identified%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Archive%20in%20batches%0A%20%20%20%20archive_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20--%20Insert%20batch%20into%20archive%0A%20%20%20%20%20%20%20%20SET%20%40archive_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20v_archive_table%2C%20'%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SELECT%20*%2C%20NOW()%20as%20archived_at%2C%20''Retention%20policy''%20as%20archive_reason%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20'''%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40archive_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20p_processed%20%3D%20p_processed%20%2B%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20ROW_COUNT()%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20archive_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Delete%20archived%20records%20from%20source%0A%20%20%20%20%20%20%20%20SET%20%40delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'DELETE%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20'%2C%20v_date_column%2C%20'%20%3C%20'''%2C%20v_cutoff_date%2C%20'''%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'LIMIT%20'%2C%20v_batch_size%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40delete_sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20DO%20SLEEP(0.1)%3B%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Archive table creation
DELIMITER //
CREATE PROCEDURE create_archive_table(IN p_source_table VARCHAR(100))
BEGIN
    DECLARE v_archive_table VARCHAR(120);
    DECLARE v_create_sql TEXT;
    
    SET v_archive_table = CONCAT(p_source_table, '_archive_', YEAR(CURDATE()));
    
    -- Create archive table with same structure
    SET v_create_sql = CONCAT(
        'CREATE TABLE IF NOT EXISTS ', v_archive_table, ' AS ',
        'SELECT * FROM ', p_source_table, ' WHERE 1=0'
    );
    
    SET @sql = v_create_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Add archive-specific columns
    SET @sql = CONCAT('ALTER TABLE ', v_archive_table, ' 
                      ADD COLUMN IF NOT EXISTS archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                      ADD COLUMN IF NOT EXISTS archive_reason VARCHAR(200)');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //

-- Archival procedure
CREATE PROCEDURE purge_by_archiving(
    IN p_policy_id INT,
    IN p_table_name VARCHAR(100),
    IN p_retention_days INT,
    IN p_criteria JSON,
    OUT p_identified BIGINT,
    OUT p_processed BIGINT
)
BEGIN
    DECLARE v_archive_table VARCHAR(120);
    DECLARE v_date_column VARCHAR(100);
    DECLARE v_cutoff_date DATE;
    DECLARE v_batch_size INT DEFAULT 10000;
    
    SET v_archive_table = CONCAT(p_table_name, '_archive_', YEAR(CURDATE()));
    SET v_date_column = JSON_UNQUOTE(JSON_EXTRACT(p_criteria, '$.date_column'));
    SET v_cutoff_date = DATE_SUB(CURDATE(), INTERVAL p_retention_days DAY);
    
    -- Create archive table
    CALL create_archive_table(p_table_name);
    
    -- Count records to archive
    SET @count_sql = CONCAT(
        'SELECT COUNT(*) FROM ', p_table_name,
        ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''''
    );
    PREPARE stmt FROM @count_sql;
    EXECUTE stmt;
    -- Store in p_identified
    DEALLOCATE PREPARE stmt;
    
    -- Archive in batches
    archive_loop: LOOP
        -- Insert batch into archive
        SET @archive_sql = CONCAT(
            'INSERT INTO ', v_archive_table, ' ',
            'SELECT *, NOW() as archived_at, ''Retention policy'' as archive_reason ',
            'FROM ', p_table_name,
            ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''' ',
            'LIMIT ', v_batch_size
        );
        
        PREPARE stmt FROM @archive_sql;
        EXECUTE stmt;
        SET p_processed = p_processed + ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        IF ROW_COUNT() = 0 THEN
            LEAVE archive_loop;
        END IF;
        
        -- Delete archived records from source
        SET @delete_sql = CONCAT(
            'DELETE FROM ', p_table_name,
            ' WHERE ', v_date_column, ' &lt; ''', v_cutoff_date, ''' ',
            'LIMIT ', v_batch_size
        );
        
        PREPARE stmt FROM @delete_sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        DO SLEEP(0.1);
    END LOOP;
    
END //

DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-382-how-do-you-implement-data-masking-and-anonymization-">**382. How do you implement data masking and anonymization?**</h2>

<p><strong>Answer:</strong> Data masking and anonymization protect sensitive data by replacing, encrypting, or obfuscating original values while maintaining data utility for testing and analytics.</p>

<p><strong>Data Masking Framework:</strong></p>

<p><strong>1. Masking Rules Configuration:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20rules%20repository%0ACREATE%20TABLE%20masking_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20column_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20masking_type%20ENUM('SUBSTITUTION'%2C%20'SHUFFLING'%2C%20'ENCRYPTION'%2C%20'TOKENIZATION'%2C%20'NULLING'%2C%20'PARTIAL_MASKING')%2C%0A%20%20%20%20masking_function%20VARCHAR(200)%2C%0A%20%20%20%20masking_parameters%20JSON%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20preserve_format%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20preserve_length%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Conditional%20masking%0A%20%20%20%20masking_condition%20TEXT%2C%0A%20%20%20%20environment%20ENUM('DEV'%2C%20'TEST'%2C%20'STAGING'%2C%20'PROD')%20DEFAULT%20'DEV'%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_column_env%20(table_name%2C%20column_name%2C%20environment)%2C%0A%20%20%20%20INDEX%20idx_masking_type%20(masking_type)%0A)%3B%0A%0A--%20Insert%20masking%20rules%0AINSERT%20INTO%20masking_rules%20(%0A%20%20%20%20rule_name%2C%20table_name%2C%20column_name%2C%20masking_type%2C%20%0A%20%20%20%20masking_function%2C%20masking_parameters%2C%20environment%0A)%20VALUES%0A('Email%20Masking'%2C%20'customers'%2C%20'email'%2C%20'PARTIAL_MASKING'%2C%20%0A%20'mask_email'%2C%20'%7B%22preserve_domain%22%3A%20false%7D'%2C%20'DEV')%2C%0A%0A('Phone%20Number%20Masking'%2C%20'customers'%2C%20'phone'%2C%20'SUBSTITUTION'%2C%0A%20'generate_fake_phone'%2C%20'%7B%22country_code%22%3A%20%22US%22%7D'%2C%20'DEV')%2C%0A%0A('SSN%20Tokenization'%2C%20'customers'%2C%20'ssn'%2C%20'TOKENIZATION'%2C%0A%20'tokenize_ssn'%2C%20'%7B%22algorithm%22%3A%20%22AES256%22%7D'%2C%20'DEV')%2C%0A%0A('Credit%20Card%20Masking'%2C%20'payments'%2C%20'card_number'%2C%20'PARTIAL_MASKING'%2C%0A%20'mask_credit_card'%2C%20'%7B%22show_last%22%3A%204%7D'%2C%20'DEV')%2C%0A%0A('Name%20Shuffling'%2C%20'customers'%2C%20'name'%2C%20'SHUFFLING'%2C%0A%20'shuffle_names'%2C%20'%7B%22maintain_gender%22%3A%20true%7D'%2C%20'TEST')%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking rules repository
CREATE TABLE masking_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    column_name VARCHAR(100) NOT NULL,
    masking_type ENUM('SUBSTITUTION', 'SHUFFLING', 'ENCRYPTION', 'TOKENIZATION', 'NULLING', 'PARTIAL_MASKING'),
    masking_function VARCHAR(200),
    masking_parameters JSON,
    data_type VARCHAR(50),
    preserve_format BOOLEAN DEFAULT TRUE,
    preserve_length BOOLEAN DEFAULT TRUE,
    
    -- Conditional masking
    masking_condition TEXT,
    environment ENUM('DEV', 'TEST', 'STAGING', 'PROD') DEFAULT 'DEV',
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_column_env (table_name, column_name, environment),
    INDEX idx_masking_type (masking_type)
);

-- Insert masking rules
INSERT INTO masking_rules (
    rule_name, table_name, column_name, masking_type, 
    masking_function, masking_parameters, environment
) VALUES
('Email Masking', 'customers', 'email', 'PARTIAL_MASKING', 
 'mask_email', '{"preserve_domain": false}', 'DEV'),

('Phone Number Masking', 'customers', 'phone', 'SUBSTITUTION',
 'generate_fake_phone', '{"country_code": "US"}', 'DEV'),

('SSN Tokenization', 'customers', 'ssn', 'TOKENIZATION',
 'tokenize_ssn', '{"algorithm": "AES256"}', 'DEV'),

('Credit Card Masking', 'payments', 'card_number', 'PARTIAL_MASKING',
 'mask_credit_card', '{"show_last": 4}', 'DEV'),

('Name Shuffling', 'customers', 'name', 'SHUFFLING',
 'shuffle_names', '{"maintain_gender": true}', 'TEST');
</code></pre>
</div>

<p><strong>2. Masking Functions Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20utility%20functions%0ADELIMITER%20%2F%2F%0A%0A--%20Email%20masking%20function%0ACREATE%20FUNCTION%20mask_email(p_email%20VARCHAR(255)%2C%20p_preserve_domain%20BOOLEAN)%0ARETURNS%20VARCHAR(255)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_local_part%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_domain_part%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_masked_local%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_at_position%20INT%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_email%20IS%20NULL%20OR%20p_email%20%3D%20''%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20p_email%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_at_position%20%3D%20LOCATE('%40'%2C%20p_email)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_at_position%20%3D%200%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20'invalid%40email.com'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_local_part%20%3D%20LEFT(p_email%2C%20v_at_position%20-%201)%3B%0A%20%20%20%20SET%20v_domain_part%20%3D%20SUBSTRING(p_email%2C%20v_at_position%20%2B%201)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Mask%20local%20part%0A%20%20%20%20SET%20v_masked_local%20%3D%20CASE%0A%20%20%20%20%20%20%20%20WHEN%20LENGTH(v_local_part)%20%3C%3D%202%20THEN%20REPEAT('*'%2C%20LENGTH(v_local_part))%0A%20%20%20%20%20%20%20%20ELSE%20CONCAT(LEFT(v_local_part%2C%201)%2C%20REPEAT('*'%2C%20LENGTH(v_local_part)%20-%202)%2C%20RIGHT(v_local_part%2C%201))%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20domain%20masking%0A%20%20%20%20IF%20NOT%20p_preserve_domain%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_domain_part%20%3D%20'example.com'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20CONCAT(v_masked_local%2C%20'%40'%2C%20v_domain_part)%3B%0AEND%20%2F%2F%0A%0A--%20Credit%20card%20masking%20function%0ACREATE%20FUNCTION%20mask_credit_card(p_card_number%20VARCHAR(20)%2C%20p_show_last%20INT)%0ARETURNS%20VARCHAR(20)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_clean_number%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_masked%20VARCHAR(20)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_card_number%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Remove%20non-numeric%20characters%0A%20%20%20%20SET%20v_clean_number%20%3D%20REGEXP_REPLACE(p_card_number%2C%20'%5B%5E0-9%5D'%2C%20'')%3B%0A%20%20%20%20%0A%20%20%20%20IF%20LENGTH(v_clean_number)%20%3C%208%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20REPEAT('*'%2C%20LENGTH(v_clean_number))%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_masked%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20REPEAT('*'%2C%20LENGTH(v_clean_number)%20-%20p_show_last)%2C%0A%20%20%20%20%20%20%20%20RIGHT(v_clean_number%2C%20p_show_last)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Restore%20original%20formatting%0A%20%20%20%20IF%20p_card_number%20LIKE%20'%25-%25-%25-%25'%20THEN%0A%20%20%20%20%20%20%20%20SET%20v_masked%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%201%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%205%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%209%2C%204)%2C%20'-'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUBSTRING(v_masked%2C%2013)%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_masked%3B%0AEND%20%2F%2F%0A%0A--%20Name%20shuffling%20function%20(simplified%20version)%0ACREATE%20FUNCTION%20shuffle_name(p_name%20VARCHAR(255))%0ARETURNS%20VARCHAR(255)%0ADETERMINISTIC%0ABEGIN%0A%20%20%20%20DECLARE%20v_hash%20INT%3B%0A%20%20%20%20DECLARE%20v_fake_names%20JSON%20DEFAULT%20'%5B%22John%20Smith%22%2C%20%22Jane%20Doe%22%2C%20%22Mike%20Johnson%22%2C%20%22Sarah%20Wilson%22%2C%20%22David%20Brown%22%2C%20%22Lisa%20Davis%22%2C%20%22Robert%20Miller%22%2C%20%22Jennifer%20Garcia%22%5D'%3B%0A%20%20%20%20DECLARE%20v_name_count%20INT%3B%0A%20%20%20%20DECLARE%20v_selected_index%20INT%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_name%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_name_count%20%3D%20JSON_LENGTH(v_fake_names)%3B%0A%20%20%20%20SET%20v_hash%20%3D%20CRC32(p_name)%3B%0A%20%20%20%20SET%20v_selected_index%20%3D%20ABS(v_hash)%20%25%20v_name_count%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20JSON_UNQUOTE(JSON_EXTRACT(v_fake_names%2C%20CONCAT('%24%5B'%2C%20v_selected_index%2C%20'%5D')))%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking utility functions
DELIMITER //

-- Email masking function
CREATE FUNCTION mask_email(p_email VARCHAR(255), p_preserve_domain BOOLEAN)
RETURNS VARCHAR(255)
DETERMINISTIC
BEGIN
    DECLARE v_local_part VARCHAR(255);
    DECLARE v_domain_part VARCHAR(255);
    DECLARE v_masked_local VARCHAR(255);
    DECLARE v_at_position INT;
    
    IF p_email IS NULL OR p_email = '' THEN
        RETURN p_email;
    END IF;
    
    SET v_at_position = LOCATE('@', p_email);
    
    IF v_at_position = 0 THEN
        RETURN 'invalid@email.com';
    END IF;
    
    SET v_local_part = LEFT(p_email, v_at_position - 1);
    SET v_domain_part = SUBSTRING(p_email, v_at_position + 1);
    
    -- Mask local part
    SET v_masked_local = CASE
        WHEN LENGTH(v_local_part) &lt;= 2 THEN REPEAT('*', LENGTH(v_local_part))
        ELSE CONCAT(LEFT(v_local_part, 1), REPEAT('*', LENGTH(v_local_part) - 2), RIGHT(v_local_part, 1))
    END;
    
    -- Handle domain masking
    IF NOT p_preserve_domain THEN
        SET v_domain_part = 'example.com';
    END IF;
    
    RETURN CONCAT(v_masked_local, '@', v_domain_part);
END //

-- Credit card masking function
CREATE FUNCTION mask_credit_card(p_card_number VARCHAR(20), p_show_last INT)
RETURNS VARCHAR(20)
DETERMINISTIC
BEGIN
    DECLARE v_clean_number VARCHAR(20);
    DECLARE v_masked VARCHAR(20);
    
    IF p_card_number IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Remove non-numeric characters
    SET v_clean_number = REGEXP_REPLACE(p_card_number, '[^0-9]', '');
    
    IF LENGTH(v_clean_number) &lt; 8 THEN
        RETURN REPEAT('*', LENGTH(v_clean_number));
    END IF;
    
    SET v_masked = CONCAT(
        REPEAT('*', LENGTH(v_clean_number) - p_show_last),
        RIGHT(v_clean_number, p_show_last)
    );
    
    -- Restore original formatting
    IF p_card_number LIKE '%-%-%-%' THEN
        SET v_masked = CONCAT(
            SUBSTRING(v_masked, 1, 4), '-',
            SUBSTRING(v_masked, 5, 4), '-',
            SUBSTRING(v_masked, 9, 4), '-',
            SUBSTRING(v_masked, 13)
        );
    END IF;
    
    RETURN v_masked;
END //

-- Name shuffling function (simplified version)
CREATE FUNCTION shuffle_name(p_name VARCHAR(255))
RETURNS VARCHAR(255)
DETERMINISTIC
BEGIN
    DECLARE v_hash INT;
    DECLARE v_fake_names JSON DEFAULT '["John Smith", "Jane Doe", "Mike Johnson", "Sarah Wilson", "David Brown", "Lisa Davis", "Robert Miller", "Jennifer Garcia"]';
    DECLARE v_name_count INT;
    DECLARE v_selected_index INT;
    
    IF p_name IS NULL THEN
        RETURN NULL;
    END IF;
    
    SET v_name_count = JSON_LENGTH(v_fake_names);
    SET v_hash = CRC32(p_name);
    SET v_selected_index = ABS(v_hash) % v_name_count;
    
    RETURN JSON_UNQUOTE(JSON_EXTRACT(v_fake_names, CONCAT('$[', v_selected_index, ']')));
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Comprehensive Masking Execution:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Masking%20execution%20procedure%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_data_masking(IN%20p_environment%20VARCHAR(10))%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_table_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_column_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_masking_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_masking_function%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_masking_parameters%20JSON%3B%0A%20%20%20%20DECLARE%20v_masking_condition%20TEXT%3B%0A%20%20%20%20DECLARE%20v_update_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_records_masked%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20masking_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20table_name%2C%20column_name%2C%20masking_type%2C%20masking_function%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20masking_parameters%2C%20masking_condition%0A%20%20%20%20%20%20%20%20FROM%20masking_rules%0A%20%20%20%20%20%20%20%20WHERE%20environment%20%3D%20p_environment%0A%20%20%20%20%20%20%20%20ORDER%20BY%20table_name%2C%20column_name%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20masking%20execution%20log%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20masking_log%20(%0A%20%20%20%20%20%20%20%20table_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20column_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20masking_type%20VARCHAR(50)%2C%0A%20%20%20%20%20%20%20%20records_masked%20BIGINT%2C%0A%20%20%20%20%20%20%20%20execution_time%20DECIMAL(10%2C3)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20masking_cursor%3B%0A%20%20%20%20%0A%20%20%20%20masking_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20masking_cursor%20INTO%20v_table_name%2C%20v_column_name%2C%20v_masking_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_masking_function%2C%20v_masking_parameters%2C%20v_masking_condition%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20masking_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20SET%20%40start_time%20%3D%20NOW(3)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Build%20update%20SQL%20based%20on%20masking%20type%0A%20%20%20%20%20%20%20%20CASE%20v_masking_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'PARTIAL_MASKING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IF%20v_masking_function%20%3D%20'mask_email'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20mask_email('%2C%20v_column_name%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_masking_parameters%2C%20'%24.preserve_domain')%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ELSEIF%20v_masking_function%20%3D%20'mask_credit_card'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20mask_credit_card('%2C%20v_column_name%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_EXTRACT(v_masking_parameters%2C%20'%24.show_last')%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'SHUFFLING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20shuffle_name('%2C%20v_column_name%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'NULLING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20NULL'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'SUBSTITUTION'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20v_table_name%2C%20'%20SET%20'%2C%20v_column_name%2C%20'%20%3D%20''MASKED_DATA'''%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Add%20condition%20if%20specified%0A%20%20%20%20%20%20%20%20IF%20v_masking_condition%20IS%20NOT%20NULL%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(v_update_sql%2C%20'%20WHERE%20'%2C%20v_masking_condition)%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20masking%0A%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_update_sql%3B%0A%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20SET%20v_records_masked%20%3D%20ROW_COUNT()%3B%0A%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Log%20execution%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20masking_log%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_table_name%2C%20v_column_name%2C%20v_masking_type%2C%20v_records_masked%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(MICROSECOND%2C%20%40start_time%2C%20NOW(3))%20%2F%201000%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20masking_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20execution%20summary%0A%20%20%20%20SELECT%20*%20FROM%20masking_log%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20to%20permanent%20table%0A%20%20%20%20INSERT%20INTO%20masking_execution_log%20(%0A%20%20%20%20%20%20%20%20environment%2C%20execution_date%2C%20tables_processed%2C%20total_records_masked%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_environment%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20(SELECT%20COUNT(DISTINCT%20table_name)%20FROM%20masking_log)%2C%0A%20%20%20%20%20%20%20%20(SELECT%20SUM(records_masked)%20FROM%20masking_log)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20masking_log%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Masking execution procedure
DELIMITER //
CREATE PROCEDURE execute_data_masking(IN p_environment VARCHAR(10))
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_table_name VARCHAR(100);
    DECLARE v_column_name VARCHAR(100);
    DECLARE v_masking_type VARCHAR(50);
    DECLARE v_masking_function VARCHAR(200);
    DECLARE v_masking_parameters JSON;
    DECLARE v_masking_condition TEXT;
    DECLARE v_update_sql TEXT;
    DECLARE v_records_masked BIGINT DEFAULT 0;
    
    DECLARE masking_cursor CURSOR FOR
        SELECT table_name, column_name, masking_type, masking_function, 
               masking_parameters, masking_condition
        FROM masking_rules
        WHERE environment = p_environment
        ORDER BY table_name, column_name;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create masking execution log
    CREATE TEMPORARY TABLE masking_log (
        table_name VARCHAR(100),
        column_name VARCHAR(100),
        masking_type VARCHAR(50),
        records_masked BIGINT,
        execution_time DECIMAL(10,3)
    );
    
    OPEN masking_cursor;
    
    masking_loop: LOOP
        FETCH masking_cursor INTO v_table_name, v_column_name, v_masking_type,
                                 v_masking_function, v_masking_parameters, v_masking_condition;
        
        IF done THEN
            LEAVE masking_loop;
        END IF;
        
        SET @start_time = NOW(3);
        
        -- Build update SQL based on masking type
        CASE v_masking_type
            WHEN 'PARTIAL_MASKING' THEN
                IF v_masking_function = 'mask_email' THEN
                    SET v_update_sql = CONCAT(
                        'UPDATE ', v_table_name, ' SET ', v_column_name, ' = mask_email(', v_column_name, ', ',
                        JSON_EXTRACT(v_masking_parameters, '$.preserve_domain'), ')'
                    );
                ELSEIF v_masking_function = 'mask_credit_card' THEN
                    SET v_update_sql = CONCAT(
                        'UPDATE ', v_table_name, ' SET ', v_column_name, ' = mask_credit_card(', v_column_name, ', ',
                        JSON_EXTRACT(v_masking_parameters, '$.show_last'), ')'
                    );
                END IF;
            
            WHEN 'SHUFFLING' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = shuffle_name(', v_column_name, ')'
                );
            
            WHEN 'NULLING' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = NULL'
                );
            
            WHEN 'SUBSTITUTION' THEN
                SET v_update_sql = CONCAT(
                    'UPDATE ', v_table_name, ' SET ', v_column_name, ' = ''MASKED_DATA'''
                );
        END CASE;
        
        -- Add condition if specified
        IF v_masking_condition IS NOT NULL THEN
            SET v_update_sql = CONCAT(v_update_sql, ' WHERE ', v_masking_condition);
        END IF;
        
        -- Execute masking
        SET @sql = v_update_sql;
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        SET v_records_masked = ROW_COUNT();
        DEALLOCATE PREPARE stmt;
        
        -- Log execution
        INSERT INTO masking_log VALUES (
            v_table_name, v_column_name, v_masking_type, v_records_masked,
            TIMESTAMPDIFF(MICROSECOND, @start_time, NOW(3)) / 1000
        );
        
    END LOOP;
    
    CLOSE masking_cursor;
    
    -- Return execution summary
    SELECT * FROM masking_log;
    
    -- Log to permanent table
    INSERT INTO masking_execution_log (
        environment, execution_date, tables_processed, total_records_masked
    ) VALUES (
        p_environment, NOW(),
        (SELECT COUNT(DISTINCT table_name) FROM masking_log),
        (SELECT SUM(records_masked) FROM masking_log)
    );
    
    DROP TEMPORARY TABLE masking_log;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Tokenization and Encryption:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Tokenization%20system%0ACREATE%20TABLE%20tokenization_vault%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20token%20VARCHAR(255)%20UNIQUE%20NOT%20NULL%2C%0A%20%20%20%20encrypted_value%20VARBINARY(500)%20NOT%20NULL%2C%0A%20%20%20%20data_type%20VARCHAR(50)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20last_accessed%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_token%20(token)%2C%0A%20%20%20%20INDEX%20idx_created_at%20(created_at)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0A%0A--%20Tokenization%20function%0ACREATE%20FUNCTION%20tokenize_value(p_original_value%20VARCHAR(500)%2C%20p_data_type%20VARCHAR(50))%0ARETURNS%20VARCHAR(255)%0AMODIFIES%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20v_token%20VARCHAR(255)%3B%0A%20%20%20%20DECLARE%20v_encrypted_value%20VARBINARY(500)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_original_value%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20unique%20token%0A%20%20%20%20SET%20v_token%20%3D%20CONCAT('TKN_'%2C%20UPPER(SHA2(CONCAT(p_original_value%2C%20UNIX_TIMESTAMP()%2C%20RAND())%2C%20256)))%3B%0A%20%20%20%20SET%20v_token%20%3D%20LEFT(v_token%2C%2032)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Encrypt%20original%20value%20(simplified%20-%20use%20proper%20encryption%20in%20production)%0A%20%20%20%20SET%20v_encrypted_value%20%3D%20AES_ENCRYPT(p_original_value%2C%20'encryption_key_here')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Store%20in%20vault%0A%20%20%20%20INSERT%20INTO%20tokenization_vault%20(token%2C%20encrypted_value%2C%20data_type)%0A%20%20%20%20VALUES%20(v_token%2C%20v_encrypted_value%2C%20p_data_type)%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_token%3B%0AEND%20%2F%2F%0A%0A--%20Detokenization%20function%0ACREATE%20FUNCTION%20detokenize_value(p_token%20VARCHAR(255))%0ARETURNS%20VARCHAR(500)%0AREADS%20SQL%20DATA%0ABEGIN%0A%20%20%20%20DECLARE%20v_encrypted_value%20VARBINARY(500)%3B%0A%20%20%20%20DECLARE%20v_original_value%20VARCHAR(500)%3B%0A%20%20%20%20%0A%20%20%20%20IF%20p_token%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20NULL%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Retrieve%20from%20vault%0A%20%20%20%20SELECT%20encrypted_value%20INTO%20v_encrypted_value%0A%20%20%20%20FROM%20tokenization_vault%0A%20%20%20%20WHERE%20token%20%3D%20p_token%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_encrypted_value%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20RETURN%20'TOKEN_NOT_FOUND'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Decrypt%20value%0A%20%20%20%20SET%20v_original_value%20%3D%20AES_DECRYPT(v_encrypted_value%2C%20'encryption_key_here')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20access%20timestamp%0A%20%20%20%20UPDATE%20tokenization_vault%20%0A%20%20%20%20SET%20last_accessed%20%3D%20NOW()%0A%20%20%20%20WHERE%20token%20%3D%20p_token%3B%0A%20%20%20%20%0A%20%20%20%20RETURN%20v_original_value%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Tokenization system
CREATE TABLE tokenization_vault (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    token VARCHAR(255) UNIQUE NOT NULL,
    encrypted_value VARBINARY(500) NOT NULL,
    data_type VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_token (token),
    INDEX idx_created_at (created_at)
);

DELIMITER //

-- Tokenization function
CREATE FUNCTION tokenize_value(p_original_value VARCHAR(500), p_data_type VARCHAR(50))
RETURNS VARCHAR(255)
MODIFIES SQL DATA
BEGIN
    DECLARE v_token VARCHAR(255);
    DECLARE v_encrypted_value VARBINARY(500);
    
    IF p_original_value IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Generate unique token
    SET v_token = CONCAT('TKN_', UPPER(SHA2(CONCAT(p_original_value, UNIX_TIMESTAMP(), RAND()), 256)));
    SET v_token = LEFT(v_token, 32);
    
    -- Encrypt original value (simplified - use proper encryption in production)
    SET v_encrypted_value = AES_ENCRYPT(p_original_value, 'encryption_key_here');
    
    -- Store in vault
    INSERT INTO tokenization_vault (token, encrypted_value, data_type)
    VALUES (v_token, v_encrypted_value, p_data_type);
    
    RETURN v_token;
END //

-- Detokenization function
CREATE FUNCTION detokenize_value(p_token VARCHAR(255))
RETURNS VARCHAR(500)
READS SQL DATA
BEGIN
    DECLARE v_encrypted_value VARBINARY(500);
    DECLARE v_original_value VARCHAR(500);
    
    IF p_token IS NULL THEN
        RETURN NULL;
    END IF;
    
    -- Retrieve from vault
    SELECT encrypted_value INTO v_encrypted_value
    FROM tokenization_vault
    WHERE token = p_token;
    
    IF v_encrypted_value IS NULL THEN
        RETURN 'TOKEN_NOT_FOUND';
    END IF;
    
    -- Decrypt value
    SET v_original_value = AES_DECRYPT(v_encrypted_value, 'encryption_key_here');
    
    -- Update access timestamp
    UPDATE tokenization_vault 
    SET last_accessed = NOW()
    WHERE token = p_token;
    
    RETURN v_original_value;
END //

DELIMITER ;
</code></pre>
</div>

<p>---</p>

<h2 id="-383-what-are-data-lake-and-data-warehouse-differences-">**383. What are data lake and data warehouse differences?**</h2>

<p><strong>Answer:</strong> Data lakes store raw, unstructured data in native format for flexible analysis, while data warehouses contain structured, processed data optimized for specific business intelligence and reporting needs.</p>

<p><strong>Architecture Comparison:</strong></p>

<p><strong>1. Data Warehouse Structure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Traditional%20data%20warehouse%20schema%20(star%20schema)%0A--%20Fact%20table%20(central%20metrics)%0ACREATE%20TABLE%20sales_fact%20(%0A%20%20%20%20sale_id%20BIGINT%20PRIMARY%20KEY%2C%0A%20%20%20%20date_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20customer_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20store_key%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Measures%2FMetrics%0A%20%20%20%20quantity_sold%20INT%20NOT%20NULL%2C%0A%20%20%20%20unit_price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20total_amount%20DECIMAL(12%2C2)%20NOT%20NULL%2C%0A%20%20%20%20discount_amount%20DECIMAL(10%2C2)%20DEFAULT%200%2C%0A%20%20%20%20profit_margin%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Pre-calculated%20aggregations%0A%20%20%20%20monthly_total%20DECIMAL(12%2C2)%2C%0A%20%20%20%20quarterly_total%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Foreign%20keys%20to%20dimension%20tables%0A%20%20%20%20FOREIGN%20KEY%20(date_key)%20REFERENCES%20date_dimension(date_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(customer_key)%20REFERENCES%20customer_dimension(customer_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_key)%20REFERENCES%20product_dimension(product_key)%2C%0A%20%20%20%20FOREIGN%20KEY%20(store_key)%20REFERENCES%20store_dimension(store_key)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Optimized%20indexes%20for%20OLAP%20queries%0A%20%20%20%20INDEX%20idx_date_customer%20(date_key%2C%20customer_key)%2C%0A%20%20%20%20INDEX%20idx_product_store%20(product_key%2C%20store_key)%2C%0A%20%20%20%20INDEX%20idx_time_series%20(date_key%2C%20total_amount)%0A)%3B%0A%0A--%20Dimension%20table%20(descriptive%20attributes)%0ACREATE%20TABLE%20customer_dimension%20(%0A%20%20%20%20customer_key%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20VARCHAR(50)%20NOT%20NULL%2C%20--%20Business%20key%0A%20%20%20%20%0A%20%20%20%20--%20Current%20attributes%20(SCD%20Type%201)%0A%20%20%20%20customer_name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Historical%20attributes%20(SCD%20Type%202)%0A%20%20%20%20customer_segment%20VARCHAR(50)%2C%0A%20%20%20%20credit_rating%20VARCHAR(10)%2C%0A%20%20%20%20city%20VARCHAR(100)%2C%0A%20%20%20%20state%20VARCHAR(50)%2C%0A%20%20%20%20country%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SCD%20metadata%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20expiry_date%20DATE%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20is_current%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20version_number%20INT%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20--%20Hierarchy%20support%0A%20%20%20%20region%20VARCHAR(50)%2C%0A%20%20%20%20sales_territory%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_id%20(customer_id)%2C%0A%20%20%20%20INDEX%20idx_current%20(is_current)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%2C%0A%20%20%20%20INDEX%20idx_segment%20(customer_segment)%0A)%3B%0A%0A--%20Data%20mart%20for%20specific%20business%20area%0ACREATE%20TABLE%20marketing_datamart%20AS%0ASELECT%20%0A%20%20%20%20dd.year%2C%0A%20%20%20%20dd.quarter%2C%0A%20%20%20%20dd.month_name%2C%0A%20%20%20%20cd.customer_segment%2C%0A%20%20%20%20cd.region%2C%0A%20%20%20%20pd.product_category%2C%0A%20%20%20%20%0A%20%20%20%20--%20Pre-aggregated%20metrics%0A%20%20%20%20COUNT(DISTINCT%20sf.customer_key)%20as%20unique_customers%2C%0A%20%20%20%20SUM(sf.total_amount)%20as%20total_revenue%2C%0A%20%20%20%20AVG(sf.total_amount)%20as%20avg_order_value%2C%0A%20%20%20%20SUM(sf.quantity_sold)%20as%20total_units%2C%0A%20%20%20%20%0A%20%20%20%20--%20Calculated%20KPIs%0A%20%20%20%20SUM(sf.total_amount)%20%2F%20COUNT(DISTINCT%20sf.customer_key)%20as%20revenue_per_customer%2C%0A%20%20%20%20COUNT(sf.sale_id)%20%2F%20COUNT(DISTINCT%20sf.customer_key)%20as%20orders_per_customer%0A%20%20%20%20%0AFROM%20sales_fact%20sf%0AJOIN%20date_dimension%20dd%20ON%20sf.date_key%20%3D%20dd.date_key%0AJOIN%20customer_dimension%20cd%20ON%20sf.customer_key%20%3D%20cd.customer_key%0AJOIN%20product_dimension%20pd%20ON%20sf.product_key%20%3D%20pd.product_key%0AWHERE%20dd.year%20%3E%3D%20YEAR(CURDATE())%20-%202%0AGROUP%20BY%20dd.year%2C%20dd.quarter%2C%20dd.month_name%2C%20cd.customer_segment%2C%20%0A%20%20%20%20%20%20%20%20%20cd.region%2C%20pd.product_category%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Traditional data warehouse schema (star schema)
-- Fact table (central metrics)
CREATE TABLE sales_fact (
    sale_id BIGINT PRIMARY KEY,
    date_key INT NOT NULL,
    customer_key INT NOT NULL,
    product_key INT NOT NULL,
    store_key INT NOT NULL,
    
    -- Measures/Metrics
    quantity_sold INT NOT NULL,
    unit_price DECIMAL(10,2) NOT NULL,
    total_amount DECIMAL(12,2) NOT NULL,
    discount_amount DECIMAL(10,2) DEFAULT 0,
    profit_margin DECIMAL(10,2),
    
    -- Pre-calculated aggregations
    monthly_total DECIMAL(12,2),
    quarterly_total DECIMAL(12,2),
    
    -- Foreign keys to dimension tables
    FOREIGN KEY (date_key) REFERENCES date_dimension(date_key),
    FOREIGN KEY (customer_key) REFERENCES customer_dimension(customer_key),
    FOREIGN KEY (product_key) REFERENCES product_dimension(product_key),
    FOREIGN KEY (store_key) REFERENCES store_dimension(store_key),
    
    -- Optimized indexes for OLAP queries
    INDEX idx_date_customer (date_key, customer_key),
    INDEX idx_product_store (product_key, store_key),
    INDEX idx_time_series (date_key, total_amount)
);

-- Dimension table (descriptive attributes)
CREATE TABLE customer_dimension (
    customer_key INT AUTO_INCREMENT PRIMARY KEY,
    customer_id VARCHAR(50) NOT NULL, -- Business key
    
    -- Current attributes (SCD Type 1)
    customer_name VARCHAR(255) NOT NULL,
    email VARCHAR(255),
    phone VARCHAR(20),
    
    -- Historical attributes (SCD Type 2)
    customer_segment VARCHAR(50),
    credit_rating VARCHAR(10),
    city VARCHAR(100),
    state VARCHAR(50),
    country VARCHAR(50),
    
    -- SCD metadata
    effective_date DATE NOT NULL,
    expiry_date DATE DEFAULT '9999-12-31',
    is_current BOOLEAN DEFAULT TRUE,
    version_number INT DEFAULT 1,
    
    -- Hierarchy support
    region VARCHAR(50),
    sales_territory VARCHAR(50),
    
    INDEX idx_customer_id (customer_id),
    INDEX idx_current (is_current),
    INDEX idx_effective_date (effective_date),
    INDEX idx_segment (customer_segment)
);

-- Data mart for specific business area
CREATE TABLE marketing_datamart AS
SELECT 
    dd.year,
    dd.quarter,
    dd.month_name,
    cd.customer_segment,
    cd.region,
    pd.product_category,
    
    -- Pre-aggregated metrics
    COUNT(DISTINCT sf.customer_key) as unique_customers,
    SUM(sf.total_amount) as total_revenue,
    AVG(sf.total_amount) as avg_order_value,
    SUM(sf.quantity_sold) as total_units,
    
    -- Calculated KPIs
    SUM(sf.total_amount) / COUNT(DISTINCT sf.customer_key) as revenue_per_customer,
    COUNT(sf.sale_id) / COUNT(DISTINCT sf.customer_key) as orders_per_customer
    
FROM sales_fact sf
JOIN date_dimension dd ON sf.date_key = dd.date_key
JOIN customer_dimension cd ON sf.customer_key = cd.customer_key
JOIN product_dimension pd ON sf.product_key = pd.product_key
WHERE dd.year &gt;= YEAR(CURDATE()) - 2
GROUP BY dd.year, dd.quarter, dd.month_name, cd.customer_segment, 
         cd.region, pd.product_category;
</code></pre>
</div>

<p><strong>2. Data Lake Structure (Schema-on-Read):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Raw%20data%20landing%20tables%20(minimal%20structure)%0ACREATE%20TABLE%20raw_customer_data%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20raw_data%20JSON%20NOT%20NULL%2C%0A%20%20%20%20file_path%20VARCHAR(500)%2C%0A%20%20%20%20file_format%20ENUM('JSON'%2C%20'CSV'%2C%20'XML'%2C%20'PARQUET'%2C%20'AVRO')%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source_system%20(source_system)%2C%0A%20%20%20%20INDEX%20idx_ingestion_timestamp%20(ingestion_timestamp)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Schema%20registry%20for%20data%20lake%0ACREATE%20TABLE%20data_lake_schemas%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20schema_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20schema_version%20VARCHAR(20)%20NOT%20NULL%2C%0A%20%20%20%20data_source%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20schema_definition%20JSON%20NOT%20NULL%2C%0A%20%20%20%20schema_evolution%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_schema_version%20(schema_name%2C%20schema_version)%2C%0A%20%20%20%20INDEX%20idx_data_source%20(data_source)%0A)%3B%0A%0A--%20Data%20lake%20catalog%0ACREATE%20TABLE%20data_lake_catalog%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20dataset_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20dataset_path%20VARCHAR(1000)%20NOT%20NULL%2C%0A%20%20%20%20dataset_type%20ENUM('RAW'%2C%20'CLEANSED'%2C%20'CURATED'%2C%20'SANDBOX')%2C%0A%20%20%20%20data_format%20VARCHAR(50)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Schema%20information%0A%20%20%20%20schema_id%20INT%2C%0A%20%20%20%20inferred_schema%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Partitioning%20information%0A%20%20%20%20partition_columns%20JSON%2C%0A%20%20%20%20partition_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Statistics%0A%20%20%20%20record_count%20BIGINT%2C%0A%20%20%20%20file_count%20INT%2C%0A%20%20%20%20total_size_bytes%20BIGINT%2C%0A%20%20%20%20last_updated%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20data_owner%20VARCHAR(100)%2C%0A%20%20%20%20access_level%20ENUM('PUBLIC'%2C%20'RESTRICTED'%2C%20'CONFIDENTIAL')%2C%0A%20%20%20%20retention_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(schema_id)%20REFERENCES%20data_lake_schemas(id)%2C%0A%20%20%20%20INDEX%20idx_dataset_type%20(dataset_type)%2C%0A%20%20%20%20INDEX%20idx_data_owner%20(data_owner)%2C%0A%20%20%20%20INDEX%20idx_last_updated%20(last_updated)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Raw data landing tables (minimal structure)
CREATE TABLE raw_customer_data (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_system VARCHAR(100),
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    raw_data JSON NOT NULL,
    file_path VARCHAR(500),
    file_format ENUM('JSON', 'CSV', 'XML', 'PARQUET', 'AVRO'),
    data_quality_score DECIMAL(3,2),
    
    INDEX idx_source_system (source_system),
    INDEX idx_ingestion_timestamp (ingestion_timestamp),
    INDEX idx_data_quality (data_quality_score)
);

-- Schema registry for data lake
CREATE TABLE data_lake_schemas (
    id INT AUTO_INCREMENT PRIMARY KEY,
    schema_name VARCHAR(200) NOT NULL,
    schema_version VARCHAR(20) NOT NULL,
    data_source VARCHAR(100) NOT NULL,
    schema_definition JSON NOT NULL,
    schema_evolution JSON,
    
    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    is_active BOOLEAN DEFAULT TRUE,
    
    UNIQUE KEY uk_schema_version (schema_name, schema_version),
    INDEX idx_data_source (data_source)
);

-- Data lake catalog
CREATE TABLE data_lake_catalog (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    dataset_name VARCHAR(200) NOT NULL,
    dataset_path VARCHAR(1000) NOT NULL,
    dataset_type ENUM('RAW', 'CLEANSED', 'CURATED', 'SANDBOX'),
    data_format VARCHAR(50),
    
    -- Schema information
    schema_id INT,
    inferred_schema JSON,
    
    -- Partitioning information
    partition_columns JSON,
    partition_count INT,
    
    -- Statistics
    record_count BIGINT,
    file_count INT,
    total_size_bytes BIGINT,
    last_updated TIMESTAMP,
    
    -- Governance
    data_owner VARCHAR(100),
    access_level ENUM('PUBLIC', 'RESTRICTED', 'CONFIDENTIAL'),
    retention_days INT,
    
    FOREIGN KEY (schema_id) REFERENCES data_lake_schemas(id),
    INDEX idx_dataset_type (dataset_type),
    INDEX idx_data_owner (data_owner),
    INDEX idx_last_updated (last_updated)
);
</code></pre>
</div>

<p><strong>3. Hybrid Architecture (Data Lakehouse):</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Delta%20tables%20combining%20lake%20flexibility%20with%20warehouse%20performance%0ACREATE%20TABLE%20delta_customer_events%20(%0A%20%20%20%20event_id%20VARCHAR(100)%20PRIMARY%20KEY%2C%0A%20%20%20%20customer_id%20VARCHAR(50)%20NOT%20NULL%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Flexible%20schema%20using%20JSON%0A%20%20%20%20event_properties%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Structured%20columns%20for%20common%20queries%0A%20%20%20%20session_id%20VARCHAR(100)%2C%0A%20%20%20%20page_url%20VARCHAR(500)%2C%0A%20%20%20%20user_agent%20TEXT%2C%0A%20%20%20%20ip_address%20VARCHAR(45)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Partitioning%20columns%0A%20%20%20%20event_date%20DATE%20GENERATED%20ALWAYS%20AS%20(DATE(event_timestamp))%20STORED%2C%0A%20%20%20%20event_hour%20INT%20GENERATED%20ALWAYS%20AS%20(HOUR(event_timestamp))%20STORED%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%20metadata%0A%20%20%20%20data_version%20INT%20DEFAULT%201%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20source_file%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_customer_date%20(customer_id%2C%20event_date)%2C%0A%20%20%20%20INDEX%20idx_event_type_timestamp%20(event_type%2C%20event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_session%20(session_id)%0A)%20PARTITION%20BY%20RANGE%20(YEAR(event_date))%20(%0A%20%20%20%20PARTITION%20p2022%20VALUES%20LESS%20THAN%20(2023)%2C%0A%20%20%20%20PARTITION%20p2023%20VALUES%20LESS%20THAN%20(2024)%2C%0A%20%20%20%20PARTITION%20p2024%20VALUES%20LESS%20THAN%20(2025)%2C%0A%20%20%20%20PARTITION%20p_future%20VALUES%20LESS%20THAN%20MAXVALUE%0A)%3B%0A%0A--%20Materialized%20views%20for%20performance%20(warehouse-like)%0ACREATE%20VIEW%20customer_behavior_summary%20AS%0ASELECT%20%0A%20%20%20%20customer_id%2C%0A%20%20%20%20event_date%2C%0A%20%20%20%20COUNT(*)%20as%20total_events%2C%0A%20%20%20%20COUNT(DISTINCT%20session_id)%20as%20sessions%2C%0A%20%20%20%20COUNT(DISTINCT%20event_type)%20as%20unique_event_types%2C%0A%20%20%20%20%0A%20%20%20%20--%20JSON%20aggregations%0A%20%20%20%20JSON_ARRAYAGG(DISTINCT%20event_type)%20as%20event_types%2C%0A%20%20%20%20JSON_OBJECTAGG(event_type%2C%20COUNT(*))%20as%20event_counts%2C%0A%20%20%20%20%0A%20%20%20%20--%20Time-based%20metrics%0A%20%20%20%20MIN(event_timestamp)%20as%20first_event%2C%0A%20%20%20%20MAX(event_timestamp)%20as%20last_event%2C%0A%20%20%20%20TIMESTAMPDIFF(MINUTE%2C%20MIN(event_timestamp)%2C%20MAX(event_timestamp))%20as%20session_duration_minutes%0A%20%20%20%20%0AFROM%20delta_customer_events%0AWHERE%20event_date%20%3E%3D%20DATE_SUB(CURDATE()%2C%20INTERVAL%2030%20DAY)%0AGROUP%20BY%20customer_id%2C%20event_date%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Delta tables combining lake flexibility with warehouse performance
CREATE TABLE delta_customer_events (
    event_id VARCHAR(100) PRIMARY KEY,
    customer_id VARCHAR(50) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_timestamp TIMESTAMP NOT NULL,
    
    -- Flexible schema using JSON
    event_properties JSON,
    
    -- Structured columns for common queries
    session_id VARCHAR(100),
    page_url VARCHAR(500),
    user_agent TEXT,
    ip_address VARCHAR(45),
    
    -- Partitioning columns
    event_date DATE GENERATED ALWAYS AS (DATE(event_timestamp)) STORED,
    event_hour INT GENERATED ALWAYS AS (HOUR(event_timestamp)) STORED,
    
    -- Data quality metadata
    data_version INT DEFAULT 1,
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source_file VARCHAR(500),
    
    INDEX idx_customer_date (customer_id, event_date),
    INDEX idx_event_type_timestamp (event_type, event_timestamp),
    INDEX idx_session (session_id)
) PARTITION BY RANGE (YEAR(event_date)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- Materialized views for performance (warehouse-like)
CREATE VIEW customer_behavior_summary AS
SELECT 
    customer_id,
    event_date,
    COUNT(*) as total_events,
    COUNT(DISTINCT session_id) as sessions,
    COUNT(DISTINCT event_type) as unique_event_types,
    
    -- JSON aggregations
    JSON_ARRAYAGG(DISTINCT event_type) as event_types,
    JSON_OBJECTAGG(event_type, COUNT(*)) as event_counts,
    
    -- Time-based metrics
    MIN(event_timestamp) as first_event,
    MAX(event_timestamp) as last_event,
    TIMESTAMPDIFF(MINUTE, MIN(event_timestamp), MAX(event_timestamp)) as session_duration_minutes
    
FROM delta_customer_events
WHERE event_date &gt;= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
GROUP BY customer_id, event_date;
</code></pre>
</div>

<p><strong>4. Data Processing Patterns:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20for%20Data%20Warehouse%20(Transform%20then%20Load)%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20etl_process_sales_data()%0ABEGIN%0A%20%20%20%20DECLARE%20batch_date%20DATE%20DEFAULT%20CURDATE()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20and%20transform%20in%20staging%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20staging_sales%20AS%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20--%20Standardize%20and%20clean%20data%0A%20%20%20%20%20%20%20%20UPPER(TRIM(customer_name))%20as%20customer_name%2C%0A%20%20%20%20%20%20%20%20REGEXP_REPLACE(phone%2C%20'%5B%5E0-9%2B%5D'%2C%20'')%20as%20clean_phone%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Business%20rule%20transformations%0A%20%20%20%20%20%20%20%20CASE%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20total_amount%20%3E%2010000%20THEN%20'HIGH_VALUE'%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20total_amount%20%3E%201000%20THEN%20'MEDIUM_VALUE'%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%20'LOW_VALUE'%0A%20%20%20%20%20%20%20%20END%20as%20order_category%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Lookups%20and%20enrichment%0A%20%20%20%20%20%20%20%20(SELECT%20customer_key%20FROM%20customer_dimension%20%0A%20%20%20%20%20%20%20%20%20WHERE%20customer_id%20%3D%20raw_sales.customer_id%20AND%20is_current%20%3D%20TRUE)%20as%20customer_key%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Date%20dimension%20lookup%0A%20%20%20%20%20%20%20%20(SELECT%20date_key%20FROM%20date_dimension%20%0A%20%20%20%20%20%20%20%20%20WHERE%20full_date%20%3D%20DATE(raw_sales.order_timestamp))%20as%20date_key%2C%0A%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20*%0A%20%20%20%20FROM%20raw_sales_data%0A%20%20%20%20WHERE%20DATE(created_at)%20%3D%20batch_date%3B%0A%20%20%20%20%0A%20%20%20%20--%20Load%20into%20fact%20table%0A%20%20%20%20INSERT%20INTO%20sales_fact%20(%0A%20%20%20%20%20%20%20%20customer_key%2C%20date_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20quantity_sold%2C%20unit_price%2C%20total_amount%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20customer_key%2C%20date_key%2C%20product_key%2C%20store_key%2C%0A%20%20%20%20%20%20%20%20quantity%2C%20price%2C%20total%0A%20%20%20%20FROM%20staging_sales%0A%20%20%20%20WHERE%20customer_key%20IS%20NOT%20NULL%20AND%20date_key%20IS%20NOT%20NULL%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20staging_sales%3B%0AEND%20%2F%2F%0A%0A--%20ELT%20for%20Data%20Lake%20(Load%20then%20Transform)%0ACREATE%20PROCEDURE%20elt_process_raw_events()%0ABEGIN%0A%20%20%20%20--%20Load%20raw%20data%20first%0A%20%20%20%20INSERT%20INTO%20raw_customer_events%20(source_system%2C%20raw_data%2C%20file_format)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20'web_analytics'%2C%0A%20%20%20%20%20%20%20%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20%20%20%20%20'timestamp'%2C%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'user_id'%2C%20user_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'event'%2C%20event_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'properties'%2C%20properties%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'metadata'%2C%20metadata%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20'JSON'%0A%20%20%20%20FROM%20external_event_stream%3B%0A%20%20%20%20%0A%20%20%20%20--%20Transform%20on-demand%20using%20views%0A%20%20%20%20CREATE%20OR%20REPLACE%20VIEW%20processed_events%20AS%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20id%2C%0A%20%20%20%20%20%20%20%20source_system%2C%0A%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.user_id'))%20as%20user_id%2C%0A%20%20%20%20%20%20%20%20JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.event'))%20as%20event_type%2C%0A%20%20%20%20%20%20%20%20STR_TO_DATE(JSON_UNQUOTE(JSON_EXTRACT(raw_data%2C%20'%24.timestamp'))%2C%20'%25Y-%25m-%25d%20%25H%3A%25i%3A%25s')%20as%20event_timestamp%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(raw_data%2C%20'%24.properties')%20as%20event_properties%2C%0A%20%20%20%20%20%20%20%20ingestion_timestamp%0A%20%20%20%20FROM%20raw_customer_events%0A%20%20%20%20WHERE%20source_system%20%3D%20'web_analytics'%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL for Data Warehouse (Transform then Load)
DELIMITER //
CREATE PROCEDURE etl_process_sales_data()
BEGIN
    DECLARE batch_date DATE DEFAULT CURDATE();
    
    -- Extract and transform in staging
    CREATE TEMPORARY TABLE staging_sales AS
    SELECT 
        -- Standardize and clean data
        UPPER(TRIM(customer_name)) as customer_name,
        REGEXP_REPLACE(phone, '[^0-9+]', '') as clean_phone,
        
        -- Business rule transformations
        CASE 
            WHEN total_amount &gt; 10000 THEN 'HIGH_VALUE'
            WHEN total_amount &gt; 1000 THEN 'MEDIUM_VALUE'
            ELSE 'LOW_VALUE'
        END as order_category,
        
        -- Lookups and enrichment
        (SELECT customer_key FROM customer_dimension 
         WHERE customer_id = raw_sales.customer_id AND is_current = TRUE) as customer_key,
        
        -- Date dimension lookup
        (SELECT date_key FROM date_dimension 
         WHERE full_date = DATE(raw_sales.order_timestamp)) as date_key,
         
        *
    FROM raw_sales_data
    WHERE DATE(created_at) = batch_date;
    
    -- Load into fact table
    INSERT INTO sales_fact (
        customer_key, date_key, product_key, store_key,
        quantity_sold, unit_price, total_amount
    )
    SELECT 
        customer_key, date_key, product_key, store_key,
        quantity, price, total
    FROM staging_sales
    WHERE customer_key IS NOT NULL AND date_key IS NOT NULL;
    
    DROP TEMPORARY TABLE staging_sales;
END //

-- ELT for Data Lake (Load then Transform)
CREATE PROCEDURE elt_process_raw_events()
BEGIN
    -- Load raw data first
    INSERT INTO raw_customer_events (source_system, raw_data, file_format)
    SELECT 
        'web_analytics',
        JSON_OBJECT(
            'timestamp', event_timestamp,
            'user_id', user_id,
            'event', event_name,
            'properties', properties,
            'metadata', metadata
        ),
        'JSON'
    FROM external_event_stream;
    
    -- Transform on-demand using views
    CREATE OR REPLACE VIEW processed_events AS
    SELECT 
        id,
        source_system,
        JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.user_id')) as user_id,
        JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.event')) as event_type,
        STR_TO_DATE(JSON_UNQUOTE(JSON_EXTRACT(raw_data, '$.timestamp')), '%Y-%m-%d %H:%i:%s') as event_timestamp,
        JSON_EXTRACT(raw_data, '$.properties') as event_properties,
        ingestion_timestamp
    FROM raw_customer_events
    WHERE source_system = 'web_analytics';
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Key Differences Summary:</strong></p>

<p>- <strong>Data Warehouse</strong>: Structured, schema-on-write, optimized for known queries, expensive storage</p>
<p>- <strong>Data Lake</strong>: Flexible, schema-on-read, supports all data types, cost-effective storage</p>
<p>- <strong>Data Lakehouse</strong>: Combines benefits of both, ACID transactions on data lake storage</p>


<p>---</p>

<h2 id="-384-how-do-you-handle-real-time-data-processing-">**384. How do you handle real-time data processing?**</h2>

<p><strong>Answer:</strong> Real-time data processing involves capturing, processing, and analyzing data as it arrives, using streaming architectures, change data capture, and event-driven systems for immediate insights and actions.</p>

<p><strong>Real-Time Architecture Components:</strong></p>

<p><strong>1. Change Data Capture (CDC) Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20CDC%20configuration%20table%0ACREATE%20TABLE%20cdc_configuration%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20cdc_enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_inserts%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_updates%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20capture_deletes%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Streaming%20configuration%0A%20%20%20%20stream_destination%20VARCHAR(200)%2C%0A%20%20%20%20batch_size%20INT%20DEFAULT%201000%2C%0A%20%20%20%20flush_interval_seconds%20INT%20DEFAULT%205%2C%0A%20%20%20%20%0A%20%20%20%20--%20Filtering%0A%20%20%20%20column_filter%20JSON%2C%0A%20%20%20%20row_filter%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_name%20(table_name)%0A)%3B%0A%0A--%20CDC%20log%20table%0ACREATE%20TABLE%20cdc_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20operation_type%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20primary_key_value%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20data%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_columns%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20change_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20binlog_file%20VARCHAR(255)%2C%0A%20%20%20%20binlog_position%20BIGINT%2C%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processed%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20stream_offset%20BIGINT%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_operation%20(table_name%2C%20operation_type)%2C%0A%20%20%20%20INDEX%20idx_change_timestamp%20(change_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processed%20(processed)%2C%0A%20%20%20%20INDEX%20idx_primary_key%20(table_name%2C%20primary_key_value)%0A)%3B%0A%0A--%20CDC%20trigger%20implementation%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_cdc_triggers(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_trigger_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20INSERT%20trigger%0A%20%20%20%20SET%20v_trigger_sql%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_cdc_insert%0A%20%20%20%20%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20cdc_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20operation_type%2C%20primary_key_value%2C%20new_values%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20''INSERT''%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_trigger_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20UPDATE%20trigger%0A%20%20%20%20SET%20v_trigger_sql%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_cdc_update%0A%20%20%20%20%20%20%20%20AFTER%20UPDATE%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20cdc_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20operation_type%2C%20primary_key_value%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20old_values%2C%20new_values%2C%20changed_columns%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20''UPDATE''%2C%20NEW.id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20OLD.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%20FROM%20information_schema.columns%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20table_schema%20%3D%20DATABASE())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_ARRAY('%2C%20--%20This%20would%20contain%20logic%20to%20detect%20changed%20columns%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_trigger_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- CDC configuration table
CREATE TABLE cdc_configuration (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    cdc_enabled BOOLEAN DEFAULT TRUE,
    capture_inserts BOOLEAN DEFAULT TRUE,
    capture_updates BOOLEAN DEFAULT TRUE,
    capture_deletes BOOLEAN DEFAULT TRUE,
    
    -- Streaming configuration
    stream_destination VARCHAR(200),
    batch_size INT DEFAULT 1000,
    flush_interval_seconds INT DEFAULT 5,
    
    -- Filtering
    column_filter JSON,
    row_filter TEXT,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_name (table_name)
);

-- CDC log table
CREATE TABLE cdc_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    operation_type ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    primary_key_value VARCHAR(255) NOT NULL,
    
    -- Change data
    old_values JSON,
    new_values JSON,
    changed_columns JSON,
    
    -- Metadata
    change_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    binlog_file VARCHAR(255),
    binlog_position BIGINT,
    transaction_id VARCHAR(100),
    
    -- Processing status
    processed BOOLEAN DEFAULT FALSE,
    processed_at TIMESTAMP NULL,
    stream_offset BIGINT,
    
    INDEX idx_table_operation (table_name, operation_type),
    INDEX idx_change_timestamp (change_timestamp),
    INDEX idx_processed (processed),
    INDEX idx_primary_key (table_name, primary_key_value)
);

-- CDC trigger implementation
DELIMITER //
CREATE PROCEDURE create_cdc_triggers(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE v_trigger_sql TEXT;
    
    -- INSERT trigger
    SET v_trigger_sql = CONCAT('
        CREATE TRIGGER ', p_table_name, '_cdc_insert
        AFTER INSERT ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO cdc_log (
                table_name, operation_type, primary_key_value, new_values
            ) VALUES (
                ''', p_table_name, ''', ''INSERT'', NEW.id,
                JSON_OBJECT(', 
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', NEW.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                ')
            );
        END'
    );
    
    SET @sql = v_trigger_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- UPDATE trigger
    SET v_trigger_sql = CONCAT('
        CREATE TRIGGER ', p_table_name, '_cdc_update
        AFTER UPDATE ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO cdc_log (
                table_name, operation_type, primary_key_value, 
                old_values, new_values, changed_columns
            ) VALUES (
                ''', p_table_name, ''', ''UPDATE'', NEW.id,
                JSON_OBJECT(', 
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', OLD.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                '),
                JSON_OBJECT(',
                (SELECT GROUP_CONCAT(
                    CONCAT('''', column_name, ''', NEW.', column_name)
                    SEPARATOR ', '
                ) FROM information_schema.columns 
                WHERE table_name = p_table_name 
                AND table_schema = DATABASE()),
                '),
                JSON_ARRAY(', -- This would contain logic to detect changed columns
                ')
            );
        END'
    );
    
    SET @sql = v_trigger_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //
DELIMITER ;
</code></pre>
</div>

<p><strong>2. Event Streaming Infrastructure:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Event%20stream%20configuration%0ACREATE%20TABLE%20event_streams%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20stream_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20stream_type%20ENUM('CDC'%2C%20'APPLICATION'%2C%20'SENSOR'%2C%20'LOG')%20NOT%20NULL%2C%0A%20%20%20%20source_table%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stream%20properties%0A%20%20%20%20partition_key%20VARCHAR(100)%2C%0A%20%20%20%20retention_hours%20INT%20DEFAULT%20168%2C%20--%207%20days%0A%20%20%20%20compression_type%20ENUM('NONE'%2C%20'GZIP'%2C%20'SNAPPY')%20DEFAULT%20'SNAPPY'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20configuration%0A%20%20%20%20consumer_groups%20JSON%2C%0A%20%20%20%20processing_lag_threshold_seconds%20INT%20DEFAULT%2060%2C%0A%20%20%20%20%0A%20%20%20%20--%20Monitoring%0A%20%20%20%20events_per_second%20DECIMAL(10%2C2)%2C%0A%20%20%20%20last_event_timestamp%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_stream_name%20(stream_name)%2C%0A%20%20%20%20INDEX%20idx_stream_type%20(stream_type)%0A)%3B%0A%0A--%20Real-time%20event%20processing%0ACREATE%20TABLE%20real_time_events%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20stream_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20event_timestamp%20TIMESTAMP(6)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Event%20payload%0A%20%20%20%20event_data%20JSON%20NOT%20NULL%2C%0A%20%20%20%20event_schema_version%20VARCHAR(20)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20metadata%0A%20%20%20%20partition_key%20VARCHAR(255)%2C%0A%20%20%20%20offset_position%20BIGINT%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processing_status%20ENUM('PENDING'%2C%20'PROCESSING'%2C%20'COMPLETED'%2C%20'FAILED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_stream_timestamp%20(stream_name%2C%20event_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_partition_offset%20(partition_key%2C%20offset_position)%0A)%3B%0A%0A--%20Real-time%20aggregations%0ACREATE%20TABLE%20real_time_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20metric_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20time_window%20ENUM('1MIN'%2C%20'5MIN'%2C%20'15MIN'%2C%20'1HOUR')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metric%20values%0A%20%20%20%20metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_count%20BIGINT%2C%0A%20%20%20%20metric_sum%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_avg%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_min%20DECIMAL(15%2C4)%2C%0A%20%20%20%20metric_max%20DECIMAL(15%2C4)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Dimensions%0A%20%20%20%20dimensions%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20calculated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20data_points_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_metric_time_window%20(metric_name%2C%20metric_timestamp%2C%20time_window%2C%20dimensions(255))%2C%0A%20%20%20%20INDEX%20idx_metric_timestamp%20(metric_name%2C%20metric_timestamp)%2C%0A%20%20%20%20INDEX%20idx_time_window%20(time_window)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Event stream configuration
CREATE TABLE event_streams (
    id INT AUTO_INCREMENT PRIMARY KEY,
    stream_name VARCHAR(100) NOT NULL,
    stream_type ENUM('CDC', 'APPLICATION', 'SENSOR', 'LOG') NOT NULL,
    source_table VARCHAR(100),
    
    -- Stream properties
    partition_key VARCHAR(100),
    retention_hours INT DEFAULT 168, -- 7 days
    compression_type ENUM('NONE', 'GZIP', 'SNAPPY') DEFAULT 'SNAPPY',
    
    -- Processing configuration
    consumer_groups JSON,
    processing_lag_threshold_seconds INT DEFAULT 60,
    
    -- Monitoring
    events_per_second DECIMAL(10,2),
    last_event_timestamp TIMESTAMP,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_stream_name (stream_name),
    INDEX idx_stream_type (stream_type)
);

-- Real-time event processing
CREATE TABLE real_time_events (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    stream_name VARCHAR(100) NOT NULL,
    event_id VARCHAR(255) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_timestamp TIMESTAMP(6) NOT NULL,
    
    -- Event payload
    event_data JSON NOT NULL,
    event_schema_version VARCHAR(20),
    
    -- Processing metadata
    partition_key VARCHAR(255),
    offset_position BIGINT,
    ingestion_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    
    -- Processing status
    processing_status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING',
    processed_at TIMESTAMP NULL,
    error_message TEXT,
    retry_count INT DEFAULT 0,
    
    INDEX idx_stream_timestamp (stream_name, event_timestamp),
    INDEX idx_processing_status (processing_status),
    INDEX idx_event_type (event_type),
    INDEX idx_partition_offset (partition_key, offset_position)
);

-- Real-time aggregations
CREATE TABLE real_time_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_timestamp TIMESTAMP NOT NULL,
    time_window ENUM('1MIN', '5MIN', '15MIN', '1HOUR') NOT NULL,
    
    -- Metric values
    metric_value DECIMAL(15,4),
    metric_count BIGINT,
    metric_sum DECIMAL(15,4),
    metric_avg DECIMAL(15,4),
    metric_min DECIMAL(15,4),
    metric_max DECIMAL(15,4),
    
    -- Dimensions
    dimensions JSON,
    
    -- Metadata
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    data_points_count INT,
    
    UNIQUE KEY uk_metric_time_window (metric_name, metric_timestamp, time_window, dimensions(255)),
    INDEX idx_metric_timestamp (metric_name, metric_timestamp),
    INDEX idx_time_window (time_window)
);
</code></pre>
</div>

<p><strong>3. Stream Processing Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Stream%20processor%20for%20real-time%20analytics%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20process_real_time_events()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_event_id%20BIGINT%3B%0A%20%20%20%20DECLARE%20v_stream_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_event_type%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_event_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_event_timestamp%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20event_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20stream_name%2C%20event_type%2C%20event_data%2C%20event_timestamp%0A%20%20%20%20%20%20%20%20FROM%20real_time_events%0A%20%20%20%20%20%20%20%20WHERE%20processing_status%20%3D%20'PENDING'%0A%20%20%20%20%20%20%20%20ORDER%20BY%20event_timestamp%0A%20%20%20%20%20%20%20%20LIMIT%201000%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20event_cursor%3B%0A%20%20%20%20%0A%20%20%20%20processing_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20event_cursor%20INTO%20v_event_id%2C%20v_stream_name%2C%20v_event_type%2C%20v_event_data%2C%20v_event_timestamp%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20processing_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20processing%20status%0A%20%20%20%20%20%20%20%20UPDATE%20real_time_events%20%0A%20%20%20%20%20%20%20%20SET%20processing_status%20%3D%20'PROCESSING'%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_event_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Process%20based%20on%20event%20type%0A%20%20%20%20%20%20%20%20CASE%20v_event_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'user_action'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_user_action_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'transaction'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_transaction_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'system_metric'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_system_metric_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20ELSE%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20process_generic_event(v_event_id%2C%20v_event_data%2C%20v_event_timestamp)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Mark%20as%20completed%0A%20%20%20%20%20%20%20%20UPDATE%20real_time_events%20%0A%20%20%20%20%20%20%20%20SET%20processing_status%20%3D%20'COMPLETED'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20processed_at%20%3D%20NOW()%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20v_event_id%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20event_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Process%20user%20action%20events%0ACREATE%20PROCEDURE%20process_user_action_event(%0A%20%20%20%20IN%20p_event_id%20BIGINT%2C%0A%20%20%20%20IN%20p_event_data%20JSON%2C%0A%20%20%20%20IN%20p_event_timestamp%20TIMESTAMP%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_user_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_action_type%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_session_id%20VARCHAR(100)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20event%20data%0A%20%20%20%20SET%20v_user_id%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.user_id'))%3B%0A%20%20%20%20SET%20v_action_type%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.action'))%3B%0A%20%20%20%20SET%20v_session_id%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_event_data%2C%20'%24.session_id'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20real-time%20user%20session%0A%20%20%20%20INSERT%20INTO%20user_sessions%20(%0A%20%20%20%20%20%20%20%20user_id%2C%20session_id%2C%20last_activity%2C%20action_count%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_user_id%2C%20v_session_id%2C%20p_event_timestamp%2C%201%0A%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20last_activity%20%3D%20p_event_timestamp%2C%0A%20%20%20%20%20%20%20%20action_count%20%3D%20action_count%20%2B%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20real-time%20metrics%0A%20%20%20%20CALL%20update_real_time_metric('user_actions_per_minute'%2C%201%2C%20p_event_timestamp%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('action_type'%2C%20v_action_type))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Trigger%20alerts%20if%20needed%0A%20%20%20%20IF%20v_action_type%20%3D%20'purchase'%20THEN%0A%20%20%20%20%20%20%20%20CALL%20check_purchase_alerts(v_user_id%2C%20p_event_data)%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Update%20real-time%20metrics%20with%20windowing%0ACREATE%20PROCEDURE%20update_real_time_metric(%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_metric_value%20DECIMAL(15%2C4)%2C%0A%20%20%20%20IN%20p_timestamp%20TIMESTAMP%2C%0A%20%20%20%20IN%20p_dimensions%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_1min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_5min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_15min_window%20TIMESTAMP%3B%0A%20%20%20%20DECLARE%20v_1hour_window%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20--%20Calculate%20time%20windows%0A%20%20%20%20SET%20v_1min_window%20%3D%20DATE_FORMAT(p_timestamp%2C%20'%25Y-%25m-%25d%20%25H%3A%25i%3A00')%3B%0A%20%20%20%20SET%20v_5min_window%20%3D%20FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp)%20%2F%20300)%20*%20300)%3B%0A%20%20%20%20SET%20v_15min_window%20%3D%20FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp)%20%2F%20900)%20*%20900)%3B%0A%20%20%20%20SET%20v_1hour_window%20%3D%20DATE_FORMAT(p_timestamp%2C%20'%25Y-%25m-%25d%20%25H%3A00%3A00')%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%201-minute%20window%0A%20%20%20%20INSERT%20INTO%20real_time_metrics%20(%0A%20%20%20%20%20%20%20%20metric_name%2C%20metric_timestamp%2C%20time_window%2C%20metric_value%2C%20%0A%20%20%20%20%20%20%20%20metric_count%2C%20metric_sum%2C%20dimensions%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_metric_name%2C%20v_1min_window%2C%20'1MIN'%2C%20p_metric_value%2C%201%2C%20p_metric_value%2C%20p_dimensions%0A%20%20%20%20)%20ON%20DUPLICATE%20KEY%20UPDATE%0A%20%20%20%20%20%20%20%20metric_count%20%3D%20metric_count%20%2B%201%2C%0A%20%20%20%20%20%20%20%20metric_sum%20%3D%20metric_sum%20%2B%20p_metric_value%2C%0A%20%20%20%20%20%20%20%20metric_avg%20%3D%20metric_sum%20%2F%20metric_count%2C%0A%20%20%20%20%20%20%20%20metric_min%20%3D%20LEAST(metric_min%2C%20p_metric_value)%2C%0A%20%20%20%20%20%20%20%20metric_max%20%3D%20GREATEST(metric_max%2C%20p_metric_value)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20other%20windows%20similarly...%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Stream processor for real-time analytics
DELIMITER //
CREATE PROCEDURE process_real_time_events()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_event_id BIGINT;
    DECLARE v_stream_name VARCHAR(100);
    DECLARE v_event_type VARCHAR(100);
    DECLARE v_event_data JSON;
    DECLARE v_event_timestamp TIMESTAMP;
    
    DECLARE event_cursor CURSOR FOR
        SELECT id, stream_name, event_type, event_data, event_timestamp
        FROM real_time_events
        WHERE processing_status = 'PENDING'
        ORDER BY event_timestamp
        LIMIT 1000;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN event_cursor;
    
    processing_loop: LOOP
        FETCH event_cursor INTO v_event_id, v_stream_name, v_event_type, v_event_data, v_event_timestamp;
        
        IF done THEN
            LEAVE processing_loop;
        END IF;
        
        -- Update processing status
        UPDATE real_time_events 
        SET processing_status = 'PROCESSING'
        WHERE id = v_event_id;
        
        -- Process based on event type
        CASE v_event_type
            WHEN 'user_action' THEN
                CALL process_user_action_event(v_event_id, v_event_data, v_event_timestamp);
            
            WHEN 'transaction' THEN
                CALL process_transaction_event(v_event_id, v_event_data, v_event_timestamp);
            
            WHEN 'system_metric' THEN
                CALL process_system_metric_event(v_event_id, v_event_data, v_event_timestamp);
            
            ELSE
                CALL process_generic_event(v_event_id, v_event_data, v_event_timestamp);
        END CASE;
        
        -- Mark as completed
        UPDATE real_time_events 
        SET processing_status = 'COMPLETED',
            processed_at = NOW()
        WHERE id = v_event_id;
        
    END LOOP;
    
    CLOSE event_cursor;
END //

-- Process user action events
CREATE PROCEDURE process_user_action_event(
    IN p_event_id BIGINT,
    IN p_event_data JSON,
    IN p_event_timestamp TIMESTAMP
)
BEGIN
    DECLARE v_user_id VARCHAR(100);
    DECLARE v_action_type VARCHAR(100);
    DECLARE v_session_id VARCHAR(100);
    
    -- Extract event data
    SET v_user_id = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.user_id'));
    SET v_action_type = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.action'));
    SET v_session_id = JSON_UNQUOTE(JSON_EXTRACT(p_event_data, '$.session_id'));
    
    -- Update real-time user session
    INSERT INTO user_sessions (
        user_id, session_id, last_activity, action_count
    ) VALUES (
        v_user_id, v_session_id, p_event_timestamp, 1
    ) ON DUPLICATE KEY UPDATE
        last_activity = p_event_timestamp,
        action_count = action_count + 1;
    
    -- Update real-time metrics
    CALL update_real_time_metric('user_actions_per_minute', 1, p_event_timestamp, 
                                JSON_OBJECT('action_type', v_action_type));
    
    -- Trigger alerts if needed
    IF v_action_type = 'purchase' THEN
        CALL check_purchase_alerts(v_user_id, p_event_data);
    END IF;
    
END //

-- Update real-time metrics with windowing
CREATE PROCEDURE update_real_time_metric(
    IN p_metric_name VARCHAR(100),
    IN p_metric_value DECIMAL(15,4),
    IN p_timestamp TIMESTAMP,
    IN p_dimensions JSON
)
BEGIN
    DECLARE v_1min_window TIMESTAMP;
    DECLARE v_5min_window TIMESTAMP;
    DECLARE v_15min_window TIMESTAMP;
    DECLARE v_1hour_window TIMESTAMP;
    
    -- Calculate time windows
    SET v_1min_window = DATE_FORMAT(p_timestamp, '%Y-%m-%d %H:%i:00');
    SET v_5min_window = FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp) / 300) * 300);
    SET v_15min_window = FROM_UNIXTIME(FLOOR(UNIX_TIMESTAMP(p_timestamp) / 900) * 900);
    SET v_1hour_window = DATE_FORMAT(p_timestamp, '%Y-%m-%d %H:00:00');
    
    -- Update 1-minute window
    INSERT INTO real_time_metrics (
        metric_name, metric_timestamp, time_window, metric_value, 
        metric_count, metric_sum, dimensions
    ) VALUES (
        p_metric_name, v_1min_window, '1MIN', p_metric_value, 1, p_metric_value, p_dimensions
    ) ON DUPLICATE KEY UPDATE
        metric_count = metric_count + 1,
        metric_sum = metric_sum + p_metric_value,
        metric_avg = metric_sum / metric_count,
        metric_min = LEAST(metric_min, p_metric_value),
        metric_max = GREATEST(metric_max, p_metric_value);
    
    -- Update other windows similarly...
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Real-Time Alerting System:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Real-time%20alert%20rules%0ACREATE%20TABLE%20alert_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20metric_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20condition_type%20ENUM('THRESHOLD'%2C%20'ANOMALY'%2C%20'TREND'%2C%20'PATTERN')%20NOT%20NULL%2C%0A%20%20%20%20condition_config%20JSON%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Alert%20configuration%0A%20%20%20%20severity%20ENUM('INFO'%2C%20'WARNING'%2C%20'CRITICAL')%20DEFAULT%20'WARNING'%2C%0A%20%20%20%20notification_channels%20JSON%2C%0A%20%20%20%20cooldown_minutes%20INT%20DEFAULT%2015%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20last_triggered%20TIMESTAMP%20NULL%2C%0A%20%20%20%20trigger_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_metric_name%20(metric_name)%2C%0A%20%20%20%20INDEX%20idx_is_active%20(is_active)%0A)%3B%0A%0A--%20Real-time%20alert%20processing%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20check_real_time_alerts()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_id%20INT%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_metric_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_condition_type%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_condition_config%20JSON%3B%0A%20%20%20%20DECLARE%20v_severity%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_cooldown_minutes%20INT%3B%0A%20%20%20%20DECLARE%20v_last_triggered%20TIMESTAMP%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20alert_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20rule_name%2C%20metric_name%2C%20condition_type%2C%20condition_config%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20severity%2C%20cooldown_minutes%2C%20last_triggered%0A%20%20%20%20%20%20%20%20FROM%20alert_rules%0A%20%20%20%20%20%20%20%20WHERE%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20alert_cursor%3B%0A%20%20%20%20%0A%20%20%20%20alert_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20alert_cursor%20INTO%20v_rule_id%2C%20v_rule_name%2C%20v_metric_name%2C%20v_condition_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_condition_config%2C%20v_severity%2C%20v_cooldown_minutes%2C%20v_last_triggered%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20alert_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Check%20cooldown%20period%0A%20%20%20%20%20%20%20%20IF%20v_last_triggered%20IS%20NOT%20NULL%20AND%20%0A%20%20%20%20%20%20%20%20%20%20%20TIMESTAMPDIFF(MINUTE%2C%20v_last_triggered%2C%20NOW())%20%3C%20v_cooldown_minutes%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20ITERATE%20alert_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Evaluate%20alert%20condition%0A%20%20%20%20%20%20%20%20CASE%20v_condition_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'THRESHOLD'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_threshold_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ANOMALY'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_anomaly_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'TREND'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20check_trend_alert(v_rule_id%2C%20v_metric_name%2C%20v_condition_config%2C%20v_severity)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20alert_cursor%3B%0AEND%20%2F%2F%0A%0A--%20Threshold-based%20alerting%0ACREATE%20PROCEDURE%20check_threshold_alert(%0A%20%20%20%20IN%20p_rule_id%20INT%2C%0A%20%20%20%20IN%20p_metric_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_condition_config%20JSON%2C%0A%20%20%20%20IN%20p_severity%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_threshold%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20v_operator%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_time_window%20VARCHAR(10)%3B%0A%20%20%20%20DECLARE%20v_current_value%20DECIMAL(15%2C4)%3B%0A%20%20%20%20DECLARE%20v_alert_triggered%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Extract%20configuration%0A%20%20%20%20SET%20v_threshold%20%3D%20JSON_EXTRACT(p_condition_config%2C%20'%24.threshold')%3B%0A%20%20%20%20SET%20v_operator%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_condition_config%2C%20'%24.operator'))%3B%0A%20%20%20%20SET%20v_time_window%20%3D%20JSON_UNQUOTE(JSON_EXTRACT(p_condition_config%2C%20'%24.time_window'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20metric%20value%0A%20%20%20%20SELECT%20metric_avg%20INTO%20v_current_value%0A%20%20%20%20FROM%20real_time_metrics%0A%20%20%20%20WHERE%20metric_name%20%3D%20p_metric_name%0A%20%20%20%20AND%20time_window%20%3D%20v_time_window%0A%20%20%20%20AND%20metric_timestamp%20%3E%3D%20DATE_SUB(NOW()%2C%20INTERVAL%205%20MINUTE)%0A%20%20%20%20ORDER%20BY%20metric_timestamp%20DESC%0A%20%20%20%20LIMIT%201%3B%0A%20%20%20%20%0A%20%20%20%20--%20Evaluate%20condition%0A%20%20%20%20CASE%20v_operator%0A%20%20%20%20%20%20%20%20WHEN%20'%3E'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3E%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3C'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3C%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3E%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3E%3D%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3C%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3C%3D%20v_threshold)%3B%0A%20%20%20%20%20%20%20%20WHEN%20'%3D'%20THEN%20SET%20v_alert_triggered%20%3D%20(v_current_value%20%3D%20v_threshold)%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Trigger%20alert%20if%20condition%20met%0A%20%20%20%20IF%20v_alert_triggered%20THEN%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20alert_instances%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20rule_id%2C%20metric_name%2C%20alert_value%2C%20threshold_value%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20severity%2C%20triggered_at%2C%20status%0A%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20p_rule_id%2C%20p_metric_name%2C%20v_current_value%2C%20v_threshold%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_severity%2C%20NOW()%2C%20'ACTIVE'%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Update%20rule%20trigger%20info%0A%20%20%20%20%20%20%20%20UPDATE%20alert_rules%0A%20%20%20%20%20%20%20%20SET%20last_triggered%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20trigger_count%20%3D%20trigger_count%20%2B%201%0A%20%20%20%20%20%20%20%20WHERE%20id%20%3D%20p_rule_id%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Real-time alert rules
CREATE TABLE alert_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_name VARCHAR(200) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    condition_type ENUM('THRESHOLD', 'ANOMALY', 'TREND', 'PATTERN') NOT NULL,
    condition_config JSON NOT NULL,
    
    -- Alert configuration
    severity ENUM('INFO', 'WARNING', 'CRITICAL') DEFAULT 'WARNING',
    notification_channels JSON,
    cooldown_minutes INT DEFAULT 15,
    
    -- Status
    is_active BOOLEAN DEFAULT TRUE,
    last_triggered TIMESTAMP NULL,
    trigger_count INT DEFAULT 0,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_metric_name (metric_name),
    INDEX idx_is_active (is_active)
);

-- Real-time alert processing
DELIMITER //
CREATE PROCEDURE check_real_time_alerts()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_id INT;
    DECLARE v_rule_name VARCHAR(200);
    DECLARE v_metric_name VARCHAR(100);
    DECLARE v_condition_type VARCHAR(20);
    DECLARE v_condition_config JSON;
    DECLARE v_severity VARCHAR(20);
    DECLARE v_cooldown_minutes INT;
    DECLARE v_last_triggered TIMESTAMP;
    
    DECLARE alert_cursor CURSOR FOR
        SELECT id, rule_name, metric_name, condition_type, condition_config,
               severity, cooldown_minutes, last_triggered
        FROM alert_rules
        WHERE is_active = TRUE;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN alert_cursor;
    
    alert_loop: LOOP
        FETCH alert_cursor INTO v_rule_id, v_rule_name, v_metric_name, v_condition_type,
                               v_condition_config, v_severity, v_cooldown_minutes, v_last_triggered;
        
        IF done THEN
            LEAVE alert_loop;
        END IF;
        
        -- Check cooldown period
        IF v_last_triggered IS NOT NULL AND 
           TIMESTAMPDIFF(MINUTE, v_last_triggered, NOW()) &lt; v_cooldown_minutes THEN
            ITERATE alert_loop;
        END IF;
        
        -- Evaluate alert condition
        CASE v_condition_type
            WHEN 'THRESHOLD' THEN
                CALL check_threshold_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
            
            WHEN 'ANOMALY' THEN
                CALL check_anomaly_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
            
            WHEN 'TREND' THEN
                CALL check_trend_alert(v_rule_id, v_metric_name, v_condition_config, v_severity);
        END CASE;
        
    END LOOP;
    
    CLOSE alert_cursor;
END //

-- Threshold-based alerting
CREATE PROCEDURE check_threshold_alert(
    IN p_rule_id INT,
    IN p_metric_name VARCHAR(100),
    IN p_condition_config JSON,
    IN p_severity VARCHAR(20)
)
BEGIN
    DECLARE v_threshold DECIMAL(15,4);
    DECLARE v_operator VARCHAR(10);
    DECLARE v_time_window VARCHAR(10);
    DECLARE v_current_value DECIMAL(15,4);
    DECLARE v_alert_triggered BOOLEAN DEFAULT FALSE;
    
    -- Extract configuration
    SET v_threshold = JSON_EXTRACT(p_condition_config, '$.threshold');
    SET v_operator = JSON_UNQUOTE(JSON_EXTRACT(p_condition_config, '$.operator'));
    SET v_time_window = JSON_UNQUOTE(JSON_EXTRACT(p_condition_config, '$.time_window'));
    
    -- Get current metric value
    SELECT metric_avg INTO v_current_value
    FROM real_time_metrics
    WHERE metric_name = p_metric_name
    AND time_window = v_time_window
    AND metric_timestamp &gt;= DATE_SUB(NOW(), INTERVAL 5 MINUTE)
    ORDER BY metric_timestamp DESC
    LIMIT 1;
    
    -- Evaluate condition
    CASE v_operator
        WHEN '&gt;' THEN SET v_alert_triggered = (v_current_value &gt; v_threshold);
        WHEN '&lt;' THEN SET v_alert_triggered = (v_current_value &lt; v_threshold);
        WHEN '&gt;=' THEN SET v_alert_triggered = (v_current_value &gt;= v_threshold);
        WHEN '&lt;=' THEN SET v_alert_triggered = (v_current_value &lt;= v_threshold);
        WHEN '=' THEN SET v_alert_triggered = (v_current_value = v_threshold);
    END CASE;
    
    -- Trigger alert if condition met
    IF v_alert_triggered THEN
        INSERT INTO alert_instances (
            rule_id, metric_name, alert_value, threshold_value,
            severity, triggered_at, status
        ) VALUES (
            p_rule_id, p_metric_name, v_current_value, v_threshold,
            p_severity, NOW(), 'ACTIVE'
        );
        
        -- Update rule trigger info
        UPDATE alert_rules
        SET last_triggered = NOW(),
            trigger_count = trigger_count + 1
        WHERE id = p_rule_id;
    END IF;
    
END //

DELIMITER ;
</code></pre>
</div>

<p>This completes the real-time data processing implementation with CDC, streaming, and alerting capabilities.</p>

<p>---</p>

<h2 id="-385-what-are-data-integration-patterns-and-etl-vs-elt-">**385. What are data integration patterns and ETL vs ELT?**</h2>

<p><strong>Answer:</strong> Data integration patterns define how data flows between systems, with ETL (Extract-Transform-Load) processing data before storage and ELT (Extract-Load-Transform) storing raw data first then transforming as needed.</p>

<p><strong>ETL Pattern Implementation:</strong></p>

<p><strong>1. Traditional ETL Pipeline:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ETL%20staging%20and%20control%20tables%0ACREATE%20TABLE%20etl_job_control%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20job_type%20ENUM('EXTRACT'%2C%20'TRANSFORM'%2C%20'LOAD'%2C%20'FULL_ETL')%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20target_system%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Execution%20control%0A%20%20%20%20schedule_expression%20VARCHAR(100)%2C%20--%20Cron%20expression%0A%20%20%20%20max_runtime_minutes%20INT%20DEFAULT%2060%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%203%2C%0A%20%20%20%20dependency_jobs%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%20tracking%0A%20%20%20%20last_run_start%20TIMESTAMP%20NULL%2C%0A%20%20%20%20last_run_end%20TIMESTAMP%20NULL%2C%0A%20%20%20%20last_run_status%20ENUM('SUCCESS'%2C%20'FAILED'%2C%20'RUNNING'%2C%20'CANCELLED')%2C%0A%20%20%20%20last_run_records_processed%20BIGINT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Configuration%0A%20%20%20%20job_parameters%20JSON%2C%0A%20%20%20%20notification_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_job_name%20(job_name)%2C%0A%20%20%20%20INDEX%20idx_job_type%20(job_type)%2C%0A%20%20%20%20INDEX%20idx_last_run_status%20(last_run_status)%0A)%3B%0A%0A--%20ETL%20execution%20log%0ACREATE%20TABLE%20etl_execution_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20execution_id%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Execution%20details%0A%20%20%20%20started_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20completed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20status%20ENUM('RUNNING'%2C%20'SUCCESS'%2C%20'FAILED'%2C%20'CANCELLED')%20DEFAULT%20'RUNNING'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metrics%0A%20%20%20%20records_extracted%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_transformed%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_loaded%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20records_rejected%20BIGINT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Error%20handling%0A%20%20%20%20error_message%20TEXT%2C%0A%20%20%20%20error_details%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Performance%0A%20%20%20%20extraction_duration_seconds%20INT%2C%0A%20%20%20%20transformation_duration_seconds%20INT%2C%0A%20%20%20%20loading_duration_seconds%20INT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(job_id)%20REFERENCES%20etl_job_control(id)%2C%0A%20%20%20%20INDEX%20idx_execution_id%20(execution_id)%2C%0A%20%20%20%20INDEX%20idx_started_at%20(started_at)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A%0A--%20ETL%20transformation%20rules%0ACREATE%20TABLE%20etl_transformation_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20job_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20rule_order%20INT%20NOT%20NULL%2C%0A%20%20%20%20rule_type%20ENUM('VALIDATION'%2C%20'CLEANSING'%2C%20'ENRICHMENT'%2C%20'AGGREGATION'%2C%20'BUSINESS_RULE')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rule%20definition%0A%20%20%20%20source_columns%20JSON%2C%0A%20%20%20%20target_columns%20JSON%2C%0A%20%20%20%20transformation_logic%20TEXT%2C%0A%20%20%20%20validation_criteria%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Error%20handling%0A%20%20%20%20on_error_action%20ENUM('REJECT'%2C%20'DEFAULT'%2C%20'SKIP'%2C%20'FAIL_JOB')%20DEFAULT%20'REJECT'%2C%0A%20%20%20%20default_value%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(job_id)%20REFERENCES%20etl_job_control(id)%2C%0A%20%20%20%20INDEX%20idx_job_order%20(job_id%2C%20rule_order)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ETL staging and control tables
CREATE TABLE etl_job_control (
    id INT AUTO_INCREMENT PRIMARY KEY,
    job_name VARCHAR(100) NOT NULL,
    job_type ENUM('EXTRACT', 'TRANSFORM', 'LOAD', 'FULL_ETL') NOT NULL,
    source_system VARCHAR(100),
    target_system VARCHAR(100),
    
    -- Execution control
    schedule_expression VARCHAR(100), -- Cron expression
    max_runtime_minutes INT DEFAULT 60,
    retry_count INT DEFAULT 3,
    dependency_jobs JSON,
    
    -- Status tracking
    last_run_start TIMESTAMP NULL,
    last_run_end TIMESTAMP NULL,
    last_run_status ENUM('SUCCESS', 'FAILED', 'RUNNING', 'CANCELLED'),
    last_run_records_processed BIGINT,
    
    -- Configuration
    job_parameters JSON,
    notification_config JSON,
    
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_job_name (job_name),
    INDEX idx_job_type (job_type),
    INDEX idx_last_run_status (last_run_status)
);

-- ETL execution log
CREATE TABLE etl_execution_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    job_id INT NOT NULL,
    execution_id VARCHAR(100) NOT NULL,
    
    -- Execution details
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP NULL,
    status ENUM('RUNNING', 'SUCCESS', 'FAILED', 'CANCELLED') DEFAULT 'RUNNING',
    
    -- Metrics
    records_extracted BIGINT DEFAULT 0,
    records_transformed BIGINT DEFAULT 0,
    records_loaded BIGINT DEFAULT 0,
    records_rejected BIGINT DEFAULT 0,
    
    -- Error handling
    error_message TEXT,
    error_details JSON,
    
    -- Performance
    extraction_duration_seconds INT,
    transformation_duration_seconds INT,
    loading_duration_seconds INT,
    
    FOREIGN KEY (job_id) REFERENCES etl_job_control(id),
    INDEX idx_execution_id (execution_id),
    INDEX idx_started_at (started_at),
    INDEX idx_status (status)
);

-- ETL transformation rules
CREATE TABLE etl_transformation_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    job_id INT NOT NULL,
    rule_name VARCHAR(200) NOT NULL,
    rule_order INT NOT NULL,
    rule_type ENUM('VALIDATION', 'CLEANSING', 'ENRICHMENT', 'AGGREGATION', 'BUSINESS_RULE'),
    
    -- Rule definition
    source_columns JSON,
    target_columns JSON,
    transformation_logic TEXT,
    validation_criteria TEXT,
    
    -- Error handling
    on_error_action ENUM('REJECT', 'DEFAULT', 'SKIP', 'FAIL_JOB') DEFAULT 'REJECT',
    default_value VARCHAR(500),
    
    is_active BOOLEAN DEFAULT TRUE,
    
    FOREIGN KEY (job_id) REFERENCES etl_job_control(id),
    INDEX idx_job_order (job_id, rule_order)
);
</code></pre>
</div>

<p><strong>2. ETL Processing Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20ETL%20orchestrator%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_etl_job(IN%20p_job_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_job_id%20INT%3B%0A%20%20%20%20DECLARE%20v_execution_id%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_source_system%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_target_system%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_job_parameters%20JSON%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_start_time%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20EXIT%20HANDLER%20FOR%20SQLEXCEPTION%0A%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20UPDATE%20etl_execution_log%20%0A%20%20%20%20%20%20%20%20SET%20status%20%3D%20'FAILED'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20completed_at%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20error_message%20%3D%20'ETL%20job%20failed%20with%20SQL%20exception'%0A%20%20%20%20%20%20%20%20WHERE%20execution_id%20%3D%20v_execution_id%3B%0A%20%20%20%20%20%20%20%20RESIGNAL%3B%0A%20%20%20%20END%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20job%20configuration%0A%20%20%20%20SELECT%20id%2C%20source_system%2C%20target_system%2C%20job_parameters%0A%20%20%20%20INTO%20v_job_id%2C%20v_source_system%2C%20v_target_system%2C%20v_job_parameters%0A%20%20%20%20FROM%20etl_job_control%0A%20%20%20%20WHERE%20job_name%20%3D%20p_job_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_job_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'ETL%20job%20not%20found%20or%20inactive'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Generate%20execution%20ID%0A%20%20%20%20SET%20v_execution_id%20%3D%20CONCAT(p_job_name%2C%20'_'%2C%20DATE_FORMAT(NOW()%2C%20'%25Y%25m%25d_%25H%25i%25s'))%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20execution%20start%0A%20%20%20%20INSERT%20INTO%20etl_execution_log%20(job_id%2C%20execution_id%2C%20started_at)%0A%20%20%20%20VALUES%20(v_job_id%2C%20v_execution_id%2C%20v_start_time)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20ETL%20phases%0A%20%20%20%20CALL%20etl_extract_phase(v_job_id%2C%20v_execution_id%2C%20v_source_system%2C%20v_job_parameters)%3B%0A%20%20%20%20CALL%20etl_transform_phase(v_job_id%2C%20v_execution_id%2C%20v_job_parameters)%3B%0A%20%20%20%20CALL%20etl_load_phase(v_job_id%2C%20v_execution_id%2C%20v_target_system%2C%20v_job_parameters)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20completion%20status%0A%20%20%20%20UPDATE%20etl_execution_log%20%0A%20%20%20%20SET%20status%20%3D%20'SUCCESS'%2C%0A%20%20%20%20%20%20%20%20completed_at%20%3D%20NOW()%0A%20%20%20%20WHERE%20execution_id%20%3D%20v_execution_id%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20job%20control%0A%20%20%20%20UPDATE%20etl_job_control%0A%20%20%20%20SET%20last_run_start%20%3D%20v_start_time%2C%0A%20%20%20%20%20%20%20%20last_run_end%20%3D%20NOW()%2C%0A%20%20%20%20%20%20%20%20last_run_status%20%3D%20'SUCCESS'%2C%0A%20%20%20%20%20%20%20%20last_run_records_processed%20%3D%20v_records_processed%0A%20%20%20%20WHERE%20id%20%3D%20v_job_id%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20ETL%20Transform%20Phase%0ACREATE%20PROCEDURE%20etl_transform_phase(%0A%20%20%20%20IN%20p_job_id%20INT%2C%0A%20%20%20%20IN%20p_execution_id%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_job_parameters%20JSON%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_rule_id%20INT%3B%0A%20%20%20%20DECLARE%20v_rule_name%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_rule_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_transformation_logic%20TEXT%3B%0A%20%20%20%20DECLARE%20v_validation_criteria%20TEXT%3B%0A%20%20%20%20DECLARE%20v_on_error_action%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_records_processed%20BIGINT%20DEFAULT%200%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20transform_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20rule_name%2C%20rule_type%2C%20transformation_logic%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20validation_criteria%2C%20on_error_action%0A%20%20%20%20%20%20%20%20FROM%20etl_transformation_rules%0A%20%20%20%20%20%20%20%20WHERE%20job_id%20%3D%20p_job_id%20AND%20is_active%20%3D%20TRUE%0A%20%20%20%20%20%20%20%20ORDER%20BY%20rule_order%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20transform_cursor%3B%0A%20%20%20%20%0A%20%20%20%20transform_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20transform_cursor%20INTO%20v_rule_id%2C%20v_rule_name%2C%20v_rule_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v_transformation_logic%2C%20v_validation_criteria%2C%20v_on_error_action%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20transform_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Execute%20transformation%20based%20on%20type%0A%20%20%20%20%20%20%20%20CASE%20v_rule_type%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'VALIDATION'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_validation_rule(v_rule_id%2C%20v_validation_criteria%2C%20v_on_error_action)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'CLEANSING'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_cleansing_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'ENRICHMENT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_enrichment_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'BUSINESS_RULE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CALL%20apply_business_rule(v_rule_id%2C%20v_transformation_logic)%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20transform_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Update%20transformation%20metrics%0A%20%20%20%20UPDATE%20etl_execution_log%0A%20%20%20%20SET%20records_transformed%20%3D%20v_records_processed%2C%0A%20%20%20%20%20%20%20%20transformation_duration_seconds%20%3D%20TIMESTAMPDIFF(SECOND%2C%20started_at%2C%20NOW())%0A%20%20%20%20WHERE%20execution_id%20%3D%20p_execution_id%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Data%20validation%20rule%0ACREATE%20PROCEDURE%20apply_validation_rule(%0A%20%20%20%20IN%20p_rule_id%20INT%2C%0A%20%20%20%20IN%20p_validation_criteria%20TEXT%2C%0A%20%20%20%20IN%20p_on_error_action%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_invalid_count%20INT%20DEFAULT%200%3B%0A%20%20%20%20DECLARE%20v_validation_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Build%20validation%20query%0A%20%20%20%20SET%20v_validation_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20COUNT(*)%20FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20%0A%20%20%20%20%20%20%20%20p_validation_criteria%2C%20')'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20validation%0A%20%20%20%20SET%20%40sql%20%3D%20v_validation_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Get%20result%20into%20v_invalid_count%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20validation%20failures%0A%20%20%20%20IF%20v_invalid_count%20%3E%200%20THEN%0A%20%20%20%20%20%20%20%20CASE%20p_on_error_action%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'REJECT'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Move%20invalid%20records%20to%20reject%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40reject_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20etl_rejected_records%20SELECT%20*%2C%20'''%2C%20p_rule_id%2C%20'''%20as%20rule_id%2C%20NOW()%20as%20rejected_at%20'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20p_validation_criteria%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40reject_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20--%20Remove%20invalid%20records%20from%20staging%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40delete_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'DELETE%20FROM%20etl_staging_data%20WHERE%20NOT%20('%2C%20p_validation_criteria%2C%20')'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40delete_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20WHEN%20'FAIL_JOB'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Validation%20rule%20failed%20-%20job%20terminated'%3B%0A%20%20%20%20%20%20%20%20END%20CASE%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main ETL orchestrator
DELIMITER //
CREATE PROCEDURE execute_etl_job(IN p_job_name VARCHAR(100))
BEGIN
    DECLARE v_job_id INT;
    DECLARE v_execution_id VARCHAR(100);
    DECLARE v_source_system VARCHAR(100);
    DECLARE v_target_system VARCHAR(100);
    DECLARE v_job_parameters JSON;
    DECLARE v_records_processed BIGINT DEFAULT 0;
    DECLARE v_start_time TIMESTAMP DEFAULT NOW();
    
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        UPDATE etl_execution_log 
        SET status = 'FAILED',
            completed_at = NOW(),
            error_message = 'ETL job failed with SQL exception'
        WHERE execution_id = v_execution_id;
        RESIGNAL;
    END;
    
    -- Get job configuration
    SELECT id, source_system, target_system, job_parameters
    INTO v_job_id, v_source_system, v_target_system, v_job_parameters
    FROM etl_job_control
    WHERE job_name = p_job_name AND is_active = TRUE;
    
    IF v_job_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'ETL job not found or inactive';
    END IF;
    
    -- Generate execution ID
    SET v_execution_id = CONCAT(p_job_name, '_', DATE_FORMAT(NOW(), '%Y%m%d_%H%i%s'));
    
    -- Log execution start
    INSERT INTO etl_execution_log (job_id, execution_id, started_at)
    VALUES (v_job_id, v_execution_id, v_start_time);
    
    -- Execute ETL phases
    CALL etl_extract_phase(v_job_id, v_execution_id, v_source_system, v_job_parameters);
    CALL etl_transform_phase(v_job_id, v_execution_id, v_job_parameters);
    CALL etl_load_phase(v_job_id, v_execution_id, v_target_system, v_job_parameters);
    
    -- Update completion status
    UPDATE etl_execution_log 
    SET status = 'SUCCESS',
        completed_at = NOW()
    WHERE execution_id = v_execution_id;
    
    -- Update job control
    UPDATE etl_job_control
    SET last_run_start = v_start_time,
        last_run_end = NOW(),
        last_run_status = 'SUCCESS',
        last_run_records_processed = v_records_processed
    WHERE id = v_job_id;
    
END //

-- ETL Transform Phase
CREATE PROCEDURE etl_transform_phase(
    IN p_job_id INT,
    IN p_execution_id VARCHAR(100),
    IN p_job_parameters JSON
)
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_rule_id INT;
    DECLARE v_rule_name VARCHAR(200);
    DECLARE v_rule_type VARCHAR(50);
    DECLARE v_transformation_logic TEXT;
    DECLARE v_validation_criteria TEXT;
    DECLARE v_on_error_action VARCHAR(20);
    DECLARE v_records_processed BIGINT DEFAULT 0;
    
    DECLARE transform_cursor CURSOR FOR
        SELECT id, rule_name, rule_type, transformation_logic, 
               validation_criteria, on_error_action
        FROM etl_transformation_rules
        WHERE job_id = p_job_id AND is_active = TRUE
        ORDER BY rule_order;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    OPEN transform_cursor;
    
    transform_loop: LOOP
        FETCH transform_cursor INTO v_rule_id, v_rule_name, v_rule_type,
                                   v_transformation_logic, v_validation_criteria, v_on_error_action;
        
        IF done THEN
            LEAVE transform_loop;
        END IF;
        
        -- Execute transformation based on type
        CASE v_rule_type
            WHEN 'VALIDATION' THEN
                CALL apply_validation_rule(v_rule_id, v_validation_criteria, v_on_error_action);
            
            WHEN 'CLEANSING' THEN
                CALL apply_cleansing_rule(v_rule_id, v_transformation_logic);
            
            WHEN 'ENRICHMENT' THEN
                CALL apply_enrichment_rule(v_rule_id, v_transformation_logic);
            
            WHEN 'BUSINESS_RULE' THEN
                CALL apply_business_rule(v_rule_id, v_transformation_logic);
        END CASE;
        
    END LOOP;
    
    CLOSE transform_cursor;
    
    -- Update transformation metrics
    UPDATE etl_execution_log
    SET records_transformed = v_records_processed,
        transformation_duration_seconds = TIMESTAMPDIFF(SECOND, started_at, NOW())
    WHERE execution_id = p_execution_id;
    
END //

-- Data validation rule
CREATE PROCEDURE apply_validation_rule(
    IN p_rule_id INT,
    IN p_validation_criteria TEXT,
    IN p_on_error_action VARCHAR(20)
)
BEGIN
    DECLARE v_invalid_count INT DEFAULT 0;
    DECLARE v_validation_sql TEXT;
    
    -- Build validation query
    SET v_validation_sql = CONCAT(
        'SELECT COUNT(*) FROM etl_staging_data WHERE NOT (', 
        p_validation_criteria, ')'
    );
    
    -- Execute validation
    SET @sql = v_validation_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    -- Get result into v_invalid_count
    DEALLOCATE PREPARE stmt;
    
    -- Handle validation failures
    IF v_invalid_count &gt; 0 THEN
        CASE p_on_error_action
            WHEN 'REJECT' THEN
                -- Move invalid records to reject table
                SET @reject_sql = CONCAT(
                    'INSERT INTO etl_rejected_records SELECT *, ''', p_rule_id, ''' as rule_id, NOW() as rejected_at ',
                    'FROM etl_staging_data WHERE NOT (', p_validation_criteria, ')'
                );
                PREPARE stmt FROM @reject_sql;
                EXECUTE stmt;
                DEALLOCATE PREPARE stmt;
                
                -- Remove invalid records from staging
                SET @delete_sql = CONCAT(
                    'DELETE FROM etl_staging_data WHERE NOT (', p_validation_criteria, ')'
                );
                PREPARE stmt FROM @delete_sql;
                EXECUTE stmt;
                DEALLOCATE PREPARE stmt;
            
            WHEN 'FAIL_JOB' THEN
                SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Validation rule failed - job terminated';
        END CASE;
    END IF;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>ELT Pattern Implementation:</strong></p>

<p><strong>1. ELT Architecture:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Raw%20data%20landing%20zone%0ACREATE%20TABLE%20raw_data_landing%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_system%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20data_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20ingestion_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Raw%20data%20storage%0A%20%20%20%20raw_payload%20JSON%20NOT%20NULL%2C%0A%20%20%20%20file_metadata%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20status%0A%20%20%20%20processing_status%20ENUM('LANDED'%2C%20'VALIDATED'%2C%20'PROCESSED'%2C%20'FAILED')%20DEFAULT%20'LANDED'%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20lineage%0A%20%20%20%20batch_id%20VARCHAR(100)%2C%0A%20%20%20%20source_file_path%20VARCHAR(500)%2C%0A%20%20%20%20record_count%20INT%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source_type%20(source_system%2C%20data_type)%2C%0A%20%20%20%20INDEX%20idx_ingestion_timestamp%20(ingestion_timestamp)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_batch_id%20(batch_id)%0A)%3B%0A%0A--%20ELT%20transformation%20catalog%0ACREATE%20TABLE%20elt_transformations%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20transformation_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20transformation_type%20ENUM('VIEW'%2C%20'MATERIALIZED_VIEW'%2C%20'STORED_PROCEDURE'%2C%20'FUNCTION')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Source%20and%20target%0A%20%20%20%20source_tables%20JSON%20NOT%20NULL%2C%0A%20%20%20%20target_table%20VARCHAR(200)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transformation%20logic%0A%20%20%20%20transformation_sql%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20transformation_schedule%20VARCHAR(100)%2C%20--%20Cron%20expression%0A%20%20%20%20%0A%20%20%20%20--%20Dependencies%0A%20%20%20%20depends_on%20JSON%2C%0A%20%20%20%20refresh_strategy%20ENUM('FULL'%2C%20'INCREMENTAL'%2C%20'MERGE')%20DEFAULT%20'FULL'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20business_description%20TEXT%2C%0A%20%20%20%20technical_notes%20TEXT%2C%0A%20%20%20%20data_owner%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_transformation_name%20(transformation_name)%2C%0A%20%20%20%20INDEX%20idx_transformation_type%20(transformation_type)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Raw data landing zone
CREATE TABLE raw_data_landing (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_system VARCHAR(100) NOT NULL,
    data_type VARCHAR(100) NOT NULL,
    ingestion_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Raw data storage
    raw_payload JSON NOT NULL,
    file_metadata JSON,
    
    -- Processing status
    processing_status ENUM('LANDED', 'VALIDATED', 'PROCESSED', 'FAILED') DEFAULT 'LANDED',
    processed_at TIMESTAMP NULL,
    
    -- Data lineage
    batch_id VARCHAR(100),
    source_file_path VARCHAR(500),
    record_count INT,
    
    INDEX idx_source_type (source_system, data_type),
    INDEX idx_ingestion_timestamp (ingestion_timestamp),
    INDEX idx_processing_status (processing_status),
    INDEX idx_batch_id (batch_id)
);

-- ELT transformation catalog
CREATE TABLE elt_transformations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    transformation_name VARCHAR(200) NOT NULL,
    transformation_type ENUM('VIEW', 'MATERIALIZED_VIEW', 'STORED_PROCEDURE', 'FUNCTION'),
    
    -- Source and target
    source_tables JSON NOT NULL,
    target_table VARCHAR(200),
    
    -- Transformation logic
    transformation_sql TEXT NOT NULL,
    transformation_schedule VARCHAR(100), -- Cron expression
    
    -- Dependencies
    depends_on JSON,
    refresh_strategy ENUM('FULL', 'INCREMENTAL', 'MERGE') DEFAULT 'FULL',
    
    -- Metadata
    business_description TEXT,
    technical_notes TEXT,
    data_owner VARCHAR(100),
    
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_transformation_name (transformation_name),
    INDEX idx_transformation_type (transformation_type)
);
</code></pre>
</div>

<p><strong>2. ELT Processing Engine:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20ELT%20transformation%20executor%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20execute_elt_transformation(IN%20p_transformation_name%20VARCHAR(200))%0ABEGIN%0A%20%20%20%20DECLARE%20v_transformation_id%20INT%3B%0A%20%20%20%20DECLARE%20v_transformation_type%20VARCHAR(50)%3B%0A%20%20%20%20DECLARE%20v_transformation_sql%20TEXT%3B%0A%20%20%20%20DECLARE%20v_target_table%20VARCHAR(200)%3B%0A%20%20%20%20DECLARE%20v_refresh_strategy%20VARCHAR(20)%3B%0A%20%20%20%20DECLARE%20v_source_tables%20JSON%3B%0A%20%20%20%20DECLARE%20v_execution_start%20TIMESTAMP%20DEFAULT%20NOW()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20transformation%20definition%0A%20%20%20%20SELECT%20id%2C%20transformation_type%2C%20transformation_sql%2C%20target_table%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20refresh_strategy%2C%20source_tables%0A%20%20%20%20INTO%20v_transformation_id%2C%20v_transformation_type%2C%20v_transformation_sql%2C%0A%20%20%20%20%20%20%20%20%20v_target_table%2C%20v_refresh_strategy%2C%20v_source_tables%0A%20%20%20%20FROM%20elt_transformations%0A%20%20%20%20WHERE%20transformation_name%20%3D%20p_transformation_name%20AND%20is_active%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_transformation_id%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'ELT%20transformation%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Execute%20based%20on%20transformation%20type%0A%20%20%20%20CASE%20v_transformation_type%0A%20%20%20%20%20%20%20%20WHEN%20'VIEW'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20create_or_replace_view(p_transformation_name%2C%20v_transformation_sql)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'MATERIALIZED_VIEW'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20CALL%20refresh_materialized_view(v_target_table%2C%20v_transformation_sql%2C%20v_refresh_strategy)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'STORED_PROCEDURE'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40sql%20%3D%20v_transformation_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20execution%0A%20%20%20%20INSERT%20INTO%20elt_execution_log%20(%0A%20%20%20%20%20%20%20%20transformation_id%2C%20transformation_name%2C%20execution_start%2C%20execution_end%2C%0A%20%20%20%20%20%20%20%20status%2C%20duration_seconds%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20v_transformation_id%2C%20p_transformation_name%2C%20v_execution_start%2C%20NOW()%2C%0A%20%20%20%20%20%20%20%20'SUCCESS'%2C%20TIMESTAMPDIFF(SECOND%2C%20v_execution_start%2C%20NOW())%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Dynamic%20view%20creation%0ACREATE%20PROCEDURE%20create_or_replace_view(%0A%20%20%20%20IN%20p_view_name%20VARCHAR(200)%2C%0A%20%20%20%20IN%20p_view_sql%20TEXT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_create_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Drop%20existing%20view%20if%20exists%0A%20%20%20%20SET%20%40drop_sql%20%3D%20CONCAT('DROP%20VIEW%20IF%20EXISTS%20'%2C%20p_view_name)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20new%20view%0A%20%20%20%20SET%20v_create_sql%20%3D%20CONCAT('CREATE%20VIEW%20'%2C%20p_view_name%2C%20'%20AS%20'%2C%20p_view_sql)%3B%0A%20%20%20%20SET%20%40sql%20%3D%20v_create_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Materialized%20view%20refresh%0ACREATE%20PROCEDURE%20refresh_materialized_view(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(200)%2C%0A%20%20%20%20IN%20p_source_sql%20TEXT%2C%0A%20%20%20%20IN%20p_refresh_strategy%20VARCHAR(20)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_temp_table%20VARCHAR(220)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20v_temp_table%20%3D%20CONCAT(p_table_name%2C%20'_temp_'%2C%20UNIX_TIMESTAMP())%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20table%20with%20new%20data%0A%20%20%20%20SET%20%40create_temp_sql%20%3D%20CONCAT('CREATE%20TABLE%20'%2C%20v_temp_table%2C%20'%20AS%20'%2C%20p_source_sql)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40create_temp_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Handle%20refresh%20strategy%0A%20%20%20%20CASE%20p_refresh_strategy%0A%20%20%20%20%20%20%20%20WHEN%20'FULL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Replace%20entire%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40drop_sql%20%3D%20CONCAT('DROP%20TABLE%20IF%20EXISTS%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40rename_sql%20%3D%20CONCAT('RENAME%20TABLE%20'%2C%20v_temp_table%2C%20'%20TO%20'%2C%20p_table_name)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40rename_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20WHEN%20'INCREMENTAL'%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Insert%20only%20new%20records%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40insert_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_table_name%2C%20'%20SELECT%20*%20FROM%20'%2C%20v_temp_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%20WHERE%20NOT%20EXISTS%20(SELECT%201%20FROM%20'%2C%20p_table_name%2C%20'%20t2%20WHERE%20t2.id%20%3D%20'%2C%20v_temp_table%2C%20'.id)'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40insert_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20--%20Clean%20up%20temp%20table%0A%20%20%20%20%20%20%20%20%20%20%20%20SET%20%40drop_temp_sql%20%3D%20CONCAT('DROP%20TABLE%20'%2C%20v_temp_table)%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20PREPARE%20stmt%20FROM%20%40drop_temp_sql%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20END%20CASE%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- ELT transformation executor
DELIMITER //
CREATE PROCEDURE execute_elt_transformation(IN p_transformation_name VARCHAR(200))
BEGIN
    DECLARE v_transformation_id INT;
    DECLARE v_transformation_type VARCHAR(50);
    DECLARE v_transformation_sql TEXT;
    DECLARE v_target_table VARCHAR(200);
    DECLARE v_refresh_strategy VARCHAR(20);
    DECLARE v_source_tables JSON;
    DECLARE v_execution_start TIMESTAMP DEFAULT NOW();
    
    -- Get transformation definition
    SELECT id, transformation_type, transformation_sql, target_table, 
           refresh_strategy, source_tables
    INTO v_transformation_id, v_transformation_type, v_transformation_sql,
         v_target_table, v_refresh_strategy, v_source_tables
    FROM elt_transformations
    WHERE transformation_name = p_transformation_name AND is_active = TRUE;
    
    IF v_transformation_id IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'ELT transformation not found';
    END IF;
    
    -- Execute based on transformation type
    CASE v_transformation_type
        WHEN 'VIEW' THEN
            CALL create_or_replace_view(p_transformation_name, v_transformation_sql);
        
        WHEN 'MATERIALIZED_VIEW' THEN
            CALL refresh_materialized_view(v_target_table, v_transformation_sql, v_refresh_strategy);
        
        WHEN 'STORED_PROCEDURE' THEN
            SET @sql = v_transformation_sql;
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
    END CASE;
    
    -- Log execution
    INSERT INTO elt_execution_log (
        transformation_id, transformation_name, execution_start, execution_end,
        status, duration_seconds
    ) VALUES (
        v_transformation_id, p_transformation_name, v_execution_start, NOW(),
        'SUCCESS', TIMESTAMPDIFF(SECOND, v_execution_start, NOW())
    );
    
END //

-- Dynamic view creation
CREATE PROCEDURE create_or_replace_view(
    IN p_view_name VARCHAR(200),
    IN p_view_sql TEXT
)
BEGIN
    DECLARE v_create_sql TEXT;
    
    -- Drop existing view if exists
    SET @drop_sql = CONCAT('DROP VIEW IF EXISTS ', p_view_name);
    PREPARE stmt FROM @drop_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Create new view
    SET v_create_sql = CONCAT('CREATE VIEW ', p_view_name, ' AS ', p_view_sql);
    SET @sql = v_create_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
END //

-- Materialized view refresh
CREATE PROCEDURE refresh_materialized_view(
    IN p_table_name VARCHAR(200),
    IN p_source_sql TEXT,
    IN p_refresh_strategy VARCHAR(20)
)
BEGIN
    DECLARE v_temp_table VARCHAR(220);
    
    SET v_temp_table = CONCAT(p_table_name, '_temp_', UNIX_TIMESTAMP());
    
    -- Create temporary table with new data
    SET @create_temp_sql = CONCAT('CREATE TABLE ', v_temp_table, ' AS ', p_source_sql);
    PREPARE stmt FROM @create_temp_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Handle refresh strategy
    CASE p_refresh_strategy
        WHEN 'FULL' THEN
            -- Replace entire table
            SET @drop_sql = CONCAT('DROP TABLE IF EXISTS ', p_table_name);
            PREPARE stmt FROM @drop_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            SET @rename_sql = CONCAT('RENAME TABLE ', v_temp_table, ' TO ', p_table_name);
            PREPARE stmt FROM @rename_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
        
        WHEN 'INCREMENTAL' THEN
            -- Insert only new records
            SET @insert_sql = CONCAT(
                'INSERT INTO ', p_table_name, ' SELECT * FROM ', v_temp_table,
                ' WHERE NOT EXISTS (SELECT 1 FROM ', p_table_name, ' t2 WHERE t2.id = ', v_temp_table, '.id)'
            );
            PREPARE stmt FROM @insert_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
            
            -- Clean up temp table
            SET @drop_temp_sql = CONCAT('DROP TABLE ', v_temp_table);
            PREPARE stmt FROM @drop_temp_sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
    END CASE;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Integration Patterns:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Hub%20and%20Spoke%20Pattern%0ACREATE%20TABLE%20integration_hub%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20entity_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20business_key%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Master%20data%0A%20%20%20%20master_record%20JSON%20NOT%20NULL%2C%0A%20%20%20%20data_quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Source%20system%20mappings%0A%20%20%20%20source_systems%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Metadata%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20last_synchronized%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_entity_business_key%20(entity_type%2C%20business_key)%2C%0A%20%20%20%20INDEX%20idx_entity_type%20(entity_type)%2C%0A%20%20%20%20INDEX%20idx_data_quality%20(data_quality_score)%0A)%3B%0A%0A--%20Event-Driven%20Integration%0ACREATE%20TABLE%20integration_events%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20event_type%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_system%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20target_systems%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Event%20data%0A%20%20%20%20event_payload%20JSON%20NOT%20NULL%2C%0A%20%20%20%20correlation_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%0A%20%20%20%20processing_status%20ENUM('PENDING'%2C%20'PROCESSING'%2C%20'COMPLETED'%2C%20'FAILED')%20DEFAULT%20'PENDING'%2C%0A%20%20%20%20retry_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20max_retries%20INT%20DEFAULT%203%2C%0A%20%20%20%20%0A%20%20%20%20--%20Timestamps%0A%20%20%20%20event_timestamp%20TIMESTAMP%20NOT%20NULL%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20processed_at%20TIMESTAMP%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_event_type%20(event_type)%2C%0A%20%20%20%20INDEX%20idx_source_system%20(source_system)%2C%0A%20%20%20%20INDEX%20idx_processing_status%20(processing_status)%2C%0A%20%20%20%20INDEX%20idx_correlation_id%20(correlation_id)%0A)%3B%0A%0A--%20API-Based%20Integration%0ACREATE%20TABLE%20api_integration_config%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20integration_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20api_endpoint%20VARCHAR(500)%20NOT%20NULL%2C%0A%20%20%20%20authentication_type%20ENUM('NONE'%2C%20'BASIC'%2C%20'BEARER'%2C%20'OAUTH2'%2C%20'API_KEY')%2C%0A%20%20%20%20authentication_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Request%20configuration%0A%20%20%20%20http_method%20ENUM('GET'%2C%20'POST'%2C%20'PUT'%2C%20'DELETE'%2C%20'PATCH')%20DEFAULT%20'GET'%2C%0A%20%20%20%20request_headers%20JSON%2C%0A%20%20%20%20request_body_template%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Response%20handling%0A%20%20%20%20response_format%20ENUM('JSON'%2C%20'XML'%2C%20'CSV'%2C%20'TEXT')%2C%0A%20%20%20%20response_mapping%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Scheduling%0A%20%20%20%20sync_frequency_minutes%20INT%20DEFAULT%2060%2C%0A%20%20%20%20last_sync_timestamp%20TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_integration_name%20(integration_name)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Hub and Spoke Pattern
CREATE TABLE integration_hub (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    entity_type VARCHAR(100) NOT NULL,
    business_key VARCHAR(255) NOT NULL,
    
    -- Master data
    master_record JSON NOT NULL,
    data_quality_score DECIMAL(3,2),
    
    -- Source system mappings
    source_systems JSON,
    
    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    last_synchronized TIMESTAMP,
    
    UNIQUE KEY uk_entity_business_key (entity_type, business_key),
    INDEX idx_entity_type (entity_type),
    INDEX idx_data_quality (data_quality_score)
);

-- Event-Driven Integration
CREATE TABLE integration_events (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,
    source_system VARCHAR(100) NOT NULL,
    target_systems JSON,
    
    -- Event data
    event_payload JSON NOT NULL,
    correlation_id VARCHAR(100),
    
    -- Processing
    processing_status ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING',
    retry_count INT DEFAULT 0,
    max_retries INT DEFAULT 3,
    
    -- Timestamps
    event_timestamp TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP NULL,
    
    INDEX idx_event_type (event_type),
    INDEX idx_source_system (source_system),
    INDEX idx_processing_status (processing_status),
    INDEX idx_correlation_id (correlation_id)
);

-- API-Based Integration
CREATE TABLE api_integration_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    integration_name VARCHAR(200) NOT NULL,
    api_endpoint VARCHAR(500) NOT NULL,
    authentication_type ENUM('NONE', 'BASIC', 'BEARER', 'OAUTH2', 'API_KEY'),
    authentication_config JSON,
    
    -- Request configuration
    http_method ENUM('GET', 'POST', 'PUT', 'DELETE', 'PATCH') DEFAULT 'GET',
    request_headers JSON,
    request_body_template TEXT,
    
    -- Response handling
    response_format ENUM('JSON', 'XML', 'CSV', 'TEXT'),
    response_mapping JSON,
    
    -- Scheduling
    sync_frequency_minutes INT DEFAULT 60,
    last_sync_timestamp TIMESTAMP,
    
    is_active BOOLEAN DEFAULT TRUE,
    
    UNIQUE KEY uk_integration_name (integration_name)
);
</code></pre>
</div>

<p><strong>Key Differences Summary:</strong></p>

<p>- <strong>ETL</strong>: Transform data before loading, suitable for structured data, predictable queries</p>
<p>- <strong>ELT</strong>: Load raw data first, transform on-demand, suitable for big data, flexible analysis</p>
<p>- <strong>Modern Trend</strong>: ELT gaining popularity with cloud data warehouses and data lakes</p>


<p>---</p>

<h2 id="-386-how-do-you-implement-data-versioning-and-change-tracking-">**386. How do you implement data versioning and change tracking?**</h2>

<p><strong>Answer:</strong> Data versioning and change tracking maintain historical records of data changes, enabling audit trails, rollback capabilities, and temporal analysis through systematic version control mechanisms.</p>

<p><strong>Temporal Data Management:</strong></p>

<p><strong>1. System-Versioned Temporal Tables:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Main%20table%20with%20system%20versioning%0ACREATE%20TABLE%20customers%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20email%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20address%20TEXT%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'suspended')%20DEFAULT%20'active'%2C%0A%20%20%20%20%0A%20%20%20%20--%20System%20versioning%20columns%0A%20%20%20%20row_start%20TIMESTAMP(6)%20GENERATED%20ALWAYS%20AS%20ROW%20START%2C%0A%20%20%20%20row_end%20TIMESTAMP(6)%20GENERATED%20ALWAYS%20AS%20ROW%20END%2C%0A%20%20%20%20%0A%20%20%20%20PERIOD%20FOR%20SYSTEM_TIME%20(row_start%2C%20row_end)%0A)%20WITH%20SYSTEM%20VERSIONING%3B%0A%0A--%20History%20table%20(automatically%20managed)%0ACREATE%20TABLE%20customers_history%20(%0A%20%20%20%20id%20INT%2C%0A%20%20%20%20name%20VARCHAR(255)%2C%0A%20%20%20%20email%20VARCHAR(255)%2C%0A%20%20%20%20phone%20VARCHAR(20)%2C%0A%20%20%20%20address%20TEXT%2C%0A%20%20%20%20status%20ENUM('active'%2C%20'inactive'%2C%20'suspended')%2C%0A%20%20%20%20row_start%20TIMESTAMP(6)%2C%0A%20%20%20%20row_end%20TIMESTAMP(6)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_id_period%20(id%2C%20row_start%2C%20row_end)%2C%0A%20%20%20%20INDEX%20idx_row_start%20(row_start)%2C%0A%20%20%20%20INDEX%20idx_row_end%20(row_end)%0A)%3B%0A%0A--%20Application-versioned%20temporal%20table%0ACREATE%20TABLE%20products%20(%0A%20%20%20%20id%20INT%20PRIMARY%20KEY%2C%0A%20%20%20%20name%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20price%20DECIMAL(10%2C2)%20NOT%20NULL%2C%0A%20%20%20%20category_id%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Application%20versioning%0A%20%20%20%20valid_from%20DATE%20NOT%20NULL%2C%0A%20%20%20%20valid_to%20DATE%20NOT%20NULL%20DEFAULT%20'9999-12-31'%2C%0A%20%20%20%20version_number%20INT%20NOT%20NULL%20DEFAULT%201%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20tracking%0A%20%20%20%20created_by%20VARCHAR(100)%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20modified_by%20VARCHAR(100)%2C%0A%20%20%20%20modified_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ensure%20no%20overlapping%20periods%20for%20same%20product%0A%20%20%20%20UNIQUE%20KEY%20uk_product_period%20(id%2C%20valid_from%2C%20valid_to)%2C%0A%20%20%20%20INDEX%20idx_valid_period%20(valid_from%2C%20valid_to)%2C%0A%20%20%20%20INDEX%20idx_version%20(id%2C%20version_number)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Main table with system versioning
CREATE TABLE customers (
    id INT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    email VARCHAR(255) NOT NULL,
    phone VARCHAR(20),
    address TEXT,
    status ENUM('active', 'inactive', 'suspended') DEFAULT 'active',
    
    -- System versioning columns
    row_start TIMESTAMP(6) GENERATED ALWAYS AS ROW START,
    row_end TIMESTAMP(6) GENERATED ALWAYS AS ROW END,
    
    PERIOD FOR SYSTEM_TIME (row_start, row_end)
) WITH SYSTEM VERSIONING;

-- History table (automatically managed)
CREATE TABLE customers_history (
    id INT,
    name VARCHAR(255),
    email VARCHAR(255),
    phone VARCHAR(20),
    address TEXT,
    status ENUM('active', 'inactive', 'suspended'),
    row_start TIMESTAMP(6),
    row_end TIMESTAMP(6),
    
    INDEX idx_id_period (id, row_start, row_end),
    INDEX idx_row_start (row_start),
    INDEX idx_row_end (row_end)
);

-- Application-versioned temporal table
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    category_id INT,
    
    -- Application versioning
    valid_from DATE NOT NULL,
    valid_to DATE NOT NULL DEFAULT '9999-12-31',
    version_number INT NOT NULL DEFAULT 1,
    
    -- Change tracking
    created_by VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    modified_by VARCHAR(100),
    modified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    -- Ensure no overlapping periods for same product
    UNIQUE KEY uk_product_period (id, valid_from, valid_to),
    INDEX idx_valid_period (valid_from, valid_to),
    INDEX idx_version (id, version_number)
);
</code></pre>
</div>

<p><strong>2. Change Data Capture (CDC) Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Change%20tracking%20configuration%0ACREATE%20TABLE%20change_tracking_config%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20tracking_enabled%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_columns%20JSON%2C%20--%20Specific%20columns%20to%20track%0A%20%20%20%20retention_days%20INT%20DEFAULT%20365%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20types%20to%20track%0A%20%20%20%20track_inserts%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_updates%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20track_deletes%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Notification%20settings%0A%20%20%20%20notify_on_change%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20notification_config%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_table_name%20(table_name)%0A)%3B%0A%0A--%20Universal%20change%20log%0ACREATE%20TABLE%20change_log%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20operation_type%20ENUM('INSERT'%2C%20'UPDATE'%2C%20'DELETE')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20data%0A%20%20%20%20old_values%20JSON%2C%0A%20%20%20%20new_values%20JSON%2C%0A%20%20%20%20changed_columns%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Change%20metadata%0A%20%20%20%20change_timestamp%20TIMESTAMP(6)%20DEFAULT%20CURRENT_TIMESTAMP(6)%2C%0A%20%20%20%20change_user%20VARCHAR(100)%2C%0A%20%20%20%20change_session%20VARCHAR(100)%2C%0A%20%20%20%20change_application%20VARCHAR(100)%2C%0A%20%20%20%20change_reason%20VARCHAR(500)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transaction%20context%0A%20%20%20%20transaction_id%20VARCHAR(100)%2C%0A%20%20%20%20batch_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20lineage%0A%20%20%20%20source_system%20VARCHAR(100)%2C%0A%20%20%20%20correlation_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_record%20(table_name%2C%20record_id)%2C%0A%20%20%20%20INDEX%20idx_change_timestamp%20(change_timestamp)%2C%0A%20%20%20%20INDEX%20idx_operation_type%20(operation_type)%2C%0A%20%20%20%20INDEX%20idx_change_user%20(change_user)%2C%0A%20%20%20%20INDEX%20idx_transaction_id%20(transaction_id)%0A)%3B%0A%0A--%20Change%20tracking%20triggers%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20create_change_tracking_triggers(IN%20p_table_name%20VARCHAR(100))%0ABEGIN%0A%20%20%20%20DECLARE%20v_columns%20TEXT%3B%0A%20%20%20%20DECLARE%20v_insert_trigger%20TEXT%3B%0A%20%20%20%20DECLARE%20v_update_trigger%20TEXT%3B%0A%20%20%20%20DECLARE%20v_delete_trigger%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20table%20columns%20for%20JSON%20construction%0A%20%20%20%20SELECT%20GROUP_CONCAT(%0A%20%20%20%20%20%20%20%20CONCAT(''''%2C%20column_name%2C%20'''%2C%20NEW.'%2C%20column_name)%0A%20%20%20%20%20%20%20%20SEPARATOR%20'%2C%20'%0A%20%20%20%20)%20INTO%20v_columns%0A%20%20%20%20FROM%20information_schema.columns%0A%20%20%20%20WHERE%20table_name%20%3D%20p_table_name%0A%20%20%20%20AND%20table_schema%20%3D%20DATABASE()%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20INSERT%20trigger%0A%20%20%20%20SET%20v_insert_trigger%20%3D%20CONCAT('%0A%20%20%20%20%20%20%20%20CREATE%20TRIGGER%20'%2C%20p_table_name%2C%20'_change_insert%0A%20%20%20%20%20%20%20%20AFTER%20INSERT%20ON%20'%2C%20p_table_name%2C%20'%0A%20%20%20%20%20%20%20%20FOR%20EACH%20ROW%0A%20%20%20%20%20%20%20%20BEGIN%0A%20%20%20%20%20%20%20%20%20%20%20%20INSERT%20INTO%20change_log%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20operation_type%2C%20new_values%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20change_user%2C%20change_session%2C%20change_application%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'''%2C%20p_table_name%2C%20'''%2C%20NEW.id%2C%20''INSERT''%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20JSON_OBJECT('%2C%20v_columns%2C%20')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_user%2C%20USER())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_session%2C%20CONNECTION_ID())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20COALESCE(%40change_application%2C%20''UNKNOWN'')%0A%20%20%20%20%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20END'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_insert_trigger%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20UPDATE%20trigger%20(similar%20pattern)%0A%20%20%20%20--%20Create%20DELETE%20trigger%20(similar%20pattern)%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Version%20management%20procedures%0ACREATE%20PROCEDURE%20create_new_version(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20INT%2C%0A%20%20%20%20IN%20p_new_data%20JSON%2C%0A%20%20%20%20IN%20p_valid_from%20DATE%2C%0A%20%20%20%20IN%20p_change_reason%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_current_version%20INT%3B%0A%20%20%20%20DECLARE%20v_update_sql%20TEXT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20current%20version%0A%20%20%20%20SET%20%40version_sql%20%3D%20CONCAT('SELECT%20MAX(version_number)%20FROM%20'%2C%20p_table_name%2C%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40version_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20result%20in%20v_current_version%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Close%20current%20version%0A%20%20%20%20SET%20%40close_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'UPDATE%20'%2C%20p_table_name%2C%20'%20SET%20valid_to%20%3D%20'''%2C%20DATE_SUB(p_valid_from%2C%20INTERVAL%201%20DAY)%2C%20''''%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id%2C%20'%20AND%20valid_to%20%3D%20''9999-12-31'''%0A%20%20%20%20)%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40close_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Insert%20new%20version%0A%20%20%20%20SET%20v_update_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'INSERT%20INTO%20'%2C%20p_table_name%2C%20'%20(id%2C%20name%2C%20price%2C%20category_id%2C%20valid_from%2C%20version_number%2C%20created_by)%20'%2C%0A%20%20%20%20%20%20%20%20'VALUES%20('%2C%20p_record_id%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20JSON_UNQUOTE(JSON_EXTRACT(p_new_data%2C%20'%24.name'))%2C%20'''%2C%20'%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(p_new_data%2C%20'%24.price')%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20JSON_EXTRACT(p_new_data%2C%20'%24.category_id')%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20p_valid_from%2C%20'''%2C%20'%2C%20v_current_version%20%2B%201%2C%20'%2C%20'%2C%0A%20%20%20%20%20%20%20%20''''%2C%20COALESCE(%40change_user%2C%20USER())%2C%20''')'%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20SET%20%40sql%20%3D%20v_update_sql%3B%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20version%20creation%0A%20%20%20%20INSERT%20INTO%20version_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20old_version%2C%20new_version%2C%0A%20%20%20%20%20%20%20%20change_reason%2C%20created_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20v_current_version%2C%20v_current_version%20%2B%201%2C%0A%20%20%20%20%20%20%20%20p_change_reason%2C%20COALESCE(%40change_user%2C%20USER())%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Change tracking configuration
CREATE TABLE change_tracking_config (
    id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    tracking_enabled BOOLEAN DEFAULT TRUE,
    track_columns JSON, -- Specific columns to track
    retention_days INT DEFAULT 365,
    
    -- Change types to track
    track_inserts BOOLEAN DEFAULT TRUE,
    track_updates BOOLEAN DEFAULT TRUE,
    track_deletes BOOLEAN DEFAULT TRUE,
    
    -- Notification settings
    notify_on_change BOOLEAN DEFAULT FALSE,
    notification_config JSON,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_table_name (table_name)
);

-- Universal change log
CREATE TABLE change_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    operation_type ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,
    
    -- Change data
    old_values JSON,
    new_values JSON,
    changed_columns JSON,
    
    -- Change metadata
    change_timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    change_user VARCHAR(100),
    change_session VARCHAR(100),
    change_application VARCHAR(100),
    change_reason VARCHAR(500),
    
    -- Transaction context
    transaction_id VARCHAR(100),
    batch_id VARCHAR(100),
    
    -- Data lineage
    source_system VARCHAR(100),
    correlation_id VARCHAR(100),
    
    INDEX idx_table_record (table_name, record_id),
    INDEX idx_change_timestamp (change_timestamp),
    INDEX idx_operation_type (operation_type),
    INDEX idx_change_user (change_user),
    INDEX idx_transaction_id (transaction_id)
);

-- Change tracking triggers
DELIMITER //
CREATE PROCEDURE create_change_tracking_triggers(IN p_table_name VARCHAR(100))
BEGIN
    DECLARE v_columns TEXT;
    DECLARE v_insert_trigger TEXT;
    DECLARE v_update_trigger TEXT;
    DECLARE v_delete_trigger TEXT;
    
    -- Get table columns for JSON construction
    SELECT GROUP_CONCAT(
        CONCAT('''', column_name, ''', NEW.', column_name)
        SEPARATOR ', '
    ) INTO v_columns
    FROM information_schema.columns
    WHERE table_name = p_table_name
    AND table_schema = DATABASE();
    
    -- Create INSERT trigger
    SET v_insert_trigger = CONCAT('
        CREATE TRIGGER ', p_table_name, '_change_insert
        AFTER INSERT ON ', p_table_name, '
        FOR EACH ROW
        BEGIN
            INSERT INTO change_log (
                table_name, record_id, operation_type, new_values,
                change_user, change_session, change_application
            ) VALUES (
                ''', p_table_name, ''', NEW.id, ''INSERT'',
                JSON_OBJECT(', v_columns, '),
                COALESCE(@change_user, USER()),
                COALESCE(@change_session, CONNECTION_ID()),
                COALESCE(@change_application, ''UNKNOWN'')
            );
        END'
    );
    
    SET @sql = v_insert_trigger;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Create UPDATE trigger (similar pattern)
    -- Create DELETE trigger (similar pattern)
    
END //

-- Version management procedures
CREATE PROCEDURE create_new_version(
    IN p_table_name VARCHAR(100),
    IN p_record_id INT,
    IN p_new_data JSON,
    IN p_valid_from DATE,
    IN p_change_reason VARCHAR(500)
)
BEGIN
    DECLARE v_current_version INT;
    DECLARE v_update_sql TEXT;
    
    -- Get current version
    SET @version_sql = CONCAT('SELECT MAX(version_number) FROM ', p_table_name, ' WHERE id = ', p_record_id);
    PREPARE stmt FROM @version_sql;
    EXECUTE stmt;
    -- Store result in v_current_version
    DEALLOCATE PREPARE stmt;
    
    -- Close current version
    SET @close_sql = CONCAT(
        'UPDATE ', p_table_name, ' SET valid_to = ''', DATE_SUB(p_valid_from, INTERVAL 1 DAY), '''',
        ' WHERE id = ', p_record_id, ' AND valid_to = ''9999-12-31'''
    );
    PREPARE stmt FROM @close_sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Insert new version
    SET v_update_sql = CONCAT(
        'INSERT INTO ', p_table_name, ' (id, name, price, category_id, valid_from, version_number, created_by) ',
        'VALUES (', p_record_id, ', ',
        '''', JSON_UNQUOTE(JSON_EXTRACT(p_new_data, '$.name')), ''', ',
        JSON_EXTRACT(p_new_data, '$.price'), ', ',
        JSON_EXTRACT(p_new_data, '$.category_id'), ', ',
        '''', p_valid_from, ''', ', v_current_version + 1, ', ',
        '''', COALESCE(@change_user, USER()), ''')'
    );
    
    SET @sql = v_update_sql;
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- Log version creation
    INSERT INTO version_log (
        table_name, record_id, old_version, new_version,
        change_reason, created_by
    ) VALUES (
        p_table_name, p_record_id, v_current_version, v_current_version + 1,
        p_change_reason, COALESCE(@change_user, USER())
    );
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>3. Data Lineage and Provenance:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20lineage%20tracking%0ACREATE%20TABLE%20data_lineage%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20source_table%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20source_record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20target_table%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20target_record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Transformation%20details%0A%20%20%20%20transformation_type%20ENUM('COPY'%2C%20'AGGREGATE'%2C%20'JOIN'%2C%20'CALCULATE'%2C%20'ENRICH')%2C%0A%20%20%20%20transformation_rule%20TEXT%2C%0A%20%20%20%20transformation_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Processing%20context%0A%20%20%20%20job_name%20VARCHAR(200)%2C%0A%20%20%20%20job_execution_id%20VARCHAR(100)%2C%0A%20%20%20%20processing_user%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20quality%0A%20%20%20%20confidence_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20quality_flags%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_source%20(source_table%2C%20source_record_id)%2C%0A%20%20%20%20INDEX%20idx_target%20(target_table%2C%20target_record_id)%2C%0A%20%20%20%20INDEX%20idx_transformation_timestamp%20(transformation_timestamp)%0A)%3B%0A%0A--%20Data%20provenance%20queries%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20trace_data_lineage(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_direction%20ENUM('UPSTREAM'%2C%20'DOWNSTREAM'%2C%20'BOTH')%0A)%0ABEGIN%0A%20%20%20%20--%20Recursive%20CTE%20to%20trace%20lineage%0A%20%20%20%20WITH%20RECURSIVE%20lineage_trace%20AS%20(%0A%20%20%20%20%20%20%20%20--%20Base%20case%3A%20starting%20record%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%200%20as%20level%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_table_name%20as%20table_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20p_record_id%20as%20record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'ORIGIN'%20as%20relationship_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NULL%20as%20transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20NULL%20as%20transformation_rule%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20upstream%20lineage%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20lt.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.source_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.source_record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'SOURCE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_rule%0A%20%20%20%20%20%20%20%20FROM%20lineage_trace%20lt%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20lt.table_name%20%3D%20dl.target_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20lt.record_id%20%3D%20dl.target_record_id%0A%20%20%20%20%20%20%20%20WHERE%20p_direction%20IN%20('UPSTREAM'%2C%20'BOTH')%0A%20%20%20%20%20%20%20%20AND%20lt.level%20%3C%2010%20%20--%20Prevent%20infinite%20recursion%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20UNION%20ALL%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Recursive%20case%3A%20downstream%20lineage%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20lt.level%20%2B%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.target_table%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.target_record_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'TARGET'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_type%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20dl.transformation_rule%0A%20%20%20%20%20%20%20%20FROM%20lineage_trace%20lt%0A%20%20%20%20%20%20%20%20JOIN%20data_lineage%20dl%20ON%20lt.table_name%20%3D%20dl.source_table%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20AND%20lt.record_id%20%3D%20dl.source_record_id%0A%20%20%20%20%20%20%20%20WHERE%20p_direction%20IN%20('DOWNSTREAM'%2C%20'BOTH')%0A%20%20%20%20%20%20%20%20AND%20lt.level%20%3C%2010%0A%20%20%20%20)%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20level%2C%0A%20%20%20%20%20%20%20%20table_name%2C%0A%20%20%20%20%20%20%20%20record_id%2C%0A%20%20%20%20%20%20%20%20relationship_type%2C%0A%20%20%20%20%20%20%20%20transformation_type%2C%0A%20%20%20%20%20%20%20%20transformation_rule%2C%0A%20%20%20%20%20%20%20%20REPEAT('%20%20'%2C%20level)%20as%20indentation%0A%20%20%20%20FROM%20lineage_trace%0A%20%20%20%20ORDER%20BY%20level%2C%20table_name%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data lineage tracking
CREATE TABLE data_lineage (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    source_table VARCHAR(100) NOT NULL,
    source_record_id VARCHAR(255) NOT NULL,
    target_table VARCHAR(100) NOT NULL,
    target_record_id VARCHAR(255) NOT NULL,
    
    -- Transformation details
    transformation_type ENUM('COPY', 'AGGREGATE', 'JOIN', 'CALCULATE', 'ENRICH'),
    transformation_rule TEXT,
    transformation_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Processing context
    job_name VARCHAR(200),
    job_execution_id VARCHAR(100),
    processing_user VARCHAR(100),
    
    -- Data quality
    confidence_score DECIMAL(3,2),
    quality_flags JSON,
    
    INDEX idx_source (source_table, source_record_id),
    INDEX idx_target (target_table, target_record_id),
    INDEX idx_transformation_timestamp (transformation_timestamp)
);

-- Data provenance queries
DELIMITER //
CREATE PROCEDURE trace_data_lineage(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_direction ENUM('UPSTREAM', 'DOWNSTREAM', 'BOTH')
)
BEGIN
    -- Recursive CTE to trace lineage
    WITH RECURSIVE lineage_trace AS (
        -- Base case: starting record
        SELECT 
            0 as level,
            p_table_name as table_name,
            p_record_id as record_id,
            'ORIGIN' as relationship_type,
            NULL as transformation_type,
            NULL as transformation_rule
        
        UNION ALL
        
        -- Recursive case: upstream lineage
        SELECT 
            lt.level + 1,
            dl.source_table,
            dl.source_record_id,
            'SOURCE',
            dl.transformation_type,
            dl.transformation_rule
        FROM lineage_trace lt
        JOIN data_lineage dl ON lt.table_name = dl.target_table 
                             AND lt.record_id = dl.target_record_id
        WHERE p_direction IN ('UPSTREAM', 'BOTH')
        AND lt.level &lt; 10  -- Prevent infinite recursion
        
        UNION ALL
        
        -- Recursive case: downstream lineage
        SELECT 
            lt.level + 1,
            dl.target_table,
            dl.target_record_id,
            'TARGET',
            dl.transformation_type,
            dl.transformation_rule
        FROM lineage_trace lt
        JOIN data_lineage dl ON lt.table_name = dl.source_table 
                             AND lt.record_id = dl.source_record_id
        WHERE p_direction IN ('DOWNSTREAM', 'BOTH')
        AND lt.level &lt; 10
    )
    SELECT 
        level,
        table_name,
        record_id,
        relationship_type,
        transformation_type,
        transformation_rule,
        REPEAT('  ', level) as indentation
    FROM lineage_trace
    ORDER BY level, table_name;
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Version Comparison and Rollback:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Version%20comparison%0ACREATE%20TABLE%20version_comparisons%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20table_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20record_id%20VARCHAR(255)%20NOT%20NULL%2C%0A%20%20%20%20version_from%20INT%20NOT%20NULL%2C%0A%20%20%20%20version_to%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Comparison%20results%0A%20%20%20%20differences%20JSON%20NOT%20NULL%2C%0A%20%20%20%20comparison_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20compared_by%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20INDEX%20idx_table_record%20(table_name%2C%20record_id)%2C%0A%20%20%20%20INDEX%20idx_versions%20(version_from%2C%20version_to)%0A)%3B%0A%0ADELIMITER%20%2F%2F%0A--%20Compare%20versions%0ACREATE%20PROCEDURE%20compare_versions(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_version_from%20INT%2C%0A%20%20%20%20IN%20p_version_to%20INT%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_from_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_to_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_differences%20JSON%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20version%20data%20(simplified%20-%20would%20need%20dynamic%20SQL%20for%20real%20implementation)%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20'price'%2C%20price%2C%0A%20%20%20%20%20%20%20%20'category_id'%2C%20category_id%2C%0A%20%20%20%20%20%20%20%20'status'%2C%20status%0A%20%20%20%20)%20INTO%20v_from_data%0A%20%20%20%20FROM%20products%0A%20%20%20%20WHERE%20id%20%3D%20p_record_id%20AND%20version_number%20%3D%20p_version_from%3B%0A%20%20%20%20%0A%20%20%20%20SELECT%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'name'%2C%20name%2C%0A%20%20%20%20%20%20%20%20'price'%2C%20price%2C%0A%20%20%20%20%20%20%20%20'category_id'%2C%20category_id%2C%0A%20%20%20%20%20%20%20%20'status'%2C%20status%0A%20%20%20%20)%20INTO%20v_to_data%0A%20%20%20%20FROM%20products%0A%20%20%20%20WHERE%20id%20%3D%20p_record_id%20AND%20version_number%20%3D%20p_version_to%3B%0A%20%20%20%20%0A%20%20%20%20--%20Calculate%20differences%20(simplified)%0A%20%20%20%20SET%20v_differences%20%3D%20JSON_OBJECT(%0A%20%20%20%20%20%20%20%20'from_version'%2C%20p_version_from%2C%0A%20%20%20%20%20%20%20%20'to_version'%2C%20p_version_to%2C%0A%20%20%20%20%20%20%20%20'from_data'%2C%20v_from_data%2C%0A%20%20%20%20%20%20%20%20'to_data'%2C%20v_to_data%2C%0A%20%20%20%20%20%20%20%20'changed_fields'%2C%20JSON_ARRAY()%20--%20Would%20contain%20actual%20field%20differences%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Store%20comparison%0A%20%20%20%20INSERT%20INTO%20version_comparisons%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20version_from%2C%20version_to%2C%20%0A%20%20%20%20%20%20%20%20differences%2C%20compared_by%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20p_version_from%2C%20p_version_to%2C%0A%20%20%20%20%20%20%20%20v_differences%2C%20USER()%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20comparison%20results%0A%20%20%20%20SELECT%20v_differences%20as%20comparison_result%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0A--%20Rollback%20to%20previous%20version%0ACREATE%20PROCEDURE%20rollback_to_version(%0A%20%20%20%20IN%20p_table_name%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_record_id%20VARCHAR(255)%2C%0A%20%20%20%20IN%20p_target_version%20INT%2C%0A%20%20%20%20IN%20p_rollback_reason%20VARCHAR(500)%0A)%0ABEGIN%0A%20%20%20%20DECLARE%20v_version_data%20JSON%3B%0A%20%20%20%20DECLARE%20v_current_version%20INT%3B%0A%20%20%20%20%0A%20%20%20%20--%20Get%20target%20version%20data%0A%20%20%20%20SET%20%40get_version_sql%20%3D%20CONCAT(%0A%20%20%20%20%20%20%20%20'SELECT%20JSON_OBJECT('%2C%0A%20%20%20%20%20%20%20%20'''name''%2C%20name%2C%20''price''%2C%20price%2C%20''category_id''%2C%20category_id'%2C%0A%20%20%20%20%20%20%20%20')%20FROM%20'%2C%20p_table_name%2C%0A%20%20%20%20%20%20%20%20'%20WHERE%20id%20%3D%20'%2C%20p_record_id%2C%20'%20AND%20version_number%20%3D%20'%2C%20p_target_version%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20PREPARE%20stmt%20FROM%20%40get_version_sql%3B%0A%20%20%20%20EXECUTE%20stmt%3B%0A%20%20%20%20--%20Store%20in%20v_version_data%0A%20%20%20%20DEALLOCATE%20PREPARE%20stmt%3B%0A%20%20%20%20%0A%20%20%20%20IF%20v_version_data%20IS%20NULL%20THEN%0A%20%20%20%20%20%20%20%20SIGNAL%20SQLSTATE%20'45000'%20SET%20MESSAGE_TEXT%20%3D%20'Target%20version%20not%20found'%3B%0A%20%20%20%20END%20IF%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20new%20version%20with%20old%20data%0A%20%20%20%20CALL%20create_new_version(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20v_version_data%2C%20CURDATE()%2C%0A%20%20%20%20%20%20%20%20CONCAT('Rollback%20to%20version%20'%2C%20p_target_version%2C%20'%3A%20'%2C%20p_rollback_reason)%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20--%20Log%20rollback%0A%20%20%20%20INSERT%20INTO%20rollback_log%20(%0A%20%20%20%20%20%20%20%20table_name%2C%20record_id%2C%20target_version%2C%20rollback_reason%2C%0A%20%20%20%20%20%20%20%20rollback_timestamp%2C%20rollback_user%0A%20%20%20%20)%20VALUES%20(%0A%20%20%20%20%20%20%20%20p_table_name%2C%20p_record_id%2C%20p_target_version%2C%20p_rollback_reason%2C%0A%20%20%20%20%20%20%20%20NOW()%2C%20USER()%0A%20%20%20%20)%3B%0A%20%20%20%20%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Version comparison
CREATE TABLE version_comparisons (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id VARCHAR(255) NOT NULL,
    version_from INT NOT NULL,
    version_to INT NOT NULL,
    
    -- Comparison results
    differences JSON NOT NULL,
    comparison_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    compared_by VARCHAR(100),
    
    INDEX idx_table_record (table_name, record_id),
    INDEX idx_versions (version_from, version_to)
);

DELIMITER //
-- Compare versions
CREATE PROCEDURE compare_versions(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_version_from INT,
    IN p_version_to INT
)
BEGIN
    DECLARE v_from_data JSON;
    DECLARE v_to_data JSON;
    DECLARE v_differences JSON;
    
    -- Get version data (simplified - would need dynamic SQL for real implementation)
    SELECT JSON_OBJECT(
        'name', name,
        'price', price,
        'category_id', category_id,
        'status', status
    ) INTO v_from_data
    FROM products
    WHERE id = p_record_id AND version_number = p_version_from;
    
    SELECT JSON_OBJECT(
        'name', name,
        'price', price,
        'category_id', category_id,
        'status', status
    ) INTO v_to_data
    FROM products
    WHERE id = p_record_id AND version_number = p_version_to;
    
    -- Calculate differences (simplified)
    SET v_differences = JSON_OBJECT(
        'from_version', p_version_from,
        'to_version', p_version_to,
        'from_data', v_from_data,
        'to_data', v_to_data,
        'changed_fields', JSON_ARRAY() -- Would contain actual field differences
    );
    
    -- Store comparison
    INSERT INTO version_comparisons (
        table_name, record_id, version_from, version_to, 
        differences, compared_by
    ) VALUES (
        p_table_name, p_record_id, p_version_from, p_version_to,
        v_differences, USER()
    );
    
    -- Return comparison results
    SELECT v_differences as comparison_result;
    
END //

-- Rollback to previous version
CREATE PROCEDURE rollback_to_version(
    IN p_table_name VARCHAR(100),
    IN p_record_id VARCHAR(255),
    IN p_target_version INT,
    IN p_rollback_reason VARCHAR(500)
)
BEGIN
    DECLARE v_version_data JSON;
    DECLARE v_current_version INT;
    
    -- Get target version data
    SET @get_version_sql = CONCAT(
        'SELECT JSON_OBJECT(',
        '''name'', name, ''price'', price, ''category_id'', category_id',
        ') FROM ', p_table_name,
        ' WHERE id = ', p_record_id, ' AND version_number = ', p_target_version
    );
    
    PREPARE stmt FROM @get_version_sql;
    EXECUTE stmt;
    -- Store in v_version_data
    DEALLOCATE PREPARE stmt;
    
    IF v_version_data IS NULL THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Target version not found';
    END IF;
    
    -- Create new version with old data
    CALL create_new_version(
        p_table_name, p_record_id, v_version_data, CURDATE(),
        CONCAT('Rollback to version ', p_target_version, ': ', p_rollback_reason)
    );
    
    -- Log rollback
    INSERT INTO rollback_log (
        table_name, record_id, target_version, rollback_reason,
        rollback_timestamp, rollback_user
    ) VALUES (
        p_table_name, p_record_id, p_target_version, p_rollback_reason,
        NOW(), USER()
    );
    
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>5. Temporal Queries:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Temporal%20query%20examples%0A--%20Point-in-time%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20AS%20OF%20'2024-01-01%2012%3A00%3A00'%3B%0A%0A--%20Range%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20FROM%20'2024-01-01'%20TO%20'2024-01-31'%3B%0A%0A--%20All%20versions%20query%0ASELECT%20*%20FROM%20customers%20%0AFOR%20SYSTEM_TIME%20ALL%0AWHERE%20id%20%3D%20123%0AORDER%20BY%20row_start%3B%0A%0A--%20Application%20versioning%20queries%0A--%20Current%20version%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20AND%20valid_to%20%3D%20'9999-12-31'%3B%0A%0A--%20Version%20at%20specific%20date%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20%0AAND%20valid_from%20%3C%3D%20'2024-01-15'%20%0AAND%20valid_to%20%3E%20'2024-01-15'%3B%0A%0A--%20All%20versions%0ASELECT%20*%20FROM%20products%20%0AWHERE%20id%20%3D%20123%20%0AORDER%20BY%20version_number%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Temporal query examples
-- Point-in-time query
SELECT * FROM customers 
FOR SYSTEM_TIME AS OF '2024-01-01 12:00:00';

-- Range query
SELECT * FROM customers 
FOR SYSTEM_TIME FROM '2024-01-01' TO '2024-01-31';

-- All versions query
SELECT * FROM customers 
FOR SYSTEM_TIME ALL
WHERE id = 123
ORDER BY row_start;

-- Application versioning queries
-- Current version
SELECT * FROM products 
WHERE id = 123 AND valid_to = '9999-12-31';

-- Version at specific date
SELECT * FROM products 
WHERE id = 123 
AND valid_from &lt;= '2024-01-15' 
AND valid_to &gt; '2024-01-15';

-- All versions
SELECT * FROM products 
WHERE id = 123 
ORDER BY version_number;
</code></pre>
</div>

<p>This completes the data versioning and change tracking implementation with comprehensive temporal data management, lineage tracking, and version control capabilities.</p>

<p>---</p>

<h2 id="-387-what-are-data-mesh-and-decentralized-data-architectures-">**387. What are data mesh and decentralized data architectures?**</h2>

<p><strong>Answer:</strong> Data mesh is a decentralized data architecture that treats data as products owned by domain teams, promoting distributed ownership while maintaining governance, discoverability, and interoperability across the organization.</p>

<p><strong>Data Mesh Architecture Implementation:</strong></p>

<p><strong>1. Domain Data Products:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20product%20registry%0ACREATE%20TABLE%20data_products%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20product_type%20ENUM('ANALYTICAL'%2C%20'OPERATIONAL'%2C%20'ML_FEATURE'%2C%20'REFERENCE')%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Product%20metadata%0A%20%20%20%20description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20business_purpose%20TEXT%2C%0A%20%20%20%20use_cases%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20product_owner%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_team%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20technical_contact%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Data%20characteristics%0A%20%20%20%20data_classification%20ENUM('PUBLIC'%2C%20'INTERNAL'%2C%20'CONFIDENTIAL'%2C%20'RESTRICTED')%2C%0A%20%20%20%20update_frequency%20ENUM('REAL_TIME'%2C%20'HOURLY'%2C%20'DAILY'%2C%20'WEEKLY'%2C%20'MONTHLY')%2C%0A%20%20%20%20data_retention_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20metrics%0A%20%20%20%20sla_availability%20DECIMAL(5%2C2)%2C%20--%2099.9%25%0A%20%20%20%20sla_freshness_hours%20INT%2C%0A%20%20%20%20quality_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Access%20information%0A%20%20%20%20access_patterns%20JSON%2C%0A%20%20%20%20api_endpoints%20JSON%2C%0A%20%20%20%20schema_registry_id%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%0A%20%20%20%20status%20ENUM('DEVELOPMENT'%2C%20'ACTIVE'%2C%20'DEPRECATED'%2C%20'RETIRED')%20DEFAULT%20'DEVELOPMENT'%2C%0A%20%20%20%20version%20VARCHAR(20)%20DEFAULT%20'1.0.0'%2C%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_product_name%20(product_name)%2C%0A%20%20%20%20INDEX%20idx_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_product_owner%20(product_owner)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A%0A--%20Domain%20boundaries%20and%20responsibilities%0ACREATE%20TABLE%20data_domains%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_name%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_description%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20domain_owner%20VARCHAR(100)%20NOT%20NULL%2C%0A%20%20%20%20domain_team_lead%20VARCHAR(100)%2C%0A%20%20%20%20team_members%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20context%0A%20%20%20%20business_capability%20VARCHAR(200)%2C%0A%20%20%20%20bounded_context%20TEXT%2C%0A%20%20%20%20key_entities%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20infrastructure%0A%20%20%20%20infrastructure_platform%20VARCHAR(100)%2C%0A%20%20%20%20data_storage_config%20JSON%2C%0A%20%20%20%20compute_resources%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20data_governance_policies%20JSON%2C%0A%20%20%20%20compliance_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_name%20(domain_name)%2C%0A%20%20%20%20INDEX%20idx_domain_owner%20(domain_owner)%0A)%3B%0A%0A--%20Data%20product%20contracts%20(API%20specifications)%0ACREATE%20TABLE%20data_product_contracts%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20contract_version%20VARCHAR(20)%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Schema%20definition%0A%20%20%20%20input_schema%20JSON%2C%0A%20%20%20%20output_schema%20JSON%2C%0A%20%20%20%20schema_evolution_strategy%20ENUM('BACKWARD_COMPATIBLE'%2C%20'FORWARD_COMPATIBLE'%2C%20'BREAKING')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Service%20level%20agreements%0A%20%20%20%20sla_definition%20JSON%20NOT%20NULL%2C%0A%20%20%20%20quality_guarantees%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Access%20patterns%0A%20%20%20%20supported_access_patterns%20JSON%2C%20--%20batch%2C%20streaming%2C%20query%2C%20etc.%0A%20%20%20%20rate_limits%20JSON%2C%0A%20%20%20%20authentication_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Documentation%0A%20%20%20%20api_documentation%20TEXT%2C%0A%20%20%20%20usage_examples%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lifecycle%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20deprecation_date%20DATE%2C%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_product_version%20(product_id%2C%20contract_version)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data product registry
CREATE TABLE data_products (
    id INT AUTO_INCREMENT PRIMARY KEY,
    product_name VARCHAR(200) NOT NULL,
    domain_name VARCHAR(100) NOT NULL,
    product_type ENUM('ANALYTICAL', 'OPERATIONAL', 'ML_FEATURE', 'REFERENCE') NOT NULL,
    
    -- Product metadata
    description TEXT NOT NULL,
    business_purpose TEXT,
    use_cases JSON,
    
    -- Ownership
    product_owner VARCHAR(100) NOT NULL,
    domain_team VARCHAR(100) NOT NULL,
    technical_contact VARCHAR(100),
    
    -- Data characteristics
    data_classification ENUM('PUBLIC', 'INTERNAL', 'CONFIDENTIAL', 'RESTRICTED'),
    update_frequency ENUM('REAL_TIME', 'HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY'),
    data_retention_days INT,
    
    -- Quality metrics
    sla_availability DECIMAL(5,2), -- 99.9%
    sla_freshness_hours INT,
    quality_score DECIMAL(3,2),
    
    -- Access information
    access_patterns JSON,
    api_endpoints JSON,
    schema_registry_id VARCHAR(100),
    
    -- Lifecycle
    status ENUM('DEVELOPMENT', 'ACTIVE', 'DEPRECATED', 'RETIRED') DEFAULT 'DEVELOPMENT',
    version VARCHAR(20) DEFAULT '1.0.0',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_product_name (product_name),
    INDEX idx_domain_name (domain_name),
    INDEX idx_product_owner (product_owner),
    INDEX idx_status (status)
);

-- Domain boundaries and responsibilities
CREATE TABLE data_domains (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_name VARCHAR(100) NOT NULL,
    domain_description TEXT,
    
    -- Ownership
    domain_owner VARCHAR(100) NOT NULL,
    domain_team_lead VARCHAR(100),
    team_members JSON,
    
    -- Business context
    business_capability VARCHAR(200),
    bounded_context TEXT,
    key_entities JSON,
    
    -- Technical infrastructure
    infrastructure_platform VARCHAR(100),
    data_storage_config JSON,
    compute_resources JSON,
    
    -- Governance
    data_governance_policies JSON,
    compliance_requirements JSON,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_domain_name (domain_name),
    INDEX idx_domain_owner (domain_owner)
);

-- Data product contracts (API specifications)
CREATE TABLE data_product_contracts (
    id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    contract_version VARCHAR(20) NOT NULL,
    
    -- Schema definition
    input_schema JSON,
    output_schema JSON,
    schema_evolution_strategy ENUM('BACKWARD_COMPATIBLE', 'FORWARD_COMPATIBLE', 'BREAKING'),
    
    -- Service level agreements
    sla_definition JSON NOT NULL,
    quality_guarantees JSON,
    
    -- Access patterns
    supported_access_patterns JSON, -- batch, streaming, query, etc.
    rate_limits JSON,
    authentication_requirements JSON,
    
    -- Documentation
    api_documentation TEXT,
    usage_examples JSON,
    
    -- Lifecycle
    effective_date DATE NOT NULL,
    deprecation_date DATE,
    is_active BOOLEAN DEFAULT TRUE,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    UNIQUE KEY uk_product_version (product_id, contract_version),
    INDEX idx_effective_date (effective_date)
);
</code></pre>
</div>

<p><strong>2. Federated Governance Implementation:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Global%20governance%20policies%0ACREATE%20TABLE%20global_governance_policies%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20policy_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20policy_category%20ENUM('DATA_QUALITY'%2C%20'SECURITY'%2C%20'PRIVACY'%2C%20'INTEROPERABILITY'%2C%20'DISCOVERABILITY')%2C%0A%20%20%20%20policy_level%20ENUM('MANDATORY'%2C%20'RECOMMENDED'%2C%20'OPTIONAL')%20DEFAULT%20'MANDATORY'%2C%0A%20%20%20%20%0A%20%20%20%20--%20Policy%20definition%0A%20%20%20%20policy_description%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20policy_rules%20JSON%20NOT%20NULL%2C%0A%20%20%20%20implementation_guidelines%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%0A%20%20%20%20compliance_check_automated%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20compliance_check_procedure%20VARCHAR(200)%2C%0A%20%20%20%20violation_consequences%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20policy_owner%20VARCHAR(100)%2C%0A%20%20%20%20approval_authority%20VARCHAR(100)%2C%0A%20%20%20%20effective_date%20DATE%20NOT%20NULL%2C%0A%20%20%20%20review_frequency_months%20INT%20DEFAULT%2012%2C%0A%20%20%20%20%0A%20%20%20%20created_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20updated_at%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_policy_name%20(policy_name)%2C%0A%20%20%20%20INDEX%20idx_policy_category%20(policy_category)%2C%0A%20%20%20%20INDEX%20idx_effective_date%20(effective_date)%0A)%3B%0A%0A--%20Domain-specific%20governance%20implementations%0ACREATE%20TABLE%20domain_governance_implementations%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20global_policy_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Implementation%20details%0A%20%20%20%20implementation_approach%20TEXT%2C%0A%20%20%20%20domain_specific_rules%20JSON%2C%0A%20%20%20%20monitoring_procedures%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Compliance%20status%0A%20%20%20%20compliance_status%20ENUM('COMPLIANT'%2C%20'PARTIAL'%2C%20'NON_COMPLIANT'%2C%20'NOT_ASSESSED')%2C%0A%20%20%20%20last_assessment_date%20DATE%2C%0A%20%20%20%20assessment_notes%20TEXT%2C%0A%20%20%20%20remediation_plan%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20implementation_owner%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(global_policy_id)%20REFERENCES%20global_governance_policies(id)%2C%0A%20%20%20%20UNIQUE%20KEY%20uk_domain_policy%20(domain_id%2C%20global_policy_id)%2C%0A%20%20%20%20INDEX%20idx_compliance_status%20(compliance_status)%0A)%3B%0A%0A--%20Self-serve%20data%20platform%20capabilities%0ACREATE%20TABLE%20platform_capabilities%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20capability_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20capability_type%20ENUM('INFRASTRUCTURE'%2C%20'TOOLING'%2C%20'GOVERNANCE'%2C%20'MONITORING')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Capability%20description%0A%20%20%20%20description%20TEXT%2C%0A%20%20%20%20technical_specifications%20JSON%2C%0A%20%20%20%20usage_documentation%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Service%20details%0A%20%20%20%20service_endpoints%20JSON%2C%0A%20%20%20%20api_documentation_url%20VARCHAR(500)%2C%0A%20%20%20%20support_contact%20VARCHAR(100)%2C%0A%20%20%20%20%0A%20%20%20%20--%20SLA%0A%20%20%20%20availability_sla%20DECIMAL(5%2C2)%2C%0A%20%20%20%20performance_sla%20JSON%2C%0A%20%20%20%20support_sla%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20tracking%0A%20%20%20%20active_users_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20usage_metrics%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20status%20ENUM('AVAILABLE'%2C%20'BETA'%2C%20'DEPRECATED'%2C%20'MAINTENANCE')%20DEFAULT%20'AVAILABLE'%2C%0A%20%20%20%20%0A%20%20%20%20UNIQUE%20KEY%20uk_capability_name%20(capability_name)%2C%0A%20%20%20%20INDEX%20idx_capability_type%20(capability_type)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Global governance policies
CREATE TABLE global_governance_policies (
    id INT AUTO_INCREMENT PRIMARY KEY,
    policy_name VARCHAR(200) NOT NULL,
    policy_category ENUM('DATA_QUALITY', 'SECURITY', 'PRIVACY', 'INTEROPERABILITY', 'DISCOVERABILITY'),
    policy_level ENUM('MANDATORY', 'RECOMMENDED', 'OPTIONAL') DEFAULT 'MANDATORY',
    
    -- Policy definition
    policy_description TEXT NOT NULL,
    policy_rules JSON NOT NULL,
    implementation_guidelines TEXT,
    
    -- Compliance
    compliance_check_automated BOOLEAN DEFAULT FALSE,
    compliance_check_procedure VARCHAR(200),
    violation_consequences TEXT,
    
    -- Governance
    policy_owner VARCHAR(100),
    approval_authority VARCHAR(100),
    effective_date DATE NOT NULL,
    review_frequency_months INT DEFAULT 12,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_policy_name (policy_name),
    INDEX idx_policy_category (policy_category),
    INDEX idx_effective_date (effective_date)
);

-- Domain-specific governance implementations
CREATE TABLE domain_governance_implementations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_id INT NOT NULL,
    global_policy_id INT NOT NULL,
    
    -- Implementation details
    implementation_approach TEXT,
    domain_specific_rules JSON,
    monitoring_procedures TEXT,
    
    -- Compliance status
    compliance_status ENUM('COMPLIANT', 'PARTIAL', 'NON_COMPLIANT', 'NOT_ASSESSED'),
    last_assessment_date DATE,
    assessment_notes TEXT,
    remediation_plan TEXT,
    
    -- Ownership
    implementation_owner VARCHAR(100),
    
    FOREIGN KEY (domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (global_policy_id) REFERENCES global_governance_policies(id),
    UNIQUE KEY uk_domain_policy (domain_id, global_policy_id),
    INDEX idx_compliance_status (compliance_status)
);

-- Self-serve data platform capabilities
CREATE TABLE platform_capabilities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    capability_name VARCHAR(200) NOT NULL,
    capability_type ENUM('INFRASTRUCTURE', 'TOOLING', 'GOVERNANCE', 'MONITORING'),
    
    -- Capability description
    description TEXT,
    technical_specifications JSON,
    usage_documentation TEXT,
    
    -- Service details
    service_endpoints JSON,
    api_documentation_url VARCHAR(500),
    support_contact VARCHAR(100),
    
    -- SLA
    availability_sla DECIMAL(5,2),
    performance_sla JSON,
    support_sla TEXT,
    
    -- Usage tracking
    active_users_count INT DEFAULT 0,
    usage_metrics JSON,
    
    status ENUM('AVAILABLE', 'BETA', 'DEPRECATED', 'MAINTENANCE') DEFAULT 'AVAILABLE',
    
    UNIQUE KEY uk_capability_name (capability_name),
    INDEX idx_capability_type (capability_type),
    INDEX idx_status (status)
);
</code></pre>
</div>

<p><strong>3. Data Product Discovery and Catalog:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Federated%20data%20catalog%0ACREATE%20TABLE%20federated_data_catalog%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Discoverability%20metadata%0A%20%20%20%20searchable_tags%20JSON%2C%0A%20%20%20%20business_glossary_terms%20JSON%2C%0A%20%20%20%20semantic_annotations%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20information%0A%20%20%20%20consumer_applications%20JSON%2C%0A%20%20%20%20usage_patterns%20JSON%2C%0A%20%20%20%20access_frequency_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20indicators%0A%20%20%20%20data_quality_metrics%20JSON%2C%0A%20%20%20%20freshness_indicators%20JSON%2C%0A%20%20%20%20completeness_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20accuracy_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Lineage%20information%0A%20%20%20%20upstream_dependencies%20JSON%2C%0A%20%20%20%20downstream_consumers%20JSON%2C%0A%20%20%20%20transformation_lineage%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Social%20features%0A%20%20%20%20user_ratings%20DECIMAL(3%2C2)%2C%0A%20%20%20%20user_reviews%20JSON%2C%0A%20%20%20%20bookmark_count%20INT%20DEFAULT%200%2C%0A%20%20%20%20%0A%20%20%20%20--%20Search%20optimization%0A%20%20%20%20search_vector%20TEXT%2C%20--%20For%20full-text%20search%0A%20%20%20%20popularity_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20last_updated%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%20ON%20UPDATE%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_id%20(product_id)%2C%0A%20%20%20%20INDEX%20idx_popularity_score%20(popularity_score)%2C%0A%20%20%20%20FULLTEXT%20idx_search_vector%20(search_vector)%0A)%3B%0A%0A--%20Data%20product%20discovery%20procedures%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20discover_data_products(%0A%20%20%20%20IN%20p_search_term%20VARCHAR(500)%2C%0A%20%20%20%20IN%20p_domain_filter%20VARCHAR(100)%2C%0A%20%20%20%20IN%20p_data_type_filter%20VARCHAR(50)%2C%0A%20%20%20%20IN%20p_quality_threshold%20DECIMAL(3%2C2)%0A)%0ABEGIN%0A%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20dp.id%2C%0A%20%20%20%20%20%20%20%20dp.product_name%2C%0A%20%20%20%20%20%20%20%20dp.domain_name%2C%0A%20%20%20%20%20%20%20%20dp.description%2C%0A%20%20%20%20%20%20%20%20dp.product_owner%2C%0A%20%20%20%20%20%20%20%20dp.quality_score%2C%0A%20%20%20%20%20%20%20%20dp.update_frequency%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Catalog%20enrichment%0A%20%20%20%20%20%20%20%20fdc.popularity_score%2C%0A%20%20%20%20%20%20%20%20fdc.user_ratings%2C%0A%20%20%20%20%20%20%20%20fdc.access_frequency_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Relevance%20scoring%0A%20%20%20%20%20%20%20%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dp.product_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%2010%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20dp.description%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20THEN%205%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20CASE%20WHEN%20MATCH(fdc.search_vector)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%20THEN%203%20ELSE%200%20END%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20fdc.popularity_score%0A%20%20%20%20%20%20%20%20)%20as%20relevance_score%2C%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Usage%20indicators%0A%20%20%20%20%20%20%20%20JSON_LENGTH(fdc.consumer_applications)%20as%20consumer_count%2C%0A%20%20%20%20%20%20%20%20fdc.bookmark_count%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20FROM%20data_products%20dp%0A%20%20%20%20JOIN%20federated_data_catalog%20fdc%20ON%20dp.id%20%3D%20fdc.product_id%0A%20%20%20%20WHERE%20dp.status%20%3D%20'ACTIVE'%0A%20%20%20%20AND%20(p_domain_filter%20IS%20NULL%20OR%20dp.domain_name%20%3D%20p_domain_filter)%0A%20%20%20%20AND%20(p_data_type_filter%20IS%20NULL%20OR%20dp.product_type%20%3D%20p_data_type_filter)%0A%20%20%20%20AND%20(p_quality_threshold%20IS%20NULL%20OR%20dp.quality_score%20%3E%3D%20p_quality_threshold)%0A%20%20%20%20AND%20(%0A%20%20%20%20%20%20%20%20p_search_term%20IS%20NULL%20OR%0A%20%20%20%20%20%20%20%20dp.product_name%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20dp.description%20LIKE%20CONCAT('%25'%2C%20p_search_term%2C%20'%25')%20OR%0A%20%20%20%20%20%20%20%20MATCH(fdc.search_vector)%20AGAINST(p_search_term%20IN%20NATURAL%20LANGUAGE%20MODE)%0A%20%20%20%20)%0A%20%20%20%20%0A%20%20%20%20HAVING%20relevance_score%20%3E%200%0A%20%20%20%20ORDER%20BY%20relevance_score%20DESC%2C%20fdc.popularity_score%20DESC%0A%20%20%20%20LIMIT%2050%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Federated data catalog
CREATE TABLE federated_data_catalog (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    
    -- Discoverability metadata
    searchable_tags JSON,
    business_glossary_terms JSON,
    semantic_annotations JSON,
    
    -- Usage information
    consumer_applications JSON,
    usage_patterns JSON,
    access_frequency_score DECIMAL(5,2),
    
    -- Quality indicators
    data_quality_metrics JSON,
    freshness_indicators JSON,
    completeness_score DECIMAL(3,2),
    accuracy_score DECIMAL(3,2),
    
    -- Lineage information
    upstream_dependencies JSON,
    downstream_consumers JSON,
    transformation_lineage JSON,
    
    -- Social features
    user_ratings DECIMAL(3,2),
    user_reviews JSON,
    bookmark_count INT DEFAULT 0,
    
    -- Search optimization
    search_vector TEXT, -- For full-text search
    popularity_score DECIMAL(5,2),
    
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_id (product_id),
    INDEX idx_popularity_score (popularity_score),
    FULLTEXT idx_search_vector (search_vector)
);

-- Data product discovery procedures
DELIMITER //
CREATE PROCEDURE discover_data_products(
    IN p_search_term VARCHAR(500),
    IN p_domain_filter VARCHAR(100),
    IN p_data_type_filter VARCHAR(50),
    IN p_quality_threshold DECIMAL(3,2)
)
BEGIN
    SELECT 
        dp.id,
        dp.product_name,
        dp.domain_name,
        dp.description,
        dp.product_owner,
        dp.quality_score,
        dp.update_frequency,
        
        -- Catalog enrichment
        fdc.popularity_score,
        fdc.user_ratings,
        fdc.access_frequency_score,
        
        -- Relevance scoring
        (
            CASE WHEN dp.product_name LIKE CONCAT('%', p_search_term, '%') THEN 10 ELSE 0 END +
            CASE WHEN dp.description LIKE CONCAT('%', p_search_term, '%') THEN 5 ELSE 0 END +
            CASE WHEN MATCH(fdc.search_vector) AGAINST(p_search_term IN NATURAL LANGUAGE MODE) THEN 3 ELSE 0 END +
            fdc.popularity_score
        ) as relevance_score,
        
        -- Usage indicators
        JSON_LENGTH(fdc.consumer_applications) as consumer_count,
        fdc.bookmark_count
        
    FROM data_products dp
    JOIN federated_data_catalog fdc ON dp.id = fdc.product_id
    WHERE dp.status = 'ACTIVE'
    AND (p_domain_filter IS NULL OR dp.domain_name = p_domain_filter)
    AND (p_data_type_filter IS NULL OR dp.product_type = p_data_type_filter)
    AND (p_quality_threshold IS NULL OR dp.quality_score &gt;= p_quality_threshold)
    AND (
        p_search_term IS NULL OR
        dp.product_name LIKE CONCAT('%', p_search_term, '%') OR
        dp.description LIKE CONCAT('%', p_search_term, '%') OR
        MATCH(fdc.search_vector) AGAINST(p_search_term IN NATURAL LANGUAGE MODE)
    )
    
    HAVING relevance_score &gt; 0
    ORDER BY relevance_score DESC, fdc.popularity_score DESC
    LIMIT 50;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>4. Data Product Lifecycle Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Data%20product%20lifecycle%20tracking%0ACREATE%20TABLE%20data_product_lifecycle%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20lifecycle_stage%20ENUM('IDEATION'%2C%20'DEVELOPMENT'%2C%20'TESTING'%2C%20'PRODUCTION'%2C%20'MAINTENANCE'%2C%20'DEPRECATION'%2C%20'RETIREMENT')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stage%20details%0A%20%20%20%20stage_entry_date%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20stage_exit_date%20TIMESTAMP%20NULL%2C%0A%20%20%20%20stage_duration_days%20INT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stage-specific%20metadata%0A%20%20%20%20stage_artifacts%20JSON%2C%0A%20%20%20%20quality_gates_passed%20JSON%2C%0A%20%20%20%20approval_checkpoints%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Stakeholder%20involvement%0A%20%20%20%20stage_owner%20VARCHAR(100)%2C%0A%20%20%20%20reviewers%20JSON%2C%0A%20%20%20%20approvers%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Notes%20and%20documentation%0A%20%20%20%20stage_notes%20TEXT%2C%0A%20%20%20%20lessons_learned%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_stage%20(product_id%2C%20lifecycle_stage)%2C%0A%20%20%20%20INDEX%20idx_stage_entry_date%20(stage_entry_date)%0A)%3B%0A%0A--%20Data%20product%20metrics%20and%20monitoring%0ACREATE%20TABLE%20data_product_metrics%20(%0A%20%20%20%20id%20BIGINT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20metric_timestamp%20TIMESTAMP%20DEFAULT%20CURRENT_TIMESTAMP%2C%0A%20%20%20%20%0A%20%20%20%20--%20Usage%20metrics%0A%20%20%20%20daily_active_consumers%20INT%2C%0A%20%20%20%20api_request_count%20BIGINT%2C%0A%20%20%20%20data_volume_gb%20DECIMAL(12%2C2)%2C%0A%20%20%20%20query_response_time_ms%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Quality%20metrics%0A%20%20%20%20data_freshness_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20completeness_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20accuracy_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20consistency_score%20DECIMAL(3%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Business%20metrics%0A%20%20%20%20business_value_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20cost_per_query%20DECIMAL(10%2C4)%2C%0A%20%20%20%20revenue_attribution%20DECIMAL(12%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Technical%20metrics%0A%20%20%20%20availability_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20error_rate_percentage%20DECIMAL(5%2C2)%2C%0A%20%20%20%20infrastructure_cost%20DECIMAL(10%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_product_timestamp%20(product_id%2C%20metric_timestamp)%2C%0A%20%20%20%20INDEX%20idx_metric_timestamp%20(metric_timestamp)%0A)%3B%0A%0A--%20Cross-domain%20data%20sharing%20agreements%0ACREATE%20TABLE%20data_sharing_agreements%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20provider_domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20consumer_domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20%0A%20%20%20%20--%20Agreement%20details%0A%20%20%20%20agreement_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20sharing_purpose%20TEXT%2C%0A%20%20%20%20data_usage_restrictions%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Terms%20and%20conditions%0A%20%20%20%20sla_terms%20JSON%2C%0A%20%20%20%20data_retention_terms%20TEXT%2C%0A%20%20%20%20privacy_requirements%20JSON%2C%0A%20%20%20%20security_requirements%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Commercial%20terms%0A%20%20%20%20cost_model%20ENUM('FREE'%2C%20'USAGE_BASED'%2C%20'SUBSCRIPTION'%2C%20'CUSTOM')%2C%0A%20%20%20%20pricing_details%20JSON%2C%0A%20%20%20%20%0A%20%20%20%20--%20Governance%0A%20%20%20%20agreement_owner%20VARCHAR(100)%2C%0A%20%20%20%20legal_review_status%20ENUM('PENDING'%2C%20'APPROVED'%2C%20'REJECTED')%2C%0A%20%20%20%20effective_date%20DATE%2C%0A%20%20%20%20expiry_date%20DATE%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20status%20ENUM('DRAFT'%2C%20'ACTIVE'%2C%20'SUSPENDED'%2C%20'TERMINATED')%20DEFAULT%20'DRAFT'%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(provider_domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(consumer_domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_provider_consumer%20(provider_domain_id%2C%20consumer_domain_id)%2C%0A%20%20%20%20INDEX%20idx_status%20(status)%0A)%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Data product lifecycle tracking
CREATE TABLE data_product_lifecycle (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    lifecycle_stage ENUM('IDEATION', 'DEVELOPMENT', 'TESTING', 'PRODUCTION', 'MAINTENANCE', 'DEPRECATION', 'RETIREMENT'),
    
    -- Stage details
    stage_entry_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    stage_exit_date TIMESTAMP NULL,
    stage_duration_days INT,
    
    -- Stage-specific metadata
    stage_artifacts JSON,
    quality_gates_passed JSON,
    approval_checkpoints JSON,
    
    -- Stakeholder involvement
    stage_owner VARCHAR(100),
    reviewers JSON,
    approvers JSON,
    
    -- Notes and documentation
    stage_notes TEXT,
    lessons_learned TEXT,
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_stage (product_id, lifecycle_stage),
    INDEX idx_stage_entry_date (stage_entry_date)
);

-- Data product metrics and monitoring
CREATE TABLE data_product_metrics (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    product_id INT NOT NULL,
    metric_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Usage metrics
    daily_active_consumers INT,
    api_request_count BIGINT,
    data_volume_gb DECIMAL(12,2),
    query_response_time_ms DECIMAL(10,2),
    
    -- Quality metrics
    data_freshness_score DECIMAL(3,2),
    completeness_percentage DECIMAL(5,2),
    accuracy_percentage DECIMAL(5,2),
    consistency_score DECIMAL(3,2),
    
    -- Business metrics
    business_value_score DECIMAL(5,2),
    cost_per_query DECIMAL(10,4),
    revenue_attribution DECIMAL(12,2),
    
    -- Technical metrics
    availability_percentage DECIMAL(5,2),
    error_rate_percentage DECIMAL(5,2),
    infrastructure_cost DECIMAL(10,2),
    
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_product_timestamp (product_id, metric_timestamp),
    INDEX idx_metric_timestamp (metric_timestamp)
);

-- Cross-domain data sharing agreements
CREATE TABLE data_sharing_agreements (
    id INT AUTO_INCREMENT PRIMARY KEY,
    provider_domain_id INT NOT NULL,
    consumer_domain_id INT NOT NULL,
    product_id INT NOT NULL,
    
    -- Agreement details
    agreement_name VARCHAR(200) NOT NULL,
    sharing_purpose TEXT,
    data_usage_restrictions JSON,
    
    -- Terms and conditions
    sla_terms JSON,
    data_retention_terms TEXT,
    privacy_requirements JSON,
    security_requirements JSON,
    
    -- Commercial terms
    cost_model ENUM('FREE', 'USAGE_BASED', 'SUBSCRIPTION', 'CUSTOM'),
    pricing_details JSON,
    
    -- Governance
    agreement_owner VARCHAR(100),
    legal_review_status ENUM('PENDING', 'APPROVED', 'REJECTED'),
    effective_date DATE,
    expiry_date DATE,
    
    -- Status
    status ENUM('DRAFT', 'ACTIVE', 'SUSPENDED', 'TERMINATED') DEFAULT 'DRAFT',
    
    FOREIGN KEY (provider_domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (consumer_domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_provider_consumer (provider_domain_id, consumer_domain_id),
    INDEX idx_status (status)
);
</code></pre>
</div>

<p><strong>5. Decentralized Data Quality Management:</strong></p>


<div class="code-container">
    <div class="code-header">
        <span class="code-language">sql</span>
        <button class="copy-btn" data-code="--%20Domain-specific%20data%20quality%20rules%0ACREATE%20TABLE%20domain_quality_rules%20(%0A%20%20%20%20id%20INT%20AUTO_INCREMENT%20PRIMARY%20KEY%2C%0A%20%20%20%20domain_id%20INT%20NOT%20NULL%2C%0A%20%20%20%20product_id%20INT%2C%0A%20%20%20%20rule_name%20VARCHAR(200)%20NOT%20NULL%2C%0A%20%20%20%20rule_category%20ENUM('COMPLETENESS'%2C%20'ACCURACY'%2C%20'CONSISTENCY'%2C%20'TIMELINESS'%2C%20'VALIDITY')%2C%0A%20%20%20%20%0A%20%20%20%20--%20Rule%20definition%0A%20%20%20%20rule_expression%20TEXT%20NOT%20NULL%2C%0A%20%20%20%20rule_parameters%20JSON%2C%0A%20%20%20%20expected_threshold%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20--%20Implementation%0A%20%20%20%20check_frequency%20ENUM('REAL_TIME'%2C%20'HOURLY'%2C%20'DAILY'%2C%20'WEEKLY')%2C%0A%20%20%20%20automated_remediation%20BOOLEAN%20DEFAULT%20FALSE%2C%0A%20%20%20%20remediation_procedure%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Ownership%0A%20%20%20%20rule_owner%20VARCHAR(100)%2C%0A%20%20%20%20business_justification%20TEXT%2C%0A%20%20%20%20%0A%20%20%20%20--%20Status%0A%20%20%20%20is_active%20BOOLEAN%20DEFAULT%20TRUE%2C%0A%20%20%20%20last_execution%20TIMESTAMP%2C%0A%20%20%20%20last_result%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%0A%20%20%20%20FOREIGN%20KEY%20(domain_id)%20REFERENCES%20data_domains(id)%2C%0A%20%20%20%20FOREIGN%20KEY%20(product_id)%20REFERENCES%20data_products(id)%2C%0A%20%20%20%20INDEX%20idx_domain_product%20(domain_id%2C%20product_id)%2C%0A%20%20%20%20INDEX%20idx_rule_category%20(rule_category)%0A)%3B%0A%0A--%20Federated%20data%20quality%20monitoring%0ADELIMITER%20%2F%2F%0ACREATE%20PROCEDURE%20monitor_federated_data_quality()%0ABEGIN%0A%20%20%20%20DECLARE%20done%20BOOLEAN%20DEFAULT%20FALSE%3B%0A%20%20%20%20DECLARE%20v_domain_id%20INT%3B%0A%20%20%20%20DECLARE%20v_domain_name%20VARCHAR(100)%3B%0A%20%20%20%20DECLARE%20v_quality_score%20DECIMAL(5%2C2)%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20domain_cursor%20CURSOR%20FOR%0A%20%20%20%20%20%20%20%20SELECT%20id%2C%20domain_name%20FROM%20data_domains%20WHERE%20status%20%3D%20'ACTIVE'%3B%0A%20%20%20%20%0A%20%20%20%20DECLARE%20CONTINUE%20HANDLER%20FOR%20NOT%20FOUND%20SET%20done%20%3D%20TRUE%3B%0A%20%20%20%20%0A%20%20%20%20--%20Create%20temporary%20results%20table%0A%20%20%20%20CREATE%20TEMPORARY%20TABLE%20quality_summary%20(%0A%20%20%20%20%20%20%20%20domain_name%20VARCHAR(100)%2C%0A%20%20%20%20%20%20%20%20total_products%20INT%2C%0A%20%20%20%20%20%20%20%20avg_quality_score%20DECIMAL(5%2C2)%2C%0A%20%20%20%20%20%20%20%20products_below_threshold%20INT%2C%0A%20%20%20%20%20%20%20%20critical_issues%20INT%0A%20%20%20%20)%3B%0A%20%20%20%20%0A%20%20%20%20OPEN%20domain_cursor%3B%0A%20%20%20%20%0A%20%20%20%20quality_loop%3A%20LOOP%0A%20%20%20%20%20%20%20%20FETCH%20domain_cursor%20INTO%20v_domain_id%2C%20v_domain_name%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20IF%20done%20THEN%0A%20%20%20%20%20%20%20%20%20%20%20%20LEAVE%20quality_loop%3B%0A%20%20%20%20%20%20%20%20END%20IF%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20--%20Calculate%20domain%20quality%20metrics%0A%20%20%20%20%20%20%20%20SELECT%20%0A%20%20%20%20%20%20%20%20%20%20%20%20COUNT(*)%20as%20total_products%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20AVG(quality_score)%20as%20avg_quality%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20quality_score%20%3C%200.8%20THEN%201%20ELSE%200%20END)%20as%20below_threshold%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20SUM(CASE%20WHEN%20quality_score%20%3C%200.6%20THEN%201%20ELSE%200%20END)%20as%20critical_issues%0A%20%20%20%20%20%20%20%20INTO%20%40total%2C%20%40avg_quality%2C%20%40below_threshold%2C%20%40critical%0A%20%20%20%20%20%20%20%20FROM%20data_products%0A%20%20%20%20%20%20%20%20WHERE%20domain_name%20%3D%20v_domain_name%20AND%20status%20%3D%20'ACTIVE'%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20quality_summary%20VALUES%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20v_domain_name%2C%20%40total%2C%20%40avg_quality%2C%20%40below_threshold%2C%20%40critical%0A%20%20%20%20%20%20%20%20)%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20END%20LOOP%3B%0A%20%20%20%20%0A%20%20%20%20CLOSE%20domain_cursor%3B%0A%20%20%20%20%0A%20%20%20%20--%20Return%20federated%20quality%20summary%0A%20%20%20%20SELECT%20*%20FROM%20quality_summary%20ORDER%20BY%20avg_quality_score%20DESC%3B%0A%20%20%20%20%0A%20%20%20%20DROP%20TEMPORARY%20TABLE%20quality_summary%3B%0AEND%20%2F%2F%0A%0ADELIMITER%20%3B%0A">Copy</button>
    </div>
    <pre><code class="language-sql">-- Domain-specific data quality rules
CREATE TABLE domain_quality_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    domain_id INT NOT NULL,
    product_id INT,
    rule_name VARCHAR(200) NOT NULL,
    rule_category ENUM('COMPLETENESS', 'ACCURACY', 'CONSISTENCY', 'TIMELINESS', 'VALIDITY'),
    
    -- Rule definition
    rule_expression TEXT NOT NULL,
    rule_parameters JSON,
    expected_threshold DECIMAL(5,2),
    
    -- Implementation
    check_frequency ENUM('REAL_TIME', 'HOURLY', 'DAILY', 'WEEKLY'),
    automated_remediation BOOLEAN DEFAULT FALSE,
    remediation_procedure TEXT,
    
    -- Ownership
    rule_owner VARCHAR(100),
    business_justification TEXT,
    
    -- Status
    is_active BOOLEAN DEFAULT TRUE,
    last_execution TIMESTAMP,
    last_result DECIMAL(5,2),
    
    FOREIGN KEY (domain_id) REFERENCES data_domains(id),
    FOREIGN KEY (product_id) REFERENCES data_products(id),
    INDEX idx_domain_product (domain_id, product_id),
    INDEX idx_rule_category (rule_category)
);

-- Federated data quality monitoring
DELIMITER //
CREATE PROCEDURE monitor_federated_data_quality()
BEGIN
    DECLARE done BOOLEAN DEFAULT FALSE;
    DECLARE v_domain_id INT;
    DECLARE v_domain_name VARCHAR(100);
    DECLARE v_quality_score DECIMAL(5,2);
    
    DECLARE domain_cursor CURSOR FOR
        SELECT id, domain_name FROM data_domains WHERE status = 'ACTIVE';
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    
    -- Create temporary results table
    CREATE TEMPORARY TABLE quality_summary (
        domain_name VARCHAR(100),
        total_products INT,
        avg_quality_score DECIMAL(5,2),
        products_below_threshold INT,
        critical_issues INT
    );
    
    OPEN domain_cursor;
    
    quality_loop: LOOP
        FETCH domain_cursor INTO v_domain_id, v_domain_name;
        
        IF done THEN
            LEAVE quality_loop;
        END IF;
        
        -- Calculate domain quality metrics
        SELECT 
            COUNT(*) as total_products,
            AVG(quality_score) as avg_quality,
            SUM(CASE WHEN quality_score &lt; 0.8 THEN 1 ELSE 0 END) as below_threshold,
            SUM(CASE WHEN quality_score &lt; 0.6 THEN 1 ELSE 0 END) as critical_issues
        INTO @total, @avg_quality, @below_threshold, @critical
        FROM data_products
        WHERE domain_name = v_domain_name AND status = 'ACTIVE';
        
        INSERT INTO quality_summary VALUES (
            v_domain_name, @total, @avg_quality, @below_threshold, @critical
        );
        
    END LOOP;
    
    CLOSE domain_cursor;
    
    -- Return federated quality summary
    SELECT * FROM quality_summary ORDER BY avg_quality_score DESC;
    
    DROP TEMPORARY TABLE quality_summary;
END //

DELIMITER ;
</code></pre>
</div>

<p><strong>Key Data Mesh Principles:</strong></p>

<p>- <strong>Domain Ownership</strong>: Each domain owns and operates their data products</p>
<p>- <strong>Data as a Product</strong>: Treat data with product thinking - quality, usability, discoverability</p>
<p>- <strong>Self-Serve Data Platform</strong>: Provide infrastructure and tools for domain autonomy</p>
<p>- <strong>Federated Computational Governance</strong>: Balance autonomy with global standards</p>


            </div>
        </main>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        
        // Initialize TOC
        document.getElementById('toc-list').innerHTML = `<li><a href="#-321-what-are-indexes-and-how-do-they-work-" class="h2-link">**321. What are indexes and how do they work?**</a></li><li><a href="#-322-what-are-the-different-types-of-indexes-in-mysql-" class="h2-link">**322. What are the different types of indexes in MySQL?**</a></li><li><a href="#-323-how-do-you-create-and-optimize-composite-indexes-" class="h2-link">**323. How do you create and optimize composite indexes?**</a></li><li><a href="#-324-what-is-the-difference-between-clustered-and-non-clustered-indexes-" class="h2-link">**324. What is the difference between clustered and non-clustered indexes?**</a></li><li><a href="#-325-how-do-you-analyze-index-usage-and-effectiveness-" class="h2-link">**325. How do you analyze index usage and effectiveness?**</a></li><li><a href="#-326-what-is-index-cardinality-and-why-is-it-important-" class="h2-link">**326. What is index cardinality and why is it important?**</a></li><li><a href="#-327-how-do-you-handle-index-maintenance-and-rebuilding-" class="h2-link">**327. How do you handle index maintenance and rebuilding?**</a></li><li><a href="#-328-what-are-covering-indexes-and-when-do-you-use-them-" class="h2-link">**328. What are covering indexes and when do you use them?**</a></li><li><a href="#-329-how-do-you-implement-full-text-search-indexes-" class="h2-link">**329. How do you implement full-text search indexes?**</a></li><li><a href="#-330-what-is-the-impact-of-indexes-on-insert-update-delete-operations-" class="h2-link">**330. What is the impact of indexes on INSERT/UPDATE/DELETE operations?**</a></li><li><a href="#-331-how-do-you-optimize-queries-using-explain-" class="h2-link">**331. How do you optimize queries using EXPLAIN?**</a></li><li><a href="#-332-what-are-query-execution-plans-and-how-do-you-read-them-" class="h2-link">**332. What are query execution plans and how do you read them?**</a></li><li><a href="#-333-how-do-you-handle-index-hints-and-force-index-usage-" class="h2-link">**333. How do you handle index hints and force index usage?**</a></li><li><a href="#-334-what-is-index-selectivity-and-how-do-you-calculate-it-" class="h2-link">**334. What is index selectivity and how do you calculate it?**</a></li><li><a href="#-335-how-do-you-optimize-order-by-and-group-by-clauses-" class="h2-link">**335. How do you optimize ORDER BY and GROUP BY clauses?**</a></li><li><a href="#-336-what-are-partial-indexes-and-when-do-you-use-them-" class="h2-link">**336. What are partial indexes and when do you use them?**</a></li><li><a href="#-337-how-do-you-handle-index-fragmentation-" class="h2-link">**337. How do you handle index fragmentation?**</a></li><li><a href="#-338-what-is-the-difference-between-b-tree-and-hash-indexes-" class="h2-link">**338. What is the difference between B-tree and Hash indexes?**</a></li><li><a href="#-339-how-do-you-optimize-joins-using-indexes-" class="h2-link">**339. How do you optimize joins using indexes?**</a></li><li><a href="#-340-what-are-invisible-indexes-and-their-use-cases-" class="h2-link">**340. What are invisible indexes and their use cases?**</a></li><li><a href="#-341-how-do-you-monitor-index-performance-and-usage-" class="h2-link">**341. How do you monitor index performance and usage?**</a></li><li><a href="#-342-what-are-functional-indexes-and-how-do-you-implement-them-" class="h2-link">**342. What are functional indexes and how do you implement them?**</a></li><li><a href="#-343-how-do-you-handle-index-bloat-and-maintenance-" class="h2-link">**343. How do you handle index bloat and maintenance?**</a></li><li><a href="#-344-what-is-index-intersection-and-how-does-it-work-" class="h2-link">**344. What is index intersection and how does it work?**</a></li><li><a href="#-345-how-do-you-optimize-database-schema-for-better-index-performance-" class="h2-link">**345. How do you optimize database schema for better index performance?**</a></li><li><a href="#-346-what-are-stored-procedures-and-their-advantages-disadvantages-" class="h2-link">**346. What are stored procedures and their advantages/disadvantages?**</a></li><li><a href="#-347-how-do-you-implement-and-use-triggers-" class="h2-link">**347. How do you implement and use triggers?**</a></li><li><a href="#-348-what-are-views-and-materialized-views-" class="h2-link">**348. What are views and materialized views?**</a></li><li><a href="#-349-how-do-you-work-with-json-data-in-mysql-" class="h2-link">**349. How do you work with JSON data in MySQL?**</a></li><li><a href="#-350-what-are-window-functions-and-how-do-you-use-them-" class="h2-link">**350. What are window functions and how do you use them?**</a></li><li><a href="#-351-how-do-you-implement-recursive-queries-with-ctes-" class="h2-link">**351. How do you implement recursive queries with CTEs?**</a></li><li><a href="#-352-what-are-user-defined-functions-udfs-" class="h2-link">**352. What are user-defined functions (UDFs)?**</a></li><li><a href="#-353-how-do-you-work-with-temporary-tables-" class="h2-link">**353. How do you work with temporary tables?**</a></li><li><a href="#-354-what-are-database-events-and-how-do-you-schedule-them-" class="h2-link">**354. What are database events and how do you schedule them?**</a></li><li><a href="#-355-how-do-you-implement-database-partitioning-" class="h2-link">**355. How do you implement database partitioning?**</a></li><li><a href="#-356-what-are-database-constraints-and-their-types-" class="h2-link">**356. What are database constraints and their types?**</a></li><li><a href="#-357-how-do-you-work-with-database-transactions-and-isolation-levels-" class="h2-link">**357. How do you work with database transactions and isolation levels?**</a></li><li><a href="#-358-what-are-database-triggers-for-auditing-and-logging-" class="h2-link">**358. What are database triggers for auditing and logging?**</a></li><li><a href="#-359-how-do-you-implement-database-replication-" class="h2-link">**359. How do you implement database replication?**</a></li><li><a href="#-360-what-are-database-locks-and-deadlock-handling-" class="h2-link">**360. What are database locks and deadlock handling?**</a></li><li><a href="#-361-what-are-database-synonyms-and-aliases-" class="h2-link">**361. What are database synonyms and aliases?**</a></li><li><a href="#-362-how-do-you-work-with-database-sequences-and-auto-increment-" class="h2-link">**362. How do you work with database sequences and auto-increment?**</a></li><li><a href="#-363-what-are-database-collations-and-character-sets-" class="h2-link">**363. What are database collations and character sets?**</a></li><li><a href="#-364-how-do-you-implement-database-connection-pooling-" class="h2-link">**364. How do you implement database connection pooling?**</a></li><li><a href="#-365-what-are-database-hints-and-optimizer-directives-" class="h2-link">**365. What are database hints and optimizer directives?**</a></li><li><a href="#-366-what-are-database-cursors-and-how-do-you-use-them-" class="h2-link">**366. What are database cursors and how do you use them?**</a></li><li><a href="#-367-what-are-database-packages-and-modules-" class="h2-link">**367. What are database packages and modules?**</a></li><li><a href="#-368-how-do-you-implement-database-auditing-and-compliance-" class="h2-link">**368. How do you implement database auditing and compliance?**</a></li><li><a href="#-369-what-are-database-federation-and-distributed-queries-" class="h2-link">**369. What are database federation and distributed queries?**</a></li><li><a href="#-370-how-do-you-implement-database-monitoring-and-alerting-" class="h2-link">**370. How do you implement database monitoring and alerting?**</a></li><li><a href="#-371-what-are-data-warehousing-concepts-in-mysql-" class="h2-link">**371. What are data warehousing concepts in MySQL?**</a></li><li><a href="#-372-how-do-you-implement-data-archiving-strategies-" class="h2-link">**372. How do you implement data archiving strategies?**</a></li><li><a href="#-373-what-are-data-migration-best-practices-" class="h2-link">**373. What are data migration best practices?**</a></li><li><a href="#-374-how-do-you-implement-data-backup-and-recovery-strategies-" class="h2-link">**374. How do you implement data backup and recovery strategies?**</a></li><li><a href="#-375-what-are-data-quality-management-techniques-" class="h2-link">**375. What are data quality management techniques?**</a></li><li><a href="#-376-how-do-you-implement-data-lineage-tracking-" class="h2-link">**376. How do you implement data lineage tracking?**</a></li><li><a href="#-377-what-are-master-data-management-mdm-principles-" class="h2-link">**377. What are master data management (MDM) principles?**</a></li><li><a href="#-378-how-do-you-implement-data-cataloging-and-metadata-management-" class="h2-link">**378. How do you implement data cataloging and metadata management?**</a></li><li><a href="#-379-what-are-data-governance-frameworks-and-policies-" class="h2-link">**379. What are data governance frameworks and policies?**</a></li><li><a href="#-380-how-do-you-implement-data-privacy-and-gdpr-compliance-" class="h2-link">**380. How do you implement data privacy and GDPR compliance?**</a></li><li><a href="#-381-what-are-data-retention-and-purging-strategies-" class="h2-link">**381. What are data retention and purging strategies?**</a></li><li><a href="#-382-how-do-you-implement-data-masking-and-anonymization-" class="h2-link">**382. How do you implement data masking and anonymization?**</a></li><li><a href="#-383-what-are-data-lake-and-data-warehouse-differences-" class="h2-link">**383. What are data lake and data warehouse differences?**</a></li><li><a href="#-384-how-do-you-handle-real-time-data-processing-" class="h2-link">**384. How do you handle real-time data processing?**</a></li><li><a href="#-385-what-are-data-integration-patterns-and-etl-vs-elt-" class="h2-link">**385. What are data integration patterns and ETL vs ELT?**</a></li><li><a href="#-386-how-do-you-implement-data-versioning-and-change-tracking-" class="h2-link">**386. How do you implement data versioning and change tracking?**</a></li><li><a href="#-387-what-are-data-mesh-and-decentralized-data-architectures-" class="h2-link">**387. What are data mesh and decentralized data architectures?**</a></li>`;
        
        // Initialize theme from localStorage
        const savedTheme = localStorage.getItem('theme') || 'light';
        document.body.setAttribute('data-theme', savedTheme);
        const themeButton = document.getElementById('theme-toggle');
        themeButton.textContent = savedTheme === 'dark' ? '☀️ Light Mode' : '🌙 Dark Mode';
        
        // Set initial theme stylesheets
        const lightTheme = document.getElementById('light-theme');
        const darkTheme = document.getElementById('dark-theme');
        if (savedTheme === 'dark') {
            lightTheme.disabled = true;
            darkTheme.disabled = false;
        } else {
            lightTheme.disabled = false;
            darkTheme.disabled = true;
        }
        
        // Mobile menu functionality
        function toggleMobileMenu() {
            const sidebar = document.getElementById('sidebar');
            const overlay = document.getElementById('mobile-overlay');
            const isOpen = sidebar.classList.contains('mobile-open');
            
            if (isOpen) {
                sidebar.classList.remove('mobile-open');
                overlay.classList.remove('active');
            } else {
                sidebar.classList.add('mobile-open');
                overlay.classList.add('active');
            }
        }
        
        // Theme toggle functionality
        function toggleTheme() {
            const body = document.body;
            const button = document.getElementById('theme-toggle');
            const currentTheme = body.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            body.setAttribute('data-theme', newTheme);
            button.textContent = newTheme === 'dark' ? '☀️ Light Mode' : '🌙 Dark Mode';
            localStorage.setItem('theme', newTheme);
            
            const lightTheme = document.getElementById('light-theme');
            const darkTheme = document.getElementById('dark-theme');
            if (newTheme === 'dark') {
                lightTheme.disabled = true;
                darkTheme.disabled = false;
            } else {
                lightTheme.disabled = false;
                darkTheme.disabled = true;
            }
            
            // Re-highlight code after theme change
            setTimeout(() => {
                if (typeof Prism !== 'undefined') {
                    Prism.highlightAll();
                }
            }, 100);
        }
        
        // Copy code functionality
        function copyCode(text, button) {
            // Modern clipboard API
            if (navigator.clipboard && navigator.clipboard.writeText) {
                navigator.clipboard.writeText(text).then(() => {
                    button.textContent = 'Copied!';
                    button.style.background = '#10b981';
                    setTimeout(() => {
                        button.textContent = 'Copy';
                        button.style.background = 'var(--accent-color)';
                    }, 2000);
                }).catch(() => {
                    fallbackCopyTextToClipboard(text, button);
                });
            } else {
                fallbackCopyTextToClipboard(text, button);
            }
        }
        
        // Fallback copy function for older browsers
        function fallbackCopyTextToClipboard(text, button) {
            const textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-999999px";
            textArea.style.top = "-999999px";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            try {
                const successful = document.execCommand('copy');
                if (successful) {
                    button.textContent = 'Copied!';
                    button.style.background = '#10b981';
                    setTimeout(() => {
                        button.textContent = 'Copy';
                        button.style.background = 'var(--accent-color)';
                    }, 2000);
                } else {
                    throw new Error('Copy command failed');
                }
            } catch (err) {
                console.error('Copy failed:', err);
                button.textContent = 'Copy failed';
                button.style.background = '#ef4444';
                setTimeout(() => {
                    button.textContent = 'Copy';
                    button.style.background = 'var(--accent-color)';
                }, 2000);
            } finally {
                document.body.removeChild(textArea);
            }
        }
        
        // Event listeners
        document.addEventListener('DOMContentLoaded', function() {
            // Mobile menu button
            const mobileMenuBtn = document.getElementById('mobile-menu-btn');
            if (mobileMenuBtn) {
                mobileMenuBtn.addEventListener('click', toggleMobileMenu);
            }
            
            // Theme toggle button
            const themeToggleBtn = document.getElementById('theme-toggle');
            if (themeToggleBtn) {
                themeToggleBtn.addEventListener('click', toggleTheme);
            }
            
            // Copy buttons
            document.addEventListener('click', function(e) {
                if (e.target.classList.contains('copy-btn')) {
                    const encodedCode = e.target.getAttribute('data-code');
                    if (encodedCode) {
                        const code = decodeURIComponent(encodedCode);
                        copyCode(code, e.target);
                    }
                }
            });
            
            // Overlay and TOC link clicks
            const overlay = document.getElementById('mobile-overlay');
            if (overlay) {
                overlay.addEventListener('click', function() {
                    const sidebar = document.getElementById('sidebar');
                    sidebar.classList.remove('mobile-open');
                    overlay.classList.remove('active');
                });
            }
            
            // TOC links
            document.addEventListener('click', function(e) {
                if (e.target.matches('.toc a')) {
                    const sidebar = document.getElementById('sidebar');
                    const overlay = document.getElementById('mobile-overlay');
                    sidebar.classList.remove('mobile-open');
                    overlay.classList.remove('active');
                }
            });
            
            // Highlight code after page load
            setTimeout(() => {
                if (typeof Prism !== 'undefined') {
                    Prism.highlightAll();
                }
            }, 500);
        });

        

    </script>
    <script src="../sidebar-fix.js"></script>
</body>
</html>